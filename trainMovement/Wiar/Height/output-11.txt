['train-height-11.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
170 34
170 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
170 38
170 39
170 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
165 71
2_165_50_11_csi_a11_29.dat
165 73
165 74
165 75
165 76
165 77
165 78
2_165_50_11_csi_a11_19.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
2_165_50_11_csi_a11_6.dat
165 96
2_165_50_11_csi_a11_28.dat
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
1_175_70_11_csi_a11_29.dat
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
180 135
180 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
180 141
1_180_85_11_csi_a11_28.dat
180 143
180 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
180 150
180 151
180 152
180 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
180 161
180 162
180 163
180 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
180 167
1_180_75_11_csi_a11_21.dat
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
180 177
180 178
180 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
180 182
1_180_75_11_csi_a11_16.dat
180 184
180 185
180 186
180 187
180 188
180 189
180 190
1_173_85_11_csi_a11_22.dat
173 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
173 197
173 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
173 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
173 204
1_173_85_11_csi_a11_2.dat
173 206
1_173_85_11_csi_a11_24.dat
173 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
173 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173
 173 173 173 173 173]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 1s - loss: 0.4980 - mae: 0.6164 - mse: 0.4980
64/93 [===================>..........] - ETA: 0s - loss: 0.4099 - mae: 0.5513 - mse: 0.4099
93/93 [==============================] - 1s 11ms/step - loss: 0.3447 - mae: 0.4969 - mse: 0.3447 - val_loss: 0.2047 - val_mae: 0.3867 - val_mse: 0.2047
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1624 - mae: 0.3429 - mse: 0.1624
64/93 [===================>..........] - ETA: 0s - loss: 0.1670 - mae: 0.3548 - mse: 0.1670
93/93 [==============================] - 1s 8ms/step - loss: 0.1644 - mae: 0.3473 - mse: 0.1644 - val_loss: 0.1592 - val_mae: 0.3617 - val_mse: 0.1592
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1648 - mae: 0.3412 - mse: 0.1648
64/93 [===================>..........] - ETA: 0s - loss: 0.1644 - mae: 0.3470 - mse: 0.1644
93/93 [==============================] - 1s 8ms/step - loss: 0.1544 - mae: 0.3393 - mse: 0.1544 - val_loss: 0.1476 - val_mae: 0.3444 - val_mse: 0.1476
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1030 - mae: 0.2940 - mse: 0.1030
64/93 [===================>..........] - ETA: 0s - loss: 0.1226 - mae: 0.3167 - mse: 0.1226
93/93 [==============================] - 1s 8ms/step - loss: 0.1163 - mae: 0.3016 - mse: 0.1163 - val_loss: 0.1675 - val_mae: 0.3365 - val_mse: 0.1675
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0955 - mae: 0.2491 - mse: 0.0955
64/93 [===================>..........] - ETA: 0s - loss: 0.0906 - mae: 0.2505 - mse: 0.0906
93/93 [==============================] - 1s 7ms/step - loss: 0.1103 - mae: 0.2747 - mse: 0.1103 - val_loss: 0.1757 - val_mae: 0.3456 - val_mse: 0.1757
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1154 - mae: 0.2835 - mse: 0.1154
64/93 [===================>..........] - ETA: 0s - loss: 0.1030 - mae: 0.2717 - mse: 0.1030
93/93 [==============================] - 1s 8ms/step - loss: 0.0963 - mae: 0.2540 - mse: 0.0963 - val_loss: 0.1439 - val_mae: 0.3031 - val_mse: 0.1439
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1003 - mae: 0.2563 - mse: 0.1003
64/93 [===================>..........] - ETA: 0s - loss: 0.0799 - mae: 0.2184 - mse: 0.0799
93/93 [==============================] - 1s 8ms/step - loss: 0.0872 - mae: 0.2342 - mse: 0.0872 - val_loss: 0.1277 - val_mae: 0.2733 - val_mse: 0.1277
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0450 - mae: 0.1678 - mse: 0.0450
64/93 [===================>..........] - ETA: 0s - loss: 0.0693 - mae: 0.2026 - mse: 0.0693
93/93 [==============================] - 1s 6ms/step - loss: 0.0684 - mae: 0.2065 - mse: 0.0684 - val_loss: 0.1390 - val_mae: 0.2816 - val_mse: 0.1390
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0646 - mae: 0.2045 - mse: 0.0646
64/93 [===================>..........] - ETA: 0s - loss: 0.0711 - mae: 0.2069 - mse: 0.0711
93/93 [==============================] - 1s 6ms/step - loss: 0.0741 - mae: 0.2123 - mse: 0.0741 - val_loss: 0.1696 - val_mae: 0.3262 - val_mse: 0.1696
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1083 - mae: 0.2438 - mse: 0.1083
64/93 [===================>..........] - ETA: 0s - loss: 0.0656 - mae: 0.1865 - mse: 0.0656
93/93 [==============================] - 1s 7ms/step - loss: 0.0679 - mae: 0.1901 - mse: 0.0679 - val_loss: 0.1671 - val_mae: 0.3152 - val_mse: 0.1671
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0898 - mae: 0.2233 - mse: 0.0898
64/93 [===================>..........] - ETA: 0s - loss: 0.0574 - mae: 0.1785 - mse: 0.0574
93/93 [==============================] - 1s 8ms/step - loss: 0.0627 - mae: 0.1808 - mse: 0.0627 - val_loss: 0.1567 - val_mae: 0.2923 - val_mse: 0.1567
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0536 - mae: 0.1729 - mse: 0.0536
64/93 [===================>..........] - ETA: 0s - loss: 0.0675 - mae: 0.1888 - mse: 0.0675
93/93 [==============================] - 1s 7ms/step - loss: 0.0614 - mae: 0.1836 - mse: 0.0614 - val_loss: 0.1412 - val_mae: 0.2606 - val_mse: 0.1412
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0994 - mae: 0.2287 - mse: 0.0994
64/93 [===================>..........] - ETA: 0s - loss: 0.0734 - mae: 0.1921 - mse: 0.0734
93/93 [==============================] - 1s 6ms/step - loss: 0.0611 - mae: 0.1753 - mse: 0.0611 - val_loss: 0.1508 - val_mae: 0.2869 - val_mse: 0.1508
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0793 - mae: 0.2175 - mse: 0.0793
64/93 [===================>..........] - ETA: 0s - loss: 0.0601 - mae: 0.1831 - mse: 0.0601
93/93 [==============================] - 1s 7ms/step - loss: 0.0571 - mae: 0.1782 - mse: 0.0571 - val_loss: 0.1539 - val_mae: 0.3010 - val_mse: 0.1539
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0279 - mae: 0.1320 - mse: 0.0279
64/93 [===================>..........] - ETA: 0s - loss: 0.0586 - mae: 0.1753 - mse: 0.0586
93/93 [==============================] - 1s 7ms/step - loss: 0.0593 - mae: 0.1734 - mse: 0.0593 - val_loss: 0.1340 - val_mae: 0.2727 - val_mse: 0.1340
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0708 - mae: 0.2009 - mse: 0.0708
64/93 [===================>..........] - ETA: 0s - loss: 0.0595 - mae: 0.1828 - mse: 0.0595
93/93 [==============================] - 1s 6ms/step - loss: 0.0509 - mae: 0.1737 - mse: 0.0509 - val_loss: 0.1158 - val_mae: 0.2496 - val_mse: 0.1158
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0627 - mae: 0.1995 - mse: 0.0627
64/93 [===================>..........] - ETA: 0s - loss: 0.0565 - mae: 0.1853 - mse: 0.0565
93/93 [==============================] - 1s 7ms/step - loss: 0.0568 - mae: 0.1824 - mse: 0.0568 - val_loss: 0.1315 - val_mae: 0.2851 - val_mse: 0.1315
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0389 - mae: 0.1476 - mse: 0.0389
64/93 [===================>..........] - ETA: 0s - loss: 0.0432 - mae: 0.1585 - mse: 0.0432
93/93 [==============================] - 1s 7ms/step - loss: 0.0500 - mae: 0.1685 - mse: 0.0500 - val_loss: 0.1322 - val_mae: 0.2874 - val_mse: 0.1322
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0445 - mae: 0.1737 - mse: 0.0445
64/93 [===================>..........] - ETA: 0s - loss: 0.0426 - mae: 0.1621 - mse: 0.0426
93/93 [==============================] - 1s 6ms/step - loss: 0.0447 - mae: 0.1620 - mse: 0.0447 - val_loss: 0.0897 - val_mae: 0.2036 - val_mse: 0.0897
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0405 - mae: 0.1680 - mse: 0.0405
64/93 [===================>..........] - ETA: 0s - loss: 0.0512 - mae: 0.1825 - mse: 0.0512
93/93 [==============================] - 1s 6ms/step - loss: 0.0502 - mae: 0.1763 - mse: 0.0502 - val_loss: 0.1077 - val_mae: 0.2411 - val_mse: 0.1077
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0443 - mae: 0.1501 - mse: 0.0443
64/93 [===================>..........] - ETA: 0s - loss: 0.0412 - mae: 0.1461 - mse: 0.0412
93/93 [==============================] - 1s 8ms/step - loss: 0.0408 - mae: 0.1477 - mse: 0.0408 - val_loss: 0.1260 - val_mae: 0.2713 - val_mse: 0.1260
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0442 - mae: 0.1736 - mse: 0.0442
64/93 [===================>..........] - ETA: 0s - loss: 0.0469 - mae: 0.1660 - mse: 0.0469
93/93 [==============================] - 1s 7ms/step - loss: 0.0414 - mae: 0.1580 - mse: 0.0414 - val_loss: 0.1134 - val_mae: 0.2471 - val_mse: 0.1134
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0307 - mae: 0.1265 - mse: 0.0307
64/93 [===================>..........] - ETA: 0s - loss: 0.0367 - mae: 0.1348 - mse: 0.0367
93/93 [==============================] - 1s 6ms/step - loss: 0.0329 - mae: 0.1269 - mse: 0.0329 - val_loss: 0.1046 - val_mae: 0.2251 - val_mse: 0.1046
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0477 - mae: 0.1698 - mse: 0.0477
64/93 [===================>..........] - ETA: 0s - loss: 0.0431 - mae: 0.1547 - mse: 0.0431
93/93 [==============================] - 1s 7ms/step - loss: 0.0363 - mae: 0.1446 - mse: 0.0363 - val_loss: 0.0969 - val_mae: 0.2139 - val_mse: 0.0969
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0307 - mae: 0.1323 - mse: 0.0307
64/93 [===================>..........] - ETA: 0s - loss: 0.0347 - mae: 0.1339 - mse: 0.0347
93/93 [==============================] - 1s 7ms/step - loss: 0.0309 - mae: 0.1271 - mse: 0.0309 - val_loss: 0.1172 - val_mae: 0.2561 - val_mse: 0.1172
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0300 - mae: 0.1354 - mse: 0.0300
64/93 [===================>..........] - ETA: 0s - loss: 0.0360 - mae: 0.1424 - mse: 0.0360
93/93 [==============================] - 1s 7ms/step - loss: 0.0344 - mae: 0.1393 - mse: 0.0344 - val_loss: 0.1029 - val_mae: 0.2373 - val_mse: 0.1029
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0158 - mae: 0.0981 - mse: 0.0158
64/93 [===================>..........] - ETA: 0s - loss: 0.0207 - mae: 0.1109 - mse: 0.0207
93/93 [==============================] - 1s 7ms/step - loss: 0.0248 - mae: 0.1163 - mse: 0.0248 - val_loss: 0.0818 - val_mae: 0.1976 - val_mse: 0.0818
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0306 - mae: 0.1313 - mse: 0.0306
64/93 [===================>..........] - ETA: 0s - loss: 0.0265 - mae: 0.1236 - mse: 0.0265
93/93 [==============================] - 1s 6ms/step - loss: 0.0305 - mae: 0.1346 - mse: 0.0305 - val_loss: 0.0889 - val_mae: 0.2019 - val_mse: 0.0889
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0419 - mae: 0.1466 - mse: 0.0419
64/93 [===================>..........] - ETA: 0s - loss: 0.0337 - mae: 0.1306 - mse: 0.0337
93/93 [==============================] - 1s 6ms/step - loss: 0.0300 - mae: 0.1252 - mse: 0.0300 - val_loss: 0.1134 - val_mae: 0.2469 - val_mse: 0.1134
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0260 - mae: 0.1297 - mse: 0.0260
64/93 [===================>..........] - ETA: 0s - loss: 0.0240 - mae: 0.1183 - mse: 0.0240
93/93 [==============================] - 1s 7ms/step - loss: 0.0303 - mae: 0.1275 - mse: 0.0303 - val_loss: 0.0894 - val_mae: 0.1904 - val_mse: 0.0894
Saving trained model...
89
Testing...
heightdiff= [0.         0.         0.         0.         0.         4.27026367]
average prediction= [2.6734157]
baseline= 6.796296296296297
eachuser= [0. 0. 0. 0. 0. 4.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.06756591796875
['train-height-11.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
170 34
170 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
170 38
170 39
170 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
165 71
2_165_50_11_csi_a11_29.dat
165 73
165 74
165 75
165 76
165 77
165 78
2_165_50_11_csi_a11_19.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
2_165_50_11_csi_a11_6.dat
165 96
2_165_50_11_csi_a11_28.dat
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
1_175_70_11_csi_a11_29.dat
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
180 135
180 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
180 141
1_180_85_11_csi_a11_28.dat
180 143
180 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
180 150
180 151
180 152
180 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
180 161
180 162
180 163
180 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
180 167
1_180_75_11_csi_a11_21.dat
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
180 177
180 178
180 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
180 182
1_180_75_11_csi_a11_16.dat
180 184
180 185
180 186
180 187
180 188
180 189
180 190
1_173_85_11_csi_a11_22.dat
173 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
173 197
173 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
173 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
173 204
1_173_85_11_csi_a11_2.dat
173 206
1_173_85_11_csi_a11_24.dat
173 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
173 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173
 173 173 173 173 173]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 1s - loss: 0.4400 - mae: 0.5558 - mse: 0.4400
64/93 [===================>..........] - ETA: 0s - loss: 0.3809 - mae: 0.5154 - mse: 0.3809
93/93 [==============================] - 1s 12ms/step - loss: 0.3450 - mae: 0.4990 - mse: 0.3450 - val_loss: 0.1899 - val_mae: 0.3949 - val_mse: 0.1899
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1600 - mae: 0.3779 - mse: 0.1600
64/93 [===================>..........] - ETA: 0s - loss: 0.1678 - mae: 0.3718 - mse: 0.1678
93/93 [==============================] - 1s 7ms/step - loss: 0.1572 - mae: 0.3480 - mse: 0.1572 - val_loss: 0.1146 - val_mae: 0.2748 - val_mse: 0.1146
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1729 - mae: 0.3225 - mse: 0.1729
64/93 [===================>..........] - ETA: 0s - loss: 0.1608 - mae: 0.2961 - mse: 0.1608
93/93 [==============================] - 1s 7ms/step - loss: 0.1549 - mae: 0.2977 - mse: 0.1549 - val_loss: 0.0918 - val_mae: 0.2540 - val_mse: 0.0918
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1300 - mae: 0.2910 - mse: 0.1300
64/93 [===================>..........] - ETA: 0s - loss: 0.1222 - mae: 0.2796 - mse: 0.1222
93/93 [==============================] - 1s 6ms/step - loss: 0.1264 - mae: 0.2914 - mse: 0.1264 - val_loss: 0.0892 - val_mae: 0.2579 - val_mse: 0.0892
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0950 - mae: 0.2587 - mse: 0.0950
64/93 [===================>..........] - ETA: 0s - loss: 0.1007 - mae: 0.2686 - mse: 0.1007
93/93 [==============================] - 1s 7ms/step - loss: 0.1072 - mae: 0.2755 - mse: 0.1072 - val_loss: 0.0907 - val_mae: 0.2632 - val_mse: 0.0907
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0910 - mae: 0.2527 - mse: 0.0910
64/93 [===================>..........] - ETA: 0s - loss: 0.0999 - mae: 0.2656 - mse: 0.0999
93/93 [==============================] - 1s 6ms/step - loss: 0.1012 - mae: 0.2607 - mse: 0.1012 - val_loss: 0.0650 - val_mae: 0.2208 - val_mse: 0.0650
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0848 - mae: 0.2383 - mse: 0.0848
64/93 [===================>..........] - ETA: 0s - loss: 0.0777 - mae: 0.2303 - mse: 0.0777
93/93 [==============================] - 1s 6ms/step - loss: 0.0833 - mae: 0.2309 - mse: 0.0833 - val_loss: 0.0411 - val_mae: 0.1648 - val_mse: 0.0411
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0819 - mae: 0.2339 - mse: 0.0819
64/93 [===================>..........] - ETA: 0s - loss: 0.0796 - mae: 0.2296 - mse: 0.0796
93/93 [==============================] - 1s 7ms/step - loss: 0.0814 - mae: 0.2339 - mse: 0.0814 - val_loss: 0.0373 - val_mae: 0.1541 - val_mse: 0.0373
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0695 - mae: 0.2153 - mse: 0.0695
64/93 [===================>..........] - ETA: 0s - loss: 0.0611 - mae: 0.2074 - mse: 0.0611
93/93 [==============================] - 1s 7ms/step - loss: 0.0687 - mae: 0.2136 - mse: 0.0687 - val_loss: 0.0301 - val_mae: 0.1455 - val_mse: 0.0301
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0941 - mae: 0.2304 - mse: 0.0941
64/93 [===================>..........] - ETA: 0s - loss: 0.0715 - mae: 0.2074 - mse: 0.0715
93/93 [==============================] - 1s 7ms/step - loss: 0.0688 - mae: 0.2022 - mse: 0.0688 - val_loss: 0.0359 - val_mae: 0.1652 - val_mse: 0.0359
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0493 - mae: 0.1835 - mse: 0.0493
64/93 [===================>..........] - ETA: 0s - loss: 0.0555 - mae: 0.1855 - mse: 0.0555
93/93 [==============================] - 1s 7ms/step - loss: 0.0614 - mae: 0.1904 - mse: 0.0614 - val_loss: 0.0358 - val_mae: 0.1642 - val_mse: 0.0358
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0788 - mae: 0.2215 - mse: 0.0788
64/93 [===================>..........] - ETA: 0s - loss: 0.0665 - mae: 0.2018 - mse: 0.0665
93/93 [==============================] - 1s 7ms/step - loss: 0.0621 - mae: 0.1899 - mse: 0.0621 - val_loss: 0.0216 - val_mae: 0.1337 - val_mse: 0.0216
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0418 - mae: 0.1498 - mse: 0.0418
64/93 [===================>..........] - ETA: 0s - loss: 0.0480 - mae: 0.1669 - mse: 0.0480
93/93 [==============================] - 1s 7ms/step - loss: 0.0506 - mae: 0.1755 - mse: 0.0506 - val_loss: 0.0173 - val_mae: 0.1195 - val_mse: 0.0173
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0515 - mae: 0.1769 - mse: 0.0515
64/93 [===================>..........] - ETA: 0s - loss: 0.0509 - mae: 0.1719 - mse: 0.0509
93/93 [==============================] - 1s 6ms/step - loss: 0.0481 - mae: 0.1695 - mse: 0.0481 - val_loss: 0.0163 - val_mae: 0.1186 - val_mse: 0.0163
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0237 - mae: 0.1291 - mse: 0.0237
64/93 [===================>..........] - ETA: 0s - loss: 0.0370 - mae: 0.1531 - mse: 0.0370
93/93 [==============================] - 1s 6ms/step - loss: 0.0399 - mae: 0.1555 - mse: 0.0399 - val_loss: 0.0223 - val_mae: 0.1263 - val_mse: 0.0223
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0373 - mae: 0.1354 - mse: 0.0373
64/93 [===================>..........] - ETA: 0s - loss: 0.0330 - mae: 0.1314 - mse: 0.0330
93/93 [==============================] - 1s 7ms/step - loss: 0.0419 - mae: 0.1412 - mse: 0.0419 - val_loss: 0.0209 - val_mae: 0.1198 - val_mse: 0.0209
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0490 - mae: 0.1380 - mse: 0.0490
64/93 [===================>..........] - ETA: 0s - loss: 0.0361 - mae: 0.1264 - mse: 0.0361
93/93 [==============================] - 1s 6ms/step - loss: 0.0325 - mae: 0.1247 - mse: 0.0325 - val_loss: 0.0093 - val_mae: 0.0827 - val_mse: 0.0093
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0208 - mae: 0.1048 - mse: 0.0208
64/93 [===================>..........] - ETA: 0s - loss: 0.0262 - mae: 0.1221 - mse: 0.0262
93/93 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.1219 - mse: 0.0281 - val_loss: 0.0096 - val_mae: 0.0824 - val_mse: 0.0096
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0410 - mae: 0.1463 - mse: 0.0410
64/93 [===================>..........] - ETA: 0s - loss: 0.0356 - mae: 0.1431 - mse: 0.0356
93/93 [==============================] - 1s 7ms/step - loss: 0.0264 - mae: 0.1169 - mse: 0.0264 - val_loss: 0.0236 - val_mae: 0.1365 - val_mse: 0.0236
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0254 - mae: 0.1344 - mse: 0.0254
64/93 [===================>..........] - ETA: 0s - loss: 0.0364 - mae: 0.1486 - mse: 0.0364
93/93 [==============================] - 1s 6ms/step - loss: 0.0333 - mae: 0.1432 - mse: 0.0333 - val_loss: 0.0176 - val_mae: 0.1172 - val_mse: 0.0176
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0323 - mae: 0.1322 - mse: 0.0323
64/93 [===================>..........] - ETA: 0s - loss: 0.0283 - mae: 0.1275 - mse: 0.0283
93/93 [==============================] - 1s 6ms/step - loss: 0.0264 - mae: 0.1271 - mse: 0.0264 - val_loss: 0.0097 - val_mae: 0.0739 - val_mse: 0.0097
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0334 - mae: 0.1335 - mse: 0.0334
64/93 [===================>..........] - ETA: 0s - loss: 0.0227 - mae: 0.1108 - mse: 0.0227
93/93 [==============================] - 0s 5ms/step - loss: 0.0270 - mae: 0.1176 - mse: 0.0270 - val_loss: 0.0268 - val_mae: 0.1447 - val_mse: 0.0268
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0227 - mae: 0.1159 - mse: 0.0227
64/93 [===================>..........] - ETA: 0s - loss: 0.0351 - mae: 0.1374 - mse: 0.0351
93/93 [==============================] - 0s 5ms/step - loss: 0.0316 - mae: 0.1286 - mse: 0.0316 - val_loss: 0.0269 - val_mae: 0.1416 - val_mse: 0.0269
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0271 - mae: 0.1310 - mse: 0.0271
64/93 [===================>..........] - ETA: 0s - loss: 0.0336 - mae: 0.1310 - mse: 0.0336
93/93 [==============================] - 0s 5ms/step - loss: 0.0359 - mae: 0.1332 - mse: 0.0359 - val_loss: 0.0169 - val_mae: 0.1051 - val_mse: 0.0169
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0311 - mae: 0.1255 - mse: 0.0311
64/93 [===================>..........] - ETA: 0s - loss: 0.0212 - mae: 0.1070 - mse: 0.0212
93/93 [==============================] - 0s 5ms/step - loss: 0.0228 - mae: 0.1123 - mse: 0.0228 - val_loss: 0.0233 - val_mae: 0.1318 - val_mse: 0.0233
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0274 - mae: 0.1171 - mse: 0.0274
64/93 [===================>..........] - ETA: 0s - loss: 0.0272 - mae: 0.1125 - mse: 0.0272
93/93 [==============================] - 0s 5ms/step - loss: 0.0266 - mae: 0.1117 - mse: 0.0266 - val_loss: 0.0404 - val_mae: 0.1752 - val_mse: 0.0404
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0113 - mae: 0.0802 - mse: 0.0113
64/93 [===================>..........] - ETA: 0s - loss: 0.0269 - mae: 0.1114 - mse: 0.0269
93/93 [==============================] - 0s 4ms/step - loss: 0.0234 - mae: 0.1055 - mse: 0.0234 - val_loss: 0.0260 - val_mae: 0.1375 - val_mse: 0.0260
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0280 - mae: 0.1162 - mse: 0.0280
64/93 [===================>..........] - ETA: 0s - loss: 0.0178 - mae: 0.0877 - mse: 0.0178
93/93 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0930 - mse: 0.0180 - val_loss: 0.0093 - val_mae: 0.0738 - val_mse: 0.0093
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0127 - mae: 0.0953 - mse: 0.0127
64/93 [===================>..........] - ETA: 0s - loss: 0.0217 - mae: 0.1134 - mse: 0.0217
93/93 [==============================] - 0s 4ms/step - loss: 0.0237 - mae: 0.1155 - mse: 0.0237 - val_loss: 0.0175 - val_mae: 0.1104 - val_mse: 0.0175
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0298 - mae: 0.1205 - mse: 0.0298
64/93 [===================>..........] - ETA: 0s - loss: 0.0196 - mae: 0.0951 - mse: 0.0196
93/93 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0949 - mse: 0.0181 - val_loss: 0.0395 - val_mae: 0.1741 - val_mse: 0.0395
Saving trained model...
89
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         12.25926208]
average prediction= [5.3408856]
baseline= 7.87037037037037
eachuser= [0. 0. 0. 0. 0. 5.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 2.4518524169921876
['train-height-11.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
170 34
170 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
170 38
170 39
170 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
165 71
2_165_50_11_csi_a11_29.dat
165 73
165 74
165 75
165 76
165 77
165 78
2_165_50_11_csi_a11_19.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
2_165_50_11_csi_a11_6.dat
165 96
2_165_50_11_csi_a11_28.dat
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
1_175_70_11_csi_a11_29.dat
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
180 135
180 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
180 141
1_180_85_11_csi_a11_28.dat
180 143
180 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
180 150
180 151
180 152
180 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
180 161
180 162
180 163
180 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
180 167
1_180_75_11_csi_a11_21.dat
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
180 177
180 178
180 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
180 182
1_180_75_11_csi_a11_16.dat
180 184
180 185
180 186
180 187
180 188
180 189
180 190
1_173_85_11_csi_a11_22.dat
173 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
173 197
173 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
173 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
173 204
1_173_85_11_csi_a11_2.dat
173 206
1_173_85_11_csi_a11_24.dat
173 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
173 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173
 173 173 173 173 173]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.4097 - mae: 0.5326 - mse: 0.4097
64/93 [===================>..........] - ETA: 0s - loss: 0.3995 - mae: 0.5264 - mse: 0.3995
93/93 [==============================] - 1s 8ms/step - loss: 0.4196 - mae: 0.5463 - mse: 0.4196 - val_loss: 0.2755 - val_mae: 0.4399 - val_mse: 0.2755
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.3570 - mae: 0.5213 - mse: 0.3570
64/93 [===================>..........] - ETA: 0s - loss: 0.2911 - mae: 0.4613 - mse: 0.2911
93/93 [==============================] - 0s 5ms/step - loss: 0.2674 - mae: 0.4457 - mse: 0.2674 - val_loss: 0.1531 - val_mae: 0.3302 - val_mse: 0.1531
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.2073 - mae: 0.4253 - mse: 0.2073
64/93 [===================>..........] - ETA: 0s - loss: 0.1949 - mae: 0.4095 - mse: 0.1949
93/93 [==============================] - 0s 5ms/step - loss: 0.1835 - mae: 0.3887 - mse: 0.1835 - val_loss: 0.1560 - val_mae: 0.3494 - val_mse: 0.1560
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.2076 - mae: 0.4045 - mse: 0.2076
64/93 [===================>..........] - ETA: 0s - loss: 0.1882 - mae: 0.3755 - mse: 0.1882
93/93 [==============================] - 0s 5ms/step - loss: 0.1893 - mae: 0.3805 - mse: 0.1893 - val_loss: 0.1157 - val_mae: 0.3084 - val_mse: 0.1157
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1825 - mae: 0.4026 - mse: 0.1825
64/93 [===================>..........] - ETA: 0s - loss: 0.1571 - mae: 0.3540 - mse: 0.1571
93/93 [==============================] - 0s 4ms/step - loss: 0.1487 - mae: 0.3386 - mse: 0.1487 - val_loss: 0.0918 - val_mae: 0.2706 - val_mse: 0.0918
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1272 - mae: 0.3203 - mse: 0.1272
64/93 [===================>..........] - ETA: 0s - loss: 0.1290 - mae: 0.3178 - mse: 0.1290
93/93 [==============================] - 0s 5ms/step - loss: 0.1249 - mae: 0.3075 - mse: 0.1249 - val_loss: 0.0782 - val_mae: 0.2409 - val_mse: 0.0782
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1162 - mae: 0.2977 - mse: 0.1162
64/93 [===================>..........] - ETA: 0s - loss: 0.1150 - mae: 0.2914 - mse: 0.1150
93/93 [==============================] - 0s 5ms/step - loss: 0.1157 - mae: 0.2951 - mse: 0.1157 - val_loss: 0.0585 - val_mae: 0.2121 - val_mse: 0.0585
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0855 - mae: 0.2416 - mse: 0.0855
64/93 [===================>..........] - ETA: 0s - loss: 0.0966 - mae: 0.2648 - mse: 0.0966
93/93 [==============================] - 0s 5ms/step - loss: 0.0957 - mae: 0.2597 - mse: 0.0957 - val_loss: 0.0388 - val_mae: 0.1766 - val_mse: 0.0388
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0630 - mae: 0.2233 - mse: 0.0630
64/93 [===================>..........] - ETA: 0s - loss: 0.0687 - mae: 0.2276 - mse: 0.0687
93/93 [==============================] - 0s 5ms/step - loss: 0.0786 - mae: 0.2334 - mse: 0.0786 - val_loss: 0.0250 - val_mae: 0.1364 - val_mse: 0.0250
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0569 - mae: 0.2004 - mse: 0.0569
64/93 [===================>..........] - ETA: 0s - loss: 0.0499 - mae: 0.1804 - mse: 0.0499
93/93 [==============================] - 0s 4ms/step - loss: 0.0686 - mae: 0.2107 - mse: 0.0686 - val_loss: 0.0190 - val_mae: 0.1124 - val_mse: 0.0190
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0538 - mae: 0.1794 - mse: 0.0538
64/93 [===================>..........] - ETA: 0s - loss: 0.0783 - mae: 0.2102 - mse: 0.0783
93/93 [==============================] - 0s 4ms/step - loss: 0.0625 - mae: 0.1901 - mse: 0.0625 - val_loss: 0.0264 - val_mae: 0.1443 - val_mse: 0.0264
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0636 - mae: 0.1823 - mse: 0.0636
64/93 [===================>..........] - ETA: 0s - loss: 0.0546 - mae: 0.1766 - mse: 0.0546
93/93 [==============================] - 0s 5ms/step - loss: 0.0652 - mae: 0.1895 - mse: 0.0652 - val_loss: 0.0169 - val_mae: 0.1231 - val_mse: 0.0169
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0746 - mae: 0.1957 - mse: 0.0746
64/93 [===================>..........] - ETA: 0s - loss: 0.0612 - mae: 0.1672 - mse: 0.0612
93/93 [==============================] - 0s 4ms/step - loss: 0.0580 - mae: 0.1711 - mse: 0.0580 - val_loss: 0.0082 - val_mae: 0.0826 - val_mse: 0.0082
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0441 - mae: 0.1488 - mse: 0.0441
64/93 [===================>..........] - ETA: 0s - loss: 0.0519 - mae: 0.1605 - mse: 0.0519
93/93 [==============================] - 0s 5ms/step - loss: 0.0541 - mae: 0.1684 - mse: 0.0541 - val_loss: 0.0081 - val_mae: 0.0843 - val_mse: 0.0081
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0336 - mae: 0.1604 - mse: 0.0336
64/93 [===================>..........] - ETA: 0s - loss: 0.0243 - mae: 0.1266 - mse: 0.0243
93/93 [==============================] - 0s 5ms/step - loss: 0.0561 - mae: 0.1640 - mse: 0.0561 - val_loss: 0.0296 - val_mae: 0.1577 - val_mse: 0.0296
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0596 - mae: 0.1922 - mse: 0.0596
64/93 [===================>..........] - ETA: 0s - loss: 0.0635 - mae: 0.1915 - mse: 0.0635
93/93 [==============================] - 1s 6ms/step - loss: 0.0597 - mae: 0.1824 - mse: 0.0597 - val_loss: 0.0135 - val_mae: 0.1107 - val_mse: 0.0135
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0272 - mae: 0.1226 - mse: 0.0272
64/93 [===================>..........] - ETA: 0s - loss: 0.0376 - mae: 0.1516 - mse: 0.0376
93/93 [==============================] - 1s 7ms/step - loss: 0.0436 - mae: 0.1584 - mse: 0.0436 - val_loss: 0.0028 - val_mae: 0.0455 - val_mse: 0.0028
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0288 - mae: 0.1298 - mse: 0.0288
64/93 [===================>..........] - ETA: 0s - loss: 0.0380 - mae: 0.1428 - mse: 0.0380
93/93 [==============================] - 1s 7ms/step - loss: 0.0441 - mae: 0.1550 - mse: 0.0441 - val_loss: 0.0074 - val_mae: 0.0798 - val_mse: 0.0074
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0365 - mae: 0.1501 - mse: 0.0365
64/93 [===================>..........] - ETA: 0s - loss: 0.0395 - mae: 0.1425 - mse: 0.0395
93/93 [==============================] - 1s 7ms/step - loss: 0.0351 - mae: 0.1377 - mse: 0.0351 - val_loss: 0.0179 - val_mae: 0.1140 - val_mse: 0.0179
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0533 - mae: 0.1595 - mse: 0.0533
64/93 [===================>..........] - ETA: 0s - loss: 0.0335 - mae: 0.1293 - mse: 0.0335
93/93 [==============================] - 1s 7ms/step - loss: 0.0393 - mae: 0.1396 - mse: 0.0393 - val_loss: 0.0113 - val_mae: 0.0859 - val_mse: 0.0113
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0336 - mae: 0.1265 - mse: 0.0336
64/93 [===================>..........] - ETA: 0s - loss: 0.0308 - mae: 0.1258 - mse: 0.0308
93/93 [==============================] - 1s 7ms/step - loss: 0.0324 - mae: 0.1334 - mse: 0.0324 - val_loss: 0.0019 - val_mae: 0.0357 - val_mse: 0.0019
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0353 - mae: 0.1512 - mse: 0.0353
64/93 [===================>..........] - ETA: 0s - loss: 0.0309 - mae: 0.1239 - mse: 0.0309
93/93 [==============================] - 1s 8ms/step - loss: 0.0320 - mae: 0.1261 - mse: 0.0320 - val_loss: 0.0074 - val_mae: 0.0742 - val_mse: 0.0074
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0347 - mae: 0.1308 - mse: 0.0347
64/93 [===================>..........] - ETA: 0s - loss: 0.0271 - mae: 0.1135 - mse: 0.0271
93/93 [==============================] - 1s 8ms/step - loss: 0.0242 - mae: 0.1102 - mse: 0.0242 - val_loss: 0.0126 - val_mae: 0.0993 - val_mse: 0.0126
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0327 - mae: 0.1235 - mse: 0.0327
64/93 [===================>..........] - ETA: 0s - loss: 0.0299 - mae: 0.1199 - mse: 0.0299
93/93 [==============================] - 1s 8ms/step - loss: 0.0282 - mae: 0.1223 - mse: 0.0282 - val_loss: 0.0158 - val_mae: 0.1022 - val_mse: 0.0158
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0388 - mae: 0.1482 - mse: 0.0388
64/93 [===================>..........] - ETA: 0s - loss: 0.0334 - mae: 0.1354 - mse: 0.0334
93/93 [==============================] - 1s 8ms/step - loss: 0.0282 - mae: 0.1229 - mse: 0.0282 - val_loss: 0.0137 - val_mae: 0.1013 - val_mse: 0.0137
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0415 - mae: 0.1441 - mse: 0.0415
64/93 [===================>..........] - ETA: 0s - loss: 0.0264 - mae: 0.1130 - mse: 0.0264
93/93 [==============================] - 1s 8ms/step - loss: 0.0259 - mae: 0.1173 - mse: 0.0259 - val_loss: 0.0167 - val_mae: 0.1179 - val_mse: 0.0167
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0130 - mae: 0.0901 - mse: 0.0130
64/93 [===================>..........] - ETA: 0s - loss: 0.0252 - mae: 0.1093 - mse: 0.0252
93/93 [==============================] - 1s 8ms/step - loss: 0.0209 - mae: 0.0993 - mse: 0.0209 - val_loss: 0.0137 - val_mae: 0.1065 - val_mse: 0.0137
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0164 - mae: 0.0921 - mse: 0.0164
64/93 [===================>..........] - ETA: 0s - loss: 0.0262 - mae: 0.1093 - mse: 0.0262
93/93 [==============================] - 1s 7ms/step - loss: 0.0267 - mae: 0.1163 - mse: 0.0267 - val_loss: 0.0184 - val_mae: 0.1204 - val_mse: 0.0184
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0086 - mae: 0.0753 - mse: 0.0086
64/93 [===================>..........] - ETA: 0s - loss: 0.0149 - mae: 0.0884 - mse: 0.0149
93/93 [==============================] - 1s 8ms/step - loss: 0.0189 - mae: 0.0948 - mse: 0.0189 - val_loss: 0.0255 - val_mae: 0.1428 - val_mse: 0.0255
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0289 - mae: 0.1150 - mse: 0.0289
64/93 [===================>..........] - ETA: 0s - loss: 0.0210 - mae: 0.0982 - mse: 0.0210
93/93 [==============================] - 1s 8ms/step - loss: 0.0204 - mae: 0.0995 - mse: 0.0204 - val_loss: 0.0166 - val_mae: 0.1152 - val_mse: 0.0166
Saving trained model...
89
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         12.50675964]
average prediction= [3.5669577]
baseline= 7.537037037037037
eachuser= [0. 0. 0. 0. 0. 5.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 2.5013519287109376
['train-height-11.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
170 34
170 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
170 38
170 39
170 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
165 71
2_165_50_11_csi_a11_29.dat
165 73
165 74
165 75
165 76
165 77
165 78
2_165_50_11_csi_a11_19.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
2_165_50_11_csi_a11_6.dat
165 96
2_165_50_11_csi_a11_28.dat
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
1_175_70_11_csi_a11_29.dat
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
180 135
180 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
180 141
1_180_85_11_csi_a11_28.dat
180 143
180 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
180 150
180 151
180 152
180 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
180 161
180 162
180 163
180 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
180 167
1_180_75_11_csi_a11_21.dat
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
180 177
180 178
180 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
180 182
1_180_75_11_csi_a11_16.dat
180 184
180 185
180 186
180 187
180 188
180 189
180 190
1_173_85_11_csi_a11_22.dat
173 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
173 197
173 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
173 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
173 204
1_173_85_11_csi_a11_2.dat
173 206
1_173_85_11_csi_a11_24.dat
173 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
173 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173
 173 173 173 173 173]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 1s - loss: 0.5073 - mae: 0.5914 - mse: 0.5073
64/93 [===================>..........] - ETA: 0s - loss: 0.4435 - mae: 0.5576 - mse: 0.4435
93/93 [==============================] - 1s 12ms/step - loss: 0.4299 - mae: 0.5675 - mse: 0.4299 - val_loss: 0.2209 - val_mae: 0.3909 - val_mse: 0.2209
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.2180 - mae: 0.4198 - mse: 0.2180
64/93 [===================>..........] - ETA: 0s - loss: 0.1928 - mae: 0.3915 - mse: 0.1928
93/93 [==============================] - 1s 8ms/step - loss: 0.1803 - mae: 0.3774 - mse: 0.1803 - val_loss: 0.1437 - val_mae: 0.3462 - val_mse: 0.1437
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1177 - mae: 0.2641 - mse: 0.1177
64/93 [===================>..........] - ETA: 0s - loss: 0.1629 - mae: 0.3074 - mse: 0.1629
93/93 [==============================] - 1s 8ms/step - loss: 0.1655 - mae: 0.3135 - mse: 0.1655 - val_loss: 0.1401 - val_mae: 0.3460 - val_mse: 0.1401
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1682 - mae: 0.3272 - mse: 0.1682
64/93 [===================>..........] - ETA: 0s - loss: 0.1604 - mae: 0.3258 - mse: 0.1604
93/93 [==============================] - 1s 8ms/step - loss: 0.1496 - mae: 0.3192 - mse: 0.1496 - val_loss: 0.1134 - val_mae: 0.2846 - val_mse: 0.1134
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1162 - mae: 0.2910 - mse: 0.1162
64/93 [===================>..........] - ETA: 0s - loss: 0.0977 - mae: 0.2660 - mse: 0.0977
93/93 [==============================] - 1s 8ms/step - loss: 0.1004 - mae: 0.2700 - mse: 0.1004 - val_loss: 0.1284 - val_mae: 0.2815 - val_mse: 0.1284
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1118 - mae: 0.2906 - mse: 0.1118
64/93 [===================>..........] - ETA: 0s - loss: 0.1136 - mae: 0.2919 - mse: 0.1136
93/93 [==============================] - 1s 8ms/step - loss: 0.1115 - mae: 0.2886 - mse: 0.1115 - val_loss: 0.1186 - val_mae: 0.2699 - val_mse: 0.1186
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1410 - mae: 0.3133 - mse: 0.1410
64/93 [===================>..........] - ETA: 0s - loss: 0.1204 - mae: 0.2876 - mse: 0.1204
93/93 [==============================] - 1s 8ms/step - loss: 0.1039 - mae: 0.2610 - mse: 0.1039 - val_loss: 0.0955 - val_mae: 0.2477 - val_mse: 0.0955
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0647 - mae: 0.2074 - mse: 0.0647
64/93 [===================>..........] - ETA: 0s - loss: 0.1049 - mae: 0.2557 - mse: 0.1049
93/93 [==============================] - 1s 8ms/step - loss: 0.0952 - mae: 0.2485 - mse: 0.0952 - val_loss: 0.0821 - val_mae: 0.2246 - val_mse: 0.0821
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1187 - mae: 0.2790 - mse: 0.1187
64/93 [===================>..........] - ETA: 0s - loss: 0.1079 - mae: 0.2722 - mse: 0.1079
93/93 [==============================] - 1s 8ms/step - loss: 0.0944 - mae: 0.2548 - mse: 0.0944 - val_loss: 0.0780 - val_mae: 0.2182 - val_mse: 0.0780
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0706 - mae: 0.1871 - mse: 0.0706
64/93 [===================>..........] - ETA: 0s - loss: 0.0824 - mae: 0.2139 - mse: 0.0824
93/93 [==============================] - 1s 7ms/step - loss: 0.0791 - mae: 0.2167 - mse: 0.0791 - val_loss: 0.0788 - val_mae: 0.2131 - val_mse: 0.0788
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0931 - mae: 0.2451 - mse: 0.0931
64/93 [===================>..........] - ETA: 0s - loss: 0.0766 - mae: 0.2201 - mse: 0.0766
93/93 [==============================] - 1s 7ms/step - loss: 0.0768 - mae: 0.2272 - mse: 0.0768 - val_loss: 0.0762 - val_mae: 0.2018 - val_mse: 0.0762
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0483 - mae: 0.1810 - mse: 0.0483
64/93 [===================>..........] - ETA: 0s - loss: 0.0648 - mae: 0.1990 - mse: 0.0648
93/93 [==============================] - 1s 8ms/step - loss: 0.0674 - mae: 0.2041 - mse: 0.0674 - val_loss: 0.0647 - val_mae: 0.1807 - val_mse: 0.0647
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0844 - mae: 0.2155 - mse: 0.0844
64/93 [===================>..........] - ETA: 0s - loss: 0.0680 - mae: 0.2013 - mse: 0.0680
93/93 [==============================] - 1s 8ms/step - loss: 0.0655 - mae: 0.2027 - mse: 0.0655 - val_loss: 0.0579 - val_mae: 0.1662 - val_mse: 0.0579
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0558 - mae: 0.1911 - mse: 0.0558
64/93 [===================>..........] - ETA: 0s - loss: 0.0646 - mae: 0.1993 - mse: 0.0646
93/93 [==============================] - 1s 8ms/step - loss: 0.0659 - mae: 0.2042 - mse: 0.0659 - val_loss: 0.0577 - val_mae: 0.1645 - val_mse: 0.0577
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0428 - mae: 0.1832 - mse: 0.0428
64/93 [===================>..........] - ETA: 0s - loss: 0.0628 - mae: 0.2144 - mse: 0.0628
93/93 [==============================] - 1s 8ms/step - loss: 0.0586 - mae: 0.2035 - mse: 0.0586 - val_loss: 0.0487 - val_mae: 0.1558 - val_mse: 0.0487
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0545 - mae: 0.1920 - mse: 0.0545
64/93 [===================>..........] - ETA: 0s - loss: 0.0409 - mae: 0.1621 - mse: 0.0409
93/93 [==============================] - 1s 8ms/step - loss: 0.0521 - mae: 0.1863 - mse: 0.0521 - val_loss: 0.0441 - val_mae: 0.1537 - val_mse: 0.0441
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0636 - mae: 0.2077 - mse: 0.0636
64/93 [===================>..........] - ETA: 0s - loss: 0.0468 - mae: 0.1732 - mse: 0.0468
93/93 [==============================] - 1s 7ms/step - loss: 0.0504 - mae: 0.1805 - mse: 0.0504 - val_loss: 0.0506 - val_mae: 0.1705 - val_mse: 0.0506
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0408 - mae: 0.1488 - mse: 0.0408
64/93 [===================>..........] - ETA: 0s - loss: 0.0371 - mae: 0.1494 - mse: 0.0371
93/93 [==============================] - 1s 7ms/step - loss: 0.0393 - mae: 0.1559 - mse: 0.0393 - val_loss: 0.0459 - val_mae: 0.1712 - val_mse: 0.0459
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0443 - mae: 0.1600 - mse: 0.0443
64/93 [===================>..........] - ETA: 0s - loss: 0.0354 - mae: 0.1488 - mse: 0.0354
93/93 [==============================] - 1s 7ms/step - loss: 0.0311 - mae: 0.1382 - mse: 0.0311 - val_loss: 0.0373 - val_mae: 0.1584 - val_mse: 0.0373
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0251 - mae: 0.1273 - mse: 0.0251
64/93 [===================>..........] - ETA: 0s - loss: 0.0333 - mae: 0.1399 - mse: 0.0333
93/93 [==============================] - 1s 7ms/step - loss: 0.0314 - mae: 0.1364 - mse: 0.0314 - val_loss: 0.0283 - val_mae: 0.1410 - val_mse: 0.0283
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0240 - mae: 0.1250 - mse: 0.0240
64/93 [===================>..........] - ETA: 0s - loss: 0.0286 - mae: 0.1234 - mse: 0.0286
93/93 [==============================] - 1s 7ms/step - loss: 0.0260 - mae: 0.1202 - mse: 0.0260 - val_loss: 0.0281 - val_mae: 0.1385 - val_mse: 0.0281
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0361 - mae: 0.1394 - mse: 0.0361
64/93 [===================>..........] - ETA: 0s - loss: 0.0290 - mae: 0.1247 - mse: 0.0290
93/93 [==============================] - 1s 8ms/step - loss: 0.0283 - mae: 0.1277 - mse: 0.0283 - val_loss: 0.0302 - val_mae: 0.1399 - val_mse: 0.0302
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0138 - mae: 0.0931 - mse: 0.0138
64/93 [===================>..........] - ETA: 0s - loss: 0.0266 - mae: 0.1173 - mse: 0.0266
93/93 [==============================] - 1s 7ms/step - loss: 0.0255 - mae: 0.1197 - mse: 0.0255 - val_loss: 0.0307 - val_mae: 0.1367 - val_mse: 0.0307
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0184 - mae: 0.1097 - mse: 0.0184
64/93 [===================>..........] - ETA: 0s - loss: 0.0276 - mae: 0.1227 - mse: 0.0276
93/93 [==============================] - 1s 7ms/step - loss: 0.0279 - mae: 0.1266 - mse: 0.0279 - val_loss: 0.0226 - val_mae: 0.1224 - val_mse: 0.0226
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0288 - mae: 0.1261 - mse: 0.0288
64/93 [===================>..........] - ETA: 0s - loss: 0.0350 - mae: 0.1309 - mse: 0.0350
93/93 [==============================] - 1s 8ms/step - loss: 0.0320 - mae: 0.1262 - mse: 0.0320 - val_loss: 0.0234 - val_mae: 0.1244 - val_mse: 0.0234
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0292 - mae: 0.1079 - mse: 0.0292
64/93 [===================>..........] - ETA: 0s - loss: 0.0307 - mae: 0.1165 - mse: 0.0307
93/93 [==============================] - 0s 5ms/step - loss: 0.0267 - mae: 0.1122 - mse: 0.0267 - val_loss: 0.0270 - val_mae: 0.1301 - val_mse: 0.0270
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0186 - mae: 0.0961 - mse: 0.0186
64/93 [===================>..........] - ETA: 0s - loss: 0.0238 - mae: 0.1122 - mse: 0.0238
93/93 [==============================] - 0s 5ms/step - loss: 0.0233 - mae: 0.1121 - mse: 0.0233 - val_loss: 0.0216 - val_mae: 0.1185 - val_mse: 0.0216
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0198 - mae: 0.0942 - mse: 0.0198
64/93 [===================>..........] - ETA: 0s - loss: 0.0213 - mae: 0.0940 - mse: 0.0213
93/93 [==============================] - 1s 5ms/step - loss: 0.0271 - mae: 0.1115 - mse: 0.0271 - val_loss: 0.0246 - val_mae: 0.1283 - val_mse: 0.0246
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0171 - mae: 0.0982 - mse: 0.0171
64/93 [===================>..........] - ETA: 0s - loss: 0.0236 - mae: 0.1084 - mse: 0.0236
93/93 [==============================] - 0s 5ms/step - loss: 0.0232 - mae: 0.1081 - mse: 0.0232 - val_loss: 0.0299 - val_mae: 0.1399 - val_mse: 0.0299
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0251 - mae: 0.1139 - mse: 0.0251
64/93 [===================>..........] - ETA: 0s - loss: 0.0228 - mae: 0.1064 - mse: 0.0228
93/93 [==============================] - 0s 5ms/step - loss: 0.0217 - mae: 0.1085 - mse: 0.0217 - val_loss: 0.0249 - val_mae: 0.1316 - val_mse: 0.0249
Saving trained model...
89
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         20.85708618]
average prediction= [2.9130876]
baseline= 8.018518518518519
eachuser= [0. 0. 0. 0. 0. 6.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 3.4761810302734375
['train-height-11.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
170 34
170 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
170 38
170 39
170 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
165 71
2_165_50_11_csi_a11_29.dat
165 73
165 74
165 75
165 76
165 77
165 78
2_165_50_11_csi_a11_19.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
2_165_50_11_csi_a11_6.dat
165 96
2_165_50_11_csi_a11_28.dat
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
1_175_70_11_csi_a11_29.dat
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
180 135
180 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
180 141
1_180_85_11_csi_a11_28.dat
180 143
180 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
180 150
180 151
180 152
180 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
180 161
180 162
180 163
180 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
180 167
1_180_75_11_csi_a11_21.dat
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
180 177
180 178
180 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
180 182
1_180_75_11_csi_a11_16.dat
180 184
180 185
180 186
180 187
180 188
180 189
180 190
1_173_85_11_csi_a11_22.dat
173 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
173 197
173 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
173 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
173 204
1_173_85_11_csi_a11_2.dat
173 206
1_173_85_11_csi_a11_24.dat
173 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
173 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173
 173 173 173 173 173]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 1s - loss: 0.7969 - mae: 0.8324 - mse: 0.7969
64/93 [===================>..........] - ETA: 0s - loss: 0.6207 - mae: 0.7024 - mse: 0.6207
93/93 [==============================] - 1s 11ms/step - loss: 0.5523 - mae: 0.6674 - mse: 0.5523 - val_loss: 0.3561 - val_mae: 0.5470 - val_mse: 0.3561
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.2931 - mae: 0.4861 - mse: 0.2931
64/93 [===================>..........] - ETA: 0s - loss: 0.2497 - mae: 0.4345 - mse: 0.2497
93/93 [==============================] - 1s 6ms/step - loss: 0.2298 - mae: 0.4227 - mse: 0.2298 - val_loss: 0.1236 - val_mae: 0.3052 - val_mse: 0.1236
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1277 - mae: 0.3024 - mse: 0.1277
64/93 [===================>..........] - ETA: 0s - loss: 0.1744 - mae: 0.3324 - mse: 0.1744
93/93 [==============================] - 1s 6ms/step - loss: 0.1559 - mae: 0.3053 - mse: 0.1559 - val_loss: 0.0992 - val_mae: 0.2236 - val_mse: 0.0992
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1899 - mae: 0.3339 - mse: 0.1899
64/93 [===================>..........] - ETA: 0s - loss: 0.1995 - mae: 0.3382 - mse: 0.1995
93/93 [==============================] - 1s 6ms/step - loss: 0.1829 - mae: 0.3212 - mse: 0.1829 - val_loss: 0.0885 - val_mae: 0.2480 - val_mse: 0.0885
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1683 - mae: 0.3185 - mse: 0.1683
64/93 [===================>..........] - ETA: 0s - loss: 0.1329 - mae: 0.2899 - mse: 0.1329
93/93 [==============================] - 1s 6ms/step - loss: 0.1256 - mae: 0.2846 - mse: 0.1256 - val_loss: 0.1290 - val_mae: 0.3126 - val_mse: 0.1290
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1097 - mae: 0.2747 - mse: 0.1097
64/93 [===================>..........] - ETA: 0s - loss: 0.1024 - mae: 0.2608 - mse: 0.1024
93/93 [==============================] - 1s 6ms/step - loss: 0.1176 - mae: 0.2844 - mse: 0.1176 - val_loss: 0.1581 - val_mae: 0.3608 - val_mse: 0.1581
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1085 - mae: 0.2920 - mse: 0.1085
64/93 [===================>..........] - ETA: 0s - loss: 0.1096 - mae: 0.2776 - mse: 0.1096
93/93 [==============================] - 1s 6ms/step - loss: 0.1065 - mae: 0.2745 - mse: 0.1065 - val_loss: 0.1326 - val_mae: 0.3301 - val_mse: 0.1326
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0912 - mae: 0.2356 - mse: 0.0912
64/93 [===================>..........] - ETA: 0s - loss: 0.0997 - mae: 0.2591 - mse: 0.0997
93/93 [==============================] - 1s 6ms/step - loss: 0.0996 - mae: 0.2552 - mse: 0.0996 - val_loss: 0.0836 - val_mae: 0.2482 - val_mse: 0.0836
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0909 - mae: 0.2472 - mse: 0.0909
64/93 [===================>..........] - ETA: 0s - loss: 0.0798 - mae: 0.2138 - mse: 0.0798
93/93 [==============================] - 1s 6ms/step - loss: 0.0767 - mae: 0.2091 - mse: 0.0767 - val_loss: 0.0561 - val_mae: 0.1732 - val_mse: 0.0561
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0794 - mae: 0.1950 - mse: 0.0794
64/93 [===================>..........] - ETA: 0s - loss: 0.0671 - mae: 0.1872 - mse: 0.0671
93/93 [==============================] - 1s 8ms/step - loss: 0.0851 - mae: 0.2198 - mse: 0.0851 - val_loss: 0.0551 - val_mae: 0.1728 - val_mse: 0.0551
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0960 - mae: 0.2420 - mse: 0.0960
64/93 [===================>..........] - ETA: 0s - loss: 0.0783 - mae: 0.2189 - mse: 0.0783
93/93 [==============================] - 1s 8ms/step - loss: 0.0786 - mae: 0.2251 - mse: 0.0786 - val_loss: 0.0794 - val_mae: 0.2428 - val_mse: 0.0794
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0647 - mae: 0.2034 - mse: 0.0647
64/93 [===================>..........] - ETA: 0s - loss: 0.0735 - mae: 0.2116 - mse: 0.0735
93/93 [==============================] - 1s 8ms/step - loss: 0.0651 - mae: 0.1952 - mse: 0.0651 - val_loss: 0.0999 - val_mae: 0.2821 - val_mse: 0.0999
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0667 - mae: 0.1975 - mse: 0.0667
64/93 [===================>..........] - ETA: 0s - loss: 0.0626 - mae: 0.1895 - mse: 0.0626
93/93 [==============================] - 1s 8ms/step - loss: 0.0677 - mae: 0.2057 - mse: 0.0677 - val_loss: 0.0945 - val_mae: 0.2734 - val_mse: 0.0945
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0651 - mae: 0.1846 - mse: 0.0651
64/93 [===================>..........] - ETA: 0s - loss: 0.0601 - mae: 0.1741 - mse: 0.0601
93/93 [==============================] - 1s 8ms/step - loss: 0.0597 - mae: 0.1811 - mse: 0.0597 - val_loss: 0.0698 - val_mae: 0.2254 - val_mse: 0.0698
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0463 - mae: 0.1542 - mse: 0.0463
64/93 [===================>..........] - ETA: 0s - loss: 0.0618 - mae: 0.1781 - mse: 0.0618
93/93 [==============================] - 1s 8ms/step - loss: 0.0652 - mae: 0.1905 - mse: 0.0652 - val_loss: 0.0556 - val_mae: 0.1902 - val_mse: 0.0556
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0571 - mae: 0.1909 - mse: 0.0571
64/93 [===================>..........] - ETA: 0s - loss: 0.0554 - mae: 0.1874 - mse: 0.0554
93/93 [==============================] - 1s 7ms/step - loss: 0.0632 - mae: 0.1916 - mse: 0.0632 - val_loss: 0.0509 - val_mae: 0.1791 - val_mse: 0.0509
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0693 - mae: 0.2150 - mse: 0.0693
64/93 [===================>..........] - ETA: 0s - loss: 0.0595 - mae: 0.1838 - mse: 0.0595
93/93 [==============================] - 1s 6ms/step - loss: 0.0571 - mae: 0.1801 - mse: 0.0571 - val_loss: 0.0542 - val_mae: 0.1925 - val_mse: 0.0542
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0794 - mae: 0.2158 - mse: 0.0794
64/93 [===================>..........] - ETA: 0s - loss: 0.0675 - mae: 0.2037 - mse: 0.0675
93/93 [==============================] - 1s 6ms/step - loss: 0.0575 - mae: 0.1861 - mse: 0.0575 - val_loss: 0.0600 - val_mae: 0.2104 - val_mse: 0.0600
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0742 - mae: 0.1966 - mse: 0.0742
64/93 [===================>..........] - ETA: 0s - loss: 0.0599 - mae: 0.1846 - mse: 0.0599
93/93 [==============================] - 1s 6ms/step - loss: 0.0557 - mae: 0.1798 - mse: 0.0557 - val_loss: 0.0574 - val_mae: 0.2065 - val_mse: 0.0574
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0660 - mae: 0.1848 - mse: 0.0660
64/93 [===================>..........] - ETA: 0s - loss: 0.0564 - mae: 0.1824 - mse: 0.0564
93/93 [==============================] - 1s 6ms/step - loss: 0.0588 - mae: 0.1894 - mse: 0.0588 - val_loss: 0.0493 - val_mae: 0.1873 - val_mse: 0.0493
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0492 - mae: 0.1684 - mse: 0.0492
64/93 [===================>..........] - ETA: 0s - loss: 0.0428 - mae: 0.1547 - mse: 0.0428
93/93 [==============================] - 1s 6ms/step - loss: 0.0482 - mae: 0.1658 - mse: 0.0482 - val_loss: 0.0406 - val_mae: 0.1667 - val_mse: 0.0406
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0379 - mae: 0.1557 - mse: 0.0379
64/93 [===================>..........] - ETA: 0s - loss: 0.0438 - mae: 0.1639 - mse: 0.0438
93/93 [==============================] - 1s 6ms/step - loss: 0.0405 - mae: 0.1566 - mse: 0.0405 - val_loss: 0.0341 - val_mae: 0.1513 - val_mse: 0.0341
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0316 - mae: 0.1265 - mse: 0.0316
64/93 [===================>..........] - ETA: 0s - loss: 0.0457 - mae: 0.1561 - mse: 0.0457
93/93 [==============================] - 1s 6ms/step - loss: 0.0502 - mae: 0.1713 - mse: 0.0502 - val_loss: 0.0302 - val_mae: 0.1446 - val_mse: 0.0302
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0632 - mae: 0.1781 - mse: 0.0632
64/93 [===================>..........] - ETA: 0s - loss: 0.0497 - mae: 0.1651 - mse: 0.0497
93/93 [==============================] - 1s 6ms/step - loss: 0.0467 - mae: 0.1652 - mse: 0.0467 - val_loss: 0.0385 - val_mae: 0.1742 - val_mse: 0.0385
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0397 - mae: 0.1478 - mse: 0.0397
64/93 [===================>..........] - ETA: 0s - loss: 0.0368 - mae: 0.1487 - mse: 0.0368
93/93 [==============================] - 1s 6ms/step - loss: 0.0360 - mae: 0.1459 - mse: 0.0360 - val_loss: 0.0358 - val_mae: 0.1683 - val_mse: 0.0358
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0253 - mae: 0.1204 - mse: 0.0253
64/93 [===================>..........] - ETA: 0s - loss: 0.0297 - mae: 0.1399 - mse: 0.0297
93/93 [==============================] - 1s 6ms/step - loss: 0.0363 - mae: 0.1482 - mse: 0.0363 - val_loss: 0.0290 - val_mae: 0.1493 - val_mse: 0.0290
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0512 - mae: 0.1816 - mse: 0.0512
64/93 [===================>..........] - ETA: 0s - loss: 0.0383 - mae: 0.1563 - mse: 0.0383
93/93 [==============================] - 1s 6ms/step - loss: 0.0333 - mae: 0.1475 - mse: 0.0333 - val_loss: 0.0184 - val_mae: 0.1105 - val_mse: 0.0184
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0530 - mae: 0.1758 - mse: 0.0530
64/93 [===================>..........] - ETA: 0s - loss: 0.0430 - mae: 0.1536 - mse: 0.0430
93/93 [==============================] - 1s 6ms/step - loss: 0.0346 - mae: 0.1363 - mse: 0.0346 - val_loss: 0.0161 - val_mae: 0.1073 - val_mse: 0.0161
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0247 - mae: 0.1296 - mse: 0.0247
64/93 [===================>..........] - ETA: 0s - loss: 0.0279 - mae: 0.1302 - mse: 0.0279
93/93 [==============================] - 1s 6ms/step - loss: 0.0346 - mae: 0.1355 - mse: 0.0346 - val_loss: 0.0232 - val_mae: 0.1419 - val_mse: 0.0232
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0229 - mae: 0.1058 - mse: 0.0229
64/93 [===================>..........] - ETA: 0s - loss: 0.0312 - mae: 0.1230 - mse: 0.0312
93/93 [==============================] - 1s 6ms/step - loss: 0.0289 - mae: 0.1220 - mse: 0.0289 - val_loss: 0.0232 - val_mae: 0.1420 - val_mse: 0.0232
Saving trained model...
89
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         38.98748779]
average prediction= [3.0275133]
baseline= 11.38888888888889
eachuser= [ 0.  0.  0.  0.  0. 15.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 2.599165852864583
['train-height-11.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
170 34
170 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
170 38
170 39
170 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
165 71
2_165_50_11_csi_a11_29.dat
165 73
165 74
165 75
165 76
165 77
165 78
2_165_50_11_csi_a11_19.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
2_165_50_11_csi_a11_6.dat
165 96
2_165_50_11_csi_a11_28.dat
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
1_175_70_11_csi_a11_29.dat
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
180 135
180 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
180 141
1_180_85_11_csi_a11_28.dat
180 143
180 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
180 150
180 151
180 152
180 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
180 161
180 162
180 163
180 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
180 167
1_180_75_11_csi_a11_21.dat
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
180 177
180 178
180 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
180 182
1_180_75_11_csi_a11_16.dat
180 184
180 185
180 186
180 187
180 188
180 189
180 190
1_173_85_11_csi_a11_22.dat
173 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
173 197
173 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
173 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
173 204
1_173_85_11_csi_a11_2.dat
173 206
1_173_85_11_csi_a11_24.dat
173 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
173 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173
 173 173 173 173 173]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.5287 - mae: 0.6503 - mse: 0.5287
64/93 [===================>..........] - ETA: 0s - loss: 0.4540 - mae: 0.5887 - mse: 0.4540
93/93 [==============================] - 1s 11ms/step - loss: 0.4096 - mae: 0.5688 - mse: 0.4096 - val_loss: 0.2509 - val_mae: 0.4586 - val_mse: 0.2509
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.2823 - mae: 0.5060 - mse: 0.2823
64/93 [===================>..........] - ETA: 0s - loss: 0.2479 - mae: 0.4484 - mse: 0.2479
93/93 [==============================] - 1s 6ms/step - loss: 0.2655 - mae: 0.4591 - mse: 0.2655 - val_loss: 0.1323 - val_mae: 0.2944 - val_mse: 0.1323
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1900 - mae: 0.3571 - mse: 0.1900
64/93 [===================>..........] - ETA: 0s - loss: 0.1973 - mae: 0.3554 - mse: 0.1973
93/93 [==============================] - 1s 5ms/step - loss: 0.2106 - mae: 0.3672 - mse: 0.2106 - val_loss: 0.1051 - val_mae: 0.2662 - val_mse: 0.1051
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1601 - mae: 0.3364 - mse: 0.1601
64/93 [===================>..........] - ETA: 0s - loss: 0.1515 - mae: 0.3366 - mse: 0.1515
93/93 [==============================] - 0s 5ms/step - loss: 0.1530 - mae: 0.3431 - mse: 0.1530 - val_loss: 0.0963 - val_mae: 0.2540 - val_mse: 0.0963
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1391 - mae: 0.3299 - mse: 0.1391
64/93 [===================>..........] - ETA: 0s - loss: 0.1165 - mae: 0.2936 - mse: 0.1165
93/93 [==============================] - 0s 5ms/step - loss: 0.1166 - mae: 0.2955 - mse: 0.1166 - val_loss: 0.0644 - val_mae: 0.2052 - val_mse: 0.0644
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1051 - mae: 0.2757 - mse: 0.1051
64/93 [===================>..........] - ETA: 0s - loss: 0.1026 - mae: 0.2612 - mse: 0.1026
93/93 [==============================] - 0s 5ms/step - loss: 0.0954 - mae: 0.2537 - mse: 0.0954 - val_loss: 0.0384 - val_mae: 0.1642 - val_mse: 0.0384
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0742 - mae: 0.2128 - mse: 0.0742
64/93 [===================>..........] - ETA: 0s - loss: 0.0679 - mae: 0.2093 - mse: 0.0679
93/93 [==============================] - 0s 4ms/step - loss: 0.0795 - mae: 0.2292 - mse: 0.0795 - val_loss: 0.0358 - val_mae: 0.1629 - val_mse: 0.0358
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0864 - mae: 0.2383 - mse: 0.0864
64/93 [===================>..........] - ETA: 0s - loss: 0.0819 - mae: 0.2291 - mse: 0.0819
93/93 [==============================] - 0s 5ms/step - loss: 0.0752 - mae: 0.2210 - mse: 0.0752 - val_loss: 0.0282 - val_mae: 0.1325 - val_mse: 0.0282
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0622 - mae: 0.1754 - mse: 0.0622
64/93 [===================>..........] - ETA: 0s - loss: 0.0672 - mae: 0.1794 - mse: 0.0672
93/93 [==============================] - 1s 5ms/step - loss: 0.0720 - mae: 0.1873 - mse: 0.0720 - val_loss: 0.0251 - val_mae: 0.1242 - val_mse: 0.0251
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0969 - mae: 0.2136 - mse: 0.0969
64/93 [===================>..........] - ETA: 0s - loss: 0.0614 - mae: 0.1657 - mse: 0.0614
93/93 [==============================] - 0s 4ms/step - loss: 0.0701 - mae: 0.1790 - mse: 0.0701 - val_loss: 0.0279 - val_mae: 0.1410 - val_mse: 0.0279
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1078 - mae: 0.2334 - mse: 0.1078
64/93 [===================>..........] - ETA: 0s - loss: 0.0846 - mae: 0.2146 - mse: 0.0846
93/93 [==============================] - 0s 5ms/step - loss: 0.0746 - mae: 0.2077 - mse: 0.0746 - val_loss: 0.0190 - val_mae: 0.1152 - val_mse: 0.0190
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0743 - mae: 0.1935 - mse: 0.0743
64/93 [===================>..........] - ETA: 0s - loss: 0.0738 - mae: 0.1982 - mse: 0.0738
93/93 [==============================] - 0s 5ms/step - loss: 0.0730 - mae: 0.1933 - mse: 0.0730 - val_loss: 0.0218 - val_mae: 0.1214 - val_mse: 0.0218
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0673 - mae: 0.1821 - mse: 0.0673
64/93 [===================>..........] - ETA: 0s - loss: 0.0753 - mae: 0.1989 - mse: 0.0753
93/93 [==============================] - 0s 5ms/step - loss: 0.0647 - mae: 0.1865 - mse: 0.0647 - val_loss: 0.0186 - val_mae: 0.1165 - val_mse: 0.0186
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0842 - mae: 0.2310 - mse: 0.0842
64/93 [===================>..........] - ETA: 0s - loss: 0.0742 - mae: 0.2163 - mse: 0.0742
93/93 [==============================] - 0s 5ms/step - loss: 0.0657 - mae: 0.2024 - mse: 0.0657 - val_loss: 0.0181 - val_mae: 0.1125 - val_mse: 0.0181
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0414 - mae: 0.1680 - mse: 0.0414
64/93 [===================>..........] - ETA: 0s - loss: 0.0496 - mae: 0.1834 - mse: 0.0496
93/93 [==============================] - 0s 5ms/step - loss: 0.0540 - mae: 0.1845 - mse: 0.0540 - val_loss: 0.0162 - val_mae: 0.1084 - val_mse: 0.0162
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0682 - mae: 0.2092 - mse: 0.0682
64/93 [===================>..........] - ETA: 0s - loss: 0.0488 - mae: 0.1717 - mse: 0.0488
93/93 [==============================] - 0s 5ms/step - loss: 0.0457 - mae: 0.1640 - mse: 0.0457 - val_loss: 0.0133 - val_mae: 0.0991 - val_mse: 0.0133
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0370 - mae: 0.1453 - mse: 0.0370
64/93 [===================>..........] - ETA: 0s - loss: 0.0397 - mae: 0.1514 - mse: 0.0397
93/93 [==============================] - 0s 5ms/step - loss: 0.0372 - mae: 0.1509 - mse: 0.0372 - val_loss: 0.0147 - val_mae: 0.1047 - val_mse: 0.0147
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0530 - mae: 0.1690 - mse: 0.0530
64/93 [===================>..........] - ETA: 0s - loss: 0.0538 - mae: 0.1727 - mse: 0.0538
93/93 [==============================] - 0s 5ms/step - loss: 0.0445 - mae: 0.1583 - mse: 0.0445 - val_loss: 0.0124 - val_mae: 0.0961 - val_mse: 0.0124
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0365 - mae: 0.1428 - mse: 0.0365
64/93 [===================>..........] - ETA: 0s - loss: 0.0314 - mae: 0.1371 - mse: 0.0314
93/93 [==============================] - 1s 6ms/step - loss: 0.0341 - mae: 0.1382 - mse: 0.0341 - val_loss: 0.0173 - val_mae: 0.1043 - val_mse: 0.0173
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0284 - mae: 0.1355 - mse: 0.0284
64/93 [===================>..........] - ETA: 0s - loss: 0.0329 - mae: 0.1348 - mse: 0.0329
93/93 [==============================] - 1s 6ms/step - loss: 0.0313 - mae: 0.1336 - mse: 0.0313 - val_loss: 0.0175 - val_mae: 0.1022 - val_mse: 0.0175
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0364 - mae: 0.1459 - mse: 0.0364
64/93 [===================>..........] - ETA: 0s - loss: 0.0351 - mae: 0.1454 - mse: 0.0351
93/93 [==============================] - 1s 6ms/step - loss: 0.0377 - mae: 0.1524 - mse: 0.0377 - val_loss: 0.0194 - val_mae: 0.1045 - val_mse: 0.0194
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0331 - mae: 0.1557 - mse: 0.0331
64/93 [===================>..........] - ETA: 0s - loss: 0.0344 - mae: 0.1467 - mse: 0.0344
93/93 [==============================] - 1s 6ms/step - loss: 0.0340 - mae: 0.1425 - mse: 0.0340 - val_loss: 0.0121 - val_mae: 0.0941 - val_mse: 0.0121
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0543 - mae: 0.1579 - mse: 0.0543
64/93 [===================>..........] - ETA: 0s - loss: 0.0352 - mae: 0.1317 - mse: 0.0352
93/93 [==============================] - 1s 6ms/step - loss: 0.0296 - mae: 0.1218 - mse: 0.0296 - val_loss: 0.0123 - val_mae: 0.0951 - val_mse: 0.0123
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0314 - mae: 0.1378 - mse: 0.0314
64/93 [===================>..........] - ETA: 0s - loss: 0.0293 - mae: 0.1275 - mse: 0.0293
93/93 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.1209 - mse: 0.0271 - val_loss: 0.0178 - val_mae: 0.1096 - val_mse: 0.0178
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0284 - mae: 0.1254 - mse: 0.0284
64/93 [===================>..........] - ETA: 0s - loss: 0.0316 - mae: 0.1364 - mse: 0.0316
93/93 [==============================] - 1s 6ms/step - loss: 0.0308 - mae: 0.1346 - mse: 0.0308 - val_loss: 0.0208 - val_mae: 0.1146 - val_mse: 0.0208
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0254 - mae: 0.1156 - mse: 0.0254
64/93 [===================>..........] - ETA: 0s - loss: 0.0227 - mae: 0.1130 - mse: 0.0227
93/93 [==============================] - 1s 6ms/step - loss: 0.0226 - mae: 0.1121 - mse: 0.0226 - val_loss: 0.0186 - val_mae: 0.1085 - val_mse: 0.0186
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0254 - mae: 0.1306 - mse: 0.0254
64/93 [===================>..........] - ETA: 0s - loss: 0.0252 - mae: 0.1171 - mse: 0.0252
93/93 [==============================] - 1s 6ms/step - loss: 0.0217 - mae: 0.1098 - mse: 0.0217 - val_loss: 0.0120 - val_mae: 0.0917 - val_mse: 0.0120
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0206 - mae: 0.1159 - mse: 0.0206
64/93 [===================>..........] - ETA: 0s - loss: 0.0181 - mae: 0.1082 - mse: 0.0181
93/93 [==============================] - 1s 6ms/step - loss: 0.0227 - mae: 0.1170 - mse: 0.0227 - val_loss: 0.0111 - val_mae: 0.0904 - val_mse: 0.0111
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0192 - mae: 0.1092 - mse: 0.0192
64/93 [===================>..........] - ETA: 0s - loss: 0.0224 - mae: 0.1170 - mse: 0.0224
93/93 [==============================] - 1s 6ms/step - loss: 0.0240 - mae: 0.1183 - mse: 0.0240 - val_loss: 0.0135 - val_mae: 0.0995 - val_mse: 0.0135
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0183 - mae: 0.1041 - mse: 0.0183
64/93 [===================>..........] - ETA: 0s - loss: 0.0213 - mae: 0.1130 - mse: 0.0213
93/93 [==============================] - 1s 6ms/step - loss: 0.0286 - mae: 0.1227 - mse: 0.0286 - val_loss: 0.0166 - val_mae: 0.1069 - val_mse: 0.0166
Saving trained model...
89
Testing...
heightdiff= [0.         0.         0.         0.         0.         6.30503845]
average prediction= [2.1886551]
baseline= 7.648148148148148
eachuser= [0. 0. 0. 0. 0. 4.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.5762596130371094
['train-height-11.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
170 34
170 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
170 38
170 39
170 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
165 71
2_165_50_11_csi_a11_29.dat
165 73
165 74
165 75
165 76
165 77
165 78
2_165_50_11_csi_a11_19.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
2_165_50_11_csi_a11_6.dat
165 96
2_165_50_11_csi_a11_28.dat
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
1_175_70_11_csi_a11_29.dat
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
180 135
180 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
180 141
1_180_85_11_csi_a11_28.dat
180 143
180 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
180 150
180 151
180 152
180 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
180 161
180 162
180 163
180 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
180 167
1_180_75_11_csi_a11_21.dat
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
180 177
180 178
180 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
180 182
1_180_75_11_csi_a11_16.dat
180 184
180 185
180 186
180 187
180 188
180 189
180 190
1_173_85_11_csi_a11_22.dat
173 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
173 197
173 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
173 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
173 204
1_173_85_11_csi_a11_2.dat
173 206
1_173_85_11_csi_a11_24.dat
173 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
173 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173
 173 173 173 173 173]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 1s - loss: 0.3980 - mae: 0.5266 - mse: 0.3980
64/93 [===================>..........] - ETA: 0s - loss: 0.3802 - mae: 0.5341 - mse: 0.3802
93/93 [==============================] - 1s 11ms/step - loss: 0.3184 - mae: 0.4850 - mse: 0.3184 - val_loss: 0.1249 - val_mae: 0.3202 - val_mse: 0.1249
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1307 - mae: 0.3299 - mse: 0.1307
64/93 [===================>..........] - ETA: 0s - loss: 0.1648 - mae: 0.3629 - mse: 0.1648
93/93 [==============================] - 1s 6ms/step - loss: 0.1620 - mae: 0.3477 - mse: 0.1620 - val_loss: 0.0891 - val_mae: 0.2425 - val_mse: 0.0891
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1631 - mae: 0.3387 - mse: 0.1631
64/93 [===================>..........] - ETA: 0s - loss: 0.1736 - mae: 0.3494 - mse: 0.1736
93/93 [==============================] - 0s 5ms/step - loss: 0.1676 - mae: 0.3428 - mse: 0.1676 - val_loss: 0.0862 - val_mae: 0.2606 - val_mse: 0.0862
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1031 - mae: 0.2749 - mse: 0.1031
64/93 [===================>..........] - ETA: 0s - loss: 0.1256 - mae: 0.3125 - mse: 0.1256
93/93 [==============================] - 0s 5ms/step - loss: 0.1242 - mae: 0.3036 - mse: 0.1242 - val_loss: 0.1035 - val_mae: 0.2978 - val_mse: 0.1035
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1209 - mae: 0.2937 - mse: 0.1209
64/93 [===================>..........] - ETA: 0s - loss: 0.1354 - mae: 0.3117 - mse: 0.1354
93/93 [==============================] - 1s 5ms/step - loss: 0.1192 - mae: 0.2922 - mse: 0.1192 - val_loss: 0.0829 - val_mae: 0.2631 - val_mse: 0.0829
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1100 - mae: 0.2703 - mse: 0.1100
64/93 [===================>..........] - ETA: 0s - loss: 0.0953 - mae: 0.2573 - mse: 0.0953
93/93 [==============================] - 0s 5ms/step - loss: 0.0913 - mae: 0.2536 - mse: 0.0913 - val_loss: 0.0494 - val_mae: 0.1943 - val_mse: 0.0494
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1013 - mae: 0.2683 - mse: 0.1013
64/93 [===================>..........] - ETA: 0s - loss: 0.0973 - mae: 0.2521 - mse: 0.0973
93/93 [==============================] - 0s 5ms/step - loss: 0.0992 - mae: 0.2539 - mse: 0.0992 - val_loss: 0.0393 - val_mae: 0.1508 - val_mse: 0.0393
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0943 - mae: 0.2509 - mse: 0.0943
64/93 [===================>..........] - ETA: 0s - loss: 0.0871 - mae: 0.2362 - mse: 0.0871
93/93 [==============================] - 0s 5ms/step - loss: 0.0876 - mae: 0.2397 - mse: 0.0876 - val_loss: 0.0302 - val_mae: 0.1436 - val_mse: 0.0302
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0665 - mae: 0.2071 - mse: 0.0665
64/93 [===================>..........] - ETA: 0s - loss: 0.0655 - mae: 0.1960 - mse: 0.0655
93/93 [==============================] - 0s 5ms/step - loss: 0.0743 - mae: 0.2119 - mse: 0.0743 - val_loss: 0.0306 - val_mae: 0.1493 - val_mse: 0.0306
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0793 - mae: 0.2110 - mse: 0.0793
64/93 [===================>..........] - ETA: 0s - loss: 0.0649 - mae: 0.1965 - mse: 0.0649
93/93 [==============================] - 0s 5ms/step - loss: 0.0712 - mae: 0.2094 - mse: 0.0712 - val_loss: 0.0224 - val_mae: 0.1246 - val_mse: 0.0224
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0650 - mae: 0.1902 - mse: 0.0650
64/93 [===================>..........] - ETA: 0s - loss: 0.0744 - mae: 0.2073 - mse: 0.0744
93/93 [==============================] - 0s 5ms/step - loss: 0.0717 - mae: 0.1966 - mse: 0.0717 - val_loss: 0.0151 - val_mae: 0.1022 - val_mse: 0.0151
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0795 - mae: 0.2121 - mse: 0.0795
64/93 [===================>..........] - ETA: 0s - loss: 0.0813 - mae: 0.2193 - mse: 0.0813
93/93 [==============================] - 0s 5ms/step - loss: 0.0777 - mae: 0.2151 - mse: 0.0777 - val_loss: 0.0135 - val_mae: 0.0973 - val_mse: 0.0135
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0258 - mae: 0.1318 - mse: 0.0258
64/93 [===================>..........] - ETA: 0s - loss: 0.0628 - mae: 0.1832 - mse: 0.0628
93/93 [==============================] - 0s 5ms/step - loss: 0.0737 - mae: 0.2057 - mse: 0.0737 - val_loss: 0.0168 - val_mae: 0.1101 - val_mse: 0.0168
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0567 - mae: 0.1866 - mse: 0.0567
64/93 [===================>..........] - ETA: 0s - loss: 0.0497 - mae: 0.1736 - mse: 0.0497
93/93 [==============================] - 0s 5ms/step - loss: 0.0671 - mae: 0.1893 - mse: 0.0671 - val_loss: 0.0200 - val_mae: 0.1213 - val_mse: 0.0200
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0600 - mae: 0.1811 - mse: 0.0600
64/93 [===================>..........] - ETA: 0s - loss: 0.0710 - mae: 0.1960 - mse: 0.0710
93/93 [==============================] - 1s 6ms/step - loss: 0.0683 - mae: 0.1968 - mse: 0.0683 - val_loss: 0.0156 - val_mae: 0.1024 - val_mse: 0.0156
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0495 - mae: 0.1741 - mse: 0.0495
64/93 [===================>..........] - ETA: 0s - loss: 0.0507 - mae: 0.1684 - mse: 0.0507
93/93 [==============================] - 0s 5ms/step - loss: 0.0619 - mae: 0.1904 - mse: 0.0619 - val_loss: 0.0150 - val_mae: 0.0995 - val_mse: 0.0150
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0689 - mae: 0.2069 - mse: 0.0689
64/93 [===================>..........] - ETA: 0s - loss: 0.0531 - mae: 0.1724 - mse: 0.0531
93/93 [==============================] - 0s 5ms/step - loss: 0.0619 - mae: 0.1868 - mse: 0.0619 - val_loss: 0.0149 - val_mae: 0.0975 - val_mse: 0.0149
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0486 - mae: 0.1747 - mse: 0.0486
64/93 [===================>..........] - ETA: 0s - loss: 0.0729 - mae: 0.2181 - mse: 0.0729
93/93 [==============================] - 0s 5ms/step - loss: 0.0712 - mae: 0.2163 - mse: 0.0712 - val_loss: 0.0200 - val_mae: 0.1224 - val_mse: 0.0200
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0784 - mae: 0.2086 - mse: 0.0784
64/93 [===================>..........] - ETA: 0s - loss: 0.0593 - mae: 0.1774 - mse: 0.0593
93/93 [==============================] - 1s 6ms/step - loss: 0.0576 - mae: 0.1801 - mse: 0.0576 - val_loss: 0.0263 - val_mae: 0.1475 - val_mse: 0.0263
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0700 - mae: 0.2247 - mse: 0.0700
64/93 [===================>..........] - ETA: 0s - loss: 0.0702 - mae: 0.2077 - mse: 0.0702
93/93 [==============================] - 0s 5ms/step - loss: 0.0644 - mae: 0.1953 - mse: 0.0644 - val_loss: 0.0156 - val_mae: 0.1025 - val_mse: 0.0156
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0535 - mae: 0.1645 - mse: 0.0535
64/93 [===================>..........] - ETA: 0s - loss: 0.0494 - mae: 0.1668 - mse: 0.0494
93/93 [==============================] - 0s 5ms/step - loss: 0.0488 - mae: 0.1682 - mse: 0.0488 - val_loss: 0.0142 - val_mae: 0.0854 - val_mse: 0.0142
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0643 - mae: 0.2045 - mse: 0.0643
64/93 [===================>..........] - ETA: 0s - loss: 0.0544 - mae: 0.1867 - mse: 0.0544
93/93 [==============================] - 0s 5ms/step - loss: 0.0551 - mae: 0.1849 - mse: 0.0551 - val_loss: 0.0142 - val_mae: 0.1001 - val_mse: 0.0142
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0490 - mae: 0.1749 - mse: 0.0490
64/93 [===================>..........] - ETA: 0s - loss: 0.0413 - mae: 0.1540 - mse: 0.0413
93/93 [==============================] - 1s 6ms/step - loss: 0.0422 - mae: 0.1556 - mse: 0.0422 - val_loss: 0.0216 - val_mae: 0.1299 - val_mse: 0.0216
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0410 - mae: 0.1569 - mse: 0.0410
64/93 [===================>..........] - ETA: 0s - loss: 0.0383 - mae: 0.1388 - mse: 0.0383
93/93 [==============================] - 0s 5ms/step - loss: 0.0388 - mae: 0.1469 - mse: 0.0388 - val_loss: 0.0157 - val_mae: 0.0974 - val_mse: 0.0157
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0417 - mae: 0.1577 - mse: 0.0417
64/93 [===================>..........] - ETA: 0s - loss: 0.0520 - mae: 0.1697 - mse: 0.0520
93/93 [==============================] - 0s 5ms/step - loss: 0.0486 - mae: 0.1647 - mse: 0.0486 - val_loss: 0.0146 - val_mae: 0.0878 - val_mse: 0.0146
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0692 - mae: 0.2071 - mse: 0.0692
64/93 [===================>..........] - ETA: 0s - loss: 0.0510 - mae: 0.1773 - mse: 0.0510
93/93 [==============================] - 0s 5ms/step - loss: 0.0446 - mae: 0.1671 - mse: 0.0446 - val_loss: 0.0193 - val_mae: 0.1099 - val_mse: 0.0193
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0196 - mae: 0.1143 - mse: 0.0196
64/93 [===================>..........] - ETA: 0s - loss: 0.0321 - mae: 0.1382 - mse: 0.0321
93/93 [==============================] - 1s 6ms/step - loss: 0.0347 - mae: 0.1401 - mse: 0.0347 - val_loss: 0.0225 - val_mae: 0.1303 - val_mse: 0.0225
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0536 - mae: 0.1857 - mse: 0.0536
64/93 [===================>..........] - ETA: 0s - loss: 0.0463 - mae: 0.1610 - mse: 0.0463
93/93 [==============================] - 0s 4ms/step - loss: 0.0395 - mae: 0.1507 - mse: 0.0395 - val_loss: 0.0144 - val_mae: 0.0842 - val_mse: 0.0144
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0401 - mae: 0.1605 - mse: 0.0401
64/93 [===================>..........] - ETA: 0s - loss: 0.0370 - mae: 0.1454 - mse: 0.0370
93/93 [==============================] - 0s 5ms/step - loss: 0.0344 - mae: 0.1391 - mse: 0.0344 - val_loss: 0.0243 - val_mae: 0.1387 - val_mse: 0.0243
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0257 - mae: 0.1246 - mse: 0.0257
64/93 [===================>..........] - ETA: 0s - loss: 0.0307 - mae: 0.1303 - mse: 0.0307
93/93 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.1221 - mse: 0.0281 - val_loss: 0.0341 - val_mae: 0.1663 - val_mse: 0.0341
Saving trained model...
89
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         13.47227478]
average prediction= [3.9617965]
baseline= 8.907407407407407
eachuser= [0. 0. 0. 0. 0. 7.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.9246106828962053
['train-height-11.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
170 34
170 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
170 38
170 39
170 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
165 71
2_165_50_11_csi_a11_29.dat
165 73
165 74
165 75
165 76
165 77
165 78
2_165_50_11_csi_a11_19.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
2_165_50_11_csi_a11_6.dat
165 96
2_165_50_11_csi_a11_28.dat
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
1_175_70_11_csi_a11_29.dat
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
180 135
180 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
180 141
1_180_85_11_csi_a11_28.dat
180 143
180 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
180 150
180 151
180 152
180 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
180 161
180 162
180 163
180 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
180 167
1_180_75_11_csi_a11_21.dat
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
180 177
180 178
180 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
180 182
1_180_75_11_csi_a11_16.dat
180 184
180 185
180 186
180 187
180 188
180 189
180 190
1_173_85_11_csi_a11_22.dat
173 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
173 197
173 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
173 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
173 204
1_173_85_11_csi_a11_2.dat
173 206
1_173_85_11_csi_a11_24.dat
173 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
173 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173
 173 173 173 173 173]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.3868 - mae: 0.5066 - mse: 0.3868
64/93 [===================>..........] - ETA: 0s - loss: 0.3414 - mae: 0.4884 - mse: 0.3414
93/93 [==============================] - 1s 10ms/step - loss: 0.2750 - mae: 0.4338 - mse: 0.2750 - val_loss: 0.0407 - val_mae: 0.1683 - val_mse: 0.0407
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0898 - mae: 0.2608 - mse: 0.0898
64/93 [===================>..........] - ETA: 0s - loss: 0.1219 - mae: 0.2901 - mse: 0.1219
93/93 [==============================] - 1s 7ms/step - loss: 0.1295 - mae: 0.3029 - mse: 0.1295 - val_loss: 0.0688 - val_mae: 0.2342 - val_mse: 0.0688
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1181 - mae: 0.3030 - mse: 0.1181
64/93 [===================>..........] - ETA: 0s - loss: 0.1132 - mae: 0.2859 - mse: 0.1132
93/93 [==============================] - 0s 5ms/step - loss: 0.0990 - mae: 0.2619 - mse: 0.0990 - val_loss: 0.0246 - val_mae: 0.1133 - val_mse: 0.0246
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0845 - mae: 0.2365 - mse: 0.0845
64/93 [===================>..........] - ETA: 0s - loss: 0.0905 - mae: 0.2425 - mse: 0.0905
93/93 [==============================] - 1s 6ms/step - loss: 0.0864 - mae: 0.2355 - mse: 0.0864 - val_loss: 0.0397 - val_mae: 0.1706 - val_mse: 0.0397
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0781 - mae: 0.2269 - mse: 0.0781
64/93 [===================>..........] - ETA: 0s - loss: 0.0864 - mae: 0.2376 - mse: 0.0864
93/93 [==============================] - 1s 6ms/step - loss: 0.0806 - mae: 0.2281 - mse: 0.0806 - val_loss: 0.0412 - val_mae: 0.1826 - val_mse: 0.0412
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1059 - mae: 0.2841 - mse: 0.1059
64/93 [===================>..........] - ETA: 0s - loss: 0.0946 - mae: 0.2553 - mse: 0.0946
93/93 [==============================] - 1s 6ms/step - loss: 0.0810 - mae: 0.2285 - mse: 0.0810 - val_loss: 0.0234 - val_mae: 0.1227 - val_mse: 0.0234
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0793 - mae: 0.2140 - mse: 0.0793
64/93 [===================>..........] - ETA: 0s - loss: 0.0669 - mae: 0.2029 - mse: 0.0669
93/93 [==============================] - 1s 7ms/step - loss: 0.0743 - mae: 0.2169 - mse: 0.0743 - val_loss: 0.0186 - val_mae: 0.1071 - val_mse: 0.0186
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0808 - mae: 0.2262 - mse: 0.0808
64/93 [===================>..........] - ETA: 0s - loss: 0.0791 - mae: 0.2312 - mse: 0.0791
93/93 [==============================] - 1s 6ms/step - loss: 0.0726 - mae: 0.2169 - mse: 0.0726 - val_loss: 0.0185 - val_mae: 0.1162 - val_mse: 0.0185
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0474 - mae: 0.1732 - mse: 0.0474
64/93 [===================>..........] - ETA: 0s - loss: 0.0553 - mae: 0.1842 - mse: 0.0553
93/93 [==============================] - 0s 5ms/step - loss: 0.0613 - mae: 0.1947 - mse: 0.0613 - val_loss: 0.0247 - val_mae: 0.1408 - val_mse: 0.0247
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0547 - mae: 0.1925 - mse: 0.0547
64/93 [===================>..........] - ETA: 0s - loss: 0.0706 - mae: 0.2179 - mse: 0.0706
93/93 [==============================] - 0s 5ms/step - loss: 0.0635 - mae: 0.2060 - mse: 0.0635 - val_loss: 0.0271 - val_mae: 0.1457 - val_mse: 0.0271
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0421 - mae: 0.1615 - mse: 0.0421
64/93 [===================>..........] - ETA: 0s - loss: 0.0514 - mae: 0.1768 - mse: 0.0514
93/93 [==============================] - 1s 6ms/step - loss: 0.0553 - mae: 0.1832 - mse: 0.0553 - val_loss: 0.0217 - val_mae: 0.1257 - val_mse: 0.0217
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0434 - mae: 0.1640 - mse: 0.0434
64/93 [===================>..........] - ETA: 0s - loss: 0.0439 - mae: 0.1656 - mse: 0.0439
93/93 [==============================] - 0s 5ms/step - loss: 0.0435 - mae: 0.1646 - mse: 0.0435 - val_loss: 0.0122 - val_mae: 0.0949 - val_mse: 0.0122
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0491 - mae: 0.1752 - mse: 0.0491
64/93 [===================>..........] - ETA: 0s - loss: 0.0651 - mae: 0.2138 - mse: 0.0651
93/93 [==============================] - 1s 5ms/step - loss: 0.0523 - mae: 0.1856 - mse: 0.0523 - val_loss: 0.0129 - val_mae: 0.0979 - val_mse: 0.0129
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0761 - mae: 0.2215 - mse: 0.0761
64/93 [===================>..........] - ETA: 0s - loss: 0.0555 - mae: 0.1854 - mse: 0.0555
93/93 [==============================] - 0s 5ms/step - loss: 0.0517 - mae: 0.1787 - mse: 0.0517 - val_loss: 0.0283 - val_mae: 0.1514 - val_mse: 0.0283
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0566 - mae: 0.1841 - mse: 0.0566
64/93 [===================>..........] - ETA: 0s - loss: 0.0521 - mae: 0.1742 - mse: 0.0521
93/93 [==============================] - 1s 6ms/step - loss: 0.0450 - mae: 0.1594 - mse: 0.0450 - val_loss: 0.0409 - val_mae: 0.1794 - val_mse: 0.0409
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0240 - mae: 0.1300 - mse: 0.0240
64/93 [===================>..........] - ETA: 0s - loss: 0.0415 - mae: 0.1548 - mse: 0.0415
93/93 [==============================] - 0s 5ms/step - loss: 0.0375 - mae: 0.1494 - mse: 0.0375 - val_loss: 0.0307 - val_mae: 0.1604 - val_mse: 0.0307
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0291 - mae: 0.1421 - mse: 0.0291
64/93 [===================>..........] - ETA: 0s - loss: 0.0317 - mae: 0.1482 - mse: 0.0317
93/93 [==============================] - 0s 5ms/step - loss: 0.0341 - mae: 0.1464 - mse: 0.0341 - val_loss: 0.0193 - val_mae: 0.1282 - val_mse: 0.0193
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0244 - mae: 0.1242 - mse: 0.0244
64/93 [===================>..........] - ETA: 0s - loss: 0.0316 - mae: 0.1390 - mse: 0.0316
93/93 [==============================] - 0s 4ms/step - loss: 0.0341 - mae: 0.1446 - mse: 0.0341 - val_loss: 0.0197 - val_mae: 0.1277 - val_mse: 0.0197
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0353 - mae: 0.1575 - mse: 0.0353
64/93 [===================>..........] - ETA: 0s - loss: 0.0341 - mae: 0.1470 - mse: 0.0341
93/93 [==============================] - 0s 4ms/step - loss: 0.0340 - mae: 0.1417 - mse: 0.0340 - val_loss: 0.0319 - val_mae: 0.1532 - val_mse: 0.0319
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0339 - mae: 0.1372 - mse: 0.0339
64/93 [===================>..........] - ETA: 0s - loss: 0.0303 - mae: 0.1378 - mse: 0.0303
93/93 [==============================] - 0s 5ms/step - loss: 0.0287 - mae: 0.1375 - mse: 0.0287 - val_loss: 0.0318 - val_mae: 0.1538 - val_mse: 0.0318
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0336 - mae: 0.1273 - mse: 0.0336
64/93 [===================>..........] - ETA: 0s - loss: 0.0324 - mae: 0.1269 - mse: 0.0324
93/93 [==============================] - 0s 5ms/step - loss: 0.0297 - mae: 0.1277 - mse: 0.0297 - val_loss: 0.0214 - val_mae: 0.1315 - val_mse: 0.0214
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0307 - mae: 0.1323 - mse: 0.0307
64/93 [===================>..........] - ETA: 0s - loss: 0.0240 - mae: 0.1233 - mse: 0.0240
93/93 [==============================] - 0s 5ms/step - loss: 0.0296 - mae: 0.1301 - mse: 0.0296 - val_loss: 0.0203 - val_mae: 0.1311 - val_mse: 0.0203
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0339 - mae: 0.1440 - mse: 0.0339
64/93 [===================>..........] - ETA: 0s - loss: 0.0308 - mae: 0.1368 - mse: 0.0308
93/93 [==============================] - 0s 5ms/step - loss: 0.0347 - mae: 0.1397 - mse: 0.0347 - val_loss: 0.0260 - val_mae: 0.1431 - val_mse: 0.0260
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0350 - mae: 0.1431 - mse: 0.0350
64/93 [===================>..........] - ETA: 0s - loss: 0.0277 - mae: 0.1307 - mse: 0.0277
93/93 [==============================] - 0s 5ms/step - loss: 0.0247 - mae: 0.1229 - mse: 0.0247 - val_loss: 0.0211 - val_mae: 0.1349 - val_mse: 0.0211
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0359 - mae: 0.1215 - mse: 0.0359
64/93 [===================>..........] - ETA: 0s - loss: 0.0264 - mae: 0.1134 - mse: 0.0264
93/93 [==============================] - 0s 5ms/step - loss: 0.0317 - mae: 0.1250 - mse: 0.0317 - val_loss: 0.0212 - val_mae: 0.1377 - val_mse: 0.0212
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0513 - mae: 0.1738 - mse: 0.0513
64/93 [===================>..........] - ETA: 0s - loss: 0.0468 - mae: 0.1671 - mse: 0.0468
93/93 [==============================] - 1s 5ms/step - loss: 0.0374 - mae: 0.1428 - mse: 0.0374 - val_loss: 0.0315 - val_mae: 0.1577 - val_mse: 0.0315
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0285 - mae: 0.1263 - mse: 0.0285
64/93 [===================>..........] - ETA: 0s - loss: 0.0231 - mae: 0.1153 - mse: 0.0231
93/93 [==============================] - 1s 6ms/step - loss: 0.0294 - mae: 0.1268 - mse: 0.0294 - val_loss: 0.0338 - val_mae: 0.1619 - val_mse: 0.0338
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0401 - mae: 0.1352 - mse: 0.0401
64/93 [===================>..........] - ETA: 0s - loss: 0.0310 - mae: 0.1266 - mse: 0.0310
93/93 [==============================] - 1s 6ms/step - loss: 0.0280 - mae: 0.1246 - mse: 0.0280 - val_loss: 0.0207 - val_mae: 0.1312 - val_mse: 0.0207
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0274 - mae: 0.1334 - mse: 0.0274
64/93 [===================>..........] - ETA: 0s - loss: 0.0301 - mae: 0.1337 - mse: 0.0301
93/93 [==============================] - 0s 5ms/step - loss: 0.0304 - mae: 0.1305 - mse: 0.0304 - val_loss: 0.0202 - val_mae: 0.1282 - val_mse: 0.0202
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0219 - mae: 0.1247 - mse: 0.0219
64/93 [===================>..........] - ETA: 0s - loss: 0.0176 - mae: 0.1096 - mse: 0.0176
93/93 [==============================] - 0s 5ms/step - loss: 0.0217 - mae: 0.1145 - mse: 0.0217 - val_loss: 0.0249 - val_mae: 0.1383 - val_mse: 0.0249
Saving trained model...
89
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         27.21801758]
average prediction= [4.2451334]
baseline= 9.907407407407407
eachuser= [ 0.  0.  0.  0.  0. 10.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 2.7218017578125
['train-height-11.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
170 34
170 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
170 38
170 39
170 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
165 71
2_165_50_11_csi_a11_29.dat
165 73
165 74
165 75
165 76
165 77
165 78
2_165_50_11_csi_a11_19.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
2_165_50_11_csi_a11_6.dat
165 96
2_165_50_11_csi_a11_28.dat
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
1_175_70_11_csi_a11_29.dat
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
180 135
180 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
180 141
1_180_85_11_csi_a11_28.dat
180 143
180 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
180 150
180 151
180 152
180 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
180 161
180 162
180 163
180 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
180 167
1_180_75_11_csi_a11_21.dat
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
180 177
180 178
180 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
180 182
1_180_75_11_csi_a11_16.dat
180 184
180 185
180 186
180 187
180 188
180 189
180 190
1_173_85_11_csi_a11_22.dat
173 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
173 197
173 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
173 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
173 204
1_173_85_11_csi_a11_2.dat
173 206
1_173_85_11_csi_a11_24.dat
173 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
173 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173
 173 173 173 173 173]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.4833 - mae: 0.5860 - mse: 0.4833
64/93 [===================>..........] - ETA: 0s - loss: 0.4410 - mae: 0.5656 - mse: 0.4410
93/93 [==============================] - 1s 10ms/step - loss: 0.3877 - mae: 0.5296 - mse: 0.3877 - val_loss: 0.2194 - val_mae: 0.4035 - val_mse: 0.2194
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1535 - mae: 0.3408 - mse: 0.1535
64/93 [===================>..........] - ETA: 0s - loss: 0.1495 - mae: 0.3403 - mse: 0.1495
93/93 [==============================] - 1s 6ms/step - loss: 0.1412 - mae: 0.3266 - mse: 0.1412 - val_loss: 0.1080 - val_mae: 0.2508 - val_mse: 0.1080
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1946 - mae: 0.3424 - mse: 0.1946
64/93 [===================>..........] - ETA: 0s - loss: 0.1980 - mae: 0.3579 - mse: 0.1980
93/93 [==============================] - 1s 6ms/step - loss: 0.1929 - mae: 0.3538 - mse: 0.1929 - val_loss: 0.0912 - val_mae: 0.2399 - val_mse: 0.0912
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1368 - mae: 0.3061 - mse: 0.1368
64/93 [===================>..........] - ETA: 0s - loss: 0.1197 - mae: 0.2886 - mse: 0.1197
93/93 [==============================] - 0s 5ms/step - loss: 0.1159 - mae: 0.2907 - mse: 0.1159 - val_loss: 0.1336 - val_mae: 0.3159 - val_mse: 0.1336
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0952 - mae: 0.2674 - mse: 0.0952
64/93 [===================>..........] - ETA: 0s - loss: 0.1023 - mae: 0.2743 - mse: 0.1023
93/93 [==============================] - 0s 5ms/step - loss: 0.1096 - mae: 0.2815 - mse: 0.1096 - val_loss: 0.1681 - val_mae: 0.3425 - val_mse: 0.1681
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1692 - mae: 0.3473 - mse: 0.1692
64/93 [===================>..........] - ETA: 0s - loss: 0.1328 - mae: 0.3106 - mse: 0.1328
93/93 [==============================] - 1s 5ms/step - loss: 0.1262 - mae: 0.3048 - mse: 0.1262 - val_loss: 0.1402 - val_mae: 0.3109 - val_mse: 0.1402
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0785 - mae: 0.2438 - mse: 0.0785
64/93 [===================>..........] - ETA: 0s - loss: 0.0993 - mae: 0.2684 - mse: 0.0993
93/93 [==============================] - 0s 5ms/step - loss: 0.1020 - mae: 0.2699 - mse: 0.1020 - val_loss: 0.0943 - val_mae: 0.2439 - val_mse: 0.0943
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0874 - mae: 0.2479 - mse: 0.0874
64/93 [===================>..........] - ETA: 0s - loss: 0.0978 - mae: 0.2514 - mse: 0.0978
93/93 [==============================] - 0s 5ms/step - loss: 0.0975 - mae: 0.2557 - mse: 0.0975 - val_loss: 0.0776 - val_mae: 0.2073 - val_mse: 0.0776
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1044 - mae: 0.2630 - mse: 0.1044
64/93 [===================>..........] - ETA: 0s - loss: 0.0813 - mae: 0.2259 - mse: 0.0813
93/93 [==============================] - 0s 5ms/step - loss: 0.0717 - mae: 0.2086 - mse: 0.0717 - val_loss: 0.0789 - val_mae: 0.2060 - val_mse: 0.0789
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0683 - mae: 0.2173 - mse: 0.0683
64/93 [===================>..........] - ETA: 0s - loss: 0.0681 - mae: 0.2114 - mse: 0.0681
93/93 [==============================] - 0s 4ms/step - loss: 0.0681 - mae: 0.2027 - mse: 0.0681 - val_loss: 0.0899 - val_mae: 0.2139 - val_mse: 0.0899
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0331 - mae: 0.1507 - mse: 0.0331
64/93 [===================>..........] - ETA: 0s - loss: 0.0545 - mae: 0.1855 - mse: 0.0545
93/93 [==============================] - 0s 5ms/step - loss: 0.0603 - mae: 0.1851 - mse: 0.0603 - val_loss: 0.0927 - val_mae: 0.2092 - val_mse: 0.0927
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0501 - mae: 0.1824 - mse: 0.0501
64/93 [===================>..........] - ETA: 0s - loss: 0.0600 - mae: 0.1925 - mse: 0.0600
93/93 [==============================] - 1s 5ms/step - loss: 0.0618 - mae: 0.1907 - mse: 0.0618 - val_loss: 0.0818 - val_mae: 0.1888 - val_mse: 0.0818
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0635 - mae: 0.2067 - mse: 0.0635
64/93 [===================>..........] - ETA: 0s - loss: 0.0658 - mae: 0.1933 - mse: 0.0658
93/93 [==============================] - 0s 5ms/step - loss: 0.0644 - mae: 0.1899 - mse: 0.0644 - val_loss: 0.0756 - val_mae: 0.1748 - val_mse: 0.0756
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0717 - mae: 0.1869 - mse: 0.0717
64/93 [===================>..........] - ETA: 0s - loss: 0.0723 - mae: 0.1986 - mse: 0.0723
93/93 [==============================] - 0s 5ms/step - loss: 0.0641 - mae: 0.1838 - mse: 0.0641 - val_loss: 0.0703 - val_mae: 0.1630 - val_mse: 0.0703
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0872 - mae: 0.2222 - mse: 0.0872
64/93 [===================>..........] - ETA: 0s - loss: 0.0632 - mae: 0.1987 - mse: 0.0632
93/93 [==============================] - 0s 5ms/step - loss: 0.0637 - mae: 0.1961 - mse: 0.0637 - val_loss: 0.0816 - val_mae: 0.2009 - val_mse: 0.0816
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0450 - mae: 0.1653 - mse: 0.0450
64/93 [===================>..........] - ETA: 0s - loss: 0.0521 - mae: 0.1771 - mse: 0.0521
93/93 [==============================] - 0s 5ms/step - loss: 0.0582 - mae: 0.1845 - mse: 0.0582 - val_loss: 0.0890 - val_mae: 0.2204 - val_mse: 0.0890
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0351 - mae: 0.1480 - mse: 0.0351
64/93 [===================>..........] - ETA: 0s - loss: 0.0504 - mae: 0.1762 - mse: 0.0504
93/93 [==============================] - 0s 5ms/step - loss: 0.0543 - mae: 0.1772 - mse: 0.0543 - val_loss: 0.0739 - val_mae: 0.1929 - val_mse: 0.0739
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0641 - mae: 0.1838 - mse: 0.0641
64/93 [===================>..........] - ETA: 0s - loss: 0.0472 - mae: 0.1620 - mse: 0.0472
93/93 [==============================] - 0s 5ms/step - loss: 0.0509 - mae: 0.1681 - mse: 0.0509 - val_loss: 0.0599 - val_mae: 0.1551 - val_mse: 0.0599
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0236 - mae: 0.1330 - mse: 0.0236
64/93 [===================>..........] - ETA: 0s - loss: 0.0552 - mae: 0.1798 - mse: 0.0552
93/93 [==============================] - 0s 5ms/step - loss: 0.0549 - mae: 0.1812 - mse: 0.0549 - val_loss: 0.0567 - val_mae: 0.1531 - val_mse: 0.0567
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0376 - mae: 0.1532 - mse: 0.0376
64/93 [===================>..........] - ETA: 0s - loss: 0.0448 - mae: 0.1581 - mse: 0.0448
93/93 [==============================] - 0s 4ms/step - loss: 0.0481 - mae: 0.1615 - mse: 0.0481 - val_loss: 0.0607 - val_mae: 0.1744 - val_mse: 0.0607
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0399 - mae: 0.1385 - mse: 0.0399
64/93 [===================>..........] - ETA: 0s - loss: 0.0368 - mae: 0.1410 - mse: 0.0368
93/93 [==============================] - 0s 5ms/step - loss: 0.0414 - mae: 0.1493 - mse: 0.0414 - val_loss: 0.0526 - val_mae: 0.1604 - val_mse: 0.0526
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0416 - mae: 0.1478 - mse: 0.0416
64/93 [===================>..........] - ETA: 0s - loss: 0.0378 - mae: 0.1428 - mse: 0.0378
93/93 [==============================] - 0s 5ms/step - loss: 0.0372 - mae: 0.1377 - mse: 0.0372 - val_loss: 0.0451 - val_mae: 0.1463 - val_mse: 0.0451
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0684 - mae: 0.1879 - mse: 0.0684
64/93 [===================>..........] - ETA: 0s - loss: 0.0583 - mae: 0.1780 - mse: 0.0583
93/93 [==============================] - 0s 5ms/step - loss: 0.0457 - mae: 0.1571 - mse: 0.0457 - val_loss: 0.0441 - val_mae: 0.1507 - val_mse: 0.0441
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0589 - mae: 0.1599 - mse: 0.0589
64/93 [===================>..........] - ETA: 0s - loss: 0.0463 - mae: 0.1471 - mse: 0.0463
93/93 [==============================] - 0s 5ms/step - loss: 0.0402 - mae: 0.1428 - mse: 0.0402 - val_loss: 0.0394 - val_mae: 0.1429 - val_mse: 0.0394
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0193 - mae: 0.1130 - mse: 0.0193
64/93 [===================>..........] - ETA: 0s - loss: 0.0368 - mae: 0.1409 - mse: 0.0368
93/93 [==============================] - 0s 5ms/step - loss: 0.0401 - mae: 0.1402 - mse: 0.0401 - val_loss: 0.0327 - val_mae: 0.1264 - val_mse: 0.0327
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0355 - mae: 0.1476 - mse: 0.0355
64/93 [===================>..........] - ETA: 0s - loss: 0.0359 - mae: 0.1437 - mse: 0.0359
93/93 [==============================] - 0s 5ms/step - loss: 0.0394 - mae: 0.1478 - mse: 0.0394 - val_loss: 0.0304 - val_mae: 0.1265 - val_mse: 0.0304
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0420 - mae: 0.1509 - mse: 0.0420
64/93 [===================>..........] - ETA: 0s - loss: 0.0320 - mae: 0.1308 - mse: 0.0320
93/93 [==============================] - 0s 4ms/step - loss: 0.0336 - mae: 0.1294 - mse: 0.0336 - val_loss: 0.0337 - val_mae: 0.1491 - val_mse: 0.0337
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0312 - mae: 0.1281 - mse: 0.0312
64/93 [===================>..........] - ETA: 0s - loss: 0.0331 - mae: 0.1389 - mse: 0.0331
93/93 [==============================] - 0s 5ms/step - loss: 0.0371 - mae: 0.1452 - mse: 0.0371 - val_loss: 0.0323 - val_mae: 0.1537 - val_mse: 0.0323
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0299 - mae: 0.1242 - mse: 0.0299
64/93 [===================>..........] - ETA: 0s - loss: 0.0366 - mae: 0.1394 - mse: 0.0366
93/93 [==============================] - 0s 4ms/step - loss: 0.0288 - mae: 0.1245 - mse: 0.0288 - val_loss: 0.0211 - val_mae: 0.1217 - val_mse: 0.0211
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0440 - mae: 0.1505 - mse: 0.0440
64/93 [===================>..........] - ETA: 0s - loss: 0.0370 - mae: 0.1390 - mse: 0.0370
93/93 [==============================] - 0s 5ms/step - loss: 0.0304 - mae: 0.1274 - mse: 0.0304 - val_loss: 0.0235 - val_mae: 0.1350 - val_mse: 0.0235
Saving trained model...
89
Testing...
heightdiff= [0.         0.         0.         0.         0.         7.04216003]
average prediction= [3.1059265]
baseline= 7.981481481481482
eachuser= [0. 0. 0. 0. 0. 6.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.173693339029948
['train-height-11.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
170 34
170 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
170 38
170 39
170 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
165 71
2_165_50_11_csi_a11_29.dat
165 73
165 74
165 75
165 76
165 77
165 78
2_165_50_11_csi_a11_19.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
2_165_50_11_csi_a11_6.dat
165 96
2_165_50_11_csi_a11_28.dat
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
1_175_70_11_csi_a11_29.dat
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
180 135
180 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
180 141
1_180_85_11_csi_a11_28.dat
180 143
180 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
180 150
180 151
180 152
180 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
180 161
180 162
180 163
180 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
180 167
1_180_75_11_csi_a11_21.dat
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
180 177
180 178
180 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
180 182
1_180_75_11_csi_a11_16.dat
180 184
180 185
180 186
180 187
180 188
180 189
180 190
1_173_85_11_csi_a11_22.dat
173 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
173 197
173 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
173 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
173 204
1_173_85_11_csi_a11_2.dat
173 206
1_173_85_11_csi_a11_24.dat
173 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
173 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173
 173 173 173 173 173]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.4941 - mae: 0.6206 - mse: 0.4941
64/93 [===================>..........] - ETA: 0s - loss: 0.4144 - mae: 0.5552 - mse: 0.4144
93/93 [==============================] - 1s 9ms/step - loss: 0.3766 - mae: 0.5325 - mse: 0.3766 - val_loss: 0.2230 - val_mae: 0.4278 - val_mse: 0.2230
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1497 - mae: 0.3219 - mse: 0.1497
64/93 [===================>..........] - ETA: 0s - loss: 0.1858 - mae: 0.3815 - mse: 0.1858
93/93 [==============================] - 1s 6ms/step - loss: 0.1969 - mae: 0.3895 - mse: 0.1969 - val_loss: 0.0899 - val_mae: 0.2708 - val_mse: 0.0899
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1742 - mae: 0.3516 - mse: 0.1742
64/93 [===================>..........] - ETA: 0s - loss: 0.1524 - mae: 0.3260 - mse: 0.1524
93/93 [==============================] - 0s 5ms/step - loss: 0.1830 - mae: 0.3529 - mse: 0.1830 - val_loss: 0.0613 - val_mae: 0.2275 - val_mse: 0.0613
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1820 - mae: 0.3532 - mse: 0.1820
64/93 [===================>..........] - ETA: 0s - loss: 0.1397 - mae: 0.3037 - mse: 0.1397
93/93 [==============================] - 0s 5ms/step - loss: 0.1444 - mae: 0.3183 - mse: 0.1444 - val_loss: 0.0667 - val_mae: 0.2223 - val_mse: 0.0667
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1344 - mae: 0.2949 - mse: 0.1344
64/93 [===================>..........] - ETA: 0s - loss: 0.1246 - mae: 0.2900 - mse: 0.1246
93/93 [==============================] - 0s 5ms/step - loss: 0.1150 - mae: 0.2782 - mse: 0.1150 - val_loss: 0.0559 - val_mae: 0.1958 - val_mse: 0.0559
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1343 - mae: 0.3029 - mse: 0.1343
64/93 [===================>..........] - ETA: 0s - loss: 0.1038 - mae: 0.2646 - mse: 0.1038
93/93 [==============================] - 1s 6ms/step - loss: 0.0995 - mae: 0.2514 - mse: 0.0995 - val_loss: 0.0296 - val_mae: 0.1451 - val_mse: 0.0296
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0850 - mae: 0.2146 - mse: 0.0850
64/93 [===================>..........] - ETA: 0s - loss: 0.0901 - mae: 0.2376 - mse: 0.0901
93/93 [==============================] - 1s 7ms/step - loss: 0.0860 - mae: 0.2326 - mse: 0.0860 - val_loss: 0.0203 - val_mae: 0.1187 - val_mse: 0.0203
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1210 - mae: 0.2874 - mse: 0.1210
64/93 [===================>..........] - ETA: 0s - loss: 0.0928 - mae: 0.2387 - mse: 0.0928
93/93 [==============================] - 0s 5ms/step - loss: 0.0894 - mae: 0.2346 - mse: 0.0894 - val_loss: 0.0162 - val_mae: 0.1030 - val_mse: 0.0162
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0666 - mae: 0.2115 - mse: 0.0666
64/93 [===================>..........] - ETA: 0s - loss: 0.0728 - mae: 0.2179 - mse: 0.0728
93/93 [==============================] - 1s 6ms/step - loss: 0.0778 - mae: 0.2124 - mse: 0.0778 - val_loss: 0.0251 - val_mae: 0.1259 - val_mse: 0.0251
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0542 - mae: 0.1623 - mse: 0.0542
64/93 [===================>..........] - ETA: 0s - loss: 0.0775 - mae: 0.2038 - mse: 0.0775
93/93 [==============================] - 1s 6ms/step - loss: 0.0728 - mae: 0.1974 - mse: 0.0728 - val_loss: 0.0230 - val_mae: 0.1272 - val_mse: 0.0230
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0746 - mae: 0.2088 - mse: 0.0746
64/93 [===================>..........] - ETA: 0s - loss: 0.0763 - mae: 0.2134 - mse: 0.0763
93/93 [==============================] - 0s 5ms/step - loss: 0.0695 - mae: 0.2082 - mse: 0.0695 - val_loss: 0.0129 - val_mae: 0.0981 - val_mse: 0.0129
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0944 - mae: 0.2353 - mse: 0.0944
64/93 [===================>..........] - ETA: 0s - loss: 0.0633 - mae: 0.1885 - mse: 0.0633
93/93 [==============================] - 0s 5ms/step - loss: 0.0622 - mae: 0.1875 - mse: 0.0622 - val_loss: 0.0122 - val_mae: 0.0986 - val_mse: 0.0122
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0820 - mae: 0.2236 - mse: 0.0820
64/93 [===================>..........] - ETA: 0s - loss: 0.0714 - mae: 0.2134 - mse: 0.0714
93/93 [==============================] - 1s 7ms/step - loss: 0.0642 - mae: 0.2068 - mse: 0.0642 - val_loss: 0.0189 - val_mae: 0.1231 - val_mse: 0.0189
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0410 - mae: 0.1533 - mse: 0.0410
64/93 [===================>..........] - ETA: 0s - loss: 0.0632 - mae: 0.1867 - mse: 0.0632
93/93 [==============================] - 0s 4ms/step - loss: 0.0551 - mae: 0.1780 - mse: 0.0551 - val_loss: 0.0197 - val_mae: 0.1231 - val_mse: 0.0197
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0502 - mae: 0.1673 - mse: 0.0502
64/93 [===================>..........] - ETA: 0s - loss: 0.0403 - mae: 0.1536 - mse: 0.0403
93/93 [==============================] - 0s 5ms/step - loss: 0.0471 - mae: 0.1649 - mse: 0.0471 - val_loss: 0.0125 - val_mae: 0.1006 - val_mse: 0.0125
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0390 - mae: 0.1658 - mse: 0.0390
64/93 [===================>..........] - ETA: 0s - loss: 0.0425 - mae: 0.1723 - mse: 0.0425
93/93 [==============================] - 0s 5ms/step - loss: 0.0420 - mae: 0.1677 - mse: 0.0420 - val_loss: 0.0098 - val_mae: 0.0883 - val_mse: 0.0098
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0567 - mae: 0.1895 - mse: 0.0567
64/93 [===================>..........] - ETA: 0s - loss: 0.0435 - mae: 0.1569 - mse: 0.0435
93/93 [==============================] - 0s 5ms/step - loss: 0.0464 - mae: 0.1629 - mse: 0.0464 - val_loss: 0.0124 - val_mae: 0.1064 - val_mse: 0.0124
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0213 - mae: 0.1150 - mse: 0.0213
64/93 [===================>..........] - ETA: 0s - loss: 0.0245 - mae: 0.1234 - mse: 0.0245
93/93 [==============================] - 0s 5ms/step - loss: 0.0311 - mae: 0.1294 - mse: 0.0311 - val_loss: 0.0174 - val_mae: 0.1253 - val_mse: 0.0174
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0151 - mae: 0.0986 - mse: 0.0151
64/93 [===================>..........] - ETA: 0s - loss: 0.0303 - mae: 0.1248 - mse: 0.0303
93/93 [==============================] - 0s 5ms/step - loss: 0.0311 - mae: 0.1237 - mse: 0.0311 - val_loss: 0.0144 - val_mae: 0.1139 - val_mse: 0.0144
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0276 - mae: 0.1167 - mse: 0.0276
64/93 [===================>..........] - ETA: 0s - loss: 0.0291 - mae: 0.1256 - mse: 0.0291
93/93 [==============================] - 0s 5ms/step - loss: 0.0316 - mae: 0.1362 - mse: 0.0316 - val_loss: 0.0168 - val_mae: 0.1218 - val_mse: 0.0168
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0262 - mae: 0.1217 - mse: 0.0262
64/93 [===================>..........] - ETA: 0s - loss: 0.0340 - mae: 0.1459 - mse: 0.0340
93/93 [==============================] - 1s 6ms/step - loss: 0.0332 - mae: 0.1426 - mse: 0.0332 - val_loss: 0.0424 - val_mae: 0.1911 - val_mse: 0.0424
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0492 - mae: 0.1668 - mse: 0.0492
64/93 [===================>..........] - ETA: 0s - loss: 0.0510 - mae: 0.1654 - mse: 0.0510
93/93 [==============================] - 0s 5ms/step - loss: 0.0449 - mae: 0.1627 - mse: 0.0449 - val_loss: 0.0295 - val_mae: 0.1598 - val_mse: 0.0295
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0223 - mae: 0.1129 - mse: 0.0223
64/93 [===================>..........] - ETA: 0s - loss: 0.0262 - mae: 0.1165 - mse: 0.0262
93/93 [==============================] - 0s 5ms/step - loss: 0.0240 - mae: 0.1128 - mse: 0.0240 - val_loss: 0.0084 - val_mae: 0.0858 - val_mse: 0.0084
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0445 - mae: 0.1638 - mse: 0.0445
64/93 [===================>..........] - ETA: 0s - loss: 0.0334 - mae: 0.1410 - mse: 0.0334
93/93 [==============================] - 0s 5ms/step - loss: 0.0421 - mae: 0.1487 - mse: 0.0421 - val_loss: 0.0159 - val_mae: 0.1181 - val_mse: 0.0159
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0461 - mae: 0.1454 - mse: 0.0461
64/93 [===================>..........] - ETA: 0s - loss: 0.0345 - mae: 0.1355 - mse: 0.0345
93/93 [==============================] - 0s 5ms/step - loss: 0.0369 - mae: 0.1387 - mse: 0.0369 - val_loss: 0.0363 - val_mae: 0.1761 - val_mse: 0.0363
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0287 - mae: 0.1450 - mse: 0.0287
64/93 [===================>..........] - ETA: 0s - loss: 0.0289 - mae: 0.1439 - mse: 0.0289
93/93 [==============================] - 0s 5ms/step - loss: 0.0355 - mae: 0.1470 - mse: 0.0355 - val_loss: 0.0137 - val_mae: 0.1107 - val_mse: 0.0137
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0255 - mae: 0.1260 - mse: 0.0255
64/93 [===================>..........] - ETA: 0s - loss: 0.0226 - mae: 0.1140 - mse: 0.0226
93/93 [==============================] - 0s 5ms/step - loss: 0.0261 - mae: 0.1214 - mse: 0.0261 - val_loss: 0.0061 - val_mae: 0.0715 - val_mse: 0.0061
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0301 - mae: 0.1392 - mse: 0.0301
64/93 [===================>..........] - ETA: 0s - loss: 0.0270 - mae: 0.1310 - mse: 0.0270
93/93 [==============================] - 0s 4ms/step - loss: 0.0282 - mae: 0.1299 - mse: 0.0282 - val_loss: 0.0226 - val_mae: 0.1317 - val_mse: 0.0226
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0254 - mae: 0.1321 - mse: 0.0254
64/93 [===================>..........] - ETA: 0s - loss: 0.0256 - mae: 0.1281 - mse: 0.0256
93/93 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1379 - mse: 0.0326 - val_loss: 0.0418 - val_mae: 0.1883 - val_mse: 0.0418
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0219 - mae: 0.1149 - mse: 0.0219
64/93 [===================>..........] - ETA: 0s - loss: 0.0334 - mae: 0.1431 - mse: 0.0334
93/93 [==============================] - 0s 4ms/step - loss: 0.0351 - mae: 0.1417 - mse: 0.0351 - val_loss: 0.0143 - val_mae: 0.1077 - val_mse: 0.0143
Saving trained model...
89
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         23.47518921]
average prediction= [2.8290365]
baseline= 7.314814814814815
eachuser= [0. 0. 0. 0. 0. 5.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 4.695037841796875
