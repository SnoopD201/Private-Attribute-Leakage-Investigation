['train-height-12.py', '0']
155 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
155 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
155 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
155 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
170 31
170 32
170 33
170 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
170 37
170 38
2_170_60_12_csi_a12_4.dat
170 40
165 41
165 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
165 48
165 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
165 56
165 57
1_165_65_12_csi_a12_7.dat
165 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
165 70
2_165_50_12_csi_a12_13.dat
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
2_165_50_12_csi_a12_7.dat
165 87
2_165_50_12_csi_a12_23.dat
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
1_175_70_12_csi_a12_26.dat
175 127
175 128
175 129
175 130
180 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
180 134
180 135
1_180_85_12_csi_a12_19.dat
180 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
180 140
1_180_85_12_csi_a12_12.dat
180 142
180 143
180 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
180 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
180 161
180 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
180 165
180 166
180 167
180 168
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
1_180_75_12_csi_a12_12.dat
180 178
1_180_75_12_csi_a12_13.dat
180 180
180 181
180 182
1_180_75_12_csi_a12_14.dat
180 184
180 185
180 186
180 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
180 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[155 155 155 155 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.5560 - mae: 0.7032 - mse: 0.5560
64/75 [========================>.....] - ETA: 0s - loss: 0.4966 - mae: 0.6557 - mse: 0.4966
75/75 [==============================] - 1s 14ms/step - loss: 0.4917 - mae: 0.6544 - mse: 0.4917 - val_loss: 0.3434 - val_mae: 0.5052 - val_mse: 0.3434
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.3100 - mae: 0.4989 - mse: 0.3100
64/75 [========================>.....] - ETA: 0s - loss: 0.2626 - mae: 0.4431 - mse: 0.2626
75/75 [==============================] - 1s 8ms/step - loss: 0.2547 - mae: 0.4348 - mse: 0.2547 - val_loss: 0.1383 - val_mae: 0.3299 - val_mse: 0.1383
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1308 - mae: 0.3272 - mse: 0.1308
64/75 [========================>.....] - ETA: 0s - loss: 0.1409 - mae: 0.3396 - mse: 0.1409
75/75 [==============================] - 1s 9ms/step - loss: 0.1366 - mae: 0.3299 - mse: 0.1366 - val_loss: 0.1026 - val_mae: 0.2938 - val_mse: 0.1026
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1785 - mae: 0.3448 - mse: 0.1785
64/75 [========================>.....] - ETA: 0s - loss: 0.1477 - mae: 0.2986 - mse: 0.1477
75/75 [==============================] - 1s 10ms/step - loss: 0.1499 - mae: 0.3002 - mse: 0.1499 - val_loss: 0.0819 - val_mae: 0.2791 - val_mse: 0.0819
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1200 - mae: 0.2904 - mse: 0.1200
64/75 [========================>.....] - ETA: 0s - loss: 0.1035 - mae: 0.2726 - mse: 0.1035
75/75 [==============================] - 1s 9ms/step - loss: 0.0997 - mae: 0.2674 - mse: 0.0997 - val_loss: 0.0955 - val_mae: 0.2743 - val_mse: 0.0955
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0824 - mae: 0.2502 - mse: 0.0824
64/75 [========================>.....] - ETA: 0s - loss: 0.0844 - mae: 0.2529 - mse: 0.0844
75/75 [==============================] - 1s 9ms/step - loss: 0.0786 - mae: 0.2390 - mse: 0.0786 - val_loss: 0.0968 - val_mae: 0.2599 - val_mse: 0.0968
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0876 - mae: 0.2564 - mse: 0.0876
64/75 [========================>.....] - ETA: 0s - loss: 0.0753 - mae: 0.2339 - mse: 0.0753
75/75 [==============================] - 1s 9ms/step - loss: 0.0772 - mae: 0.2377 - mse: 0.0772 - val_loss: 0.0728 - val_mae: 0.2342 - val_mse: 0.0728
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0478 - mae: 0.1795 - mse: 0.0478
64/75 [========================>.....] - ETA: 0s - loss: 0.0466 - mae: 0.1803 - mse: 0.0466
75/75 [==============================] - 1s 9ms/step - loss: 0.0478 - mae: 0.1844 - mse: 0.0478 - val_loss: 0.0504 - val_mae: 0.2050 - val_mse: 0.0504
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0463 - mae: 0.1751 - mse: 0.0463
64/75 [========================>.....] - ETA: 0s - loss: 0.0539 - mae: 0.1829 - mse: 0.0539
75/75 [==============================] - 1s 9ms/step - loss: 0.0492 - mae: 0.1736 - mse: 0.0492 - val_loss: 0.0423 - val_mae: 0.1858 - val_mse: 0.0423
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0667 - mae: 0.1861 - mse: 0.0667
64/75 [========================>.....] - ETA: 0s - loss: 0.0518 - mae: 0.1742 - mse: 0.0518
75/75 [==============================] - 1s 9ms/step - loss: 0.0500 - mae: 0.1748 - mse: 0.0500 - val_loss: 0.0436 - val_mae: 0.1812 - val_mse: 0.0436
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0455 - mae: 0.1463 - mse: 0.0455
64/75 [========================>.....] - ETA: 0s - loss: 0.0517 - mae: 0.1713 - mse: 0.0517
75/75 [==============================] - 1s 10ms/step - loss: 0.0512 - mae: 0.1718 - mse: 0.0512 - val_loss: 0.0486 - val_mae: 0.1912 - val_mse: 0.0486
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0381 - mae: 0.1510 - mse: 0.0381
64/75 [========================>.....] - ETA: 0s - loss: 0.0405 - mae: 0.1528 - mse: 0.0405
75/75 [==============================] - 1s 9ms/step - loss: 0.0370 - mae: 0.1454 - mse: 0.0370 - val_loss: 0.0435 - val_mae: 0.1833 - val_mse: 0.0435
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0350 - mae: 0.1424 - mse: 0.0350
64/75 [========================>.....] - ETA: 0s - loss: 0.0366 - mae: 0.1303 - mse: 0.0366
75/75 [==============================] - 1s 9ms/step - loss: 0.0361 - mae: 0.1338 - mse: 0.0361 - val_loss: 0.0332 - val_mae: 0.1639 - val_mse: 0.0332
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0435 - mae: 0.1360 - mse: 0.0435
64/75 [========================>.....] - ETA: 0s - loss: 0.0374 - mae: 0.1377 - mse: 0.0374
75/75 [==============================] - 1s 8ms/step - loss: 0.0334 - mae: 0.1291 - mse: 0.0334 - val_loss: 0.0268 - val_mae: 0.1470 - val_mse: 0.0268
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0239 - mae: 0.1123 - mse: 0.0239
64/75 [========================>.....] - ETA: 0s - loss: 0.0370 - mae: 0.1341 - mse: 0.0370
75/75 [==============================] - 1s 9ms/step - loss: 0.0352 - mae: 0.1305 - mse: 0.0352 - val_loss: 0.0325 - val_mae: 0.1588 - val_mse: 0.0325
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0311 - mae: 0.1361 - mse: 0.0311
64/75 [========================>.....] - ETA: 0s - loss: 0.0373 - mae: 0.1361 - mse: 0.0373
75/75 [==============================] - 1s 8ms/step - loss: 0.0359 - mae: 0.1359 - mse: 0.0359 - val_loss: 0.0359 - val_mae: 0.1626 - val_mse: 0.0359
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0189 - mae: 0.1033 - mse: 0.0189
64/75 [========================>.....] - ETA: 0s - loss: 0.0318 - mae: 0.1261 - mse: 0.0318
75/75 [==============================] - 1s 9ms/step - loss: 0.0310 - mae: 0.1288 - mse: 0.0310 - val_loss: 0.0334 - val_mae: 0.1558 - val_mse: 0.0334
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0222 - mae: 0.1107 - mse: 0.0222
64/75 [========================>.....] - ETA: 0s - loss: 0.0310 - mae: 0.1231 - mse: 0.0310
75/75 [==============================] - 1s 8ms/step - loss: 0.0288 - mae: 0.1188 - mse: 0.0288 - val_loss: 0.0270 - val_mae: 0.1403 - val_mse: 0.0270
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0316 - mae: 0.1339 - mse: 0.0316
64/75 [========================>.....] - ETA: 0s - loss: 0.0310 - mae: 0.1153 - mse: 0.0310
75/75 [==============================] - 1s 8ms/step - loss: 0.0290 - mae: 0.1140 - mse: 0.0290 - val_loss: 0.0219 - val_mae: 0.1265 - val_mse: 0.0219
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0205 - mae: 0.1159 - mse: 0.0205
64/75 [========================>.....] - ETA: 0s - loss: 0.0253 - mae: 0.1110 - mse: 0.0253
75/75 [==============================] - 1s 8ms/step - loss: 0.0230 - mae: 0.1049 - mse: 0.0230 - val_loss: 0.0224 - val_mae: 0.1269 - val_mse: 0.0224
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0343 - mae: 0.1372 - mse: 0.0343
64/75 [========================>.....] - ETA: 0s - loss: 0.0250 - mae: 0.1158 - mse: 0.0250
75/75 [==============================] - 1s 9ms/step - loss: 0.0243 - mae: 0.1150 - mse: 0.0243 - val_loss: 0.0254 - val_mae: 0.1298 - val_mse: 0.0254
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0184 - mae: 0.0994 - mse: 0.0184
64/75 [========================>.....] - ETA: 0s - loss: 0.0242 - mae: 0.1032 - mse: 0.0242
75/75 [==============================] - 1s 8ms/step - loss: 0.0255 - mae: 0.1109 - mse: 0.0255 - val_loss: 0.0158 - val_mae: 0.1068 - val_mse: 0.0158
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0491 - mae: 0.1465 - mse: 0.0491
64/75 [========================>.....] - ETA: 0s - loss: 0.0333 - mae: 0.1230 - mse: 0.0333
75/75 [==============================] - 1s 8ms/step - loss: 0.0308 - mae: 0.1178 - mse: 0.0308 - val_loss: 0.0157 - val_mae: 0.1041 - val_mse: 0.0157
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0294 - mae: 0.1040 - mse: 0.0294
64/75 [========================>.....] - ETA: 0s - loss: 0.0257 - mae: 0.1066 - mse: 0.0257
75/75 [==============================] - 1s 9ms/step - loss: 0.0256 - mae: 0.1069 - mse: 0.0256 - val_loss: 0.0265 - val_mae: 0.1295 - val_mse: 0.0265
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0132 - mae: 0.0930 - mse: 0.0132
64/75 [========================>.....] - ETA: 0s - loss: 0.0207 - mae: 0.1018 - mse: 0.0207
75/75 [==============================] - 0s 6ms/step - loss: 0.0188 - mae: 0.0961 - mse: 0.0188 - val_loss: 0.0233 - val_mae: 0.1215 - val_mse: 0.0233
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0130 - mae: 0.0896 - mse: 0.0130
64/75 [========================>.....] - ETA: 0s - loss: 0.0133 - mae: 0.0910 - mse: 0.0133
75/75 [==============================] - 0s 6ms/step - loss: 0.0198 - mae: 0.1001 - mse: 0.0198 - val_loss: 0.0159 - val_mae: 0.0981 - val_mse: 0.0159
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0268 - mae: 0.1025 - mse: 0.0268
64/75 [========================>.....] - ETA: 0s - loss: 0.0222 - mae: 0.1021 - mse: 0.0222
75/75 [==============================] - 0s 6ms/step - loss: 0.0209 - mae: 0.0994 - mse: 0.0209 - val_loss: 0.0229 - val_mae: 0.1257 - val_mse: 0.0229
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0330 - mae: 0.1160 - mse: 0.0330
64/75 [========================>.....] - ETA: 0s - loss: 0.0231 - mae: 0.1022 - mse: 0.0231
75/75 [==============================] - 0s 6ms/step - loss: 0.0203 - mae: 0.0956 - mse: 0.0203 - val_loss: 0.0276 - val_mae: 0.1412 - val_mse: 0.0276
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0373 - mae: 0.1306 - mse: 0.0373
64/75 [========================>.....] - ETA: 0s - loss: 0.0331 - mae: 0.1305 - mse: 0.0331
75/75 [==============================] - 0s 5ms/step - loss: 0.0314 - mae: 0.1288 - mse: 0.0314 - val_loss: 0.0225 - val_mae: 0.1261 - val_mse: 0.0225
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0143 - mae: 0.0863 - mse: 0.0143
64/75 [========================>.....] - ETA: 0s - loss: 0.0153 - mae: 0.0960 - mse: 0.0153
75/75 [==============================] - 0s 6ms/step - loss: 0.0234 - mae: 0.1020 - mse: 0.0234 - val_loss: 0.0158 - val_mae: 0.1035 - val_mse: 0.0158
Saving trained model...
115
Testing...
heightdiff= [ 0.          0.          0.          0.         37.90170288]
average prediction= [4.5251226]
baseline= 7.642857142857143
eachuser= [0. 0. 0. 0. 3.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 12.633900960286459
['train-height-12.py', '0']
155 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
155 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
155 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
155 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
170 31
170 32
170 33
170 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
170 37
170 38
2_170_60_12_csi_a12_4.dat
170 40
165 41
165 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
165 48
165 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
165 56
165 57
1_165_65_12_csi_a12_7.dat
165 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
165 70
2_165_50_12_csi_a12_13.dat
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
2_165_50_12_csi_a12_7.dat
165 87
2_165_50_12_csi_a12_23.dat
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
1_175_70_12_csi_a12_26.dat
175 127
175 128
175 129
175 130
180 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
180 134
180 135
1_180_85_12_csi_a12_19.dat
180 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
180 140
1_180_85_12_csi_a12_12.dat
180 142
180 143
180 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
180 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
180 161
180 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
180 165
180 166
180 167
180 168
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
1_180_75_12_csi_a12_12.dat
180 178
1_180_75_12_csi_a12_13.dat
180 180
180 181
180 182
1_180_75_12_csi_a12_14.dat
180 184
180 185
180 186
180 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
180 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[155 155 155 155 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.8780 - mae: 0.9026 - mse: 0.8780
64/75 [========================>.....] - ETA: 0s - loss: 0.6544 - mae: 0.7503 - mse: 0.6544
75/75 [==============================] - 1s 14ms/step - loss: 0.6026 - mae: 0.7135 - mse: 0.6026 - val_loss: 0.2572 - val_mae: 0.4303 - val_mse: 0.2572
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.2224 - mae: 0.4122 - mse: 0.2224
64/75 [========================>.....] - ETA: 0s - loss: 0.2032 - mae: 0.3939 - mse: 0.2032
75/75 [==============================] - 1s 8ms/step - loss: 0.1844 - mae: 0.3696 - mse: 0.1844 - val_loss: 0.0466 - val_mae: 0.2085 - val_mse: 0.0466
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1840 - mae: 0.3097 - mse: 0.1840
64/75 [========================>.....] - ETA: 0s - loss: 0.1332 - mae: 0.2689 - mse: 0.1332
75/75 [==============================] - 1s 8ms/step - loss: 0.1254 - mae: 0.2633 - mse: 0.1254 - val_loss: 0.0435 - val_mae: 0.1744 - val_mse: 0.0435
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0844 - mae: 0.2443 - mse: 0.0844
64/75 [========================>.....] - ETA: 0s - loss: 0.1403 - mae: 0.2861 - mse: 0.1403
75/75 [==============================] - 1s 8ms/step - loss: 0.1256 - mae: 0.2654 - mse: 0.1256 - val_loss: 0.0521 - val_mae: 0.2162 - val_mse: 0.0521
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1001 - mae: 0.2404 - mse: 0.1001
64/75 [========================>.....] - ETA: 0s - loss: 0.1105 - mae: 0.2580 - mse: 0.1105
75/75 [==============================] - 1s 9ms/step - loss: 0.1090 - mae: 0.2597 - mse: 0.1090 - val_loss: 0.0886 - val_mae: 0.2417 - val_mse: 0.0886
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0957 - mae: 0.2627 - mse: 0.0957
64/75 [========================>.....] - ETA: 0s - loss: 0.0859 - mae: 0.2241 - mse: 0.0859
75/75 [==============================] - 1s 8ms/step - loss: 0.0870 - mae: 0.2282 - mse: 0.0870 - val_loss: 0.1068 - val_mae: 0.2496 - val_mse: 0.1068
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0850 - mae: 0.2314 - mse: 0.0850
64/75 [========================>.....] - ETA: 0s - loss: 0.0772 - mae: 0.2142 - mse: 0.0772
75/75 [==============================] - 1s 7ms/step - loss: 0.0764 - mae: 0.2107 - mse: 0.0764 - val_loss: 0.0895 - val_mae: 0.2279 - val_mse: 0.0895
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0547 - mae: 0.1820 - mse: 0.0547
64/75 [========================>.....] - ETA: 0s - loss: 0.0604 - mae: 0.1854 - mse: 0.0604
75/75 [==============================] - 1s 7ms/step - loss: 0.0662 - mae: 0.1908 - mse: 0.0662 - val_loss: 0.0611 - val_mae: 0.1905 - val_mse: 0.0611
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0510 - mae: 0.1790 - mse: 0.0510
64/75 [========================>.....] - ETA: 0s - loss: 0.0527 - mae: 0.1747 - mse: 0.0527
75/75 [==============================] - 1s 8ms/step - loss: 0.0623 - mae: 0.1910 - mse: 0.0623 - val_loss: 0.0379 - val_mae: 0.1506 - val_mse: 0.0379
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0828 - mae: 0.2031 - mse: 0.0828
64/75 [========================>.....] - ETA: 0s - loss: 0.0682 - mae: 0.1837 - mse: 0.0682
75/75 [==============================] - 1s 8ms/step - loss: 0.0654 - mae: 0.1827 - mse: 0.0654 - val_loss: 0.0328 - val_mae: 0.1403 - val_mse: 0.0328
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0886 - mae: 0.2244 - mse: 0.0886
64/75 [========================>.....] - ETA: 0s - loss: 0.0801 - mae: 0.2109 - mse: 0.0801
75/75 [==============================] - 1s 8ms/step - loss: 0.0748 - mae: 0.2043 - mse: 0.0748 - val_loss: 0.0426 - val_mae: 0.1605 - val_mse: 0.0426
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0541 - mae: 0.1717 - mse: 0.0541
64/75 [========================>.....] - ETA: 0s - loss: 0.0612 - mae: 0.1809 - mse: 0.0612
75/75 [==============================] - 1s 9ms/step - loss: 0.0561 - mae: 0.1734 - mse: 0.0561 - val_loss: 0.0503 - val_mae: 0.1724 - val_mse: 0.0503
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0575 - mae: 0.1595 - mse: 0.0575
64/75 [========================>.....] - ETA: 0s - loss: 0.0506 - mae: 0.1581 - mse: 0.0506
75/75 [==============================] - 1s 8ms/step - loss: 0.0632 - mae: 0.1745 - mse: 0.0632 - val_loss: 0.0479 - val_mae: 0.1680 - val_mse: 0.0479
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0312 - mae: 0.1391 - mse: 0.0312
64/75 [========================>.....] - ETA: 0s - loss: 0.0542 - mae: 0.1671 - mse: 0.0542
75/75 [==============================] - 1s 8ms/step - loss: 0.0480 - mae: 0.1556 - mse: 0.0480 - val_loss: 0.0411 - val_mae: 0.1554 - val_mse: 0.0411
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0620 - mae: 0.1613 - mse: 0.0620
64/75 [========================>.....] - ETA: 0s - loss: 0.0463 - mae: 0.1501 - mse: 0.0463
75/75 [==============================] - 1s 8ms/step - loss: 0.0422 - mae: 0.1459 - mse: 0.0422 - val_loss: 0.0327 - val_mae: 0.1378 - val_mse: 0.0327
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0402 - mae: 0.1447 - mse: 0.0402
64/75 [========================>.....] - ETA: 0s - loss: 0.0354 - mae: 0.1360 - mse: 0.0354
75/75 [==============================] - 1s 8ms/step - loss: 0.0331 - mae: 0.1316 - mse: 0.0331 - val_loss: 0.0239 - val_mae: 0.1176 - val_mse: 0.0239
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0440 - mae: 0.1525 - mse: 0.0440
64/75 [========================>.....] - ETA: 0s - loss: 0.0417 - mae: 0.1423 - mse: 0.0417
75/75 [==============================] - 1s 8ms/step - loss: 0.0385 - mae: 0.1369 - mse: 0.0385 - val_loss: 0.0258 - val_mae: 0.1280 - val_mse: 0.0258
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0220 - mae: 0.1105 - mse: 0.0220
64/75 [========================>.....] - ETA: 0s - loss: 0.0582 - mae: 0.1600 - mse: 0.0582
75/75 [==============================] - 1s 7ms/step - loss: 0.0519 - mae: 0.1513 - mse: 0.0519 - val_loss: 0.0252 - val_mae: 0.1311 - val_mse: 0.0252
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0257 - mae: 0.1124 - mse: 0.0257
64/75 [========================>.....] - ETA: 0s - loss: 0.0352 - mae: 0.1342 - mse: 0.0352
75/75 [==============================] - 0s 6ms/step - loss: 0.0353 - mae: 0.1320 - mse: 0.0353 - val_loss: 0.0216 - val_mae: 0.1249 - val_mse: 0.0216
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0143 - mae: 0.0973 - mse: 0.0143
64/75 [========================>.....] - ETA: 0s - loss: 0.0296 - mae: 0.1176 - mse: 0.0296
75/75 [==============================] - 0s 6ms/step - loss: 0.0291 - mae: 0.1198 - mse: 0.0291 - val_loss: 0.0179 - val_mae: 0.1162 - val_mse: 0.0179
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0372 - mae: 0.1346 - mse: 0.0372
64/75 [========================>.....] - ETA: 0s - loss: 0.0329 - mae: 0.1299 - mse: 0.0329
75/75 [==============================] - 0s 6ms/step - loss: 0.0316 - mae: 0.1285 - mse: 0.0316 - val_loss: 0.0084 - val_mae: 0.0772 - val_mse: 0.0084
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0290 - mae: 0.1258 - mse: 0.0290
64/75 [========================>.....] - ETA: 0s - loss: 0.0311 - mae: 0.1334 - mse: 0.0311
75/75 [==============================] - 0s 5ms/step - loss: 0.0310 - mae: 0.1355 - mse: 0.0310 - val_loss: 0.0130 - val_mae: 0.0977 - val_mse: 0.0130
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0268 - mae: 0.1189 - mse: 0.0268
64/75 [========================>.....] - ETA: 0s - loss: 0.0264 - mae: 0.1217 - mse: 0.0264
75/75 [==============================] - 0s 6ms/step - loss: 0.0280 - mae: 0.1246 - mse: 0.0280 - val_loss: 0.0291 - val_mae: 0.1529 - val_mse: 0.0291
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0174 - mae: 0.1029 - mse: 0.0174
64/75 [========================>.....] - ETA: 0s - loss: 0.0240 - mae: 0.1189 - mse: 0.0240
75/75 [==============================] - 0s 6ms/step - loss: 0.0245 - mae: 0.1231 - mse: 0.0245 - val_loss: 0.0112 - val_mae: 0.0919 - val_mse: 0.0112
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0177 - mae: 0.1018 - mse: 0.0177
64/75 [========================>.....] - ETA: 0s - loss: 0.0158 - mae: 0.0986 - mse: 0.0158
75/75 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 0.1011 - mse: 0.0171 - val_loss: 0.0026 - val_mae: 0.0415 - val_mse: 0.0026
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0365 - mae: 0.1377 - mse: 0.0365
64/75 [========================>.....] - ETA: 0s - loss: 0.0260 - mae: 0.1156 - mse: 0.0260
75/75 [==============================] - 0s 5ms/step - loss: 0.0273 - mae: 0.1190 - mse: 0.0273 - val_loss: 0.0087 - val_mae: 0.0832 - val_mse: 0.0087
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0237 - mae: 0.1105 - mse: 0.0237
64/75 [========================>.....] - ETA: 0s - loss: 0.0229 - mae: 0.1170 - mse: 0.0229
75/75 [==============================] - 0s 6ms/step - loss: 0.0216 - mae: 0.1140 - mse: 0.0216 - val_loss: 0.0270 - val_mae: 0.1529 - val_mse: 0.0270
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0320 - mae: 0.1346 - mse: 0.0320
64/75 [========================>.....] - ETA: 0s - loss: 0.0268 - mae: 0.1216 - mse: 0.0268
75/75 [==============================] - 0s 6ms/step - loss: 0.0271 - mae: 0.1225 - mse: 0.0271 - val_loss: 0.0078 - val_mae: 0.0813 - val_mse: 0.0078
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0175 - mae: 0.1017 - mse: 0.0175
64/75 [========================>.....] - ETA: 0s - loss: 0.0207 - mae: 0.1068 - mse: 0.0207
75/75 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 0.1046 - mse: 0.0205 - val_loss: 0.0028 - val_mae: 0.0483 - val_mse: 0.0028
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0198 - mae: 0.1043 - mse: 0.0198
64/75 [========================>.....] - ETA: 0s - loss: 0.0191 - mae: 0.1000 - mse: 0.0191
75/75 [==============================] - 0s 5ms/step - loss: 0.0215 - mae: 0.1033 - mse: 0.0215 - val_loss: 0.0121 - val_mae: 0.0958 - val_mse: 0.0121
Saving trained model...
115
Testing...
heightdiff= [0.         0.         0.         0.         4.93338013]
average prediction= [4.52902]
baseline= 6.690476190476191
eachuser= [0. 0. 0. 0. 1.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 4.933380126953125
['train-height-12.py', '0']
155 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
155 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
155 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
155 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
170 31
170 32
170 33
170 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
170 37
170 38
2_170_60_12_csi_a12_4.dat
170 40
165 41
165 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
165 48
165 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
165 56
165 57
1_165_65_12_csi_a12_7.dat
165 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
165 70
2_165_50_12_csi_a12_13.dat
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
2_165_50_12_csi_a12_7.dat
165 87
2_165_50_12_csi_a12_23.dat
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
1_175_70_12_csi_a12_26.dat
175 127
175 128
175 129
175 130
180 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
180 134
180 135
1_180_85_12_csi_a12_19.dat
180 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
180 140
1_180_85_12_csi_a12_12.dat
180 142
180 143
180 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
180 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
180 161
180 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
180 165
180 166
180 167
180 168
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
1_180_75_12_csi_a12_12.dat
180 178
1_180_75_12_csi_a12_13.dat
180 180
180 181
180 182
1_180_75_12_csi_a12_14.dat
180 184
180 185
180 186
180 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
180 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[155 155 155 155 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.6218 - mae: 0.7247 - mse: 0.6218
64/75 [========================>.....] - ETA: 0s - loss: 0.4767 - mae: 0.6168 - mse: 0.4767
75/75 [==============================] - 1s 10ms/step - loss: 0.4458 - mae: 0.5929 - mse: 0.4458 - val_loss: 0.1197 - val_mae: 0.2934 - val_mse: 0.1197
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1109 - mae: 0.2758 - mse: 0.1109
64/75 [========================>.....] - ETA: 0s - loss: 0.1698 - mae: 0.3212 - mse: 0.1698
75/75 [==============================] - 0s 6ms/step - loss: 0.1973 - mae: 0.3376 - mse: 0.1973 - val_loss: 0.1230 - val_mae: 0.3208 - val_mse: 0.1230
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.2368 - mae: 0.3558 - mse: 0.2368
64/75 [========================>.....] - ETA: 0s - loss: 0.1887 - mae: 0.3168 - mse: 0.1887
75/75 [==============================] - 0s 5ms/step - loss: 0.1708 - mae: 0.3035 - mse: 0.1708 - val_loss: 0.0963 - val_mae: 0.2621 - val_mse: 0.0963
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1052 - mae: 0.2754 - mse: 0.1052
64/75 [========================>.....] - ETA: 0s - loss: 0.0981 - mae: 0.2569 - mse: 0.0981
75/75 [==============================] - 0s 6ms/step - loss: 0.0964 - mae: 0.2548 - mse: 0.0964 - val_loss: 0.1303 - val_mae: 0.2713 - val_mse: 0.1303
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1070 - mae: 0.2796 - mse: 0.1070
64/75 [========================>.....] - ETA: 0s - loss: 0.1017 - mae: 0.2707 - mse: 0.1017
75/75 [==============================] - 0s 6ms/step - loss: 0.1031 - mae: 0.2718 - mse: 0.1031 - val_loss: 0.1364 - val_mae: 0.2803 - val_mse: 0.1364
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0660 - mae: 0.2111 - mse: 0.0660
64/75 [========================>.....] - ETA: 0s - loss: 0.0921 - mae: 0.2501 - mse: 0.0921
75/75 [==============================] - 0s 6ms/step - loss: 0.0930 - mae: 0.2463 - mse: 0.0930 - val_loss: 0.1016 - val_mae: 0.2385 - val_mse: 0.1016
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0997 - mae: 0.2461 - mse: 0.0997
64/75 [========================>.....] - ETA: 0s - loss: 0.0839 - mae: 0.2348 - mse: 0.0839
75/75 [==============================] - 0s 6ms/step - loss: 0.0915 - mae: 0.2451 - mse: 0.0915 - val_loss: 0.0674 - val_mae: 0.1916 - val_mse: 0.0674
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0653 - mae: 0.1973 - mse: 0.0653
64/75 [========================>.....] - ETA: 0s - loss: 0.0735 - mae: 0.2134 - mse: 0.0735
75/75 [==============================] - 0s 5ms/step - loss: 0.0713 - mae: 0.2119 - mse: 0.0713 - val_loss: 0.0468 - val_mae: 0.1772 - val_mse: 0.0468
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1123 - mae: 0.2538 - mse: 0.1123
64/75 [========================>.....] - ETA: 0s - loss: 0.0705 - mae: 0.1958 - mse: 0.0705
75/75 [==============================] - 0s 6ms/step - loss: 0.0665 - mae: 0.1932 - mse: 0.0665 - val_loss: 0.0438 - val_mae: 0.1660 - val_mse: 0.0438
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0691 - mae: 0.1946 - mse: 0.0691
64/75 [========================>.....] - ETA: 0s - loss: 0.0733 - mae: 0.2072 - mse: 0.0733
75/75 [==============================] - 0s 5ms/step - loss: 0.0773 - mae: 0.2077 - mse: 0.0773 - val_loss: 0.0592 - val_mae: 0.1875 - val_mse: 0.0592
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0702 - mae: 0.1964 - mse: 0.0702
64/75 [========================>.....] - ETA: 0s - loss: 0.0683 - mae: 0.1931 - mse: 0.0683
75/75 [==============================] - 0s 6ms/step - loss: 0.0615 - mae: 0.1832 - mse: 0.0615 - val_loss: 0.0809 - val_mae: 0.2389 - val_mse: 0.0809
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0585 - mae: 0.1723 - mse: 0.0585
64/75 [========================>.....] - ETA: 0s - loss: 0.0740 - mae: 0.2049 - mse: 0.0740
75/75 [==============================] - 0s 6ms/step - loss: 0.0677 - mae: 0.1944 - mse: 0.0677 - val_loss: 0.0672 - val_mae: 0.2216 - val_mse: 0.0672
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0567 - mae: 0.1808 - mse: 0.0567
64/75 [========================>.....] - ETA: 0s - loss: 0.0590 - mae: 0.1804 - mse: 0.0590
75/75 [==============================] - 0s 6ms/step - loss: 0.0543 - mae: 0.1744 - mse: 0.0543 - val_loss: 0.0344 - val_mae: 0.1491 - val_mse: 0.0344
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0679 - mae: 0.1617 - mse: 0.0679
64/75 [========================>.....] - ETA: 0s - loss: 0.0455 - mae: 0.1385 - mse: 0.0455
75/75 [==============================] - 0s 5ms/step - loss: 0.0512 - mae: 0.1468 - mse: 0.0512 - val_loss: 0.0233 - val_mae: 0.1223 - val_mse: 0.0233
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0401 - mae: 0.1544 - mse: 0.0401
64/75 [========================>.....] - ETA: 0s - loss: 0.0518 - mae: 0.1646 - mse: 0.0518
75/75 [==============================] - 1s 8ms/step - loss: 0.0486 - mae: 0.1608 - mse: 0.0486 - val_loss: 0.0385 - val_mae: 0.1741 - val_mse: 0.0385
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0450 - mae: 0.1607 - mse: 0.0450
64/75 [========================>.....] - ETA: 0s - loss: 0.0434 - mae: 0.1474 - mse: 0.0434
75/75 [==============================] - 1s 8ms/step - loss: 0.0418 - mae: 0.1412 - mse: 0.0418 - val_loss: 0.0642 - val_mae: 0.2367 - val_mse: 0.0642
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0192 - mae: 0.1070 - mse: 0.0192
64/75 [========================>.....] - ETA: 0s - loss: 0.0303 - mae: 0.1322 - mse: 0.0303
75/75 [==============================] - 1s 8ms/step - loss: 0.0437 - mae: 0.1546 - mse: 0.0437 - val_loss: 0.0577 - val_mae: 0.2258 - val_mse: 0.0577
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0290 - mae: 0.1347 - mse: 0.0290
64/75 [========================>.....] - ETA: 0s - loss: 0.0372 - mae: 0.1506 - mse: 0.0372
75/75 [==============================] - 1s 7ms/step - loss: 0.0366 - mae: 0.1464 - mse: 0.0366 - val_loss: 0.0253 - val_mae: 0.1392 - val_mse: 0.0253
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0288 - mae: 0.1325 - mse: 0.0288
64/75 [========================>.....] - ETA: 0s - loss: 0.0401 - mae: 0.1560 - mse: 0.0401
75/75 [==============================] - 1s 8ms/step - loss: 0.0455 - mae: 0.1627 - mse: 0.0455 - val_loss: 0.0290 - val_mae: 0.1500 - val_mse: 0.0290
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0500 - mae: 0.1602 - mse: 0.0500
64/75 [========================>.....] - ETA: 0s - loss: 0.0385 - mae: 0.1390 - mse: 0.0385
75/75 [==============================] - 1s 8ms/step - loss: 0.0368 - mae: 0.1366 - mse: 0.0368 - val_loss: 0.0560 - val_mae: 0.2207 - val_mse: 0.0560
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0405 - mae: 0.1548 - mse: 0.0405
64/75 [========================>.....] - ETA: 0s - loss: 0.0422 - mae: 0.1603 - mse: 0.0422
75/75 [==============================] - 1s 8ms/step - loss: 0.0402 - mae: 0.1556 - mse: 0.0402 - val_loss: 0.0575 - val_mae: 0.2230 - val_mse: 0.0575
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0442 - mae: 0.1677 - mse: 0.0442
64/75 [========================>.....] - ETA: 0s - loss: 0.0430 - mae: 0.1603 - mse: 0.0430
75/75 [==============================] - 1s 8ms/step - loss: 0.0395 - mae: 0.1548 - mse: 0.0395 - val_loss: 0.0272 - val_mae: 0.1426 - val_mse: 0.0272
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0192 - mae: 0.1085 - mse: 0.0192
64/75 [========================>.....] - ETA: 0s - loss: 0.0255 - mae: 0.1242 - mse: 0.0255
75/75 [==============================] - 1s 8ms/step - loss: 0.0266 - mae: 0.1247 - mse: 0.0266 - val_loss: 0.0144 - val_mae: 0.0958 - val_mse: 0.0144
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0370 - mae: 0.1589 - mse: 0.0370
64/75 [========================>.....] - ETA: 0s - loss: 0.0384 - mae: 0.1539 - mse: 0.0384
75/75 [==============================] - 1s 7ms/step - loss: 0.0356 - mae: 0.1461 - mse: 0.0356 - val_loss: 0.0294 - val_mae: 0.1561 - val_mse: 0.0294
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0363 - mae: 0.1421 - mse: 0.0363
64/75 [========================>.....] - ETA: 0s - loss: 0.0308 - mae: 0.1331 - mse: 0.0308
75/75 [==============================] - 1s 8ms/step - loss: 0.0285 - mae: 0.1270 - mse: 0.0285 - val_loss: 0.0386 - val_mae: 0.1857 - val_mse: 0.0386
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0229 - mae: 0.1136 - mse: 0.0229
64/75 [========================>.....] - ETA: 0s - loss: 0.0232 - mae: 0.1085 - mse: 0.0232
75/75 [==============================] - 1s 9ms/step - loss: 0.0223 - mae: 0.1090 - mse: 0.0223 - val_loss: 0.0308 - val_mae: 0.1670 - val_mse: 0.0308
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0260 - mae: 0.1206 - mse: 0.0260
64/75 [========================>.....] - ETA: 0s - loss: 0.0265 - mae: 0.1257 - mse: 0.0265
75/75 [==============================] - 1s 7ms/step - loss: 0.0320 - mae: 0.1367 - mse: 0.0320 - val_loss: 0.0257 - val_mae: 0.1530 - val_mse: 0.0257
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0249 - mae: 0.1175 - mse: 0.0249
64/75 [========================>.....] - ETA: 0s - loss: 0.0251 - mae: 0.1145 - mse: 0.0251
75/75 [==============================] - 1s 8ms/step - loss: 0.0315 - mae: 0.1288 - mse: 0.0315 - val_loss: 0.0317 - val_mae: 0.1724 - val_mse: 0.0317
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0192 - mae: 0.1146 - mse: 0.0192
64/75 [========================>.....] - ETA: 0s - loss: 0.0220 - mae: 0.1129 - mse: 0.0220
75/75 [==============================] - 1s 8ms/step - loss: 0.0246 - mae: 0.1162 - mse: 0.0246 - val_loss: 0.0306 - val_mae: 0.1698 - val_mse: 0.0306
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0192 - mae: 0.1214 - mse: 0.0192
64/75 [========================>.....] - ETA: 0s - loss: 0.0249 - mae: 0.1300 - mse: 0.0249
75/75 [==============================] - 1s 7ms/step - loss: 0.0232 - mae: 0.1243 - mse: 0.0232 - val_loss: 0.0321 - val_mae: 0.1748 - val_mse: 0.0321
Saving trained model...
115
Testing...
heightdiff= [0. 0. 0. 0. 0.]
average prediction= [4.6825857]
baseline= 5.928571428571429
eachuser= [0. 0. 0. 0. 0.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- nan
['train-height-12.py', '0']
155 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
155 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
155 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
155 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
170 31
170 32
170 33
170 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
170 37
170 38
2_170_60_12_csi_a12_4.dat
170 40
165 41
165 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
165 48
165 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
165 56
165 57
1_165_65_12_csi_a12_7.dat
165 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
165 70
2_165_50_12_csi_a12_13.dat
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
2_165_50_12_csi_a12_7.dat
165 87
2_165_50_12_csi_a12_23.dat
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
1_175_70_12_csi_a12_26.dat
175 127
175 128
175 129
175 130
180 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
180 134
180 135
1_180_85_12_csi_a12_19.dat
180 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
180 140
1_180_85_12_csi_a12_12.dat
180 142
180 143
180 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
180 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
180 161
180 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
180 165
180 166
180 167
180 168
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
1_180_75_12_csi_a12_12.dat
180 178
1_180_75_12_csi_a12_13.dat
180 180
180 181
180 182
1_180_75_12_csi_a12_14.dat
180 184
180 185
180 186
180 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
180 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[155 155 155 155 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 1s - loss: 0.4822 - mae: 0.6424 - mse: 0.4822
64/75 [========================>.....] - ETA: 0s - loss: 0.4885 - mae: 0.6436 - mse: 0.4885
75/75 [==============================] - 1s 18ms/step - loss: 0.4530 - mae: 0.6096 - mse: 0.4530 - val_loss: 0.2645 - val_mae: 0.4520 - val_mse: 0.2645
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.2000 - mae: 0.3509 - mse: 0.2000
64/75 [========================>.....] - ETA: 0s - loss: 0.1750 - mae: 0.3402 - mse: 0.1750
75/75 [==============================] - 1s 10ms/step - loss: 0.1662 - mae: 0.3363 - mse: 0.1662 - val_loss: 0.1117 - val_mae: 0.2920 - val_mse: 0.1117
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.2228 - mae: 0.3563 - mse: 0.2228
64/75 [========================>.....] - ETA: 0s - loss: 0.1910 - mae: 0.3412 - mse: 0.1910
75/75 [==============================] - 1s 10ms/step - loss: 0.1866 - mae: 0.3412 - mse: 0.1866 - val_loss: 0.1055 - val_mae: 0.2545 - val_mse: 0.1055
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1778 - mae: 0.3583 - mse: 0.1778
64/75 [========================>.....] - ETA: 0s - loss: 0.1264 - mae: 0.2937 - mse: 0.1264
75/75 [==============================] - 1s 10ms/step - loss: 0.1173 - mae: 0.2789 - mse: 0.1173 - val_loss: 0.0960 - val_mae: 0.2794 - val_mse: 0.0960
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1040 - mae: 0.2761 - mse: 0.1040
64/75 [========================>.....] - ETA: 0s - loss: 0.1001 - mae: 0.2715 - mse: 0.1001
75/75 [==============================] - 1s 10ms/step - loss: 0.0980 - mae: 0.2662 - mse: 0.0980 - val_loss: 0.1094 - val_mae: 0.2928 - val_mse: 0.1094
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0891 - mae: 0.2462 - mse: 0.0891
64/75 [========================>.....] - ETA: 0s - loss: 0.0865 - mae: 0.2432 - mse: 0.0865
75/75 [==============================] - 1s 9ms/step - loss: 0.0799 - mae: 0.2335 - mse: 0.0799 - val_loss: 0.1000 - val_mae: 0.2680 - val_mse: 0.1000
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0469 - mae: 0.1768 - mse: 0.0469
64/75 [========================>.....] - ETA: 0s - loss: 0.0617 - mae: 0.1927 - mse: 0.0617
75/75 [==============================] - 1s 10ms/step - loss: 0.0655 - mae: 0.2020 - mse: 0.0655 - val_loss: 0.0833 - val_mae: 0.2157 - val_mse: 0.0833
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0487 - mae: 0.1789 - mse: 0.0487
64/75 [========================>.....] - ETA: 0s - loss: 0.0624 - mae: 0.1880 - mse: 0.0624
75/75 [==============================] - 1s 8ms/step - loss: 0.0577 - mae: 0.1802 - mse: 0.0577 - val_loss: 0.0813 - val_mae: 0.2064 - val_mse: 0.0813
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0431 - mae: 0.1529 - mse: 0.0431
64/75 [========================>.....] - ETA: 0s - loss: 0.0459 - mae: 0.1413 - mse: 0.0459
75/75 [==============================] - 1s 8ms/step - loss: 0.0469 - mae: 0.1475 - mse: 0.0469 - val_loss: 0.0826 - val_mae: 0.2198 - val_mse: 0.0826
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0450 - mae: 0.1537 - mse: 0.0450
64/75 [========================>.....] - ETA: 0s - loss: 0.0469 - mae: 0.1703 - mse: 0.0469
75/75 [==============================] - 1s 10ms/step - loss: 0.0428 - mae: 0.1629 - mse: 0.0428 - val_loss: 0.0809 - val_mae: 0.2125 - val_mse: 0.0809
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0534 - mae: 0.1447 - mse: 0.0534
64/75 [========================>.....] - ETA: 0s - loss: 0.0495 - mae: 0.1534 - mse: 0.0495
75/75 [==============================] - 1s 8ms/step - loss: 0.0458 - mae: 0.1476 - mse: 0.0458 - val_loss: 0.0874 - val_mae: 0.2479 - val_mse: 0.0874
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0605 - mae: 0.1964 - mse: 0.0605
64/75 [========================>.....] - ETA: 0s - loss: 0.0509 - mae: 0.1811 - mse: 0.0509
75/75 [==============================] - 1s 8ms/step - loss: 0.0505 - mae: 0.1801 - mse: 0.0505 - val_loss: 0.0795 - val_mae: 0.2298 - val_mse: 0.0795
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0297 - mae: 0.1429 - mse: 0.0297
64/75 [========================>.....] - ETA: 0s - loss: 0.0346 - mae: 0.1434 - mse: 0.0346
75/75 [==============================] - 1s 7ms/step - loss: 0.0373 - mae: 0.1467 - mse: 0.0373 - val_loss: 0.0696 - val_mae: 0.1983 - val_mse: 0.0696
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0694 - mae: 0.1894 - mse: 0.0694
64/75 [========================>.....] - ETA: 0s - loss: 0.0451 - mae: 0.1497 - mse: 0.0451
75/75 [==============================] - 1s 7ms/step - loss: 0.0440 - mae: 0.1495 - mse: 0.0440 - val_loss: 0.0650 - val_mae: 0.1951 - val_mse: 0.0650
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0461 - mae: 0.1594 - mse: 0.0461
64/75 [========================>.....] - ETA: 0s - loss: 0.0363 - mae: 0.1446 - mse: 0.0363
75/75 [==============================] - 1s 7ms/step - loss: 0.0349 - mae: 0.1411 - mse: 0.0349 - val_loss: 0.0612 - val_mae: 0.1929 - val_mse: 0.0612
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0355 - mae: 0.1133 - mse: 0.0355
64/75 [========================>.....] - ETA: 0s - loss: 0.0284 - mae: 0.1160 - mse: 0.0284
75/75 [==============================] - 1s 8ms/step - loss: 0.0272 - mae: 0.1152 - mse: 0.0272 - val_loss: 0.0561 - val_mae: 0.1764 - val_mse: 0.0561
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0153 - mae: 0.0883 - mse: 0.0153
64/75 [========================>.....] - ETA: 0s - loss: 0.0256 - mae: 0.1117 - mse: 0.0256
75/75 [==============================] - 1s 8ms/step - loss: 0.0257 - mae: 0.1108 - mse: 0.0257 - val_loss: 0.0517 - val_mae: 0.1574 - val_mse: 0.0517
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0294 - mae: 0.1338 - mse: 0.0294
64/75 [========================>.....] - ETA: 0s - loss: 0.0267 - mae: 0.1245 - mse: 0.0267
75/75 [==============================] - 1s 8ms/step - loss: 0.0370 - mae: 0.1313 - mse: 0.0370 - val_loss: 0.0499 - val_mae: 0.1605 - val_mse: 0.0499
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0210 - mae: 0.1152 - mse: 0.0210
64/75 [========================>.....] - ETA: 0s - loss: 0.0315 - mae: 0.1295 - mse: 0.0315
75/75 [==============================] - 1s 8ms/step - loss: 0.0298 - mae: 0.1265 - mse: 0.0298 - val_loss: 0.0571 - val_mae: 0.2054 - val_mse: 0.0571
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0421 - mae: 0.1487 - mse: 0.0421
64/75 [========================>.....] - ETA: 0s - loss: 0.0318 - mae: 0.1319 - mse: 0.0318
75/75 [==============================] - 1s 8ms/step - loss: 0.0319 - mae: 0.1342 - mse: 0.0319 - val_loss: 0.0531 - val_mae: 0.1945 - val_mse: 0.0531
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0203 - mae: 0.1059 - mse: 0.0203
64/75 [========================>.....] - ETA: 0s - loss: 0.0219 - mae: 0.1142 - mse: 0.0219
75/75 [==============================] - 1s 9ms/step - loss: 0.0242 - mae: 0.1153 - mse: 0.0242 - val_loss: 0.0425 - val_mae: 0.1414 - val_mse: 0.0425
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0137 - mae: 0.0883 - mse: 0.0137
64/75 [========================>.....] - ETA: 0s - loss: 0.0167 - mae: 0.0989 - mse: 0.0167
75/75 [==============================] - 1s 8ms/step - loss: 0.0219 - mae: 0.1109 - mse: 0.0219 - val_loss: 0.0402 - val_mae: 0.1331 - val_mse: 0.0402
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0316 - mae: 0.1259 - mse: 0.0316
64/75 [========================>.....] - ETA: 0s - loss: 0.0275 - mae: 0.1190 - mse: 0.0275
75/75 [==============================] - 1s 7ms/step - loss: 0.0240 - mae: 0.1078 - mse: 0.0240 - val_loss: 0.0471 - val_mae: 0.1824 - val_mse: 0.0471
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0243 - mae: 0.1138 - mse: 0.0243
64/75 [========================>.....] - ETA: 0s - loss: 0.0249 - mae: 0.1214 - mse: 0.0249
75/75 [==============================] - 1s 8ms/step - loss: 0.0290 - mae: 0.1270 - mse: 0.0290 - val_loss: 0.0457 - val_mae: 0.1815 - val_mse: 0.0457
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0121 - mae: 0.0812 - mse: 0.0121
64/75 [========================>.....] - ETA: 0s - loss: 0.0197 - mae: 0.1016 - mse: 0.0197
75/75 [==============================] - 1s 7ms/step - loss: 0.0180 - mae: 0.0980 - mse: 0.0180 - val_loss: 0.0359 - val_mae: 0.1342 - val_mse: 0.0359
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0206 - mae: 0.1074 - mse: 0.0206
64/75 [========================>.....] - ETA: 0s - loss: 0.0224 - mae: 0.1063 - mse: 0.0224
75/75 [==============================] - 1s 8ms/step - loss: 0.0215 - mae: 0.1060 - mse: 0.0215 - val_loss: 0.0332 - val_mae: 0.1191 - val_mse: 0.0332
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0225 - mae: 0.1017 - mse: 0.0225
64/75 [========================>.....] - ETA: 0s - loss: 0.0211 - mae: 0.1058 - mse: 0.0211
75/75 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 0.1025 - mse: 0.0198 - val_loss: 0.0370 - val_mae: 0.1580 - val_mse: 0.0370
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0380 - mae: 0.1437 - mse: 0.0380
64/75 [========================>.....] - ETA: 0s - loss: 0.0232 - mae: 0.1087 - mse: 0.0232
75/75 [==============================] - 0s 5ms/step - loss: 0.0221 - mae: 0.1063 - mse: 0.0221 - val_loss: 0.0422 - val_mae: 0.1820 - val_mse: 0.0422
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0214 - mae: 0.1183 - mse: 0.0214
64/75 [========================>.....] - ETA: 0s - loss: 0.0206 - mae: 0.1102 - mse: 0.0206
75/75 [==============================] - 0s 6ms/step - loss: 0.0229 - mae: 0.1144 - mse: 0.0229 - val_loss: 0.0327 - val_mae: 0.1379 - val_mse: 0.0327
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0168 - mae: 0.0857 - mse: 0.0168
64/75 [========================>.....] - ETA: 0s - loss: 0.0181 - mae: 0.0968 - mse: 0.0181
75/75 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0949 - mse: 0.0171 - val_loss: 0.0326 - val_mae: 0.1394 - val_mse: 0.0326
Saving trained model...
115
Testing...
heightdiff= [ 0.          0.          0.          0.         27.18391418]
average prediction= [2.792748]
baseline= 5.976190476190476
eachuser= [0. 0. 0. 0. 2.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 13.591957092285156
['train-height-12.py', '0']
155 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
155 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
155 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
155 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
170 31
170 32
170 33
170 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
170 37
170 38
2_170_60_12_csi_a12_4.dat
170 40
165 41
165 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
165 48
165 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
165 56
165 57
1_165_65_12_csi_a12_7.dat
165 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
165 70
2_165_50_12_csi_a12_13.dat
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
2_165_50_12_csi_a12_7.dat
165 87
2_165_50_12_csi_a12_23.dat
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
1_175_70_12_csi_a12_26.dat
175 127
175 128
175 129
175 130
180 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
180 134
180 135
1_180_85_12_csi_a12_19.dat
180 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
180 140
1_180_85_12_csi_a12_12.dat
180 142
180 143
180 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
180 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
180 161
180 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
180 165
180 166
180 167
180 168
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
1_180_75_12_csi_a12_12.dat
180 178
1_180_75_12_csi_a12_13.dat
180 180
180 181
180 182
1_180_75_12_csi_a12_14.dat
180 184
180 185
180 186
180 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
180 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[155 155 155 155 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.6840 - mae: 0.7880 - mse: 0.6840
64/75 [========================>.....] - ETA: 0s - loss: 0.6030 - mae: 0.7311 - mse: 0.6030
75/75 [==============================] - 1s 13ms/step - loss: 0.5786 - mae: 0.7104 - mse: 0.5786 - val_loss: 0.3956 - val_mae: 0.5494 - val_mse: 0.3956
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.2621 - mae: 0.4335 - mse: 0.2621
64/75 [========================>.....] - ETA: 0s - loss: 0.2868 - mae: 0.4633 - mse: 0.2868
75/75 [==============================] - 1s 9ms/step - loss: 0.2695 - mae: 0.4498 - mse: 0.2695 - val_loss: 0.1885 - val_mae: 0.4140 - val_mse: 0.1885
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1873 - mae: 0.3958 - mse: 0.1873
64/75 [========================>.....] - ETA: 0s - loss: 0.1619 - mae: 0.3552 - mse: 0.1619
75/75 [==============================] - 1s 8ms/step - loss: 0.1519 - mae: 0.3416 - mse: 0.1519 - val_loss: 0.1375 - val_mae: 0.3163 - val_mse: 0.1375
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1455 - mae: 0.2870 - mse: 0.1455
64/75 [========================>.....] - ETA: 0s - loss: 0.1572 - mae: 0.2961 - mse: 0.1572
75/75 [==============================] - 1s 9ms/step - loss: 0.1736 - mae: 0.3167 - mse: 0.1736 - val_loss: 0.1002 - val_mae: 0.2878 - val_mse: 0.1002
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1194 - mae: 0.2478 - mse: 0.1194
64/75 [========================>.....] - ETA: 0s - loss: 0.1158 - mae: 0.2511 - mse: 0.1158
75/75 [==============================] - 1s 8ms/step - loss: 0.1176 - mae: 0.2642 - mse: 0.1176 - val_loss: 0.1272 - val_mae: 0.3090 - val_mse: 0.1272
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1277 - mae: 0.3113 - mse: 0.1277
64/75 [========================>.....] - ETA: 0s - loss: 0.1014 - mae: 0.2757 - mse: 0.1014
75/75 [==============================] - 1s 8ms/step - loss: 0.0944 - mae: 0.2603 - mse: 0.0944 - val_loss: 0.1476 - val_mae: 0.3008 - val_mse: 0.1476
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1122 - mae: 0.2826 - mse: 0.1122
64/75 [========================>.....] - ETA: 0s - loss: 0.1018 - mae: 0.2583 - mse: 0.1018
75/75 [==============================] - 1s 9ms/step - loss: 0.1044 - mae: 0.2625 - mse: 0.1044 - val_loss: 0.1241 - val_mae: 0.2759 - val_mse: 0.1241
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1055 - mae: 0.2622 - mse: 0.1055
64/75 [========================>.....] - ETA: 0s - loss: 0.0960 - mae: 0.2474 - mse: 0.0960
75/75 [==============================] - 1s 8ms/step - loss: 0.0863 - mae: 0.2317 - mse: 0.0863 - val_loss: 0.0712 - val_mae: 0.1953 - val_mse: 0.0712
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0690 - mae: 0.2165 - mse: 0.0690
64/75 [========================>.....] - ETA: 0s - loss: 0.0572 - mae: 0.1902 - mse: 0.0572
75/75 [==============================] - 1s 9ms/step - loss: 0.0545 - mae: 0.1831 - mse: 0.0545 - val_loss: 0.0391 - val_mae: 0.1588 - val_mse: 0.0391
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0369 - mae: 0.1434 - mse: 0.0369
64/75 [========================>.....] - ETA: 0s - loss: 0.0660 - mae: 0.1806 - mse: 0.0660
75/75 [==============================] - 1s 8ms/step - loss: 0.0768 - mae: 0.1930 - mse: 0.0768 - val_loss: 0.0355 - val_mae: 0.1471 - val_mse: 0.0355
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0623 - mae: 0.1810 - mse: 0.0623
64/75 [========================>.....] - ETA: 0s - loss: 0.0706 - mae: 0.1837 - mse: 0.0706
75/75 [==============================] - 1s 8ms/step - loss: 0.0666 - mae: 0.1788 - mse: 0.0666 - val_loss: 0.0599 - val_mae: 0.1877 - val_mse: 0.0599
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0442 - mae: 0.1621 - mse: 0.0442
64/75 [========================>.....] - ETA: 0s - loss: 0.0368 - mae: 0.1432 - mse: 0.0368
75/75 [==============================] - 1s 8ms/step - loss: 0.0457 - mae: 0.1525 - mse: 0.0457 - val_loss: 0.0786 - val_mae: 0.2288 - val_mse: 0.0786
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0564 - mae: 0.1809 - mse: 0.0564
64/75 [========================>.....] - ETA: 0s - loss: 0.0569 - mae: 0.1815 - mse: 0.0569
75/75 [==============================] - 0s 6ms/step - loss: 0.0606 - mae: 0.1854 - mse: 0.0606 - val_loss: 0.0765 - val_mae: 0.2289 - val_mse: 0.0765
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0382 - mae: 0.1321 - mse: 0.0382
64/75 [========================>.....] - ETA: 0s - loss: 0.0551 - mae: 0.1752 - mse: 0.0551
75/75 [==============================] - 0s 5ms/step - loss: 0.0552 - mae: 0.1777 - mse: 0.0552 - val_loss: 0.0506 - val_mae: 0.1834 - val_mse: 0.0506
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0516 - mae: 0.1498 - mse: 0.0516
64/75 [========================>.....] - ETA: 0s - loss: 0.0472 - mae: 0.1456 - mse: 0.0472
75/75 [==============================] - 0s 6ms/step - loss: 0.0453 - mae: 0.1444 - mse: 0.0453 - val_loss: 0.0251 - val_mae: 0.1246 - val_mse: 0.0251
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0484 - mae: 0.1781 - mse: 0.0484
64/75 [========================>.....] - ETA: 0s - loss: 0.0481 - mae: 0.1654 - mse: 0.0481
75/75 [==============================] - 0s 6ms/step - loss: 0.0454 - mae: 0.1616 - mse: 0.0454 - val_loss: 0.0264 - val_mae: 0.1282 - val_mse: 0.0264
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0203 - mae: 0.1091 - mse: 0.0203
64/75 [========================>.....] - ETA: 0s - loss: 0.0360 - mae: 0.1243 - mse: 0.0360
75/75 [==============================] - 0s 5ms/step - loss: 0.0382 - mae: 0.1270 - mse: 0.0382 - val_loss: 0.0456 - val_mae: 0.1726 - val_mse: 0.0456
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0387 - mae: 0.1460 - mse: 0.0387
64/75 [========================>.....] - ETA: 0s - loss: 0.0356 - mae: 0.1352 - mse: 0.0356
75/75 [==============================] - 0s 6ms/step - loss: 0.0351 - mae: 0.1358 - mse: 0.0351 - val_loss: 0.0605 - val_mae: 0.2099 - val_mse: 0.0605
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0405 - mae: 0.1509 - mse: 0.0405
64/75 [========================>.....] - ETA: 0s - loss: 0.0416 - mae: 0.1524 - mse: 0.0416
75/75 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 0.1514 - mse: 0.0410 - val_loss: 0.0478 - val_mae: 0.1792 - val_mse: 0.0478
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0409 - mae: 0.1311 - mse: 0.0409
64/75 [========================>.....] - ETA: 0s - loss: 0.0269 - mae: 0.1109 - mse: 0.0269
75/75 [==============================] - 0s 6ms/step - loss: 0.0342 - mae: 0.1192 - mse: 0.0342 - val_loss: 0.0318 - val_mae: 0.1382 - val_mse: 0.0318
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0371 - mae: 0.1257 - mse: 0.0371
64/75 [========================>.....] - ETA: 0s - loss: 0.0258 - mae: 0.1048 - mse: 0.0258
75/75 [==============================] - 0s 6ms/step - loss: 0.0314 - mae: 0.1118 - mse: 0.0314 - val_loss: 0.0335 - val_mae: 0.1400 - val_mse: 0.0335
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0551 - mae: 0.1629 - mse: 0.0551
64/75 [========================>.....] - ETA: 0s - loss: 0.0350 - mae: 0.1250 - mse: 0.0350
75/75 [==============================] - 0s 6ms/step - loss: 0.0353 - mae: 0.1307 - mse: 0.0353 - val_loss: 0.0480 - val_mae: 0.1713 - val_mse: 0.0480
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0369 - mae: 0.1438 - mse: 0.0369
64/75 [========================>.....] - ETA: 0s - loss: 0.0346 - mae: 0.1380 - mse: 0.0346
75/75 [==============================] - 0s 6ms/step - loss: 0.0332 - mae: 0.1343 - mse: 0.0332 - val_loss: 0.0409 - val_mae: 0.1522 - val_mse: 0.0409
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0214 - mae: 0.0921 - mse: 0.0214
64/75 [========================>.....] - ETA: 0s - loss: 0.0308 - mae: 0.1213 - mse: 0.0308
75/75 [==============================] - 0s 5ms/step - loss: 0.0297 - mae: 0.1174 - mse: 0.0297 - val_loss: 0.0356 - val_mae: 0.1390 - val_mse: 0.0356
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0240 - mae: 0.1224 - mse: 0.0240
64/75 [========================>.....] - ETA: 0s - loss: 0.0226 - mae: 0.1071 - mse: 0.0226
75/75 [==============================] - 0s 5ms/step - loss: 0.0247 - mae: 0.1125 - mse: 0.0247 - val_loss: 0.0353 - val_mae: 0.1402 - val_mse: 0.0353
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0254 - mae: 0.1199 - mse: 0.0254
64/75 [========================>.....] - ETA: 0s - loss: 0.0279 - mae: 0.1228 - mse: 0.0279
75/75 [==============================] - 0s 6ms/step - loss: 0.0249 - mae: 0.1134 - mse: 0.0249 - val_loss: 0.0455 - val_mae: 0.1663 - val_mse: 0.0455
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0433 - mae: 0.1391 - mse: 0.0433
64/75 [========================>.....] - ETA: 0s - loss: 0.0309 - mae: 0.1272 - mse: 0.0309
75/75 [==============================] - 0s 5ms/step - loss: 0.0335 - mae: 0.1311 - mse: 0.0335 - val_loss: 0.0469 - val_mae: 0.1707 - val_mse: 0.0469
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0222 - mae: 0.1067 - mse: 0.0222
64/75 [========================>.....] - ETA: 0s - loss: 0.0247 - mae: 0.1132 - mse: 0.0247
75/75 [==============================] - 0s 6ms/step - loss: 0.0260 - mae: 0.1146 - mse: 0.0260 - val_loss: 0.0298 - val_mae: 0.1287 - val_mse: 0.0298
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0216 - mae: 0.0997 - mse: 0.0216
64/75 [========================>.....] - ETA: 0s - loss: 0.0245 - mae: 0.1109 - mse: 0.0245
75/75 [==============================] - 0s 5ms/step - loss: 0.0240 - mae: 0.1109 - mse: 0.0240 - val_loss: 0.0273 - val_mae: 0.1232 - val_mse: 0.0273
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0212 - mae: 0.1075 - mse: 0.0212
64/75 [========================>.....] - ETA: 0s - loss: 0.0236 - mae: 0.1099 - mse: 0.0236
75/75 [==============================] - 0s 6ms/step - loss: 0.0260 - mae: 0.1153 - mse: 0.0260 - val_loss: 0.0318 - val_mae: 0.1426 - val_mse: 0.0318
Saving trained model...
115
Testing...
heightdiff= [0.         0.         0.         0.         9.60990906]
average prediction= [3.0311925]
baseline= 5.833333333333333
eachuser= [0. 0. 0. 0. 1.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 9.609909057617188
['train-height-12.py', '0']
155 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
155 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
155 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
155 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
170 31
170 32
170 33
170 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
170 37
170 38
2_170_60_12_csi_a12_4.dat
170 40
165 41
165 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
165 48
165 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
165 56
165 57
1_165_65_12_csi_a12_7.dat
165 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
165 70
2_165_50_12_csi_a12_13.dat
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
2_165_50_12_csi_a12_7.dat
165 87
2_165_50_12_csi_a12_23.dat
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
1_175_70_12_csi_a12_26.dat
175 127
175 128
175 129
175 130
180 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
180 134
180 135
1_180_85_12_csi_a12_19.dat
180 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
180 140
1_180_85_12_csi_a12_12.dat
180 142
180 143
180 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
180 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
180 161
180 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
180 165
180 166
180 167
180 168
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
1_180_75_12_csi_a12_12.dat
180 178
1_180_75_12_csi_a12_13.dat
180 180
180 181
180 182
1_180_75_12_csi_a12_14.dat
180 184
180 185
180 186
180 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
180 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[155 155 155 155 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.5948 - mae: 0.7297 - mse: 0.5948
64/75 [========================>.....] - ETA: 0s - loss: 0.5027 - mae: 0.6519 - mse: 0.5027
75/75 [==============================] - 1s 12ms/step - loss: 0.4561 - mae: 0.6087 - mse: 0.4561 - val_loss: 0.1346 - val_mae: 0.2773 - val_mse: 0.1346
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1664 - mae: 0.3446 - mse: 0.1664
64/75 [========================>.....] - ETA: 0s - loss: 0.1473 - mae: 0.3270 - mse: 0.1473
75/75 [==============================] - 0s 6ms/step - loss: 0.1507 - mae: 0.3262 - mse: 0.1507 - val_loss: 0.1204 - val_mae: 0.3056 - val_mse: 0.1204
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1592 - mae: 0.2883 - mse: 0.1592
64/75 [========================>.....] - ETA: 0s - loss: 0.2403 - mae: 0.3732 - mse: 0.2403
75/75 [==============================] - 0s 6ms/step - loss: 0.2167 - mae: 0.3510 - mse: 0.2167 - val_loss: 0.0687 - val_mae: 0.2483 - val_mse: 0.0687
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1549 - mae: 0.3112 - mse: 0.1549
64/75 [========================>.....] - ETA: 0s - loss: 0.1235 - mae: 0.2840 - mse: 0.1235
75/75 [==============================] - 0s 6ms/step - loss: 0.1205 - mae: 0.2828 - mse: 0.1205 - val_loss: 0.0785 - val_mae: 0.2119 - val_mse: 0.0785
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0749 - mae: 0.2376 - mse: 0.0749
64/75 [========================>.....] - ETA: 0s - loss: 0.0917 - mae: 0.2570 - mse: 0.0917
75/75 [==============================] - 0s 5ms/step - loss: 0.0966 - mae: 0.2633 - mse: 0.0966 - val_loss: 0.0785 - val_mae: 0.2047 - val_mse: 0.0785
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0953 - mae: 0.2552 - mse: 0.0953
64/75 [========================>.....] - ETA: 0s - loss: 0.0861 - mae: 0.2460 - mse: 0.0861
75/75 [==============================] - 0s 6ms/step - loss: 0.0830 - mae: 0.2389 - mse: 0.0830 - val_loss: 0.0514 - val_mae: 0.1766 - val_mse: 0.0514
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0629 - mae: 0.1988 - mse: 0.0629
64/75 [========================>.....] - ETA: 0s - loss: 0.0752 - mae: 0.2128 - mse: 0.0752
75/75 [==============================] - 0s 5ms/step - loss: 0.0698 - mae: 0.2049 - mse: 0.0698 - val_loss: 0.0285 - val_mae: 0.1439 - val_mse: 0.0285
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0594 - mae: 0.1730 - mse: 0.0594
64/75 [========================>.....] - ETA: 0s - loss: 0.0697 - mae: 0.1857 - mse: 0.0697
75/75 [==============================] - 0s 6ms/step - loss: 0.0610 - mae: 0.1706 - mse: 0.0610 - val_loss: 0.0236 - val_mae: 0.1281 - val_mse: 0.0236
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1001 - mae: 0.2011 - mse: 0.1001
64/75 [========================>.....] - ETA: 0s - loss: 0.0834 - mae: 0.1753 - mse: 0.0834
75/75 [==============================] - 0s 6ms/step - loss: 0.0742 - mae: 0.1684 - mse: 0.0742 - val_loss: 0.0332 - val_mae: 0.1541 - val_mse: 0.0332
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1122 - mae: 0.2231 - mse: 0.1122
64/75 [========================>.....] - ETA: 0s - loss: 0.0759 - mae: 0.1899 - mse: 0.0759
75/75 [==============================] - 0s 5ms/step - loss: 0.0707 - mae: 0.1865 - mse: 0.0707 - val_loss: 0.0529 - val_mae: 0.1992 - val_mse: 0.0529
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0706 - mae: 0.1922 - mse: 0.0706
64/75 [========================>.....] - ETA: 0s - loss: 0.0630 - mae: 0.1909 - mse: 0.0630
75/75 [==============================] - 0s 6ms/step - loss: 0.0636 - mae: 0.1946 - mse: 0.0636 - val_loss: 0.0507 - val_mae: 0.1947 - val_mse: 0.0507
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0473 - mae: 0.1469 - mse: 0.0473
64/75 [========================>.....] - ETA: 0s - loss: 0.0451 - mae: 0.1505 - mse: 0.0451
75/75 [==============================] - 0s 6ms/step - loss: 0.0545 - mae: 0.1614 - mse: 0.0545 - val_loss: 0.0285 - val_mae: 0.1510 - val_mse: 0.0285
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0442 - mae: 0.1445 - mse: 0.0442
64/75 [========================>.....] - ETA: 0s - loss: 0.0382 - mae: 0.1481 - mse: 0.0382
75/75 [==============================] - 0s 7ms/step - loss: 0.0441 - mae: 0.1516 - mse: 0.0441 - val_loss: 0.0239 - val_mae: 0.1388 - val_mse: 0.0239
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0381 - mae: 0.1230 - mse: 0.0381
64/75 [========================>.....] - ETA: 0s - loss: 0.0489 - mae: 0.1449 - mse: 0.0489
75/75 [==============================] - 0s 6ms/step - loss: 0.0458 - mae: 0.1437 - mse: 0.0458 - val_loss: 0.0339 - val_mae: 0.1607 - val_mse: 0.0339
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0395 - mae: 0.1377 - mse: 0.0395
64/75 [========================>.....] - ETA: 0s - loss: 0.0441 - mae: 0.1511 - mse: 0.0441
75/75 [==============================] - 0s 6ms/step - loss: 0.0448 - mae: 0.1533 - mse: 0.0448 - val_loss: 0.0406 - val_mae: 0.1736 - val_mse: 0.0406
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0502 - mae: 0.1579 - mse: 0.0502
64/75 [========================>.....] - ETA: 0s - loss: 0.0552 - mae: 0.1691 - mse: 0.0552
75/75 [==============================] - 0s 5ms/step - loss: 0.0507 - mae: 0.1621 - mse: 0.0507 - val_loss: 0.0409 - val_mae: 0.1753 - val_mse: 0.0409
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0356 - mae: 0.1287 - mse: 0.0356
64/75 [========================>.....] - ETA: 0s - loss: 0.0498 - mae: 0.1560 - mse: 0.0498
75/75 [==============================] - 0s 5ms/step - loss: 0.0458 - mae: 0.1475 - mse: 0.0458 - val_loss: 0.0272 - val_mae: 0.1414 - val_mse: 0.0272
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0284 - mae: 0.1337 - mse: 0.0284
64/75 [========================>.....] - ETA: 0s - loss: 0.0357 - mae: 0.1279 - mse: 0.0357
75/75 [==============================] - 0s 5ms/step - loss: 0.0415 - mae: 0.1343 - mse: 0.0415 - val_loss: 0.0217 - val_mae: 0.1274 - val_mse: 0.0217
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0545 - mae: 0.1534 - mse: 0.0545
64/75 [========================>.....] - ETA: 0s - loss: 0.0475 - mae: 0.1470 - mse: 0.0475
75/75 [==============================] - 1s 7ms/step - loss: 0.0438 - mae: 0.1431 - mse: 0.0438 - val_loss: 0.0318 - val_mae: 0.1573 - val_mse: 0.0318
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0585 - mae: 0.1768 - mse: 0.0585
64/75 [========================>.....] - ETA: 0s - loss: 0.0471 - mae: 0.1621 - mse: 0.0471
75/75 [==============================] - 1s 7ms/step - loss: 0.0444 - mae: 0.1592 - mse: 0.0444 - val_loss: 0.0473 - val_mae: 0.1939 - val_mse: 0.0473
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0438 - mae: 0.1639 - mse: 0.0438
64/75 [========================>.....] - ETA: 0s - loss: 0.0369 - mae: 0.1476 - mse: 0.0369
75/75 [==============================] - 0s 5ms/step - loss: 0.0384 - mae: 0.1469 - mse: 0.0384 - val_loss: 0.0313 - val_mae: 0.1598 - val_mse: 0.0313
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0461 - mae: 0.1515 - mse: 0.0461
64/75 [========================>.....] - ETA: 0s - loss: 0.0392 - mae: 0.1364 - mse: 0.0392
75/75 [==============================] - 0s 6ms/step - loss: 0.0355 - mae: 0.1310 - mse: 0.0355 - val_loss: 0.0157 - val_mae: 0.1101 - val_mse: 0.0157
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0275 - mae: 0.1159 - mse: 0.0275
64/75 [========================>.....] - ETA: 0s - loss: 0.0301 - mae: 0.1242 - mse: 0.0301
75/75 [==============================] - 0s 5ms/step - loss: 0.0309 - mae: 0.1236 - mse: 0.0309 - val_loss: 0.0136 - val_mae: 0.0998 - val_mse: 0.0136
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0224 - mae: 0.0976 - mse: 0.0224
64/75 [========================>.....] - ETA: 0s - loss: 0.0247 - mae: 0.1035 - mse: 0.0247
75/75 [==============================] - 0s 5ms/step - loss: 0.0279 - mae: 0.1122 - mse: 0.0279 - val_loss: 0.0300 - val_mae: 0.1539 - val_mse: 0.0300
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0386 - mae: 0.1353 - mse: 0.0386
64/75 [========================>.....] - ETA: 0s - loss: 0.0325 - mae: 0.1330 - mse: 0.0325
75/75 [==============================] - 0s 5ms/step - loss: 0.0305 - mae: 0.1308 - mse: 0.0305 - val_loss: 0.0405 - val_mae: 0.1755 - val_mse: 0.0405
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0457 - mae: 0.1538 - mse: 0.0457
64/75 [========================>.....] - ETA: 0s - loss: 0.0363 - mae: 0.1376 - mse: 0.0363
75/75 [==============================] - 0s 6ms/step - loss: 0.0349 - mae: 0.1382 - mse: 0.0349 - val_loss: 0.0241 - val_mae: 0.1319 - val_mse: 0.0241
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0335 - mae: 0.1389 - mse: 0.0335
64/75 [========================>.....] - ETA: 0s - loss: 0.0355 - mae: 0.1375 - mse: 0.0355
75/75 [==============================] - 0s 5ms/step - loss: 0.0317 - mae: 0.1286 - mse: 0.0317 - val_loss: 0.0149 - val_mae: 0.0966 - val_mse: 0.0149
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0223 - mae: 0.1041 - mse: 0.0223
64/75 [========================>.....] - ETA: 0s - loss: 0.0237 - mae: 0.1039 - mse: 0.0237
75/75 [==============================] - 0s 6ms/step - loss: 0.0246 - mae: 0.1069 - mse: 0.0246 - val_loss: 0.0264 - val_mae: 0.1316 - val_mse: 0.0264
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0205 - mae: 0.1060 - mse: 0.0205
64/75 [========================>.....] - ETA: 0s - loss: 0.0276 - mae: 0.1195 - mse: 0.0276
75/75 [==============================] - 0s 6ms/step - loss: 0.0273 - mae: 0.1205 - mse: 0.0273 - val_loss: 0.0360 - val_mae: 0.1574 - val_mse: 0.0360
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0178 - mae: 0.0981 - mse: 0.0178
64/75 [========================>.....] - ETA: 0s - loss: 0.0246 - mae: 0.1207 - mse: 0.0246
75/75 [==============================] - 0s 5ms/step - loss: 0.0262 - mae: 0.1220 - mse: 0.0262 - val_loss: 0.0275 - val_mae: 0.1349 - val_mse: 0.0275
Saving trained model...
115
Testing...
heightdiff= [ 0.         0.         0.         0.        10.9311676]
average prediction= [3.5365345]
baseline= 7.023809523809524
eachuser= [0. 0. 0. 0. 1.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 10.931167602539062
['train-height-12.py', '0']
155 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
155 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
155 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
155 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
170 31
170 32
170 33
170 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
170 37
170 38
2_170_60_12_csi_a12_4.dat
170 40
165 41
165 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
165 48
165 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
165 56
165 57
1_165_65_12_csi_a12_7.dat
165 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
165 70
2_165_50_12_csi_a12_13.dat
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
2_165_50_12_csi_a12_7.dat
165 87
2_165_50_12_csi_a12_23.dat
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
1_175_70_12_csi_a12_26.dat
175 127
175 128
175 129
175 130
180 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
180 134
180 135
1_180_85_12_csi_a12_19.dat
180 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
180 140
1_180_85_12_csi_a12_12.dat
180 142
180 143
180 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
180 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
180 161
180 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
180 165
180 166
180 167
180 168
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
1_180_75_12_csi_a12_12.dat
180 178
1_180_75_12_csi_a12_13.dat
180 180
180 181
180 182
1_180_75_12_csi_a12_14.dat
180 184
180 185
180 186
180 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
180 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[155 155 155 155 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.4523 - mae: 0.6086 - mse: 0.4523
64/75 [========================>.....] - ETA: 0s - loss: 0.3799 - mae: 0.5411 - mse: 0.3799
75/75 [==============================] - 1s 11ms/step - loss: 0.3453 - mae: 0.5056 - mse: 0.3453 - val_loss: 0.0439 - val_mae: 0.2032 - val_mse: 0.0439
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1108 - mae: 0.2634 - mse: 0.1108
64/75 [========================>.....] - ETA: 0s - loss: 0.1778 - mae: 0.3312 - mse: 0.1778
75/75 [==============================] - 0s 6ms/step - loss: 0.1727 - mae: 0.3232 - mse: 0.1727 - val_loss: 0.0369 - val_mae: 0.1632 - val_mse: 0.0369
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1585 - mae: 0.2635 - mse: 0.1585
64/75 [========================>.....] - ETA: 0s - loss: 0.1265 - mae: 0.2494 - mse: 0.1265
75/75 [==============================] - 0s 5ms/step - loss: 0.1167 - mae: 0.2382 - mse: 0.1167 - val_loss: 0.0719 - val_mae: 0.2390 - val_mse: 0.0719
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1591 - mae: 0.3123 - mse: 0.1591
64/75 [========================>.....] - ETA: 0s - loss: 0.1388 - mae: 0.2990 - mse: 0.1388
75/75 [==============================] - 0s 5ms/step - loss: 0.1274 - mae: 0.2880 - mse: 0.1274 - val_loss: 0.1124 - val_mae: 0.2852 - val_mse: 0.1124
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1000 - mae: 0.2731 - mse: 0.1000
64/75 [========================>.....] - ETA: 0s - loss: 0.1064 - mae: 0.2762 - mse: 0.1064
75/75 [==============================] - 0s 5ms/step - loss: 0.1060 - mae: 0.2752 - mse: 0.1060 - val_loss: 0.0877 - val_mae: 0.2571 - val_mse: 0.0877
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1453 - mae: 0.3223 - mse: 0.1453
64/75 [========================>.....] - ETA: 0s - loss: 0.1165 - mae: 0.2801 - mse: 0.1165
75/75 [==============================] - 0s 5ms/step - loss: 0.1217 - mae: 0.2815 - mse: 0.1217 - val_loss: 0.0497 - val_mae: 0.2017 - val_mse: 0.0497
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0964 - mae: 0.2535 - mse: 0.0964
64/75 [========================>.....] - ETA: 0s - loss: 0.0768 - mae: 0.2267 - mse: 0.0768
75/75 [==============================] - 0s 6ms/step - loss: 0.0871 - mae: 0.2348 - mse: 0.0871 - val_loss: 0.0328 - val_mae: 0.1657 - val_mse: 0.0328
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0934 - mae: 0.2293 - mse: 0.0934
64/75 [========================>.....] - ETA: 0s - loss: 0.0845 - mae: 0.2268 - mse: 0.0845
75/75 [==============================] - 0s 6ms/step - loss: 0.0769 - mae: 0.2139 - mse: 0.0769 - val_loss: 0.0285 - val_mae: 0.1526 - val_mse: 0.0285
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0471 - mae: 0.1707 - mse: 0.0471
64/75 [========================>.....] - ETA: 0s - loss: 0.0631 - mae: 0.1910 - mse: 0.0631
75/75 [==============================] - 0s 5ms/step - loss: 0.0666 - mae: 0.1971 - mse: 0.0666 - val_loss: 0.0303 - val_mae: 0.1592 - val_mse: 0.0303
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0487 - mae: 0.1590 - mse: 0.0487
64/75 [========================>.....] - ETA: 0s - loss: 0.0774 - mae: 0.1932 - mse: 0.0774
75/75 [==============================] - 0s 6ms/step - loss: 0.0701 - mae: 0.1837 - mse: 0.0701 - val_loss: 0.0363 - val_mae: 0.1691 - val_mse: 0.0363
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0565 - mae: 0.1659 - mse: 0.0565
64/75 [========================>.....] - ETA: 0s - loss: 0.0684 - mae: 0.1898 - mse: 0.0684
75/75 [==============================] - 0s 6ms/step - loss: 0.0616 - mae: 0.1807 - mse: 0.0616 - val_loss: 0.0327 - val_mae: 0.1593 - val_mse: 0.0327
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0642 - mae: 0.1682 - mse: 0.0642
64/75 [========================>.....] - ETA: 0s - loss: 0.0540 - mae: 0.1701 - mse: 0.0540
75/75 [==============================] - 0s 5ms/step - loss: 0.0488 - mae: 0.1611 - mse: 0.0488 - val_loss: 0.0161 - val_mae: 0.1100 - val_mse: 0.0161
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0563 - mae: 0.1651 - mse: 0.0563
64/75 [========================>.....] - ETA: 0s - loss: 0.0481 - mae: 0.1521 - mse: 0.0481
75/75 [==============================] - 0s 6ms/step - loss: 0.0432 - mae: 0.1441 - mse: 0.0432 - val_loss: 0.0049 - val_mae: 0.0559 - val_mse: 0.0049
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0185 - mae: 0.1136 - mse: 0.0185
64/75 [========================>.....] - ETA: 0s - loss: 0.0377 - mae: 0.1355 - mse: 0.0377
75/75 [==============================] - 0s 5ms/step - loss: 0.0500 - mae: 0.1420 - mse: 0.0500 - val_loss: 0.0044 - val_mae: 0.0548 - val_mse: 0.0044
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0934 - mae: 0.2002 - mse: 0.0934
64/75 [========================>.....] - ETA: 0s - loss: 0.0623 - mae: 0.1673 - mse: 0.0623
75/75 [==============================] - 0s 6ms/step - loss: 0.0605 - mae: 0.1723 - mse: 0.0605 - val_loss: 0.0336 - val_mae: 0.1723 - val_mse: 0.0336
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0325 - mae: 0.1480 - mse: 0.0325
64/75 [========================>.....] - ETA: 0s - loss: 0.0578 - mae: 0.1796 - mse: 0.0578
75/75 [==============================] - 0s 6ms/step - loss: 0.0518 - mae: 0.1690 - mse: 0.0518 - val_loss: 0.0269 - val_mae: 0.1548 - val_mse: 0.0269
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0713 - mae: 0.1882 - mse: 0.0713
64/75 [========================>.....] - ETA: 0s - loss: 0.0561 - mae: 0.1705 - mse: 0.0561
75/75 [==============================] - 0s 5ms/step - loss: 0.0497 - mae: 0.1588 - mse: 0.0497 - val_loss: 0.0107 - val_mae: 0.0872 - val_mse: 0.0107
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0237 - mae: 0.1050 - mse: 0.0237
64/75 [========================>.....] - ETA: 0s - loss: 0.0359 - mae: 0.1200 - mse: 0.0359
75/75 [==============================] - 0s 6ms/step - loss: 0.0330 - mae: 0.1153 - mse: 0.0330 - val_loss: 0.0071 - val_mae: 0.0732 - val_mse: 0.0071
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0543 - mae: 0.1788 - mse: 0.0543
64/75 [========================>.....] - ETA: 0s - loss: 0.0375 - mae: 0.1416 - mse: 0.0375
75/75 [==============================] - 0s 6ms/step - loss: 0.0350 - mae: 0.1354 - mse: 0.0350 - val_loss: 0.0139 - val_mae: 0.1025 - val_mse: 0.0139
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0367 - mae: 0.1485 - mse: 0.0367
64/75 [========================>.....] - ETA: 0s - loss: 0.0390 - mae: 0.1413 - mse: 0.0390
75/75 [==============================] - 0s 5ms/step - loss: 0.0362 - mae: 0.1393 - mse: 0.0362 - val_loss: 0.0248 - val_mae: 0.1473 - val_mse: 0.0248
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0185 - mae: 0.1013 - mse: 0.0185
64/75 [========================>.....] - ETA: 0s - loss: 0.0249 - mae: 0.1204 - mse: 0.0249
75/75 [==============================] - 0s 5ms/step - loss: 0.0297 - mae: 0.1301 - mse: 0.0297 - val_loss: 0.0201 - val_mae: 0.1325 - val_mse: 0.0201
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0245 - mae: 0.1241 - mse: 0.0245
64/75 [========================>.....] - ETA: 0s - loss: 0.0281 - mae: 0.1200 - mse: 0.0281
75/75 [==============================] - 0s 5ms/step - loss: 0.0282 - mae: 0.1217 - mse: 0.0282 - val_loss: 0.0071 - val_mae: 0.0722 - val_mse: 0.0071
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0239 - mae: 0.1226 - mse: 0.0239
64/75 [========================>.....] - ETA: 0s - loss: 0.0301 - mae: 0.1270 - mse: 0.0301
75/75 [==============================] - 0s 5ms/step - loss: 0.0304 - mae: 0.1272 - mse: 0.0304 - val_loss: 0.0065 - val_mae: 0.0699 - val_mse: 0.0065
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0496 - mae: 0.1603 - mse: 0.0496
64/75 [========================>.....] - ETA: 0s - loss: 0.0353 - mae: 0.1370 - mse: 0.0353
75/75 [==============================] - 0s 5ms/step - loss: 0.0380 - mae: 0.1405 - mse: 0.0380 - val_loss: 0.0334 - val_mae: 0.1757 - val_mse: 0.0334
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0363 - mae: 0.1498 - mse: 0.0363
64/75 [========================>.....] - ETA: 0s - loss: 0.0393 - mae: 0.1543 - mse: 0.0393
75/75 [==============================] - 0s 5ms/step - loss: 0.0352 - mae: 0.1441 - mse: 0.0352 - val_loss: 0.0301 - val_mae: 0.1667 - val_mse: 0.0301
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0302 - mae: 0.1346 - mse: 0.0302
64/75 [========================>.....] - ETA: 0s - loss: 0.0298 - mae: 0.1297 - mse: 0.0298
75/75 [==============================] - 0s 5ms/step - loss: 0.0266 - mae: 0.1222 - mse: 0.0266 - val_loss: 0.0055 - val_mae: 0.0596 - val_mse: 0.0055
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0163 - mae: 0.0973 - mse: 0.0163
64/75 [========================>.....] - ETA: 0s - loss: 0.0317 - mae: 0.1318 - mse: 0.0317
75/75 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 0.1398 - mse: 0.0409 - val_loss: 0.0049 - val_mae: 0.0593 - val_mse: 0.0049
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0192 - mae: 0.1010 - mse: 0.0192
64/75 [========================>.....] - ETA: 0s - loss: 0.0234 - mae: 0.1080 - mse: 0.0234
75/75 [==============================] - 0s 5ms/step - loss: 0.0215 - mae: 0.1029 - mse: 0.0215 - val_loss: 0.0254 - val_mae: 0.1529 - val_mse: 0.0254
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0261 - mae: 0.1267 - mse: 0.0261
64/75 [========================>.....] - ETA: 0s - loss: 0.0234 - mae: 0.1155 - mse: 0.0234
75/75 [==============================] - 0s 5ms/step - loss: 0.0240 - mae: 0.1180 - mse: 0.0240 - val_loss: 0.0219 - val_mae: 0.1413 - val_mse: 0.0219
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0268 - mae: 0.1174 - mse: 0.0268
64/75 [========================>.....] - ETA: 0s - loss: 0.0280 - mae: 0.1221 - mse: 0.0280
75/75 [==============================] - 0s 6ms/step - loss: 0.0287 - mae: 0.1239 - mse: 0.0287 - val_loss: 0.0059 - val_mae: 0.0687 - val_mse: 0.0059
Saving trained model...
115
Testing...
heightdiff= [0.         0.         0.         0.         9.53414917]
average prediction= [3.2812972]
baseline= 6.690476190476191
eachuser= [0. 0. 0. 0. 1.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 9.534149169921875
['train-height-12.py', '0']
155 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
155 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
155 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
155 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
170 31
170 32
170 33
170 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
170 37
170 38
2_170_60_12_csi_a12_4.dat
170 40
165 41
165 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
165 48
165 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
165 56
165 57
1_165_65_12_csi_a12_7.dat
165 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
165 70
2_165_50_12_csi_a12_13.dat
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
2_165_50_12_csi_a12_7.dat
165 87
2_165_50_12_csi_a12_23.dat
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
1_175_70_12_csi_a12_26.dat
175 127
175 128
175 129
175 130
180 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
180 134
180 135
1_180_85_12_csi_a12_19.dat
180 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
180 140
1_180_85_12_csi_a12_12.dat
180 142
180 143
180 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
180 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
180 161
180 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
180 165
180 166
180 167
180 168
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
1_180_75_12_csi_a12_12.dat
180 178
1_180_75_12_csi_a12_13.dat
180 180
180 181
180 182
1_180_75_12_csi_a12_14.dat
180 184
180 185
180 186
180 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
180 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[155 155 155 155 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.5681 - mae: 0.6882 - mse: 0.5681
64/75 [========================>.....] - ETA: 0s - loss: 0.4478 - mae: 0.5871 - mse: 0.4478
75/75 [==============================] - 1s 13ms/step - loss: 0.4152 - mae: 0.5591 - mse: 0.4152 - val_loss: 0.1117 - val_mae: 0.2825 - val_mse: 0.1117
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1226 - mae: 0.3014 - mse: 0.1226
64/75 [========================>.....] - ETA: 0s - loss: 0.1440 - mae: 0.3104 - mse: 0.1440
75/75 [==============================] - 0s 6ms/step - loss: 0.1431 - mae: 0.3116 - mse: 0.1431 - val_loss: 0.0635 - val_mae: 0.2237 - val_mse: 0.0635
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1162 - mae: 0.2748 - mse: 0.1162
64/75 [========================>.....] - ETA: 0s - loss: 0.1252 - mae: 0.2837 - mse: 0.1252
75/75 [==============================] - 0s 5ms/step - loss: 0.1268 - mae: 0.2849 - mse: 0.1268 - val_loss: 0.0616 - val_mae: 0.2118 - val_mse: 0.0616
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1060 - mae: 0.2586 - mse: 0.1060
64/75 [========================>.....] - ETA: 0s - loss: 0.0967 - mae: 0.2484 - mse: 0.0967
75/75 [==============================] - 0s 5ms/step - loss: 0.0985 - mae: 0.2538 - mse: 0.0985 - val_loss: 0.0938 - val_mae: 0.2416 - val_mse: 0.0938
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0874 - mae: 0.2400 - mse: 0.0874
64/75 [========================>.....] - ETA: 0s - loss: 0.0872 - mae: 0.2407 - mse: 0.0872
75/75 [==============================] - 0s 6ms/step - loss: 0.0824 - mae: 0.2331 - mse: 0.0824 - val_loss: 0.0758 - val_mae: 0.2210 - val_mse: 0.0758
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0934 - mae: 0.2370 - mse: 0.0934
64/75 [========================>.....] - ETA: 0s - loss: 0.0930 - mae: 0.2326 - mse: 0.0930
75/75 [==============================] - 0s 5ms/step - loss: 0.0824 - mae: 0.2154 - mse: 0.0824 - val_loss: 0.0416 - val_mae: 0.1611 - val_mse: 0.0416
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0817 - mae: 0.2258 - mse: 0.0817
64/75 [========================>.....] - ETA: 0s - loss: 0.0733 - mae: 0.2026 - mse: 0.0733
75/75 [==============================] - 0s 5ms/step - loss: 0.0782 - mae: 0.2040 - mse: 0.0782 - val_loss: 0.0260 - val_mae: 0.1257 - val_mse: 0.0260
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1049 - mae: 0.2093 - mse: 0.1049
64/75 [========================>.....] - ETA: 0s - loss: 0.0811 - mae: 0.1884 - mse: 0.0811
75/75 [==============================] - 0s 5ms/step - loss: 0.0728 - mae: 0.1815 - mse: 0.0728 - val_loss: 0.0348 - val_mae: 0.1517 - val_mse: 0.0348
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0673 - mae: 0.1881 - mse: 0.0673
64/75 [========================>.....] - ETA: 0s - loss: 0.0643 - mae: 0.1836 - mse: 0.0643
75/75 [==============================] - 0s 6ms/step - loss: 0.0616 - mae: 0.1817 - mse: 0.0616 - val_loss: 0.0422 - val_mae: 0.1714 - val_mse: 0.0422
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0400 - mae: 0.1487 - mse: 0.0400
64/75 [========================>.....] - ETA: 0s - loss: 0.0466 - mae: 0.1592 - mse: 0.0466
75/75 [==============================] - 0s 6ms/step - loss: 0.0459 - mae: 0.1612 - mse: 0.0459 - val_loss: 0.0318 - val_mae: 0.1477 - val_mse: 0.0318
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0815 - mae: 0.1821 - mse: 0.0815
64/75 [========================>.....] - ETA: 0s - loss: 0.0546 - mae: 0.1583 - mse: 0.0546
75/75 [==============================] - 0s 5ms/step - loss: 0.0519 - mae: 0.1562 - mse: 0.0519 - val_loss: 0.0249 - val_mae: 0.1293 - val_mse: 0.0249
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0528 - mae: 0.1637 - mse: 0.0528
64/75 [========================>.....] - ETA: 0s - loss: 0.0543 - mae: 0.1569 - mse: 0.0543
75/75 [==============================] - 0s 6ms/step - loss: 0.0518 - mae: 0.1550 - mse: 0.0518 - val_loss: 0.0319 - val_mae: 0.1570 - val_mse: 0.0319
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0413 - mae: 0.1406 - mse: 0.0413
64/75 [========================>.....] - ETA: 0s - loss: 0.0424 - mae: 0.1354 - mse: 0.0424
75/75 [==============================] - 0s 5ms/step - loss: 0.0395 - mae: 0.1336 - mse: 0.0395 - val_loss: 0.0420 - val_mae: 0.1893 - val_mse: 0.0420
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0800 - mae: 0.2188 - mse: 0.0800
64/75 [========================>.....] - ETA: 0s - loss: 0.0629 - mae: 0.1874 - mse: 0.0629
75/75 [==============================] - 0s 5ms/step - loss: 0.0581 - mae: 0.1787 - mse: 0.0581 - val_loss: 0.0380 - val_mae: 0.1815 - val_mse: 0.0380
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0233 - mae: 0.1121 - mse: 0.0233
64/75 [========================>.....] - ETA: 0s - loss: 0.0270 - mae: 0.1257 - mse: 0.0270
75/75 [==============================] - 0s 5ms/step - loss: 0.0369 - mae: 0.1451 - mse: 0.0369 - val_loss: 0.0365 - val_mae: 0.1792 - val_mse: 0.0365
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0310 - mae: 0.1363 - mse: 0.0310
64/75 [========================>.....] - ETA: 0s - loss: 0.0384 - mae: 0.1449 - mse: 0.0384
75/75 [==============================] - 0s 6ms/step - loss: 0.0423 - mae: 0.1456 - mse: 0.0423 - val_loss: 0.0278 - val_mae: 0.1552 - val_mse: 0.0278
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0716 - mae: 0.1786 - mse: 0.0716
64/75 [========================>.....] - ETA: 0s - loss: 0.0460 - mae: 0.1490 - mse: 0.0460
75/75 [==============================] - 0s 5ms/step - loss: 0.0440 - mae: 0.1482 - mse: 0.0440 - val_loss: 0.0379 - val_mae: 0.1842 - val_mse: 0.0379
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0493 - mae: 0.1487 - mse: 0.0493
64/75 [========================>.....] - ETA: 0s - loss: 0.0409 - mae: 0.1402 - mse: 0.0409
75/75 [==============================] - 0s 6ms/step - loss: 0.0409 - mae: 0.1427 - mse: 0.0409 - val_loss: 0.0363 - val_mae: 0.1789 - val_mse: 0.0363
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0262 - mae: 0.1139 - mse: 0.0262
64/75 [========================>.....] - ETA: 0s - loss: 0.0307 - mae: 0.1252 - mse: 0.0307
75/75 [==============================] - 0s 6ms/step - loss: 0.0345 - mae: 0.1347 - mse: 0.0345 - val_loss: 0.0249 - val_mae: 0.1446 - val_mse: 0.0249
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0355 - mae: 0.1276 - mse: 0.0355
64/75 [========================>.....] - ETA: 0s - loss: 0.0278 - mae: 0.1191 - mse: 0.0278
75/75 [==============================] - 0s 6ms/step - loss: 0.0288 - mae: 0.1207 - mse: 0.0288 - val_loss: 0.0273 - val_mae: 0.1524 - val_mse: 0.0273
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0417 - mae: 0.1462 - mse: 0.0417
64/75 [========================>.....] - ETA: 0s - loss: 0.0339 - mae: 0.1310 - mse: 0.0339
75/75 [==============================] - 0s 6ms/step - loss: 0.0304 - mae: 0.1238 - mse: 0.0304 - val_loss: 0.0380 - val_mae: 0.1835 - val_mse: 0.0380
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0376 - mae: 0.1471 - mse: 0.0376
64/75 [========================>.....] - ETA: 0s - loss: 0.0319 - mae: 0.1270 - mse: 0.0319
75/75 [==============================] - 0s 5ms/step - loss: 0.0303 - mae: 0.1240 - mse: 0.0303 - val_loss: 0.0370 - val_mae: 0.1823 - val_mse: 0.0370
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0278 - mae: 0.1303 - mse: 0.0278
64/75 [========================>.....] - ETA: 0s - loss: 0.0268 - mae: 0.1235 - mse: 0.0268
75/75 [==============================] - 0s 5ms/step - loss: 0.0278 - mae: 0.1266 - mse: 0.0278 - val_loss: 0.0287 - val_mae: 0.1597 - val_mse: 0.0287
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0274 - mae: 0.1262 - mse: 0.0274
64/75 [========================>.....] - ETA: 0s - loss: 0.0254 - mae: 0.1167 - mse: 0.0254
75/75 [==============================] - 0s 5ms/step - loss: 0.0294 - mae: 0.1208 - mse: 0.0294 - val_loss: 0.0260 - val_mae: 0.1512 - val_mse: 0.0260
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0293 - mae: 0.1216 - mse: 0.0293
64/75 [========================>.....] - ETA: 0s - loss: 0.0235 - mae: 0.1105 - mse: 0.0235
75/75 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 0.1092 - mse: 0.0219 - val_loss: 0.0227 - val_mae: 0.1402 - val_mse: 0.0227
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0162 - mae: 0.0900 - mse: 0.0162
64/75 [========================>.....] - ETA: 0s - loss: 0.0228 - mae: 0.1126 - mse: 0.0228
75/75 [==============================] - 0s 5ms/step - loss: 0.0212 - mae: 0.1084 - mse: 0.0212 - val_loss: 0.0213 - val_mae: 0.1348 - val_mse: 0.0213
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0178 - mae: 0.0925 - mse: 0.0178
64/75 [========================>.....] - ETA: 0s - loss: 0.0204 - mae: 0.1014 - mse: 0.0204
75/75 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 0.1028 - mse: 0.0210 - val_loss: 0.0283 - val_mae: 0.1582 - val_mse: 0.0283
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0161 - mae: 0.0920 - mse: 0.0161
64/75 [========================>.....] - ETA: 0s - loss: 0.0216 - mae: 0.1101 - mse: 0.0216
75/75 [==============================] - 0s 6ms/step - loss: 0.0198 - mae: 0.1063 - mse: 0.0198 - val_loss: 0.0342 - val_mae: 0.1731 - val_mse: 0.0342
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0187 - mae: 0.1065 - mse: 0.0187
64/75 [========================>.....] - ETA: 0s - loss: 0.0210 - mae: 0.1104 - mse: 0.0210
75/75 [==============================] - 0s 5ms/step - loss: 0.0235 - mae: 0.1153 - mse: 0.0235 - val_loss: 0.0282 - val_mae: 0.1570 - val_mse: 0.0282
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0179 - mae: 0.1024 - mse: 0.0179
64/75 [========================>.....] - ETA: 0s - loss: 0.0165 - mae: 0.0931 - mse: 0.0165
75/75 [==============================] - 0s 5ms/step - loss: 0.0162 - mae: 0.0912 - mse: 0.0162 - val_loss: 0.0152 - val_mae: 0.1171 - val_mse: 0.0152
Saving trained model...
115
Testing...
heightdiff= [0. 0. 0. 0. 0.]
average prediction= [3.3133566]
baseline= 6.880952380952381
eachuser= [0. 0. 0. 0. 0.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- nan
['train-height-12.py', '0']
155 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
155 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
155 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
155 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
170 31
170 32
170 33
170 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
170 37
170 38
2_170_60_12_csi_a12_4.dat
170 40
165 41
165 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
165 48
165 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
165 56
165 57
1_165_65_12_csi_a12_7.dat
165 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
165 70
2_165_50_12_csi_a12_13.dat
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
2_165_50_12_csi_a12_7.dat
165 87
2_165_50_12_csi_a12_23.dat
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
1_175_70_12_csi_a12_26.dat
175 127
175 128
175 129
175 130
180 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
180 134
180 135
1_180_85_12_csi_a12_19.dat
180 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
180 140
1_180_85_12_csi_a12_12.dat
180 142
180 143
180 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
180 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
180 161
180 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
180 165
180 166
180 167
180 168
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
1_180_75_12_csi_a12_12.dat
180 178
1_180_75_12_csi_a12_13.dat
180 180
180 181
180 182
1_180_75_12_csi_a12_14.dat
180 184
180 185
180 186
180 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
180 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[155 155 155 155 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.6243 - mae: 0.7336 - mse: 0.6243
64/75 [========================>.....] - ETA: 0s - loss: 0.5744 - mae: 0.7071 - mse: 0.5744
75/75 [==============================] - 1s 11ms/step - loss: 0.5526 - mae: 0.6954 - mse: 0.5526 - val_loss: 0.3585 - val_mae: 0.5572 - val_mse: 0.3585
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.3422 - mae: 0.5363 - mse: 0.3422
64/75 [========================>.....] - ETA: 0s - loss: 0.2795 - mae: 0.4663 - mse: 0.2795
75/75 [==============================] - 0s 6ms/step - loss: 0.2609 - mae: 0.4510 - mse: 0.2609 - val_loss: 0.1023 - val_mae: 0.2742 - val_mse: 0.1023
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0997 - mae: 0.2604 - mse: 0.0997
64/75 [========================>.....] - ETA: 0s - loss: 0.0942 - mae: 0.2420 - mse: 0.0942
75/75 [==============================] - 0s 5ms/step - loss: 0.0909 - mae: 0.2342 - mse: 0.0909 - val_loss: 0.0562 - val_mae: 0.1696 - val_mse: 0.0562
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.2165 - mae: 0.3734 - mse: 0.2165
64/75 [========================>.....] - ETA: 0s - loss: 0.1820 - mae: 0.3388 - mse: 0.1820
75/75 [==============================] - 0s 6ms/step - loss: 0.1675 - mae: 0.3236 - mse: 0.1675 - val_loss: 0.0321 - val_mae: 0.1673 - val_mse: 0.0321
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1007 - mae: 0.2448 - mse: 0.1007
64/75 [========================>.....] - ETA: 0s - loss: 0.0994 - mae: 0.2368 - mse: 0.0994
75/75 [==============================] - 0s 6ms/step - loss: 0.0925 - mae: 0.2296 - mse: 0.0925 - val_loss: 0.0780 - val_mae: 0.2327 - val_mse: 0.0780
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0944 - mae: 0.2378 - mse: 0.0944
64/75 [========================>.....] - ETA: 0s - loss: 0.0899 - mae: 0.2288 - mse: 0.0899
75/75 [==============================] - 0s 5ms/step - loss: 0.0894 - mae: 0.2298 - mse: 0.0894 - val_loss: 0.1211 - val_mae: 0.3056 - val_mse: 0.1211
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1089 - mae: 0.2596 - mse: 0.1089
64/75 [========================>.....] - ETA: 0s - loss: 0.0981 - mae: 0.2564 - mse: 0.0981
75/75 [==============================] - 0s 6ms/step - loss: 0.0975 - mae: 0.2567 - mse: 0.0975 - val_loss: 0.1113 - val_mae: 0.2941 - val_mse: 0.1113
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0883 - mae: 0.2447 - mse: 0.0883
64/75 [========================>.....] - ETA: 0s - loss: 0.0768 - mae: 0.2340 - mse: 0.0768
75/75 [==============================] - 0s 6ms/step - loss: 0.0878 - mae: 0.2446 - mse: 0.0878 - val_loss: 0.0699 - val_mae: 0.2219 - val_mse: 0.0699
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0737 - mae: 0.1811 - mse: 0.0737
64/75 [========================>.....] - ETA: 0s - loss: 0.0546 - mae: 0.1706 - mse: 0.0546
75/75 [==============================] - 0s 6ms/step - loss: 0.0534 - mae: 0.1706 - mse: 0.0534 - val_loss: 0.0402 - val_mae: 0.1601 - val_mse: 0.0402
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0263 - mae: 0.1258 - mse: 0.0263
64/75 [========================>.....] - ETA: 0s - loss: 0.0457 - mae: 0.1465 - mse: 0.0457
75/75 [==============================] - 0s 6ms/step - loss: 0.0591 - mae: 0.1553 - mse: 0.0591 - val_loss: 0.0247 - val_mae: 0.1322 - val_mse: 0.0247
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0859 - mae: 0.2244 - mse: 0.0859
64/75 [========================>.....] - ETA: 0s - loss: 0.0642 - mae: 0.1877 - mse: 0.0642
75/75 [==============================] - 0s 5ms/step - loss: 0.0584 - mae: 0.1802 - mse: 0.0584 - val_loss: 0.0314 - val_mae: 0.1422 - val_mse: 0.0314
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0331 - mae: 0.1442 - mse: 0.0331
64/75 [========================>.....] - ETA: 0s - loss: 0.0633 - mae: 0.1730 - mse: 0.0633
75/75 [==============================] - 0s 6ms/step - loss: 0.0586 - mae: 0.1679 - mse: 0.0586 - val_loss: 0.0415 - val_mae: 0.1609 - val_mse: 0.0415
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0452 - mae: 0.1293 - mse: 0.0452
64/75 [========================>.....] - ETA: 0s - loss: 0.0402 - mae: 0.1368 - mse: 0.0402
75/75 [==============================] - 0s 6ms/step - loss: 0.0477 - mae: 0.1461 - mse: 0.0477 - val_loss: 0.0513 - val_mae: 0.1846 - val_mse: 0.0513
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0633 - mae: 0.1769 - mse: 0.0633
64/75 [========================>.....] - ETA: 0s - loss: 0.0471 - mae: 0.1548 - mse: 0.0471
75/75 [==============================] - 0s 6ms/step - loss: 0.0420 - mae: 0.1461 - mse: 0.0420 - val_loss: 0.0534 - val_mae: 0.1899 - val_mse: 0.0534
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0337 - mae: 0.1308 - mse: 0.0337
64/75 [========================>.....] - ETA: 0s - loss: 0.0495 - mae: 0.1717 - mse: 0.0495
75/75 [==============================] - 0s 6ms/step - loss: 0.0456 - mae: 0.1637 - mse: 0.0456 - val_loss: 0.0454 - val_mae: 0.1701 - val_mse: 0.0454
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0328 - mae: 0.1465 - mse: 0.0328
64/75 [========================>.....] - ETA: 0s - loss: 0.0297 - mae: 0.1366 - mse: 0.0297
75/75 [==============================] - 0s 6ms/step - loss: 0.0342 - mae: 0.1432 - mse: 0.0342 - val_loss: 0.0335 - val_mae: 0.1418 - val_mse: 0.0335
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0200 - mae: 0.1150 - mse: 0.0200
64/75 [========================>.....] - ETA: 0s - loss: 0.0328 - mae: 0.1385 - mse: 0.0328
75/75 [==============================] - 0s 6ms/step - loss: 0.0424 - mae: 0.1522 - mse: 0.0424 - val_loss: 0.0347 - val_mae: 0.1452 - val_mse: 0.0347
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0355 - mae: 0.1314 - mse: 0.0355
64/75 [========================>.....] - ETA: 0s - loss: 0.0312 - mae: 0.1273 - mse: 0.0312
75/75 [==============================] - 0s 6ms/step - loss: 0.0352 - mae: 0.1348 - mse: 0.0352 - val_loss: 0.0444 - val_mae: 0.1750 - val_mse: 0.0444
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0294 - mae: 0.1294 - mse: 0.0294
64/75 [========================>.....] - ETA: 0s - loss: 0.0281 - mae: 0.1274 - mse: 0.0281
75/75 [==============================] - 0s 6ms/step - loss: 0.0324 - mae: 0.1332 - mse: 0.0324 - val_loss: 0.0442 - val_mae: 0.1777 - val_mse: 0.0442
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0292 - mae: 0.1282 - mse: 0.0292
64/75 [========================>.....] - ETA: 0s - loss: 0.0290 - mae: 0.1291 - mse: 0.0290
75/75 [==============================] - 0s 5ms/step - loss: 0.0268 - mae: 0.1238 - mse: 0.0268 - val_loss: 0.0338 - val_mae: 0.1513 - val_mse: 0.0338
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0190 - mae: 0.0951 - mse: 0.0190
64/75 [========================>.....] - ETA: 0s - loss: 0.0316 - mae: 0.1170 - mse: 0.0316
75/75 [==============================] - 0s 5ms/step - loss: 0.0293 - mae: 0.1144 - mse: 0.0293 - val_loss: 0.0289 - val_mae: 0.1373 - val_mse: 0.0289
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0400 - mae: 0.1320 - mse: 0.0400
64/75 [========================>.....] - ETA: 0s - loss: 0.0311 - mae: 0.1209 - mse: 0.0311
75/75 [==============================] - 0s 6ms/step - loss: 0.0277 - mae: 0.1136 - mse: 0.0277 - val_loss: 0.0268 - val_mae: 0.1286 - val_mse: 0.0268
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0289 - mae: 0.1303 - mse: 0.0289
64/75 [========================>.....] - ETA: 0s - loss: 0.0272 - mae: 0.1203 - mse: 0.0272
75/75 [==============================] - 0s 6ms/step - loss: 0.0301 - mae: 0.1259 - mse: 0.0301 - val_loss: 0.0419 - val_mae: 0.1783 - val_mse: 0.0419
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0277 - mae: 0.1207 - mse: 0.0277
64/75 [========================>.....] - ETA: 0s - loss: 0.0310 - mae: 0.1277 - mse: 0.0310
75/75 [==============================] - 0s 6ms/step - loss: 0.0308 - mae: 0.1296 - mse: 0.0308 - val_loss: 0.0533 - val_mae: 0.2054 - val_mse: 0.0533
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0346 - mae: 0.1315 - mse: 0.0346
64/75 [========================>.....] - ETA: 0s - loss: 0.0280 - mae: 0.1164 - mse: 0.0280
75/75 [==============================] - 0s 6ms/step - loss: 0.0267 - mae: 0.1141 - mse: 0.0267 - val_loss: 0.0348 - val_mae: 0.1547 - val_mse: 0.0348
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0250 - mae: 0.1191 - mse: 0.0250
64/75 [========================>.....] - ETA: 0s - loss: 0.0223 - mae: 0.1128 - mse: 0.0223
75/75 [==============================] - 0s 6ms/step - loss: 0.0260 - mae: 0.1145 - mse: 0.0260 - val_loss: 0.0176 - val_mae: 0.0909 - val_mse: 0.0176
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0125 - mae: 0.0923 - mse: 0.0125
64/75 [========================>.....] - ETA: 0s - loss: 0.0212 - mae: 0.1094 - mse: 0.0212
75/75 [==============================] - 0s 6ms/step - loss: 0.0219 - mae: 0.1120 - mse: 0.0219 - val_loss: 0.0185 - val_mae: 0.0987 - val_mse: 0.0185
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0184 - mae: 0.0890 - mse: 0.0184
64/75 [========================>.....] - ETA: 0s - loss: 0.0203 - mae: 0.1012 - mse: 0.0203
75/75 [==============================] - 0s 6ms/step - loss: 0.0237 - mae: 0.1107 - mse: 0.0237 - val_loss: 0.0333 - val_mae: 0.1572 - val_mse: 0.0333
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0261 - mae: 0.1101 - mse: 0.0261
64/75 [========================>.....] - ETA: 0s - loss: 0.0272 - mae: 0.1178 - mse: 0.0272
75/75 [==============================] - 0s 6ms/step - loss: 0.0287 - mae: 0.1231 - mse: 0.0287 - val_loss: 0.0486 - val_mae: 0.1995 - val_mse: 0.0486
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0176 - mae: 0.1001 - mse: 0.0176
64/75 [========================>.....] - ETA: 0s - loss: 0.0285 - mae: 0.1300 - mse: 0.0285
75/75 [==============================] - 0s 5ms/step - loss: 0.0295 - mae: 0.1312 - mse: 0.0295 - val_loss: 0.0290 - val_mae: 0.1492 - val_mse: 0.0290
Saving trained model...
115
Testing...
heightdiff= [ 0.          0.          0.          0.         23.02178955]
average prediction= [3.416036]
baseline= 6.928571428571429
eachuser= [0. 0. 0. 0. 2.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 11.510894775390625
['train-height-12.py', '0']
155 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
155 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
155 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
155 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
170 31
170 32
170 33
170 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
170 37
170 38
2_170_60_12_csi_a12_4.dat
170 40
165 41
165 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
165 48
165 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
165 56
165 57
1_165_65_12_csi_a12_7.dat
165 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
165 70
2_165_50_12_csi_a12_13.dat
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
2_165_50_12_csi_a12_7.dat
165 87
2_165_50_12_csi_a12_23.dat
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
1_175_70_12_csi_a12_26.dat
175 127
175 128
175 129
175 130
180 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
180 134
180 135
1_180_85_12_csi_a12_19.dat
180 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
180 140
1_180_85_12_csi_a12_12.dat
180 142
180 143
180 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
180 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
180 161
180 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
180 165
180 166
180 167
180 168
180 169
180 170
180 171
180 172
180 173
180 174
180 175
180 176
1_180_75_12_csi_a12_12.dat
180 178
1_180_75_12_csi_a12_13.dat
180 180
180 181
180 182
1_180_75_12_csi_a12_14.dat
180 184
180 185
180 186
180 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
180 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[155 155 155 155 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.6309 - mae: 0.7484 - mse: 0.6309
64/75 [========================>.....] - ETA: 0s - loss: 0.4709 - mae: 0.6220 - mse: 0.4709
75/75 [==============================] - 1s 11ms/step - loss: 0.4260 - mae: 0.5784 - mse: 0.4260 - val_loss: 0.2090 - val_mae: 0.3709 - val_mse: 0.2090
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1467 - mae: 0.3548 - mse: 0.1467
64/75 [========================>.....] - ETA: 0s - loss: 0.1501 - mae: 0.3467 - mse: 0.1501
75/75 [==============================] - 0s 6ms/step - loss: 0.1543 - mae: 0.3443 - mse: 0.1543 - val_loss: 0.1419 - val_mae: 0.3550 - val_mse: 0.1419
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.2249 - mae: 0.3873 - mse: 0.2249
64/75 [========================>.....] - ETA: 0s - loss: 0.1973 - mae: 0.3505 - mse: 0.1973
75/75 [==============================] - 0s 5ms/step - loss: 0.1799 - mae: 0.3369 - mse: 0.1799 - val_loss: 0.1131 - val_mae: 0.3160 - val_mse: 0.1131
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1476 - mae: 0.3147 - mse: 0.1476
64/75 [========================>.....] - ETA: 0s - loss: 0.1067 - mae: 0.2656 - mse: 0.1067
75/75 [==============================] - 0s 6ms/step - loss: 0.1146 - mae: 0.2831 - mse: 0.1146 - val_loss: 0.1357 - val_mae: 0.2938 - val_mse: 0.1357
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1314 - mae: 0.2962 - mse: 0.1314
64/75 [========================>.....] - ETA: 0s - loss: 0.1100 - mae: 0.2749 - mse: 0.1100
75/75 [==============================] - 0s 6ms/step - loss: 0.1068 - mae: 0.2729 - mse: 0.1068 - val_loss: 0.1282 - val_mae: 0.2768 - val_mse: 0.1282
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1093 - mae: 0.2788 - mse: 0.1093
64/75 [========================>.....] - ETA: 0s - loss: 0.0931 - mae: 0.2545 - mse: 0.0931
75/75 [==============================] - 0s 5ms/step - loss: 0.0927 - mae: 0.2522 - mse: 0.0927 - val_loss: 0.0891 - val_mae: 0.2432 - val_mse: 0.0891
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1088 - mae: 0.2772 - mse: 0.1088
64/75 [========================>.....] - ETA: 0s - loss: 0.0838 - mae: 0.2447 - mse: 0.0838
75/75 [==============================] - 0s 6ms/step - loss: 0.0870 - mae: 0.2492 - mse: 0.0870 - val_loss: 0.0625 - val_mae: 0.2112 - val_mse: 0.0625
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0852 - mae: 0.2304 - mse: 0.0852
64/75 [========================>.....] - ETA: 0s - loss: 0.0690 - mae: 0.2184 - mse: 0.0690
75/75 [==============================] - 0s 6ms/step - loss: 0.0861 - mae: 0.2361 - mse: 0.0861 - val_loss: 0.0603 - val_mae: 0.1983 - val_mse: 0.0603
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0941 - mae: 0.2155 - mse: 0.0941
64/75 [========================>.....] - ETA: 0s - loss: 0.0777 - mae: 0.2045 - mse: 0.0777
75/75 [==============================] - 0s 6ms/step - loss: 0.0752 - mae: 0.2065 - mse: 0.0752 - val_loss: 0.0689 - val_mae: 0.2175 - val_mse: 0.0689
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0852 - mae: 0.1922 - mse: 0.0852
64/75 [========================>.....] - ETA: 0s - loss: 0.0753 - mae: 0.1999 - mse: 0.0753
75/75 [==============================] - 0s 6ms/step - loss: 0.0669 - mae: 0.1873 - mse: 0.0669 - val_loss: 0.0582 - val_mae: 0.2033 - val_mse: 0.0582
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0346 - mae: 0.1497 - mse: 0.0346
64/75 [========================>.....] - ETA: 0s - loss: 0.0698 - mae: 0.1808 - mse: 0.0698
75/75 [==============================] - 0s 6ms/step - loss: 0.0632 - mae: 0.1734 - mse: 0.0632 - val_loss: 0.0456 - val_mae: 0.1840 - val_mse: 0.0456
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0236 - mae: 0.1219 - mse: 0.0236
64/75 [========================>.....] - ETA: 0s - loss: 0.0444 - mae: 0.1408 - mse: 0.0444
75/75 [==============================] - 0s 6ms/step - loss: 0.0448 - mae: 0.1453 - mse: 0.0448 - val_loss: 0.0445 - val_mae: 0.1876 - val_mse: 0.0445
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0312 - mae: 0.1423 - mse: 0.0312
64/75 [========================>.....] - ETA: 0s - loss: 0.0425 - mae: 0.1457 - mse: 0.0425
75/75 [==============================] - 0s 6ms/step - loss: 0.0415 - mae: 0.1463 - mse: 0.0415 - val_loss: 0.0452 - val_mae: 0.1922 - val_mse: 0.0452
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0584 - mae: 0.1617 - mse: 0.0584
64/75 [========================>.....] - ETA: 0s - loss: 0.0498 - mae: 0.1580 - mse: 0.0498
75/75 [==============================] - 0s 6ms/step - loss: 0.0468 - mae: 0.1552 - mse: 0.0468 - val_loss: 0.0459 - val_mae: 0.1937 - val_mse: 0.0459
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0657 - mae: 0.1780 - mse: 0.0657
64/75 [========================>.....] - ETA: 0s - loss: 0.0575 - mae: 0.1743 - mse: 0.0575
75/75 [==============================] - 0s 6ms/step - loss: 0.0501 - mae: 0.1594 - mse: 0.0501 - val_loss: 0.0407 - val_mae: 0.1798 - val_mse: 0.0407
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0220 - mae: 0.1153 - mse: 0.0220
64/75 [========================>.....] - ETA: 0s - loss: 0.0378 - mae: 0.1426 - mse: 0.0378
75/75 [==============================] - 0s 6ms/step - loss: 0.0368 - mae: 0.1432 - mse: 0.0368 - val_loss: 0.0344 - val_mae: 0.1630 - val_mse: 0.0344
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0455 - mae: 0.1565 - mse: 0.0455
64/75 [========================>.....] - ETA: 0s - loss: 0.0406 - mae: 0.1397 - mse: 0.0406
75/75 [==============================] - 0s 5ms/step - loss: 0.0379 - mae: 0.1379 - mse: 0.0379 - val_loss: 0.0384 - val_mae: 0.1750 - val_mse: 0.0384
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0587 - mae: 0.1757 - mse: 0.0587
64/75 [========================>.....] - ETA: 0s - loss: 0.0482 - mae: 0.1595 - mse: 0.0482
75/75 [==============================] - 0s 6ms/step - loss: 0.0436 - mae: 0.1516 - mse: 0.0436 - val_loss: 0.0243 - val_mae: 0.1376 - val_mse: 0.0243
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0419 - mae: 0.1446 - mse: 0.0419
64/75 [========================>.....] - ETA: 0s - loss: 0.0355 - mae: 0.1241 - mse: 0.0355
75/75 [==============================] - 0s 5ms/step - loss: 0.0311 - mae: 0.1156 - mse: 0.0311 - val_loss: 0.0217 - val_mae: 0.1322 - val_mse: 0.0217
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0228 - mae: 0.1304 - mse: 0.0228
64/75 [========================>.....] - ETA: 0s - loss: 0.0326 - mae: 0.1313 - mse: 0.0326
75/75 [==============================] - 0s 6ms/step - loss: 0.0288 - mae: 0.1210 - mse: 0.0288 - val_loss: 0.0290 - val_mae: 0.1571 - val_mse: 0.0290
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0480 - mae: 0.1531 - mse: 0.0480
64/75 [========================>.....] - ETA: 0s - loss: 0.0339 - mae: 0.1284 - mse: 0.0339
75/75 [==============================] - 0s 6ms/step - loss: 0.0325 - mae: 0.1234 - mse: 0.0325 - val_loss: 0.0322 - val_mae: 0.1671 - val_mse: 0.0322
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0199 - mae: 0.1044 - mse: 0.0199
64/75 [========================>.....] - ETA: 0s - loss: 0.0249 - mae: 0.1145 - mse: 0.0249
75/75 [==============================] - 0s 5ms/step - loss: 0.0254 - mae: 0.1184 - mse: 0.0254 - val_loss: 0.0212 - val_mae: 0.1362 - val_mse: 0.0212
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0318 - mae: 0.1060 - mse: 0.0318
64/75 [========================>.....] - ETA: 0s - loss: 0.0303 - mae: 0.1095 - mse: 0.0303
75/75 [==============================] - 0s 6ms/step - loss: 0.0279 - mae: 0.1049 - mse: 0.0279 - val_loss: 0.0181 - val_mae: 0.1265 - val_mse: 0.0181
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0300 - mae: 0.1095 - mse: 0.0300
64/75 [========================>.....] - ETA: 0s - loss: 0.0224 - mae: 0.0993 - mse: 0.0224
75/75 [==============================] - 0s 6ms/step - loss: 0.0232 - mae: 0.1046 - mse: 0.0232 - val_loss: 0.0284 - val_mae: 0.1601 - val_mse: 0.0284
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0224 - mae: 0.1162 - mse: 0.0224
64/75 [========================>.....] - ETA: 0s - loss: 0.0294 - mae: 0.1320 - mse: 0.0294
75/75 [==============================] - 0s 5ms/step - loss: 0.0316 - mae: 0.1314 - mse: 0.0316 - val_loss: 0.0245 - val_mae: 0.1480 - val_mse: 0.0245
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0185 - mae: 0.0976 - mse: 0.0185
64/75 [========================>.....] - ETA: 0s - loss: 0.0205 - mae: 0.1066 - mse: 0.0205
75/75 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 0.1032 - mse: 0.0190 - val_loss: 0.0171 - val_mae: 0.1227 - val_mse: 0.0171
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0178 - mae: 0.0933 - mse: 0.0178
64/75 [========================>.....] - ETA: 0s - loss: 0.0215 - mae: 0.1056 - mse: 0.0215
75/75 [==============================] - 0s 6ms/step - loss: 0.0259 - mae: 0.1150 - mse: 0.0259 - val_loss: 0.0201 - val_mae: 0.1337 - val_mse: 0.0201
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0250 - mae: 0.1033 - mse: 0.0250
64/75 [========================>.....] - ETA: 0s - loss: 0.0208 - mae: 0.0999 - mse: 0.0208
75/75 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 0.0962 - mse: 0.0193 - val_loss: 0.0237 - val_mae: 0.1461 - val_mse: 0.0237
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0316 - mae: 0.1198 - mse: 0.0316
64/75 [========================>.....] - ETA: 0s - loss: 0.0253 - mae: 0.1085 - mse: 0.0253
75/75 [==============================] - 0s 5ms/step - loss: 0.0235 - mae: 0.1067 - mse: 0.0235 - val_loss: 0.0149 - val_mae: 0.1132 - val_mse: 0.0149
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0325 - mae: 0.1226 - mse: 0.0325
64/75 [========================>.....] - ETA: 0s - loss: 0.0218 - mae: 0.1007 - mse: 0.0218
75/75 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 0.1011 - mse: 0.0219 - val_loss: 0.0132 - val_mae: 0.1053 - val_mse: 0.0132
Saving trained model...
115
Testing...
heightdiff= [ 0.          0.          0.          0.         26.37150574]
average prediction= [3.488909]
baseline= 6.785714285714286
eachuser= [0. 0. 0. 0. 2.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 13.185752868652344
