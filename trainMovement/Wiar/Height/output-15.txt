['train-height-15.py', '0']
155 1
155 2
155 3
2_155_65_15_csi_a15_22.dat
155 5
155 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
2_155_65_15_csi_a15_1.dat
155 18
2_155_65_15_csi_a15_4.dat
155 20
155 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
155 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
165 41
1_165_65_15_csi_a15_12.dat
165 43
165 44
165 45
165 46
165 47
1_165_65_15_csi_a15_14.dat
165 49
165 50
1_165_65_15_csi_a15_18.dat
165 52
165 53
165 54
165 55
165 56
165 57
165 58
165 59
165 60
165 61
165 62
165 63
165 64
165 65
1_165_65_15_csi_a15_15.dat
165 67
165 68
165 69
165 70
165 71
2_165_50_15_csi_a15_10.dat
165 73
165 74
165 75
165 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
2_165_50_15_csi_a15_22.dat
165 91
165 92
165 93
2_165_50_15_csi_a15_14.dat
165 95
165 96
165 97
2_165_50_15_csi_a15_20.dat
165 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
1_175_70_15_csi_a15_28.dat
175 112
175 113
175 114
175 115
1_175_70_15_csi_a15_27.dat
175 117
175 118
175 119
1_175_70_15_csi_a15_29.dat
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
180 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
180 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
180 139
180 140
180 141
180 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
180 145
1_180_85_15_csi_a15_24.dat
180 147
180 148
180 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
180 152
180 153
180 154
1_180_85_15_csi_a15_27.dat
180 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
180 159
180 160
1_180_75_15_csi_a15_23.dat
180 162
1_180_75_15_csi_a15_17.dat
180 164
180 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
180 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
180 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
180 174
1_180_75_15_csi_a15_18.dat
180 176
1_180_75_15_csi_a15_15.dat
180 178
1_180_75_15_csi_a15_13.dat
180 180
1_180_75_15_csi_a15_3.dat
180 182
1_180_75_15_csi_a15_25.dat
180 184
180 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
180 190
173 191
1_173_85_15_csi_a15_7.dat
173 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
173 198
173 199
173 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
173 203
173 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
173 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
173 211
173 212
173 213
173 214
173 215
1_173_85_15_csi_a15_29.dat
173 217
173 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 170 170 170 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 173 173 173 173 173 173 173 173 173 173 173
 173 173 173 173]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.5759 - mae: 0.6777 - mse: 0.5759
 64/106 [=================>............] - ETA: 0s - loss: 0.4494 - mae: 0.5966 - mse: 0.4494
 96/106 [==========================>...] - ETA: 0s - loss: 0.3658 - mae: 0.5178 - mse: 0.3658
106/106 [==============================] - 1s 12ms/step - loss: 0.3473 - mae: 0.5015 - mse: 0.3473 - val_loss: 0.0875 - val_mae: 0.2537 - val_mse: 0.0875
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1231 - mae: 0.2869 - mse: 0.1231
 64/106 [=================>............] - ETA: 0s - loss: 0.1277 - mae: 0.2920 - mse: 0.1277
 96/106 [==========================>...] - ETA: 0s - loss: 0.1270 - mae: 0.2892 - mse: 0.1270
106/106 [==============================] - 1s 10ms/step - loss: 0.1429 - mae: 0.3065 - mse: 0.1429 - val_loss: 0.0866 - val_mae: 0.2272 - val_mse: 0.0866
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1574 - mae: 0.3253 - mse: 0.1574
 64/106 [=================>............] - ETA: 0s - loss: 0.1364 - mae: 0.3033 - mse: 0.1364
 96/106 [==========================>...] - ETA: 0s - loss: 0.1387 - mae: 0.3077 - mse: 0.1387
106/106 [==============================] - 1s 8ms/step - loss: 0.1332 - mae: 0.2951 - mse: 0.1332 - val_loss: 0.0810 - val_mae: 0.2300 - val_mse: 0.0810
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0761 - mae: 0.2227 - mse: 0.0761
 64/106 [=================>............] - ETA: 0s - loss: 0.0887 - mae: 0.2352 - mse: 0.0887
 96/106 [==========================>...] - ETA: 0s - loss: 0.1055 - mae: 0.2609 - mse: 0.1055
106/106 [==============================] - 1s 8ms/step - loss: 0.1094 - mae: 0.2674 - mse: 0.1094 - val_loss: 0.0997 - val_mae: 0.2714 - val_mse: 0.0997
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1001 - mae: 0.2420 - mse: 0.1001
 64/106 [=================>............] - ETA: 0s - loss: 0.1080 - mae: 0.2593 - mse: 0.1080
 96/106 [==========================>...] - ETA: 0s - loss: 0.0941 - mae: 0.2432 - mse: 0.0941
106/106 [==============================] - 1s 9ms/step - loss: 0.0923 - mae: 0.2432 - mse: 0.0923 - val_loss: 0.0609 - val_mae: 0.1933 - val_mse: 0.0609
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1066 - mae: 0.2807 - mse: 0.1066
 64/106 [=================>............] - ETA: 0s - loss: 0.0827 - mae: 0.2396 - mse: 0.0827
 96/106 [==========================>...] - ETA: 0s - loss: 0.0747 - mae: 0.2242 - mse: 0.0747
106/106 [==============================] - 1s 9ms/step - loss: 0.0778 - mae: 0.2277 - mse: 0.0778 - val_loss: 0.0465 - val_mae: 0.1418 - val_mse: 0.0465
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0836 - mae: 0.2338 - mse: 0.0836
 64/106 [=================>............] - ETA: 0s - loss: 0.1021 - mae: 0.2588 - mse: 0.1021
 96/106 [==========================>...] - ETA: 0s - loss: 0.0967 - mae: 0.2527 - mse: 0.0967
106/106 [==============================] - 1s 8ms/step - loss: 0.0914 - mae: 0.2462 - mse: 0.0914 - val_loss: 0.0492 - val_mae: 0.1675 - val_mse: 0.0492
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0649 - mae: 0.2089 - mse: 0.0649
 64/106 [=================>............] - ETA: 0s - loss: 0.0807 - mae: 0.2317 - mse: 0.0807
 96/106 [==========================>...] - ETA: 0s - loss: 0.0750 - mae: 0.2181 - mse: 0.0750
106/106 [==============================] - 1s 9ms/step - loss: 0.0812 - mae: 0.2274 - mse: 0.0812 - val_loss: 0.0644 - val_mae: 0.2210 - val_mse: 0.0644
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0632 - mae: 0.1941 - mse: 0.0632
 64/106 [=================>............] - ETA: 0s - loss: 0.0777 - mae: 0.2283 - mse: 0.0777
 96/106 [==========================>...] - ETA: 0s - loss: 0.0699 - mae: 0.2130 - mse: 0.0699
106/106 [==============================] - 1s 8ms/step - loss: 0.0677 - mae: 0.2097 - mse: 0.0677 - val_loss: 0.0523 - val_mae: 0.1981 - val_mse: 0.0523
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0609 - mae: 0.1902 - mse: 0.0609
 64/106 [=================>............] - ETA: 0s - loss: 0.0749 - mae: 0.2093 - mse: 0.0749
 96/106 [==========================>...] - ETA: 0s - loss: 0.0711 - mae: 0.2017 - mse: 0.0711
106/106 [==============================] - 1s 8ms/step - loss: 0.0707 - mae: 0.2038 - mse: 0.0707 - val_loss: 0.0441 - val_mae: 0.1796 - val_mse: 0.0441
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0355 - mae: 0.1442 - mse: 0.0355
 64/106 [=================>............] - ETA: 0s - loss: 0.0457 - mae: 0.1622 - mse: 0.0457
 96/106 [==========================>...] - ETA: 0s - loss: 0.0466 - mae: 0.1655 - mse: 0.0466
106/106 [==============================] - 1s 9ms/step - loss: 0.0524 - mae: 0.1762 - mse: 0.0524 - val_loss: 0.0477 - val_mae: 0.1966 - val_mse: 0.0477
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0670 - mae: 0.2037 - mse: 0.0670
 64/106 [=================>............] - ETA: 0s - loss: 0.0552 - mae: 0.1841 - mse: 0.0552
 96/106 [==========================>...] - ETA: 0s - loss: 0.0529 - mae: 0.1801 - mse: 0.0529
106/106 [==============================] - 1s 9ms/step - loss: 0.0543 - mae: 0.1804 - mse: 0.0543 - val_loss: 0.0451 - val_mae: 0.1942 - val_mse: 0.0451
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0481 - mae: 0.1649 - mse: 0.0481
 64/106 [=================>............] - ETA: 0s - loss: 0.0482 - mae: 0.1657 - mse: 0.0482
 96/106 [==========================>...] - ETA: 0s - loss: 0.0511 - mae: 0.1665 - mse: 0.0511
106/106 [==============================] - 1s 8ms/step - loss: 0.0530 - mae: 0.1692 - mse: 0.0530 - val_loss: 0.0412 - val_mae: 0.1869 - val_mse: 0.0412
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0320 - mae: 0.1128 - mse: 0.0320
 64/106 [=================>............] - ETA: 0s - loss: 0.0527 - mae: 0.1669 - mse: 0.0527
 96/106 [==========================>...] - ETA: 0s - loss: 0.0516 - mae: 0.1668 - mse: 0.0516
106/106 [==============================] - 1s 9ms/step - loss: 0.0500 - mae: 0.1639 - mse: 0.0500 - val_loss: 0.0577 - val_mae: 0.2296 - val_mse: 0.0577
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0858 - mae: 0.2261 - mse: 0.0858
 64/106 [=================>............] - ETA: 0s - loss: 0.0556 - mae: 0.1761 - mse: 0.0556
 96/106 [==========================>...] - ETA: 0s - loss: 0.0566 - mae: 0.1800 - mse: 0.0566
106/106 [==============================] - 1s 6ms/step - loss: 0.0535 - mae: 0.1742 - mse: 0.0535 - val_loss: 0.0465 - val_mae: 0.2053 - val_mse: 0.0465
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0334 - mae: 0.1399 - mse: 0.0334
 64/106 [=================>............] - ETA: 0s - loss: 0.0300 - mae: 0.1361 - mse: 0.0300
 96/106 [==========================>...] - ETA: 0s - loss: 0.0356 - mae: 0.1426 - mse: 0.0356
106/106 [==============================] - 1s 6ms/step - loss: 0.0449 - mae: 0.1560 - mse: 0.0449 - val_loss: 0.0269 - val_mae: 0.1490 - val_mse: 0.0269
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0571 - mae: 0.1751 - mse: 0.0571
 64/106 [=================>............] - ETA: 0s - loss: 0.0513 - mae: 0.1708 - mse: 0.0513
 96/106 [==========================>...] - ETA: 0s - loss: 0.0514 - mae: 0.1724 - mse: 0.0514
106/106 [==============================] - 1s 6ms/step - loss: 0.0520 - mae: 0.1700 - mse: 0.0520 - val_loss: 0.0311 - val_mae: 0.1699 - val_mse: 0.0311
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0347 - mae: 0.1485 - mse: 0.0347
 64/106 [=================>............] - ETA: 0s - loss: 0.0359 - mae: 0.1404 - mse: 0.0359
 96/106 [==========================>...] - ETA: 0s - loss: 0.0390 - mae: 0.1496 - mse: 0.0390
106/106 [==============================] - 1s 6ms/step - loss: 0.0381 - mae: 0.1464 - mse: 0.0381 - val_loss: 0.0671 - val_mae: 0.2453 - val_mse: 0.0671
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0364 - mae: 0.1478 - mse: 0.0364
 64/106 [=================>............] - ETA: 0s - loss: 0.0387 - mae: 0.1525 - mse: 0.0387
 96/106 [==========================>...] - ETA: 0s - loss: 0.0465 - mae: 0.1650 - mse: 0.0465
106/106 [==============================] - 1s 6ms/step - loss: 0.0494 - mae: 0.1686 - mse: 0.0494 - val_loss: 0.0546 - val_mae: 0.2214 - val_mse: 0.0546
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0672 - mae: 0.1889 - mse: 0.0672
 64/106 [=================>............] - ETA: 0s - loss: 0.0508 - mae: 0.1644 - mse: 0.0508
 96/106 [==========================>...] - ETA: 0s - loss: 0.0443 - mae: 0.1561 - mse: 0.0443
106/106 [==============================] - 1s 7ms/step - loss: 0.0437 - mae: 0.1538 - mse: 0.0437 - val_loss: 0.0201 - val_mae: 0.1355 - val_mse: 0.0201
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0209 - mae: 0.1047 - mse: 0.0209
 64/106 [=================>............] - ETA: 0s - loss: 0.0453 - mae: 0.1549 - mse: 0.0453
 96/106 [==========================>...] - ETA: 0s - loss: 0.0439 - mae: 0.1536 - mse: 0.0439
106/106 [==============================] - 1s 6ms/step - loss: 0.0410 - mae: 0.1486 - mse: 0.0410 - val_loss: 0.0332 - val_mae: 0.1758 - val_mse: 0.0332
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0344 - mae: 0.1382 - mse: 0.0344
 64/106 [=================>............] - ETA: 0s - loss: 0.0394 - mae: 0.1526 - mse: 0.0394
 96/106 [==========================>...] - ETA: 0s - loss: 0.0405 - mae: 0.1481 - mse: 0.0405
106/106 [==============================] - 1s 6ms/step - loss: 0.0384 - mae: 0.1443 - mse: 0.0384 - val_loss: 0.0387 - val_mae: 0.1857 - val_mse: 0.0387
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0500 - mae: 0.1628 - mse: 0.0500
 64/106 [=================>............] - ETA: 0s - loss: 0.0442 - mae: 0.1461 - mse: 0.0442
 96/106 [==========================>...] - ETA: 0s - loss: 0.0378 - mae: 0.1390 - mse: 0.0378
106/106 [==============================] - 1s 6ms/step - loss: 0.0363 - mae: 0.1365 - mse: 0.0363 - val_loss: 0.0244 - val_mae: 0.1458 - val_mse: 0.0244
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0216 - mae: 0.1165 - mse: 0.0216
 64/106 [=================>............] - ETA: 0s - loss: 0.0225 - mae: 0.1153 - mse: 0.0225
 96/106 [==========================>...] - ETA: 0s - loss: 0.0300 - mae: 0.1231 - mse: 0.0300
106/106 [==============================] - 1s 6ms/step - loss: 0.0288 - mae: 0.1219 - mse: 0.0288 - val_loss: 0.0242 - val_mae: 0.1463 - val_mse: 0.0242
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0221 - mae: 0.1153 - mse: 0.0221
 64/106 [=================>............] - ETA: 0s - loss: 0.0302 - mae: 0.1284 - mse: 0.0302
 96/106 [==========================>...] - ETA: 0s - loss: 0.0336 - mae: 0.1318 - mse: 0.0336
106/106 [==============================] - 1s 6ms/step - loss: 0.0316 - mae: 0.1280 - mse: 0.0316 - val_loss: 0.0258 - val_mae: 0.1523 - val_mse: 0.0258
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0244 - mae: 0.1340 - mse: 0.0244
 64/106 [=================>............] - ETA: 0s - loss: 0.0208 - mae: 0.1198 - mse: 0.0208
 96/106 [==========================>...] - ETA: 0s - loss: 0.0285 - mae: 0.1331 - mse: 0.0285
106/106 [==============================] - 1s 6ms/step - loss: 0.0308 - mae: 0.1359 - mse: 0.0308 - val_loss: 0.0271 - val_mae: 0.1548 - val_mse: 0.0271
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0208 - mae: 0.1055 - mse: 0.0208
 64/106 [=================>............] - ETA: 0s - loss: 0.0235 - mae: 0.1109 - mse: 0.0235
 96/106 [==========================>...] - ETA: 0s - loss: 0.0282 - mae: 0.1206 - mse: 0.0282
106/106 [==============================] - 1s 6ms/step - loss: 0.0306 - mae: 0.1252 - mse: 0.0306 - val_loss: 0.0189 - val_mae: 0.1291 - val_mse: 0.0189
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0175 - mae: 0.1053 - mse: 0.0175
 64/106 [=================>............] - ETA: 0s - loss: 0.0296 - mae: 0.1260 - mse: 0.0296
 96/106 [==========================>...] - ETA: 0s - loss: 0.0315 - mae: 0.1267 - mse: 0.0315
106/106 [==============================] - 1s 6ms/step - loss: 0.0299 - mae: 0.1247 - mse: 0.0299 - val_loss: 0.0358 - val_mae: 0.1736 - val_mse: 0.0358
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0252 - mae: 0.1159 - mse: 0.0252
 64/106 [=================>............] - ETA: 0s - loss: 0.0236 - mae: 0.1121 - mse: 0.0236
 96/106 [==========================>...] - ETA: 0s - loss: 0.0260 - mae: 0.1222 - mse: 0.0260
106/106 [==============================] - 1s 6ms/step - loss: 0.0252 - mae: 0.1208 - mse: 0.0252 - val_loss: 0.0321 - val_mae: 0.1624 - val_mse: 0.0321
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0179 - mae: 0.1051 - mse: 0.0179
 64/106 [=================>............] - ETA: 0s - loss: 0.0188 - mae: 0.1085 - mse: 0.0188
 96/106 [==========================>...] - ETA: 0s - loss: 0.0281 - mae: 0.1232 - mse: 0.0281
106/106 [==============================] - 1s 6ms/step - loss: 0.0270 - mae: 0.1207 - mse: 0.0270 - val_loss: 0.0179 - val_mae: 0.1197 - val_mse: 0.0179
Saving trained model...
72
Testing...
heightdiff= [0.         0.         0.         0.         0.         7.38182068]
average prediction= [3.0028992]
baseline= 5.566666666666666
eachuser= [0. 0. 0. 0. 0. 2.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 3.6909103393554688
['train-height-15.py', '0']
155 1
155 2
155 3
2_155_65_15_csi_a15_22.dat
155 5
155 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
2_155_65_15_csi_a15_1.dat
155 18
2_155_65_15_csi_a15_4.dat
155 20
155 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
155 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
165 41
1_165_65_15_csi_a15_12.dat
165 43
165 44
165 45
165 46
165 47
1_165_65_15_csi_a15_14.dat
165 49
165 50
1_165_65_15_csi_a15_18.dat
165 52
165 53
165 54
165 55
165 56
165 57
165 58
165 59
165 60
165 61
165 62
165 63
165 64
165 65
1_165_65_15_csi_a15_15.dat
165 67
165 68
165 69
165 70
165 71
2_165_50_15_csi_a15_10.dat
165 73
165 74
165 75
165 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
2_165_50_15_csi_a15_22.dat
165 91
165 92
165 93
2_165_50_15_csi_a15_14.dat
165 95
165 96
165 97
2_165_50_15_csi_a15_20.dat
165 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
1_175_70_15_csi_a15_28.dat
175 112
175 113
175 114
175 115
1_175_70_15_csi_a15_27.dat
175 117
175 118
175 119
1_175_70_15_csi_a15_29.dat
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
180 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
180 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
180 139
180 140
180 141
180 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
180 145
1_180_85_15_csi_a15_24.dat
180 147
180 148
180 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
180 152
180 153
180 154
1_180_85_15_csi_a15_27.dat
180 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
180 159
180 160
1_180_75_15_csi_a15_23.dat
180 162
1_180_75_15_csi_a15_17.dat
180 164
180 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
180 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
180 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
180 174
1_180_75_15_csi_a15_18.dat
180 176
1_180_75_15_csi_a15_15.dat
180 178
1_180_75_15_csi_a15_13.dat
180 180
1_180_75_15_csi_a15_3.dat
180 182
1_180_75_15_csi_a15_25.dat
180 184
180 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
180 190
173 191
1_173_85_15_csi_a15_7.dat
173 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
173 198
173 199
173 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
173 203
173 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
173 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
173 211
173 212
173 213
173 214
173 215
1_173_85_15_csi_a15_29.dat
173 217
173 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 170 170 170 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 173 173 173 173 173 173 173 173 173 173 173
 173 173 173 173]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.4722 - mae: 0.6166 - mse: 0.4722
 64/106 [=================>............] - ETA: 0s - loss: 0.4266 - mae: 0.5756 - mse: 0.4266
 96/106 [==========================>...] - ETA: 0s - loss: 0.3883 - mae: 0.5426 - mse: 0.3883
106/106 [==============================] - 1s 12ms/step - loss: 0.3855 - mae: 0.5424 - mse: 0.3855 - val_loss: 0.1325 - val_mae: 0.2871 - val_mse: 0.1325
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1646 - mae: 0.3397 - mse: 0.1646
 64/106 [=================>............] - ETA: 0s - loss: 0.1512 - mae: 0.3280 - mse: 0.1512
 96/106 [==========================>...] - ETA: 0s - loss: 0.1494 - mae: 0.3271 - mse: 0.1494
106/106 [==============================] - 1s 8ms/step - loss: 0.1453 - mae: 0.3211 - mse: 0.1453 - val_loss: 0.1068 - val_mae: 0.2789 - val_mse: 0.1068
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.2001 - mae: 0.4038 - mse: 0.2001
 64/106 [=================>............] - ETA: 0s - loss: 0.1480 - mae: 0.3291 - mse: 0.1480
 96/106 [==========================>...] - ETA: 0s - loss: 0.1377 - mae: 0.3188 - mse: 0.1377
106/106 [==============================] - 1s 8ms/step - loss: 0.1337 - mae: 0.3159 - mse: 0.1337 - val_loss: 0.0750 - val_mae: 0.2030 - val_mse: 0.0750
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0923 - mae: 0.2437 - mse: 0.0923
 64/106 [=================>............] - ETA: 0s - loss: 0.0783 - mae: 0.2343 - mse: 0.0783
 96/106 [==========================>...] - ETA: 0s - loss: 0.0886 - mae: 0.2492 - mse: 0.0886
106/106 [==============================] - 1s 9ms/step - loss: 0.0892 - mae: 0.2504 - mse: 0.0892 - val_loss: 0.0740 - val_mae: 0.2053 - val_mse: 0.0740
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1005 - mae: 0.2701 - mse: 0.1005
 64/106 [=================>............] - ETA: 0s - loss: 0.0784 - mae: 0.2252 - mse: 0.0784
 96/106 [==========================>...] - ETA: 0s - loss: 0.0775 - mae: 0.2222 - mse: 0.0775
106/106 [==============================] - 1s 9ms/step - loss: 0.0736 - mae: 0.2180 - mse: 0.0736 - val_loss: 0.0606 - val_mae: 0.1816 - val_mse: 0.0606
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0759 - mae: 0.2273 - mse: 0.0759
 64/106 [=================>............] - ETA: 0s - loss: 0.0688 - mae: 0.2066 - mse: 0.0688
 96/106 [==========================>...] - ETA: 0s - loss: 0.0695 - mae: 0.2079 - mse: 0.0695
106/106 [==============================] - 1s 9ms/step - loss: 0.0674 - mae: 0.2046 - mse: 0.0674 - val_loss: 0.0486 - val_mae: 0.1667 - val_mse: 0.0486
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0539 - mae: 0.1712 - mse: 0.0539
 64/106 [=================>............] - ETA: 0s - loss: 0.0496 - mae: 0.1584 - mse: 0.0496
 96/106 [==========================>...] - ETA: 0s - loss: 0.0580 - mae: 0.1745 - mse: 0.0580
106/106 [==============================] - 1s 10ms/step - loss: 0.0567 - mae: 0.1727 - mse: 0.0567 - val_loss: 0.0459 - val_mae: 0.1588 - val_mse: 0.0459
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0285 - mae: 0.1262 - mse: 0.0285
 64/106 [=================>............] - ETA: 0s - loss: 0.0368 - mae: 0.1422 - mse: 0.0368
 96/106 [==========================>...] - ETA: 0s - loss: 0.0471 - mae: 0.1630 - mse: 0.0471
106/106 [==============================] - 1s 11ms/step - loss: 0.0493 - mae: 0.1664 - mse: 0.0493 - val_loss: 0.0508 - val_mae: 0.1794 - val_mse: 0.0508
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0510 - mae: 0.1712 - mse: 0.0510
 64/106 [=================>............] - ETA: 0s - loss: 0.0468 - mae: 0.1574 - mse: 0.0468
 96/106 [==========================>...] - ETA: 0s - loss: 0.0523 - mae: 0.1664 - mse: 0.0523
106/106 [==============================] - 1s 10ms/step - loss: 0.0494 - mae: 0.1628 - mse: 0.0494 - val_loss: 0.0558 - val_mae: 0.1955 - val_mse: 0.0558
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0463 - mae: 0.1687 - mse: 0.0463
 64/106 [=================>............] - ETA: 0s - loss: 0.0415 - mae: 0.1614 - mse: 0.0415
 96/106 [==========================>...] - ETA: 0s - loss: 0.0436 - mae: 0.1601 - mse: 0.0436
106/106 [==============================] - 1s 7ms/step - loss: 0.0464 - mae: 0.1635 - mse: 0.0464 - val_loss: 0.0545 - val_mae: 0.1908 - val_mse: 0.0545
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0588 - mae: 0.1781 - mse: 0.0588
 64/106 [=================>............] - ETA: 0s - loss: 0.0415 - mae: 0.1427 - mse: 0.0415
 96/106 [==========================>...] - ETA: 0s - loss: 0.0430 - mae: 0.1450 - mse: 0.0430
106/106 [==============================] - 1s 7ms/step - loss: 0.0421 - mae: 0.1456 - mse: 0.0421 - val_loss: 0.0443 - val_mae: 0.1581 - val_mse: 0.0443
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0207 - mae: 0.0995 - mse: 0.0207
 64/106 [=================>............] - ETA: 0s - loss: 0.0366 - mae: 0.1331 - mse: 0.0366
 96/106 [==========================>...] - ETA: 0s - loss: 0.0369 - mae: 0.1390 - mse: 0.0369
106/106 [==============================] - 1s 6ms/step - loss: 0.0385 - mae: 0.1436 - mse: 0.0385 - val_loss: 0.0375 - val_mae: 0.1333 - val_mse: 0.0375
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0202 - mae: 0.1034 - mse: 0.0202
 64/106 [=================>............] - ETA: 0s - loss: 0.0418 - mae: 0.1490 - mse: 0.0418
 96/106 [==========================>...] - ETA: 0s - loss: 0.0341 - mae: 0.1322 - mse: 0.0341
106/106 [==============================] - 1s 7ms/step - loss: 0.0358 - mae: 0.1366 - mse: 0.0358 - val_loss: 0.0382 - val_mae: 0.1419 - val_mse: 0.0382
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0639 - mae: 0.1866 - mse: 0.0639
 64/106 [=================>............] - ETA: 0s - loss: 0.0475 - mae: 0.1587 - mse: 0.0475
 96/106 [==========================>...] - ETA: 0s - loss: 0.0405 - mae: 0.1491 - mse: 0.0405
106/106 [==============================] - 1s 7ms/step - loss: 0.0376 - mae: 0.1421 - mse: 0.0376 - val_loss: 0.0347 - val_mae: 0.1350 - val_mse: 0.0347
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0336 - mae: 0.1387 - mse: 0.0336
 64/106 [=================>............] - ETA: 0s - loss: 0.0312 - mae: 0.1314 - mse: 0.0312
 96/106 [==========================>...] - ETA: 0s - loss: 0.0287 - mae: 0.1269 - mse: 0.0287
106/106 [==============================] - 1s 7ms/step - loss: 0.0319 - mae: 0.1335 - mse: 0.0319 - val_loss: 0.0325 - val_mae: 0.1267 - val_mse: 0.0325
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0389 - mae: 0.1550 - mse: 0.0389
 64/106 [=================>............] - ETA: 0s - loss: 0.0394 - mae: 0.1459 - mse: 0.0394
 96/106 [==========================>...] - ETA: 0s - loss: 0.0334 - mae: 0.1350 - mse: 0.0334
106/106 [==============================] - 1s 7ms/step - loss: 0.0331 - mae: 0.1356 - mse: 0.0331 - val_loss: 0.0369 - val_mae: 0.1469 - val_mse: 0.0369
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0205 - mae: 0.1040 - mse: 0.0205
 64/106 [=================>............] - ETA: 0s - loss: 0.0246 - mae: 0.1156 - mse: 0.0246
 96/106 [==========================>...] - ETA: 0s - loss: 0.0275 - mae: 0.1207 - mse: 0.0275
106/106 [==============================] - 1s 9ms/step - loss: 0.0270 - mae: 0.1209 - mse: 0.0270 - val_loss: 0.0325 - val_mae: 0.1302 - val_mse: 0.0325
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0323 - mae: 0.1433 - mse: 0.0323
 64/106 [=================>............] - ETA: 0s - loss: 0.0317 - mae: 0.1392 - mse: 0.0317
 96/106 [==========================>...] - ETA: 0s - loss: 0.0316 - mae: 0.1338 - mse: 0.0316
106/106 [==============================] - 1s 9ms/step - loss: 0.0297 - mae: 0.1286 - mse: 0.0297 - val_loss: 0.0296 - val_mae: 0.1219 - val_mse: 0.0296
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0198 - mae: 0.0835 - mse: 0.0198
 64/106 [=================>............] - ETA: 0s - loss: 0.0346 - mae: 0.1268 - mse: 0.0346
 96/106 [==========================>...] - ETA: 0s - loss: 0.0300 - mae: 0.1222 - mse: 0.0300
106/106 [==============================] - 1s 9ms/step - loss: 0.0294 - mae: 0.1221 - mse: 0.0294 - val_loss: 0.0355 - val_mae: 0.1462 - val_mse: 0.0355
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0236 - mae: 0.1009 - mse: 0.0236
 64/106 [=================>............] - ETA: 0s - loss: 0.0262 - mae: 0.1128 - mse: 0.0262
 96/106 [==========================>...] - ETA: 0s - loss: 0.0252 - mae: 0.1139 - mse: 0.0252
106/106 [==============================] - 1s 9ms/step - loss: 0.0239 - mae: 0.1113 - mse: 0.0239 - val_loss: 0.0246 - val_mae: 0.1074 - val_mse: 0.0246
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0301 - mae: 0.1247 - mse: 0.0301
 64/106 [=================>............] - ETA: 0s - loss: 0.0284 - mae: 0.1178 - mse: 0.0284
 96/106 [==========================>...] - ETA: 0s - loss: 0.0250 - mae: 0.1135 - mse: 0.0250
106/106 [==============================] - 1s 9ms/step - loss: 0.0241 - mae: 0.1127 - mse: 0.0241 - val_loss: 0.0268 - val_mae: 0.1198 - val_mse: 0.0268
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0294 - mae: 0.1309 - mse: 0.0294
 64/106 [=================>............] - ETA: 0s - loss: 0.0274 - mae: 0.1154 - mse: 0.0274
 96/106 [==========================>...] - ETA: 0s - loss: 0.0250 - mae: 0.1175 - mse: 0.0250
106/106 [==============================] - 1s 9ms/step - loss: 0.0245 - mae: 0.1165 - mse: 0.0245 - val_loss: 0.0347 - val_mae: 0.1528 - val_mse: 0.0347
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0184 - mae: 0.1087 - mse: 0.0184
 64/106 [=================>............] - ETA: 0s - loss: 0.0219 - mae: 0.1105 - mse: 0.0219
 96/106 [==========================>...] - ETA: 0s - loss: 0.0196 - mae: 0.1076 - mse: 0.0196
106/106 [==============================] - 1s 9ms/step - loss: 0.0218 - mae: 0.1114 - mse: 0.0218 - val_loss: 0.0240 - val_mae: 0.1179 - val_mse: 0.0240
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0296 - mae: 0.1303 - mse: 0.0296
 64/106 [=================>............] - ETA: 0s - loss: 0.0211 - mae: 0.1107 - mse: 0.0211
 96/106 [==========================>...] - ETA: 0s - loss: 0.0256 - mae: 0.1196 - mse: 0.0256
106/106 [==============================] - 1s 11ms/step - loss: 0.0241 - mae: 0.1156 - mse: 0.0241 - val_loss: 0.0380 - val_mae: 0.1642 - val_mse: 0.0380
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0308 - mae: 0.1455 - mse: 0.0308
 64/106 [=================>............] - ETA: 0s - loss: 0.0230 - mae: 0.1209 - mse: 0.0230
 96/106 [==========================>...] - ETA: 0s - loss: 0.0239 - mae: 0.1164 - mse: 0.0239
106/106 [==============================] - 1s 11ms/step - loss: 0.0244 - mae: 0.1195 - mse: 0.0244 - val_loss: 0.0228 - val_mae: 0.1140 - val_mse: 0.0228
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0304 - mae: 0.1267 - mse: 0.0304
 64/106 [=================>............] - ETA: 0s - loss: 0.0241 - mae: 0.1118 - mse: 0.0241
 96/106 [==========================>...] - ETA: 0s - loss: 0.0221 - mae: 0.1089 - mse: 0.0221
106/106 [==============================] - 1s 11ms/step - loss: 0.0211 - mae: 0.1073 - mse: 0.0211 - val_loss: 0.0215 - val_mae: 0.1154 - val_mse: 0.0215
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0195 - mae: 0.1156 - mse: 0.0195
 64/106 [=================>............] - ETA: 0s - loss: 0.0238 - mae: 0.1157 - mse: 0.0238
 96/106 [==========================>...] - ETA: 0s - loss: 0.0214 - mae: 0.1078 - mse: 0.0214
106/106 [==============================] - 1s 11ms/step - loss: 0.0207 - mae: 0.1054 - mse: 0.0207 - val_loss: 0.0302 - val_mae: 0.1496 - val_mse: 0.0302
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0159 - mae: 0.1009 - mse: 0.0159
 64/106 [=================>............] - ETA: 0s - loss: 0.0176 - mae: 0.1060 - mse: 0.0176
 96/106 [==========================>...] - ETA: 0s - loss: 0.0190 - mae: 0.1053 - mse: 0.0190
106/106 [==============================] - 1s 11ms/step - loss: 0.0184 - mae: 0.1039 - mse: 0.0184 - val_loss: 0.0255 - val_mae: 0.1341 - val_mse: 0.0255
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0126 - mae: 0.0797 - mse: 0.0126
 64/106 [=================>............] - ETA: 0s - loss: 0.0208 - mae: 0.0957 - mse: 0.0208
 96/106 [==========================>...] - ETA: 0s - loss: 0.0175 - mae: 0.0925 - mse: 0.0175
106/106 [==============================] - 1s 11ms/step - loss: 0.0174 - mae: 0.0935 - mse: 0.0174 - val_loss: 0.0326 - val_mae: 0.1508 - val_mse: 0.0326
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0164 - mae: 0.0880 - mse: 0.0164
 64/106 [=================>............] - ETA: 0s - loss: 0.0163 - mae: 0.0959 - mse: 0.0163
 96/106 [==========================>...] - ETA: 0s - loss: 0.0142 - mae: 0.0885 - mse: 0.0142
106/106 [==============================] - 1s 11ms/step - loss: 0.0146 - mae: 0.0901 - mse: 0.0146 - val_loss: 0.0264 - val_mae: 0.1265 - val_mse: 0.0264
Saving trained model...
72
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         12.24725342]
average prediction= [3.3509853]
baseline= 7.333333333333333
eachuser= [0. 0. 0. 0. 0. 5.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 2.44945068359375
['train-height-15.py', '0']
155 1
155 2
155 3
2_155_65_15_csi_a15_22.dat
155 5
155 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
2_155_65_15_csi_a15_1.dat
155 18
2_155_65_15_csi_a15_4.dat
155 20
155 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
155 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
165 41
1_165_65_15_csi_a15_12.dat
165 43
165 44
165 45
165 46
165 47
1_165_65_15_csi_a15_14.dat
165 49
165 50
1_165_65_15_csi_a15_18.dat
165 52
165 53
165 54
165 55
165 56
165 57
165 58
165 59
165 60
165 61
165 62
165 63
165 64
165 65
1_165_65_15_csi_a15_15.dat
165 67
165 68
165 69
165 70
165 71
2_165_50_15_csi_a15_10.dat
165 73
165 74
165 75
165 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
2_165_50_15_csi_a15_22.dat
165 91
165 92
165 93
2_165_50_15_csi_a15_14.dat
165 95
165 96
165 97
2_165_50_15_csi_a15_20.dat
165 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
1_175_70_15_csi_a15_28.dat
175 112
175 113
175 114
175 115
1_175_70_15_csi_a15_27.dat
175 117
175 118
175 119
1_175_70_15_csi_a15_29.dat
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
180 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
180 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
180 139
180 140
180 141
180 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
180 145
1_180_85_15_csi_a15_24.dat
180 147
180 148
180 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
180 152
180 153
180 154
1_180_85_15_csi_a15_27.dat
180 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
180 159
180 160
1_180_75_15_csi_a15_23.dat
180 162
1_180_75_15_csi_a15_17.dat
180 164
180 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
180 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
180 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
180 174
1_180_75_15_csi_a15_18.dat
180 176
1_180_75_15_csi_a15_15.dat
180 178
1_180_75_15_csi_a15_13.dat
180 180
1_180_75_15_csi_a15_3.dat
180 182
1_180_75_15_csi_a15_25.dat
180 184
180 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
180 190
173 191
1_173_85_15_csi_a15_7.dat
173 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
173 198
173 199
173 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
173 203
173 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
173 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
173 211
173 212
173 213
173 214
173 215
1_173_85_15_csi_a15_29.dat
173 217
173 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 170 170 170 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 173 173 173 173 173 173 173 173 173 173 173
 173 173 173 173]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.3879 - mae: 0.5350 - mse: 0.3879
 64/106 [=================>............] - ETA: 0s - loss: 0.3378 - mae: 0.4978 - mse: 0.3378
 96/106 [==========================>...] - ETA: 0s - loss: 0.2841 - mae: 0.4520 - mse: 0.2841
106/106 [==============================] - 1s 14ms/step - loss: 0.2733 - mae: 0.4401 - mse: 0.2733 - val_loss: 0.1289 - val_mae: 0.2520 - val_mse: 0.1289
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.2107 - mae: 0.3865 - mse: 0.2107
 64/106 [=================>............] - ETA: 0s - loss: 0.1748 - mae: 0.3325 - mse: 0.1748
 96/106 [==========================>...] - ETA: 0s - loss: 0.1927 - mae: 0.3574 - mse: 0.1927
106/106 [==============================] - 1s 11ms/step - loss: 0.1922 - mae: 0.3620 - mse: 0.1922 - val_loss: 0.1203 - val_mae: 0.3077 - val_mse: 0.1203
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1196 - mae: 0.2833 - mse: 0.1196
 64/106 [=================>............] - ETA: 0s - loss: 0.1202 - mae: 0.2957 - mse: 0.1202
 96/106 [==========================>...] - ETA: 0s - loss: 0.1184 - mae: 0.2943 - mse: 0.1184
106/106 [==============================] - 1s 12ms/step - loss: 0.1166 - mae: 0.2934 - mse: 0.1166 - val_loss: 0.1613 - val_mae: 0.3569 - val_mse: 0.1613
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1006 - mae: 0.2712 - mse: 0.1006
 64/106 [=================>............] - ETA: 0s - loss: 0.1076 - mae: 0.2694 - mse: 0.1076
 96/106 [==========================>...] - ETA: 0s - loss: 0.1009 - mae: 0.2642 - mse: 0.1009
106/106 [==============================] - 1s 11ms/step - loss: 0.1025 - mae: 0.2660 - mse: 0.1025 - val_loss: 0.1649 - val_mae: 0.3533 - val_mse: 0.1649
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0931 - mae: 0.2654 - mse: 0.0931
 64/106 [=================>............] - ETA: 0s - loss: 0.0851 - mae: 0.2481 - mse: 0.0851
 96/106 [==========================>...] - ETA: 0s - loss: 0.0856 - mae: 0.2505 - mse: 0.0856
106/106 [==============================] - 1s 11ms/step - loss: 0.0800 - mae: 0.2408 - mse: 0.0800 - val_loss: 0.1478 - val_mae: 0.3472 - val_mse: 0.1478
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0800 - mae: 0.2346 - mse: 0.0800
 64/106 [=================>............] - ETA: 0s - loss: 0.0800 - mae: 0.2271 - mse: 0.0800
 96/106 [==========================>...] - ETA: 0s - loss: 0.0741 - mae: 0.2167 - mse: 0.0741
106/106 [==============================] - 1s 11ms/step - loss: 0.0742 - mae: 0.2166 - mse: 0.0742 - val_loss: 0.2106 - val_mae: 0.3886 - val_mse: 0.2106
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0655 - mae: 0.2226 - mse: 0.0655
 64/106 [=================>............] - ETA: 0s - loss: 0.0866 - mae: 0.2472 - mse: 0.0866
 96/106 [==========================>...] - ETA: 0s - loss: 0.0823 - mae: 0.2354 - mse: 0.0823
106/106 [==============================] - 1s 11ms/step - loss: 0.0756 - mae: 0.2221 - mse: 0.0756 - val_loss: 0.2004 - val_mae: 0.3846 - val_mse: 0.2004
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0696 - mae: 0.2119 - mse: 0.0696
 64/106 [=================>............] - ETA: 0s - loss: 0.0704 - mae: 0.2162 - mse: 0.0704
 96/106 [==========================>...] - ETA: 0s - loss: 0.0727 - mae: 0.2191 - mse: 0.0727
106/106 [==============================] - 1s 10ms/step - loss: 0.0686 - mae: 0.2113 - mse: 0.0686 - val_loss: 0.1622 - val_mae: 0.3513 - val_mse: 0.1622
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0690 - mae: 0.2008 - mse: 0.0690
 64/106 [=================>............] - ETA: 0s - loss: 0.0640 - mae: 0.1945 - mse: 0.0640
 96/106 [==========================>...] - ETA: 0s - loss: 0.0596 - mae: 0.1871 - mse: 0.0596
106/106 [==============================] - 1s 8ms/step - loss: 0.0565 - mae: 0.1826 - mse: 0.0565 - val_loss: 0.1844 - val_mae: 0.3671 - val_mse: 0.1844
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0618 - mae: 0.2020 - mse: 0.0618
 64/106 [=================>............] - ETA: 0s - loss: 0.0527 - mae: 0.1824 - mse: 0.0527
 96/106 [==========================>...] - ETA: 0s - loss: 0.0456 - mae: 0.1699 - mse: 0.0456
106/106 [==============================] - 1s 9ms/step - loss: 0.0486 - mae: 0.1739 - mse: 0.0486 - val_loss: 0.1586 - val_mae: 0.3395 - val_mse: 0.1586
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0530 - mae: 0.1863 - mse: 0.0530
 64/106 [=================>............] - ETA: 0s - loss: 0.0546 - mae: 0.1837 - mse: 0.0546
 96/106 [==========================>...] - ETA: 0s - loss: 0.0584 - mae: 0.1896 - mse: 0.0584
106/106 [==============================] - 1s 8ms/step - loss: 0.0581 - mae: 0.1883 - mse: 0.0581 - val_loss: 0.1546 - val_mae: 0.3311 - val_mse: 0.1546
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0360 - mae: 0.1564 - mse: 0.0360
 64/106 [=================>............] - ETA: 0s - loss: 0.0498 - mae: 0.1744 - mse: 0.0498
 96/106 [==========================>...] - ETA: 0s - loss: 0.0476 - mae: 0.1725 - mse: 0.0476
106/106 [==============================] - 1s 8ms/step - loss: 0.0447 - mae: 0.1680 - mse: 0.0447 - val_loss: 0.1737 - val_mae: 0.3444 - val_mse: 0.1737
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0352 - mae: 0.1551 - mse: 0.0352
 64/106 [=================>............] - ETA: 0s - loss: 0.0412 - mae: 0.1554 - mse: 0.0412
 96/106 [==========================>...] - ETA: 0s - loss: 0.0463 - mae: 0.1641 - mse: 0.0463
106/106 [==============================] - 1s 8ms/step - loss: 0.0466 - mae: 0.1651 - mse: 0.0466 - val_loss: 0.1238 - val_mae: 0.2822 - val_mse: 0.1238
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0504 - mae: 0.1623 - mse: 0.0504
 64/106 [=================>............] - ETA: 0s - loss: 0.0449 - mae: 0.1571 - mse: 0.0449
 96/106 [==========================>...] - ETA: 0s - loss: 0.0439 - mae: 0.1593 - mse: 0.0439
106/106 [==============================] - 1s 9ms/step - loss: 0.0482 - mae: 0.1668 - mse: 0.0482 - val_loss: 0.1421 - val_mae: 0.2985 - val_mse: 0.1421
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0471 - mae: 0.1717 - mse: 0.0471
 64/106 [=================>............] - ETA: 0s - loss: 0.0423 - mae: 0.1627 - mse: 0.0423
 96/106 [==========================>...] - ETA: 0s - loss: 0.0463 - mae: 0.1710 - mse: 0.0463
106/106 [==============================] - 1s 9ms/step - loss: 0.0453 - mae: 0.1697 - mse: 0.0453 - val_loss: 0.1999 - val_mae: 0.3603 - val_mse: 0.1999
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0608 - mae: 0.1896 - mse: 0.0608
 64/106 [=================>............] - ETA: 0s - loss: 0.0612 - mae: 0.1882 - mse: 0.0612
 96/106 [==========================>...] - ETA: 0s - loss: 0.0540 - mae: 0.1778 - mse: 0.0540
106/106 [==============================] - 1s 8ms/step - loss: 0.0517 - mae: 0.1735 - mse: 0.0517 - val_loss: 0.1108 - val_mae: 0.2483 - val_mse: 0.1108
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0641 - mae: 0.2091 - mse: 0.0641
 64/106 [=================>............] - ETA: 0s - loss: 0.0543 - mae: 0.1766 - mse: 0.0543
 96/106 [==========================>...] - ETA: 0s - loss: 0.0465 - mae: 0.1613 - mse: 0.0465
106/106 [==============================] - 1s 8ms/step - loss: 0.0425 - mae: 0.1510 - mse: 0.0425 - val_loss: 0.1452 - val_mae: 0.2770 - val_mse: 0.1452
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0248 - mae: 0.1224 - mse: 0.0248
 64/106 [=================>............] - ETA: 0s - loss: 0.0284 - mae: 0.1124 - mse: 0.0284
 96/106 [==========================>...] - ETA: 0s - loss: 0.0314 - mae: 0.1263 - mse: 0.0314
106/106 [==============================] - 1s 10ms/step - loss: 0.0346 - mae: 0.1316 - mse: 0.0346 - val_loss: 0.1697 - val_mae: 0.2941 - val_mse: 0.1697
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0408 - mae: 0.1476 - mse: 0.0408
 64/106 [=================>............] - ETA: 0s - loss: 0.0507 - mae: 0.1730 - mse: 0.0507
 96/106 [==========================>...] - ETA: 0s - loss: 0.0416 - mae: 0.1549 - mse: 0.0416
106/106 [==============================] - 1s 9ms/step - loss: 0.0400 - mae: 0.1529 - mse: 0.0400 - val_loss: 0.1448 - val_mae: 0.2743 - val_mse: 0.1448
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0459 - mae: 0.1437 - mse: 0.0459
 64/106 [=================>............] - ETA: 0s - loss: 0.0468 - mae: 0.1533 - mse: 0.0468
 96/106 [==========================>...] - ETA: 0s - loss: 0.0394 - mae: 0.1436 - mse: 0.0394
106/106 [==============================] - 1s 9ms/step - loss: 0.0365 - mae: 0.1371 - mse: 0.0365 - val_loss: 0.1429 - val_mae: 0.2804 - val_mse: 0.1429
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0344 - mae: 0.1393 - mse: 0.0344
 64/106 [=================>............] - ETA: 0s - loss: 0.0354 - mae: 0.1317 - mse: 0.0354
 96/106 [==========================>...] - ETA: 0s - loss: 0.0355 - mae: 0.1359 - mse: 0.0355
106/106 [==============================] - 1s 8ms/step - loss: 0.0355 - mae: 0.1354 - mse: 0.0355 - val_loss: 0.0918 - val_mae: 0.2271 - val_mse: 0.0918
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0317 - mae: 0.1449 - mse: 0.0317
 64/106 [=================>............] - ETA: 0s - loss: 0.0439 - mae: 0.1627 - mse: 0.0439
 96/106 [==========================>...] - ETA: 0s - loss: 0.0424 - mae: 0.1604 - mse: 0.0424
106/106 [==============================] - 1s 8ms/step - loss: 0.0406 - mae: 0.1576 - mse: 0.0406 - val_loss: 0.1433 - val_mae: 0.2750 - val_mse: 0.1433
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0489 - mae: 0.1578 - mse: 0.0489
 64/106 [=================>............] - ETA: 0s - loss: 0.0359 - mae: 0.1409 - mse: 0.0359
 96/106 [==========================>...] - ETA: 0s - loss: 0.0389 - mae: 0.1428 - mse: 0.0389
106/106 [==============================] - 1s 8ms/step - loss: 0.0376 - mae: 0.1426 - mse: 0.0376 - val_loss: 0.1593 - val_mae: 0.2833 - val_mse: 0.1593
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0529 - mae: 0.1552 - mse: 0.0529
 64/106 [=================>............] - ETA: 0s - loss: 0.0345 - mae: 0.1302 - mse: 0.0345
 96/106 [==========================>...] - ETA: 0s - loss: 0.0364 - mae: 0.1397 - mse: 0.0364
106/106 [==============================] - 1s 8ms/step - loss: 0.0369 - mae: 0.1409 - mse: 0.0369 - val_loss: 0.1033 - val_mae: 0.2158 - val_mse: 0.1033
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0268 - mae: 0.1225 - mse: 0.0268
 64/106 [=================>............] - ETA: 0s - loss: 0.0292 - mae: 0.1249 - mse: 0.0292
 96/106 [==========================>...] - ETA: 0s - loss: 0.0315 - mae: 0.1297 - mse: 0.0315
106/106 [==============================] - 1s 8ms/step - loss: 0.0362 - mae: 0.1384 - mse: 0.0362 - val_loss: 0.1223 - val_mae: 0.2413 - val_mse: 0.1223
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0414 - mae: 0.1486 - mse: 0.0414
 64/106 [=================>............] - ETA: 0s - loss: 0.0330 - mae: 0.1350 - mse: 0.0330
 96/106 [==========================>...] - ETA: 0s - loss: 0.0337 - mae: 0.1346 - mse: 0.0337
106/106 [==============================] - 1s 8ms/step - loss: 0.0346 - mae: 0.1366 - mse: 0.0346 - val_loss: 0.1008 - val_mae: 0.2191 - val_mse: 0.1008
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0266 - mae: 0.1235 - mse: 0.0266
 64/106 [=================>............] - ETA: 0s - loss: 0.0400 - mae: 0.1395 - mse: 0.0400
 96/106 [==========================>...] - ETA: 0s - loss: 0.0342 - mae: 0.1363 - mse: 0.0342
106/106 [==============================] - 1s 8ms/step - loss: 0.0358 - mae: 0.1416 - mse: 0.0358 - val_loss: 0.1419 - val_mae: 0.2741 - val_mse: 0.1419
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0409 - mae: 0.1574 - mse: 0.0409
 64/106 [=================>............] - ETA: 0s - loss: 0.0340 - mae: 0.1410 - mse: 0.0340
 96/106 [==========================>...] - ETA: 0s - loss: 0.0297 - mae: 0.1317 - mse: 0.0297
106/106 [==============================] - 1s 8ms/step - loss: 0.0317 - mae: 0.1343 - mse: 0.0317 - val_loss: 0.0687 - val_mae: 0.2031 - val_mse: 0.0687
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0345 - mae: 0.1519 - mse: 0.0345
 64/106 [=================>............] - ETA: 0s - loss: 0.0317 - mae: 0.1414 - mse: 0.0317
 96/106 [==========================>...] - ETA: 0s - loss: 0.0337 - mae: 0.1408 - mse: 0.0337
106/106 [==============================] - 1s 8ms/step - loss: 0.0346 - mae: 0.1414 - mse: 0.0346 - val_loss: 0.1113 - val_mae: 0.2246 - val_mse: 0.1113
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0337 - mae: 0.1330 - mse: 0.0337
 64/106 [=================>............] - ETA: 0s - loss: 0.0347 - mae: 0.1312 - mse: 0.0347
 96/106 [==========================>...] - ETA: 0s - loss: 0.0301 - mae: 0.1232 - mse: 0.0301
106/106 [==============================] - 1s 8ms/step - loss: 0.0285 - mae: 0.1206 - mse: 0.0285 - val_loss: 0.1070 - val_mae: 0.2305 - val_mse: 0.1070
Saving trained model...
72
Testing...
heightdiff= [0.         0.         0.         0.         0.         7.86225891]
average prediction= [3.876354]
baseline= 6.266666666666667
eachuser= [0. 0. 0. 0. 0. 1.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 7.8622589111328125
['train-height-15.py', '0']
155 1
155 2
155 3
2_155_65_15_csi_a15_22.dat
155 5
155 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
2_155_65_15_csi_a15_1.dat
155 18
2_155_65_15_csi_a15_4.dat
155 20
155 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
155 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
165 41
1_165_65_15_csi_a15_12.dat
165 43
165 44
165 45
165 46
165 47
1_165_65_15_csi_a15_14.dat
165 49
165 50
1_165_65_15_csi_a15_18.dat
165 52
165 53
165 54
165 55
165 56
165 57
165 58
165 59
165 60
165 61
165 62
165 63
165 64
165 65
1_165_65_15_csi_a15_15.dat
165 67
165 68
165 69
165 70
165 71
2_165_50_15_csi_a15_10.dat
165 73
165 74
165 75
165 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
2_165_50_15_csi_a15_22.dat
165 91
165 92
165 93
2_165_50_15_csi_a15_14.dat
165 95
165 96
165 97
2_165_50_15_csi_a15_20.dat
165 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
1_175_70_15_csi_a15_28.dat
175 112
175 113
175 114
175 115
1_175_70_15_csi_a15_27.dat
175 117
175 118
175 119
1_175_70_15_csi_a15_29.dat
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
180 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
180 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
180 139
180 140
180 141
180 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
180 145
1_180_85_15_csi_a15_24.dat
180 147
180 148
180 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
180 152
180 153
180 154
1_180_85_15_csi_a15_27.dat
180 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
180 159
180 160
1_180_75_15_csi_a15_23.dat
180 162
1_180_75_15_csi_a15_17.dat
180 164
180 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
180 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
180 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
180 174
1_180_75_15_csi_a15_18.dat
180 176
1_180_75_15_csi_a15_15.dat
180 178
1_180_75_15_csi_a15_13.dat
180 180
1_180_75_15_csi_a15_3.dat
180 182
1_180_75_15_csi_a15_25.dat
180 184
180 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
180 190
173 191
1_173_85_15_csi_a15_7.dat
173 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
173 198
173 199
173 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
173 203
173 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
173 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
173 211
173 212
173 213
173 214
173 215
1_173_85_15_csi_a15_29.dat
173 217
173 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 170 170 170 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 173 173 173 173 173 173 173 173 173 173 173
 173 173 173 173]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.6219 - mae: 0.6999 - mse: 0.6219
 64/106 [=================>............] - ETA: 0s - loss: 0.5713 - mae: 0.6789 - mse: 0.5713
 96/106 [==========================>...] - ETA: 0s - loss: 0.5312 - mae: 0.6529 - mse: 0.5312
106/106 [==============================] - 1s 12ms/step - loss: 0.4881 - mae: 0.6148 - mse: 0.4881 - val_loss: 0.1460 - val_mae: 0.3212 - val_mse: 0.1460
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1899 - mae: 0.3649 - mse: 0.1899
 64/106 [=================>............] - ETA: 0s - loss: 0.1596 - mae: 0.3284 - mse: 0.1596
 96/106 [==========================>...] - ETA: 0s - loss: 0.1468 - mae: 0.3243 - mse: 0.1468
106/106 [==============================] - 1s 9ms/step - loss: 0.1498 - mae: 0.3267 - mse: 0.1498 - val_loss: 0.0906 - val_mae: 0.2497 - val_mse: 0.0906
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1510 - mae: 0.3074 - mse: 0.1510
 64/106 [=================>............] - ETA: 0s - loss: 0.1376 - mae: 0.2967 - mse: 0.1376
 96/106 [==========================>...] - ETA: 0s - loss: 0.1245 - mae: 0.2808 - mse: 0.1245
106/106 [==============================] - 1s 9ms/step - loss: 0.1221 - mae: 0.2782 - mse: 0.1221 - val_loss: 0.0656 - val_mae: 0.1711 - val_mse: 0.0656
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0825 - mae: 0.2145 - mse: 0.0825
 64/106 [=================>............] - ETA: 0s - loss: 0.0667 - mae: 0.1950 - mse: 0.0667
 96/106 [==========================>...] - ETA: 0s - loss: 0.0680 - mae: 0.1988 - mse: 0.0680
106/106 [==============================] - 1s 9ms/step - loss: 0.0710 - mae: 0.2007 - mse: 0.0710 - val_loss: 0.0845 - val_mae: 0.2406 - val_mse: 0.0845
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0816 - mae: 0.2149 - mse: 0.0816
 64/106 [=================>............] - ETA: 0s - loss: 0.0747 - mae: 0.2041 - mse: 0.0747
 96/106 [==========================>...] - ETA: 0s - loss: 0.0674 - mae: 0.1992 - mse: 0.0674
106/106 [==============================] - 1s 8ms/step - loss: 0.0709 - mae: 0.2046 - mse: 0.0709 - val_loss: 0.0734 - val_mae: 0.2097 - val_mse: 0.0734
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0581 - mae: 0.1745 - mse: 0.0581
 64/106 [=================>............] - ETA: 0s - loss: 0.0559 - mae: 0.1710 - mse: 0.0559
 96/106 [==========================>...] - ETA: 0s - loss: 0.0610 - mae: 0.1797 - mse: 0.0610
106/106 [==============================] - 1s 9ms/step - loss: 0.0617 - mae: 0.1811 - mse: 0.0617 - val_loss: 0.0698 - val_mae: 0.1938 - val_mse: 0.0698
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0498 - mae: 0.1623 - mse: 0.0498
 64/106 [=================>............] - ETA: 0s - loss: 0.0620 - mae: 0.1804 - mse: 0.0620
 96/106 [==========================>...] - ETA: 0s - loss: 0.0627 - mae: 0.1784 - mse: 0.0627
106/106 [==============================] - 1s 8ms/step - loss: 0.0613 - mae: 0.1792 - mse: 0.0613 - val_loss: 0.0718 - val_mae: 0.2054 - val_mse: 0.0718
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0510 - mae: 0.1659 - mse: 0.0510
 64/106 [=================>............] - ETA: 0s - loss: 0.0578 - mae: 0.1779 - mse: 0.0578
 96/106 [==========================>...] - ETA: 0s - loss: 0.0568 - mae: 0.1767 - mse: 0.0568
106/106 [==============================] - 1s 9ms/step - loss: 0.0568 - mae: 0.1776 - mse: 0.0568 - val_loss: 0.0733 - val_mae: 0.2178 - val_mse: 0.0733
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0855 - mae: 0.2380 - mse: 0.0855
 64/106 [=================>............] - ETA: 0s - loss: 0.0683 - mae: 0.2031 - mse: 0.0683
 96/106 [==========================>...] - ETA: 0s - loss: 0.0559 - mae: 0.1712 - mse: 0.0559
106/106 [==============================] - 1s 11ms/step - loss: 0.0567 - mae: 0.1728 - mse: 0.0567 - val_loss: 0.0691 - val_mae: 0.2040 - val_mse: 0.0691
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0587 - mae: 0.1793 - mse: 0.0587
 64/106 [=================>............] - ETA: 0s - loss: 0.0483 - mae: 0.1605 - mse: 0.0483
 96/106 [==========================>...] - ETA: 0s - loss: 0.0510 - mae: 0.1662 - mse: 0.0510
106/106 [==============================] - 1s 11ms/step - loss: 0.0503 - mae: 0.1657 - mse: 0.0503 - val_loss: 0.0640 - val_mae: 0.1815 - val_mse: 0.0640
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0573 - mae: 0.1767 - mse: 0.0573
 64/106 [=================>............] - ETA: 0s - loss: 0.0547 - mae: 0.1794 - mse: 0.0547
 96/106 [==========================>...] - ETA: 0s - loss: 0.0550 - mae: 0.1770 - mse: 0.0550
106/106 [==============================] - 1s 11ms/step - loss: 0.0573 - mae: 0.1794 - mse: 0.0573 - val_loss: 0.0666 - val_mae: 0.1995 - val_mse: 0.0666
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0552 - mae: 0.1782 - mse: 0.0552
 64/106 [=================>............] - ETA: 0s - loss: 0.0534 - mae: 0.1699 - mse: 0.0534
 96/106 [==========================>...] - ETA: 0s - loss: 0.0528 - mae: 0.1686 - mse: 0.0528
106/106 [==============================] - 1s 11ms/step - loss: 0.0536 - mae: 0.1716 - mse: 0.0536 - val_loss: 0.0635 - val_mae: 0.1883 - val_mse: 0.0635
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0386 - mae: 0.1332 - mse: 0.0386
 64/106 [=================>............] - ETA: 0s - loss: 0.0568 - mae: 0.1651 - mse: 0.0568
 96/106 [==========================>...] - ETA: 0s - loss: 0.0524 - mae: 0.1622 - mse: 0.0524
106/106 [==============================] - 1s 11ms/step - loss: 0.0542 - mae: 0.1681 - mse: 0.0542 - val_loss: 0.0567 - val_mae: 0.1508 - val_mse: 0.0567
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0372 - mae: 0.1515 - mse: 0.0372
 64/106 [=================>............] - ETA: 0s - loss: 0.0455 - mae: 0.1583 - mse: 0.0455
 96/106 [==========================>...] - ETA: 0s - loss: 0.0545 - mae: 0.1753 - mse: 0.0545
106/106 [==============================] - 1s 11ms/step - loss: 0.0545 - mae: 0.1764 - mse: 0.0545 - val_loss: 0.0648 - val_mae: 0.1973 - val_mse: 0.0648
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0475 - mae: 0.1653 - mse: 0.0475
 64/106 [=================>............] - ETA: 0s - loss: 0.0501 - mae: 0.1764 - mse: 0.0501
 96/106 [==========================>...] - ETA: 0s - loss: 0.0529 - mae: 0.1770 - mse: 0.0529
106/106 [==============================] - 1s 11ms/step - loss: 0.0543 - mae: 0.1781 - mse: 0.0543 - val_loss: 0.0736 - val_mae: 0.2223 - val_mse: 0.0736
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0617 - mae: 0.1906 - mse: 0.0617
 64/106 [=================>............] - ETA: 0s - loss: 0.0662 - mae: 0.1934 - mse: 0.0662
 96/106 [==========================>...] - ETA: 0s - loss: 0.0583 - mae: 0.1786 - mse: 0.0583
106/106 [==============================] - 1s 11ms/step - loss: 0.0549 - mae: 0.1710 - mse: 0.0549 - val_loss: 0.0564 - val_mae: 0.1641 - val_mse: 0.0564
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0422 - mae: 0.1567 - mse: 0.0422
 64/106 [=================>............] - ETA: 0s - loss: 0.0462 - mae: 0.1549 - mse: 0.0462
 96/106 [==========================>...] - ETA: 0s - loss: 0.0454 - mae: 0.1573 - mse: 0.0454
106/106 [==============================] - 1s 11ms/step - loss: 0.0453 - mae: 0.1576 - mse: 0.0453 - val_loss: 0.0527 - val_mae: 0.1504 - val_mse: 0.0527
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0432 - mae: 0.1377 - mse: 0.0432
 64/106 [=================>............] - ETA: 0s - loss: 0.0439 - mae: 0.1477 - mse: 0.0439
 96/106 [==========================>...] - ETA: 0s - loss: 0.0369 - mae: 0.1374 - mse: 0.0369
106/106 [==============================] - 1s 11ms/step - loss: 0.0414 - mae: 0.1456 - mse: 0.0414 - val_loss: 0.0558 - val_mae: 0.1672 - val_mse: 0.0558
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0444 - mae: 0.1494 - mse: 0.0444
 64/106 [=================>............] - ETA: 0s - loss: 0.0399 - mae: 0.1556 - mse: 0.0399
 96/106 [==========================>...] - ETA: 0s - loss: 0.0503 - mae: 0.1687 - mse: 0.0503
106/106 [==============================] - 1s 11ms/step - loss: 0.0521 - mae: 0.1697 - mse: 0.0521 - val_loss: 0.0532 - val_mae: 0.1649 - val_mse: 0.0532
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0365 - mae: 0.1360 - mse: 0.0365
 64/106 [=================>............] - ETA: 0s - loss: 0.0443 - mae: 0.1478 - mse: 0.0443
 96/106 [==========================>...] - ETA: 0s - loss: 0.0411 - mae: 0.1480 - mse: 0.0411
106/106 [==============================] - 1s 10ms/step - loss: 0.0429 - mae: 0.1519 - mse: 0.0429 - val_loss: 0.0530 - val_mae: 0.1689 - val_mse: 0.0530
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0553 - mae: 0.1779 - mse: 0.0553
 64/106 [=================>............] - ETA: 0s - loss: 0.0450 - mae: 0.1583 - mse: 0.0450
 96/106 [==========================>...] - ETA: 0s - loss: 0.0422 - mae: 0.1525 - mse: 0.0422
106/106 [==============================] - 1s 8ms/step - loss: 0.0433 - mae: 0.1537 - mse: 0.0433 - val_loss: 0.0653 - val_mae: 0.2044 - val_mse: 0.0653
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0586 - mae: 0.1828 - mse: 0.0586
 64/106 [=================>............] - ETA: 0s - loss: 0.0493 - mae: 0.1748 - mse: 0.0493
 96/106 [==========================>...] - ETA: 0s - loss: 0.0467 - mae: 0.1663 - mse: 0.0467
106/106 [==============================] - 1s 8ms/step - loss: 0.0436 - mae: 0.1599 - mse: 0.0436 - val_loss: 0.0499 - val_mae: 0.1545 - val_mse: 0.0499
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0257 - mae: 0.1127 - mse: 0.0257
 64/106 [=================>............] - ETA: 0s - loss: 0.0324 - mae: 0.1281 - mse: 0.0324
 96/106 [==========================>...] - ETA: 0s - loss: 0.0321 - mae: 0.1286 - mse: 0.0321
106/106 [==============================] - 1s 8ms/step - loss: 0.0353 - mae: 0.1328 - mse: 0.0353 - val_loss: 0.0479 - val_mae: 0.1458 - val_mse: 0.0479
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0372 - mae: 0.1578 - mse: 0.0372
 64/106 [=================>............] - ETA: 0s - loss: 0.0345 - mae: 0.1500 - mse: 0.0345
 96/106 [==========================>...] - ETA: 0s - loss: 0.0350 - mae: 0.1511 - mse: 0.0350
106/106 [==============================] - 1s 8ms/step - loss: 0.0326 - mae: 0.1439 - mse: 0.0326 - val_loss: 0.0522 - val_mae: 0.1679 - val_mse: 0.0522
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0450 - mae: 0.1591 - mse: 0.0450
 64/106 [=================>............] - ETA: 0s - loss: 0.0448 - mae: 0.1593 - mse: 0.0448
 96/106 [==========================>...] - ETA: 0s - loss: 0.0453 - mae: 0.1601 - mse: 0.0453
106/106 [==============================] - 1s 8ms/step - loss: 0.0430 - mae: 0.1568 - mse: 0.0430 - val_loss: 0.0544 - val_mae: 0.1763 - val_mse: 0.0544
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0295 - mae: 0.1245 - mse: 0.0295
 64/106 [=================>............] - ETA: 0s - loss: 0.0465 - mae: 0.1513 - mse: 0.0465
 96/106 [==========================>...] - ETA: 0s - loss: 0.0388 - mae: 0.1348 - mse: 0.0388
106/106 [==============================] - 1s 8ms/step - loss: 0.0384 - mae: 0.1374 - mse: 0.0384 - val_loss: 0.0458 - val_mae: 0.1509 - val_mse: 0.0458
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0261 - mae: 0.1201 - mse: 0.0261
 64/106 [=================>............] - ETA: 0s - loss: 0.0176 - mae: 0.0967 - mse: 0.0176
 96/106 [==========================>...] - ETA: 0s - loss: 0.0296 - mae: 0.1171 - mse: 0.0296
106/106 [==============================] - 1s 8ms/step - loss: 0.0281 - mae: 0.1159 - mse: 0.0281 - val_loss: 0.0465 - val_mae: 0.1555 - val_mse: 0.0465
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0456 - mae: 0.1566 - mse: 0.0456
 64/106 [=================>............] - ETA: 0s - loss: 0.0376 - mae: 0.1421 - mse: 0.0376
 96/106 [==========================>...] - ETA: 0s - loss: 0.0328 - mae: 0.1329 - mse: 0.0328
106/106 [==============================] - 1s 7ms/step - loss: 0.0321 - mae: 0.1328 - mse: 0.0321 - val_loss: 0.0569 - val_mae: 0.1935 - val_mse: 0.0569
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0217 - mae: 0.1205 - mse: 0.0217
 64/106 [=================>............] - ETA: 0s - loss: 0.0280 - mae: 0.1285 - mse: 0.0280
 96/106 [==========================>...] - ETA: 0s - loss: 0.0320 - mae: 0.1351 - mse: 0.0320
106/106 [==============================] - 1s 6ms/step - loss: 0.0335 - mae: 0.1367 - mse: 0.0335 - val_loss: 0.0445 - val_mae: 0.1616 - val_mse: 0.0445
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0367 - mae: 0.1550 - mse: 0.0367
 64/106 [=================>............] - ETA: 0s - loss: 0.0349 - mae: 0.1497 - mse: 0.0349
 96/106 [==========================>...] - ETA: 0s - loss: 0.0314 - mae: 0.1386 - mse: 0.0314
106/106 [==============================] - 1s 6ms/step - loss: 0.0336 - mae: 0.1433 - mse: 0.0336 - val_loss: 0.0392 - val_mae: 0.1457 - val_mse: 0.0392
Saving trained model...
72
Testing...
heightdiff= [ 0.         0.         0.         0.         0.        14.0877533]
average prediction= [3.653153]
baseline= 5.966666666666667
eachuser= [0. 0. 0. 0. 0. 3.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 4.6959177652994795
['train-height-15.py', '0']
155 1
155 2
155 3
2_155_65_15_csi_a15_22.dat
155 5
155 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
2_155_65_15_csi_a15_1.dat
155 18
2_155_65_15_csi_a15_4.dat
155 20
155 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
155 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
165 41
1_165_65_15_csi_a15_12.dat
165 43
165 44
165 45
165 46
165 47
1_165_65_15_csi_a15_14.dat
165 49
165 50
1_165_65_15_csi_a15_18.dat
165 52
165 53
165 54
165 55
165 56
165 57
165 58
165 59
165 60
165 61
165 62
165 63
165 64
165 65
1_165_65_15_csi_a15_15.dat
165 67
165 68
165 69
165 70
165 71
2_165_50_15_csi_a15_10.dat
165 73
165 74
165 75
165 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
2_165_50_15_csi_a15_22.dat
165 91
165 92
165 93
2_165_50_15_csi_a15_14.dat
165 95
165 96
165 97
2_165_50_15_csi_a15_20.dat
165 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
1_175_70_15_csi_a15_28.dat
175 112
175 113
175 114
175 115
1_175_70_15_csi_a15_27.dat
175 117
175 118
175 119
1_175_70_15_csi_a15_29.dat
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
180 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
180 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
180 139
180 140
180 141
180 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
180 145
1_180_85_15_csi_a15_24.dat
180 147
180 148
180 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
180 152
180 153
180 154
1_180_85_15_csi_a15_27.dat
180 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
180 159
180 160
1_180_75_15_csi_a15_23.dat
180 162
1_180_75_15_csi_a15_17.dat
180 164
180 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
180 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
180 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
180 174
1_180_75_15_csi_a15_18.dat
180 176
1_180_75_15_csi_a15_15.dat
180 178
1_180_75_15_csi_a15_13.dat
180 180
1_180_75_15_csi_a15_3.dat
180 182
1_180_75_15_csi_a15_25.dat
180 184
180 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
180 190
173 191
1_173_85_15_csi_a15_7.dat
173 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
173 198
173 199
173 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
173 203
173 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
173 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
173 211
173 212
173 213
173 214
173 215
1_173_85_15_csi_a15_29.dat
173 217
173 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 170 170 170 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 173 173 173 173 173 173 173 173 173 173 173
 173 173 173 173]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.2820 - mae: 0.4601 - mse: 0.2820
 64/106 [=================>............] - ETA: 0s - loss: 0.2924 - mae: 0.4746 - mse: 0.2924
 96/106 [==========================>...] - ETA: 0s - loss: 0.2500 - mae: 0.4323 - mse: 0.2500
106/106 [==============================] - 1s 13ms/step - loss: 0.2408 - mae: 0.4197 - mse: 0.2408 - val_loss: 0.1070 - val_mae: 0.2989 - val_mse: 0.1070
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1257 - mae: 0.3098 - mse: 0.1257
 64/106 [=================>............] - ETA: 0s - loss: 0.1648 - mae: 0.3342 - mse: 0.1648
 96/106 [==========================>...] - ETA: 0s - loss: 0.1503 - mae: 0.3187 - mse: 0.1503
106/106 [==============================] - 1s 8ms/step - loss: 0.1457 - mae: 0.3136 - mse: 0.1457 - val_loss: 0.0974 - val_mae: 0.2813 - val_mse: 0.0974
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1233 - mae: 0.3008 - mse: 0.1233
 64/106 [=================>............] - ETA: 0s - loss: 0.1202 - mae: 0.2865 - mse: 0.1202
 96/106 [==========================>...] - ETA: 0s - loss: 0.1053 - mae: 0.2609 - mse: 0.1053
106/106 [==============================] - 1s 8ms/step - loss: 0.1046 - mae: 0.2617 - mse: 0.1046 - val_loss: 0.1353 - val_mae: 0.3127 - val_mse: 0.1353
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0914 - mae: 0.2369 - mse: 0.0914
 64/106 [=================>............] - ETA: 0s - loss: 0.0866 - mae: 0.2421 - mse: 0.0866
 96/106 [==========================>...] - ETA: 0s - loss: 0.0791 - mae: 0.2281 - mse: 0.0791
106/106 [==============================] - 1s 9ms/step - loss: 0.0795 - mae: 0.2309 - mse: 0.0795 - val_loss: 0.1160 - val_mae: 0.2825 - val_mse: 0.1160
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0699 - mae: 0.2133 - mse: 0.0699
 64/106 [=================>............] - ETA: 0s - loss: 0.0741 - mae: 0.2193 - mse: 0.0741
 96/106 [==========================>...] - ETA: 0s - loss: 0.0749 - mae: 0.2236 - mse: 0.0749
106/106 [==============================] - 1s 9ms/step - loss: 0.0736 - mae: 0.2231 - mse: 0.0736 - val_loss: 0.0814 - val_mae: 0.2308 - val_mse: 0.0814
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0885 - mae: 0.2429 - mse: 0.0885
 64/106 [=================>............] - ETA: 0s - loss: 0.0845 - mae: 0.2367 - mse: 0.0845
 96/106 [==========================>...] - ETA: 0s - loss: 0.0816 - mae: 0.2316 - mse: 0.0816
106/106 [==============================] - 1s 9ms/step - loss: 0.0811 - mae: 0.2320 - mse: 0.0811 - val_loss: 0.0783 - val_mae: 0.2232 - val_mse: 0.0783
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0596 - mae: 0.1846 - mse: 0.0596
 64/106 [=================>............] - ETA: 0s - loss: 0.0579 - mae: 0.1931 - mse: 0.0579
 96/106 [==========================>...] - ETA: 0s - loss: 0.0598 - mae: 0.1945 - mse: 0.0598
106/106 [==============================] - 1s 9ms/step - loss: 0.0609 - mae: 0.1954 - mse: 0.0609 - val_loss: 0.1030 - val_mae: 0.2680 - val_mse: 0.1030
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0704 - mae: 0.2052 - mse: 0.0704
 64/106 [=================>............] - ETA: 0s - loss: 0.0600 - mae: 0.1930 - mse: 0.0600
 96/106 [==========================>...] - ETA: 0s - loss: 0.0636 - mae: 0.2010 - mse: 0.0636
106/106 [==============================] - 1s 9ms/step - loss: 0.0625 - mae: 0.1993 - mse: 0.0625 - val_loss: 0.0717 - val_mae: 0.2083 - val_mse: 0.0717
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0561 - mae: 0.1873 - mse: 0.0561
 64/106 [=================>............] - ETA: 0s - loss: 0.0496 - mae: 0.1729 - mse: 0.0496
 96/106 [==========================>...] - ETA: 0s - loss: 0.0571 - mae: 0.1806 - mse: 0.0571
106/106 [==============================] - 1s 8ms/step - loss: 0.0596 - mae: 0.1836 - mse: 0.0596 - val_loss: 0.0618 - val_mae: 0.1787 - val_mse: 0.0618
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0618 - mae: 0.1746 - mse: 0.0618
 64/106 [=================>............] - ETA: 0s - loss: 0.0696 - mae: 0.1940 - mse: 0.0696
 96/106 [==========================>...] - ETA: 0s - loss: 0.0698 - mae: 0.1983 - mse: 0.0698
106/106 [==============================] - 1s 8ms/step - loss: 0.0704 - mae: 0.2001 - mse: 0.0704 - val_loss: 0.0869 - val_mae: 0.2258 - val_mse: 0.0869
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0426 - mae: 0.1557 - mse: 0.0426
 64/106 [=================>............] - ETA: 0s - loss: 0.0498 - mae: 0.1727 - mse: 0.0498
 96/106 [==========================>...] - ETA: 0s - loss: 0.0548 - mae: 0.1861 - mse: 0.0548
106/106 [==============================] - 1s 8ms/step - loss: 0.0554 - mae: 0.1879 - mse: 0.0554 - val_loss: 0.0883 - val_mae: 0.2274 - val_mse: 0.0883
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0453 - mae: 0.1598 - mse: 0.0453
 64/106 [=================>............] - ETA: 0s - loss: 0.0539 - mae: 0.1690 - mse: 0.0539
 96/106 [==========================>...] - ETA: 0s - loss: 0.0515 - mae: 0.1656 - mse: 0.0515
106/106 [==============================] - 1s 9ms/step - loss: 0.0517 - mae: 0.1671 - mse: 0.0517 - val_loss: 0.0664 - val_mae: 0.1677 - val_mse: 0.0664
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0516 - mae: 0.1803 - mse: 0.0516
 64/106 [=================>............] - ETA: 0s - loss: 0.0633 - mae: 0.1873 - mse: 0.0633
 96/106 [==========================>...] - ETA: 0s - loss: 0.0572 - mae: 0.1810 - mse: 0.0572
106/106 [==============================] - 1s 8ms/step - loss: 0.0546 - mae: 0.1765 - mse: 0.0546 - val_loss: 0.0923 - val_mae: 0.2337 - val_mse: 0.0923
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0339 - mae: 0.1362 - mse: 0.0339
 64/106 [=================>............] - ETA: 0s - loss: 0.0481 - mae: 0.1651 - mse: 0.0481
 96/106 [==========================>...] - ETA: 0s - loss: 0.0514 - mae: 0.1700 - mse: 0.0514
106/106 [==============================] - 1s 7ms/step - loss: 0.0497 - mae: 0.1684 - mse: 0.0497 - val_loss: 0.0913 - val_mae: 0.2330 - val_mse: 0.0913
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0485 - mae: 0.1665 - mse: 0.0485
 64/106 [=================>............] - ETA: 0s - loss: 0.0433 - mae: 0.1548 - mse: 0.0433
 96/106 [==========================>...] - ETA: 0s - loss: 0.0453 - mae: 0.1584 - mse: 0.0453
106/106 [==============================] - 1s 9ms/step - loss: 0.0467 - mae: 0.1589 - mse: 0.0467 - val_loss: 0.0587 - val_mae: 0.1516 - val_mse: 0.0587
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0500 - mae: 0.1718 - mse: 0.0500
 64/106 [=================>............] - ETA: 0s - loss: 0.0667 - mae: 0.1967 - mse: 0.0667
 96/106 [==========================>...] - ETA: 0s - loss: 0.0527 - mae: 0.1680 - mse: 0.0527
106/106 [==============================] - 1s 9ms/step - loss: 0.0504 - mae: 0.1641 - mse: 0.0504 - val_loss: 0.0768 - val_mae: 0.2062 - val_mse: 0.0768
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0271 - mae: 0.1282 - mse: 0.0271
 64/106 [=================>............] - ETA: 0s - loss: 0.0337 - mae: 0.1359 - mse: 0.0337
 96/106 [==========================>...] - ETA: 0s - loss: 0.0387 - mae: 0.1448 - mse: 0.0387
106/106 [==============================] - 1s 9ms/step - loss: 0.0477 - mae: 0.1565 - mse: 0.0477 - val_loss: 0.0875 - val_mae: 0.2338 - val_mse: 0.0875
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0393 - mae: 0.1545 - mse: 0.0393
 64/106 [=================>............] - ETA: 0s - loss: 0.0326 - mae: 0.1375 - mse: 0.0326
 96/106 [==========================>...] - ETA: 0s - loss: 0.0403 - mae: 0.1416 - mse: 0.0403
106/106 [==============================] - 1s 9ms/step - loss: 0.0406 - mae: 0.1408 - mse: 0.0406 - val_loss: 0.0596 - val_mae: 0.1723 - val_mse: 0.0596
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0508 - mae: 0.1781 - mse: 0.0508
 64/106 [=================>............] - ETA: 0s - loss: 0.0385 - mae: 0.1521 - mse: 0.0385
 96/106 [==========================>...] - ETA: 0s - loss: 0.0443 - mae: 0.1569 - mse: 0.0443
106/106 [==============================] - 1s 9ms/step - loss: 0.0431 - mae: 0.1532 - mse: 0.0431 - val_loss: 0.0711 - val_mae: 0.1899 - val_mse: 0.0711
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0424 - mae: 0.1547 - mse: 0.0424
 64/106 [=================>............] - ETA: 0s - loss: 0.0401 - mae: 0.1409 - mse: 0.0401
 96/106 [==========================>...] - ETA: 0s - loss: 0.0406 - mae: 0.1428 - mse: 0.0406
106/106 [==============================] - 1s 9ms/step - loss: 0.0433 - mae: 0.1459 - mse: 0.0433 - val_loss: 0.0847 - val_mae: 0.1970 - val_mse: 0.0847
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0486 - mae: 0.1416 - mse: 0.0486
 64/106 [=================>............] - ETA: 0s - loss: 0.0420 - mae: 0.1404 - mse: 0.0420
 96/106 [==========================>...] - ETA: 0s - loss: 0.0360 - mae: 0.1319 - mse: 0.0360
106/106 [==============================] - 1s 8ms/step - loss: 0.0397 - mae: 0.1358 - mse: 0.0397 - val_loss: 0.0634 - val_mae: 0.1498 - val_mse: 0.0634
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0336 - mae: 0.1445 - mse: 0.0336
 64/106 [=================>............] - ETA: 0s - loss: 0.0409 - mae: 0.1519 - mse: 0.0409
 96/106 [==========================>...] - ETA: 0s - loss: 0.0388 - mae: 0.1440 - mse: 0.0388
106/106 [==============================] - 1s 9ms/step - loss: 0.0359 - mae: 0.1378 - mse: 0.0359 - val_loss: 0.0708 - val_mae: 0.1840 - val_mse: 0.0708
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0407 - mae: 0.1425 - mse: 0.0407
 64/106 [=================>............] - ETA: 0s - loss: 0.0303 - mae: 0.1268 - mse: 0.0303
 96/106 [==========================>...] - ETA: 0s - loss: 0.0395 - mae: 0.1414 - mse: 0.0395
106/106 [==============================] - 1s 9ms/step - loss: 0.0390 - mae: 0.1415 - mse: 0.0390 - val_loss: 0.0757 - val_mae: 0.2067 - val_mse: 0.0757
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0468 - mae: 0.1532 - mse: 0.0468
 64/106 [=================>............] - ETA: 0s - loss: 0.0448 - mae: 0.1583 - mse: 0.0448
 96/106 [==========================>...] - ETA: 0s - loss: 0.0374 - mae: 0.1418 - mse: 0.0374
106/106 [==============================] - 1s 9ms/step - loss: 0.0360 - mae: 0.1392 - mse: 0.0360 - val_loss: 0.0511 - val_mae: 0.1462 - val_mse: 0.0511
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0434 - mae: 0.1679 - mse: 0.0434
 64/106 [=================>............] - ETA: 0s - loss: 0.0427 - mae: 0.1626 - mse: 0.0427
 96/106 [==========================>...] - ETA: 0s - loss: 0.0389 - mae: 0.1473 - mse: 0.0389
106/106 [==============================] - 1s 9ms/step - loss: 0.0387 - mae: 0.1468 - mse: 0.0387 - val_loss: 0.0761 - val_mae: 0.1947 - val_mse: 0.0761
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0424 - mae: 0.1445 - mse: 0.0424
 64/106 [=================>............] - ETA: 0s - loss: 0.0399 - mae: 0.1378 - mse: 0.0399
 96/106 [==========================>...] - ETA: 0s - loss: 0.0332 - mae: 0.1279 - mse: 0.0332
106/106 [==============================] - 1s 9ms/step - loss: 0.0302 - mae: 0.1196 - mse: 0.0302 - val_loss: 0.0650 - val_mae: 0.1647 - val_mse: 0.0650
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0103 - mae: 0.0758 - mse: 0.0103
 64/106 [=================>............] - ETA: 0s - loss: 0.0260 - mae: 0.1126 - mse: 0.0260
 96/106 [==========================>...] - ETA: 0s - loss: 0.0264 - mae: 0.1149 - mse: 0.0264
106/106 [==============================] - 1s 9ms/step - loss: 0.0251 - mae: 0.1131 - mse: 0.0251 - val_loss: 0.0498 - val_mae: 0.1360 - val_mse: 0.0498
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0462 - mae: 0.1504 - mse: 0.0462
 64/106 [=================>............] - ETA: 0s - loss: 0.0387 - mae: 0.1363 - mse: 0.0387
 96/106 [==========================>...] - ETA: 0s - loss: 0.0354 - mae: 0.1257 - mse: 0.0354
106/106 [==============================] - 1s 11ms/step - loss: 0.0345 - mae: 0.1259 - mse: 0.0345 - val_loss: 0.0778 - val_mae: 0.2073 - val_mse: 0.0778
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0427 - mae: 0.1430 - mse: 0.0427
 64/106 [=================>............] - ETA: 0s - loss: 0.0382 - mae: 0.1450 - mse: 0.0382
 96/106 [==========================>...] - ETA: 0s - loss: 0.0352 - mae: 0.1370 - mse: 0.0352
106/106 [==============================] - 1s 11ms/step - loss: 0.0328 - mae: 0.1316 - mse: 0.0328 - val_loss: 0.0519 - val_mae: 0.1661 - val_mse: 0.0519
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0257 - mae: 0.1234 - mse: 0.0257
 64/106 [=================>............] - ETA: 0s - loss: 0.0283 - mae: 0.1276 - mse: 0.0283
 96/106 [==========================>...] - ETA: 0s - loss: 0.0269 - mae: 0.1220 - mse: 0.0269
106/106 [==============================] - 1s 10ms/step - loss: 0.0280 - mae: 0.1255 - mse: 0.0280 - val_loss: 0.0616 - val_mae: 0.1840 - val_mse: 0.0616
Saving trained model...
72
Testing...
heightdiff= [0.         0.         0.         0.         0.         5.37736511]
average prediction= [3.7066534]
baseline= 7.6
eachuser= [0. 0. 0. 0. 0. 4.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.3443412780761719
['train-height-15.py', '0']
155 1
155 2
155 3
2_155_65_15_csi_a15_22.dat
155 5
155 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
2_155_65_15_csi_a15_1.dat
155 18
2_155_65_15_csi_a15_4.dat
155 20
155 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
155 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
165 41
1_165_65_15_csi_a15_12.dat
165 43
165 44
165 45
165 46
165 47
1_165_65_15_csi_a15_14.dat
165 49
165 50
1_165_65_15_csi_a15_18.dat
165 52
165 53
165 54
165 55
165 56
165 57
165 58
165 59
165 60
165 61
165 62
165 63
165 64
165 65
1_165_65_15_csi_a15_15.dat
165 67
165 68
165 69
165 70
165 71
2_165_50_15_csi_a15_10.dat
165 73
165 74
165 75
165 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
2_165_50_15_csi_a15_22.dat
165 91
165 92
165 93
2_165_50_15_csi_a15_14.dat
165 95
165 96
165 97
2_165_50_15_csi_a15_20.dat
165 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
1_175_70_15_csi_a15_28.dat
175 112
175 113
175 114
175 115
1_175_70_15_csi_a15_27.dat
175 117
175 118
175 119
1_175_70_15_csi_a15_29.dat
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
180 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
180 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
180 139
180 140
180 141
180 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
180 145
1_180_85_15_csi_a15_24.dat
180 147
180 148
180 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
180 152
180 153
180 154
1_180_85_15_csi_a15_27.dat
180 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
180 159
180 160
1_180_75_15_csi_a15_23.dat
180 162
1_180_75_15_csi_a15_17.dat
180 164
180 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
180 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
180 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
180 174
1_180_75_15_csi_a15_18.dat
180 176
1_180_75_15_csi_a15_15.dat
180 178
1_180_75_15_csi_a15_13.dat
180 180
1_180_75_15_csi_a15_3.dat
180 182
1_180_75_15_csi_a15_25.dat
180 184
180 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
180 190
173 191
1_173_85_15_csi_a15_7.dat
173 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
173 198
173 199
173 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
173 203
173 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
173 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
173 211
173 212
173 213
173 214
173 215
1_173_85_15_csi_a15_29.dat
173 217
173 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 170 170 170 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 173 173 173 173 173 173 173 173 173 173 173
 173 173 173 173]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.5455 - mae: 0.6739 - mse: 0.5455
 64/106 [=================>............] - ETA: 0s - loss: 0.4589 - mae: 0.5997 - mse: 0.4589
 96/106 [==========================>...] - ETA: 0s - loss: 0.3906 - mae: 0.5482 - mse: 0.3906
106/106 [==============================] - 1s 12ms/step - loss: 0.3801 - mae: 0.5401 - mse: 0.3801 - val_loss: 0.1006 - val_mae: 0.2434 - val_mse: 0.1006
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1624 - mae: 0.3410 - mse: 0.1624
 64/106 [=================>............] - ETA: 0s - loss: 0.1402 - mae: 0.3114 - mse: 0.1402
 96/106 [==========================>...] - ETA: 0s - loss: 0.1494 - mae: 0.3141 - mse: 0.1494
106/106 [==============================] - 1s 6ms/step - loss: 0.1458 - mae: 0.3065 - mse: 0.1458 - val_loss: 0.0523 - val_mae: 0.2049 - val_mse: 0.0523
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0970 - mae: 0.2453 - mse: 0.0970
 64/106 [=================>............] - ETA: 0s - loss: 0.1561 - mae: 0.2869 - mse: 0.1561
 96/106 [==========================>...] - ETA: 0s - loss: 0.1448 - mae: 0.2821 - mse: 0.1448
106/106 [==============================] - 1s 6ms/step - loss: 0.1440 - mae: 0.2803 - mse: 0.1440 - val_loss: 0.0502 - val_mae: 0.1707 - val_mse: 0.0502
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0645 - mae: 0.2098 - mse: 0.0645
 64/106 [=================>............] - ETA: 0s - loss: 0.0823 - mae: 0.2308 - mse: 0.0823
 96/106 [==========================>...] - ETA: 0s - loss: 0.0926 - mae: 0.2474 - mse: 0.0926
106/106 [==============================] - 1s 6ms/step - loss: 0.0938 - mae: 0.2513 - mse: 0.0938 - val_loss: 0.0676 - val_mae: 0.2015 - val_mse: 0.0676
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1132 - mae: 0.2736 - mse: 0.1132
 64/106 [=================>............] - ETA: 0s - loss: 0.1149 - mae: 0.2843 - mse: 0.1149
 96/106 [==========================>...] - ETA: 0s - loss: 0.1058 - mae: 0.2743 - mse: 0.1058
106/106 [==============================] - 1s 6ms/step - loss: 0.1035 - mae: 0.2710 - mse: 0.1035 - val_loss: 0.0347 - val_mae: 0.1304 - val_mse: 0.0347
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0928 - mae: 0.2426 - mse: 0.0928
 64/106 [=================>............] - ETA: 0s - loss: 0.0777 - mae: 0.2235 - mse: 0.0777
 96/106 [==========================>...] - ETA: 0s - loss: 0.0746 - mae: 0.2177 - mse: 0.0746
106/106 [==============================] - 1s 6ms/step - loss: 0.0722 - mae: 0.2123 - mse: 0.0722 - val_loss: 0.0102 - val_mae: 0.0921 - val_mse: 0.0102
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0605 - mae: 0.1955 - mse: 0.0605
 64/106 [=================>............] - ETA: 0s - loss: 0.0699 - mae: 0.2109 - mse: 0.0699
 96/106 [==========================>...] - ETA: 0s - loss: 0.0707 - mae: 0.2097 - mse: 0.0707
106/106 [==============================] - 1s 6ms/step - loss: 0.0690 - mae: 0.2064 - mse: 0.0690 - val_loss: 0.0064 - val_mae: 0.0698 - val_mse: 0.0064
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0747 - mae: 0.2252 - mse: 0.0747
 64/106 [=================>............] - ETA: 0s - loss: 0.0662 - mae: 0.2011 - mse: 0.0662
 96/106 [==========================>...] - ETA: 0s - loss: 0.0681 - mae: 0.2048 - mse: 0.0681
106/106 [==============================] - 1s 6ms/step - loss: 0.0662 - mae: 0.2027 - mse: 0.0662 - val_loss: 0.0109 - val_mae: 0.0817 - val_mse: 0.0109
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0545 - mae: 0.1866 - mse: 0.0545
 64/106 [=================>............] - ETA: 0s - loss: 0.0621 - mae: 0.1942 - mse: 0.0621
 96/106 [==========================>...] - ETA: 0s - loss: 0.0567 - mae: 0.1866 - mse: 0.0567
106/106 [==============================] - 1s 6ms/step - loss: 0.0592 - mae: 0.1916 - mse: 0.0592 - val_loss: 0.0172 - val_mae: 0.1149 - val_mse: 0.0172
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0478 - mae: 0.1734 - mse: 0.0478
 64/106 [=================>............] - ETA: 0s - loss: 0.0562 - mae: 0.1809 - mse: 0.0562
 96/106 [==========================>...] - ETA: 0s - loss: 0.0541 - mae: 0.1766 - mse: 0.0541
106/106 [==============================] - 1s 6ms/step - loss: 0.0552 - mae: 0.1786 - mse: 0.0552 - val_loss: 0.0122 - val_mae: 0.0956 - val_mse: 0.0122
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0376 - mae: 0.1429 - mse: 0.0376
 64/106 [=================>............] - ETA: 0s - loss: 0.0602 - mae: 0.1903 - mse: 0.0602
 96/106 [==========================>...] - ETA: 0s - loss: 0.0550 - mae: 0.1799 - mse: 0.0550
106/106 [==============================] - 1s 6ms/step - loss: 0.0536 - mae: 0.1773 - mse: 0.0536 - val_loss: 0.0174 - val_mae: 0.1136 - val_mse: 0.0174
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0593 - mae: 0.1828 - mse: 0.0593
 64/106 [=================>............] - ETA: 0s - loss: 0.0501 - mae: 0.1640 - mse: 0.0501
 96/106 [==========================>...] - ETA: 0s - loss: 0.0564 - mae: 0.1769 - mse: 0.0564
106/106 [==============================] - 1s 6ms/step - loss: 0.0535 - mae: 0.1723 - mse: 0.0535 - val_loss: 0.0220 - val_mae: 0.1283 - val_mse: 0.0220
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0554 - mae: 0.1812 - mse: 0.0554
 64/106 [=================>............] - ETA: 0s - loss: 0.0487 - mae: 0.1671 - mse: 0.0487
 96/106 [==========================>...] - ETA: 0s - loss: 0.0533 - mae: 0.1789 - mse: 0.0533
106/106 [==============================] - 1s 6ms/step - loss: 0.0530 - mae: 0.1789 - mse: 0.0530 - val_loss: 0.0212 - val_mae: 0.1250 - val_mse: 0.0212
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0280 - mae: 0.1306 - mse: 0.0280
 64/106 [=================>............] - ETA: 0s - loss: 0.0362 - mae: 0.1440 - mse: 0.0362
 96/106 [==========================>...] - ETA: 0s - loss: 0.0442 - mae: 0.1553 - mse: 0.0442
106/106 [==============================] - 1s 6ms/step - loss: 0.0460 - mae: 0.1589 - mse: 0.0460 - val_loss: 0.0160 - val_mae: 0.1052 - val_mse: 0.0160
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0382 - mae: 0.1320 - mse: 0.0382
 64/106 [=================>............] - ETA: 0s - loss: 0.0447 - mae: 0.1550 - mse: 0.0447
 96/106 [==========================>...] - ETA: 0s - loss: 0.0383 - mae: 0.1422 - mse: 0.0383
106/106 [==============================] - 1s 7ms/step - loss: 0.0436 - mae: 0.1528 - mse: 0.0436 - val_loss: 0.0117 - val_mae: 0.0829 - val_mse: 0.0117
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0325 - mae: 0.1293 - mse: 0.0325
 64/106 [=================>............] - ETA: 0s - loss: 0.0439 - mae: 0.1488 - mse: 0.0439
 96/106 [==========================>...] - ETA: 0s - loss: 0.0534 - mae: 0.1714 - mse: 0.0534
106/106 [==============================] - 1s 6ms/step - loss: 0.0521 - mae: 0.1698 - mse: 0.0521 - val_loss: 0.0145 - val_mae: 0.0943 - val_mse: 0.0145
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0281 - mae: 0.1291 - mse: 0.0281
 64/106 [=================>............] - ETA: 0s - loss: 0.0408 - mae: 0.1499 - mse: 0.0408
 96/106 [==========================>...] - ETA: 0s - loss: 0.0486 - mae: 0.1702 - mse: 0.0486
106/106 [==============================] - 1s 6ms/step - loss: 0.0450 - mae: 0.1627 - mse: 0.0450 - val_loss: 0.0278 - val_mae: 0.1440 - val_mse: 0.0278
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0228 - mae: 0.1235 - mse: 0.0228
 64/106 [=================>............] - ETA: 0s - loss: 0.0404 - mae: 0.1497 - mse: 0.0404
 96/106 [==========================>...] - ETA: 0s - loss: 0.0448 - mae: 0.1574 - mse: 0.0448
106/106 [==============================] - 1s 6ms/step - loss: 0.0445 - mae: 0.1569 - mse: 0.0445 - val_loss: 0.0254 - val_mae: 0.1365 - val_mse: 0.0254
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0323 - mae: 0.1430 - mse: 0.0323
 64/106 [=================>............] - ETA: 0s - loss: 0.0417 - mae: 0.1576 - mse: 0.0417
 96/106 [==========================>...] - ETA: 0s - loss: 0.0428 - mae: 0.1590 - mse: 0.0428
106/106 [==============================] - 1s 6ms/step - loss: 0.0423 - mae: 0.1578 - mse: 0.0423 - val_loss: 0.0171 - val_mae: 0.1089 - val_mse: 0.0171
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0580 - mae: 0.1830 - mse: 0.0580
 64/106 [=================>............] - ETA: 0s - loss: 0.0429 - mae: 0.1591 - mse: 0.0429
 96/106 [==========================>...] - ETA: 0s - loss: 0.0470 - mae: 0.1590 - mse: 0.0470
106/106 [==============================] - 1s 6ms/step - loss: 0.0443 - mae: 0.1539 - mse: 0.0443 - val_loss: 0.0220 - val_mae: 0.1262 - val_mse: 0.0220
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0430 - mae: 0.1488 - mse: 0.0430
 64/106 [=================>............] - ETA: 0s - loss: 0.0366 - mae: 0.1352 - mse: 0.0366
 96/106 [==========================>...] - ETA: 0s - loss: 0.0329 - mae: 0.1295 - mse: 0.0329
106/106 [==============================] - 1s 6ms/step - loss: 0.0331 - mae: 0.1325 - mse: 0.0331 - val_loss: 0.0140 - val_mae: 0.0932 - val_mse: 0.0140
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0456 - mae: 0.1561 - mse: 0.0456
 64/106 [=================>............] - ETA: 0s - loss: 0.0462 - mae: 0.1614 - mse: 0.0462
 96/106 [==========================>...] - ETA: 0s - loss: 0.0369 - mae: 0.1425 - mse: 0.0369
106/106 [==============================] - 1s 6ms/step - loss: 0.0446 - mae: 0.1535 - mse: 0.0446 - val_loss: 0.0145 - val_mae: 0.0947 - val_mse: 0.0145
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0315 - mae: 0.1298 - mse: 0.0315
 64/106 [=================>............] - ETA: 0s - loss: 0.0379 - mae: 0.1506 - mse: 0.0379
 96/106 [==========================>...] - ETA: 0s - loss: 0.0345 - mae: 0.1424 - mse: 0.0345
106/106 [==============================] - 1s 6ms/step - loss: 0.0323 - mae: 0.1355 - mse: 0.0323 - val_loss: 0.0122 - val_mae: 0.0842 - val_mse: 0.0122
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0433 - mae: 0.1564 - mse: 0.0433
 64/106 [=================>............] - ETA: 0s - loss: 0.0392 - mae: 0.1480 - mse: 0.0392
 96/106 [==========================>...] - ETA: 0s - loss: 0.0363 - mae: 0.1433 - mse: 0.0363
106/106 [==============================] - 1s 6ms/step - loss: 0.0381 - mae: 0.1453 - mse: 0.0381 - val_loss: 0.0247 - val_mae: 0.1371 - val_mse: 0.0247
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0218 - mae: 0.1171 - mse: 0.0218
 64/106 [=================>............] - ETA: 0s - loss: 0.0344 - mae: 0.1423 - mse: 0.0344
 96/106 [==========================>...] - ETA: 0s - loss: 0.0410 - mae: 0.1524 - mse: 0.0410
106/106 [==============================] - 1s 6ms/step - loss: 0.0389 - mae: 0.1493 - mse: 0.0389 - val_loss: 0.0297 - val_mae: 0.1541 - val_mse: 0.0297
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0330 - mae: 0.1512 - mse: 0.0330
 64/106 [=================>............] - ETA: 0s - loss: 0.0292 - mae: 0.1374 - mse: 0.0292
 96/106 [==========================>...] - ETA: 0s - loss: 0.0307 - mae: 0.1346 - mse: 0.0307
106/106 [==============================] - 1s 6ms/step - loss: 0.0293 - mae: 0.1316 - mse: 0.0293 - val_loss: 0.0133 - val_mae: 0.0993 - val_mse: 0.0133
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0385 - mae: 0.1615 - mse: 0.0385
 64/106 [=================>............] - ETA: 0s - loss: 0.0386 - mae: 0.1478 - mse: 0.0386
 96/106 [==========================>...] - ETA: 0s - loss: 0.0298 - mae: 0.1292 - mse: 0.0298
106/106 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.1227 - mse: 0.0276 - val_loss: 0.0107 - val_mae: 0.0883 - val_mse: 0.0107
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0400 - mae: 0.1505 - mse: 0.0400
 64/106 [=================>............] - ETA: 0s - loss: 0.0347 - mae: 0.1383 - mse: 0.0347
 96/106 [==========================>...] - ETA: 0s - loss: 0.0337 - mae: 0.1398 - mse: 0.0337
106/106 [==============================] - 1s 6ms/step - loss: 0.0327 - mae: 0.1374 - mse: 0.0327 - val_loss: 0.0179 - val_mae: 0.1202 - val_mse: 0.0179
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0162 - mae: 0.1050 - mse: 0.0162
 64/106 [=================>............] - ETA: 0s - loss: 0.0169 - mae: 0.1030 - mse: 0.0169
 96/106 [==========================>...] - ETA: 0s - loss: 0.0223 - mae: 0.1149 - mse: 0.0223
106/106 [==============================] - 1s 5ms/step - loss: 0.0274 - mae: 0.1222 - mse: 0.0274 - val_loss: 0.0341 - val_mae: 0.1648 - val_mse: 0.0341
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0303 - mae: 0.1315 - mse: 0.0303
 64/106 [=================>............] - ETA: 0s - loss: 0.0291 - mae: 0.1254 - mse: 0.0291
 96/106 [==========================>...] - ETA: 0s - loss: 0.0237 - mae: 0.1135 - mse: 0.0237
106/106 [==============================] - 1s 6ms/step - loss: 0.0253 - mae: 0.1190 - mse: 0.0253 - val_loss: 0.0176 - val_mae: 0.1009 - val_mse: 0.0176
Saving trained model...
72
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         38.89675903]
average prediction= [3.495661]
baseline= 7.033333333333333
eachuser= [0. 0. 0. 0. 0. 5.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 7.779351806640625
['train-height-15.py', '0']
155 1
155 2
155 3
2_155_65_15_csi_a15_22.dat
155 5
155 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
2_155_65_15_csi_a15_1.dat
155 18
2_155_65_15_csi_a15_4.dat
155 20
155 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
155 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
165 41
1_165_65_15_csi_a15_12.dat
165 43
165 44
165 45
165 46
165 47
1_165_65_15_csi_a15_14.dat
165 49
165 50
1_165_65_15_csi_a15_18.dat
165 52
165 53
165 54
165 55
165 56
165 57
165 58
165 59
165 60
165 61
165 62
165 63
165 64
165 65
1_165_65_15_csi_a15_15.dat
165 67
165 68
165 69
165 70
165 71
2_165_50_15_csi_a15_10.dat
165 73
165 74
165 75
165 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
2_165_50_15_csi_a15_22.dat
165 91
165 92
165 93
2_165_50_15_csi_a15_14.dat
165 95
165 96
165 97
2_165_50_15_csi_a15_20.dat
165 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
1_175_70_15_csi_a15_28.dat
175 112
175 113
175 114
175 115
1_175_70_15_csi_a15_27.dat
175 117
175 118
175 119
1_175_70_15_csi_a15_29.dat
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
180 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
180 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
180 139
180 140
180 141
180 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
180 145
1_180_85_15_csi_a15_24.dat
180 147
180 148
180 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
180 152
180 153
180 154
1_180_85_15_csi_a15_27.dat
180 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
180 159
180 160
1_180_75_15_csi_a15_23.dat
180 162
1_180_75_15_csi_a15_17.dat
180 164
180 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
180 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
180 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
180 174
1_180_75_15_csi_a15_18.dat
180 176
1_180_75_15_csi_a15_15.dat
180 178
1_180_75_15_csi_a15_13.dat
180 180
1_180_75_15_csi_a15_3.dat
180 182
1_180_75_15_csi_a15_25.dat
180 184
180 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
180 190
173 191
1_173_85_15_csi_a15_7.dat
173 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
173 198
173 199
173 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
173 203
173 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
173 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
173 211
173 212
173 213
173 214
173 215
1_173_85_15_csi_a15_29.dat
173 217
173 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 170 170 170 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 173 173 173 173 173 173 173 173 173 173 173
 173 173 173 173]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.4586 - mae: 0.6014 - mse: 0.4586
 64/106 [=================>............] - ETA: 0s - loss: 0.3463 - mae: 0.5205 - mse: 0.3463
 96/106 [==========================>...] - ETA: 0s - loss: 0.2823 - mae: 0.4525 - mse: 0.2823
106/106 [==============================] - 1s 11ms/step - loss: 0.2673 - mae: 0.4373 - mse: 0.2673 - val_loss: 0.0940 - val_mae: 0.2233 - val_mse: 0.0940
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1229 - mae: 0.2979 - mse: 0.1229
 64/106 [=================>............] - ETA: 0s - loss: 0.1908 - mae: 0.3270 - mse: 0.1908
 96/106 [==========================>...] - ETA: 0s - loss: 0.1931 - mae: 0.3332 - mse: 0.1931
106/106 [==============================] - 1s 6ms/step - loss: 0.1895 - mae: 0.3328 - mse: 0.1895 - val_loss: 0.0849 - val_mae: 0.2127 - val_mse: 0.0849
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0712 - mae: 0.2121 - mse: 0.0712
 64/106 [=================>............] - ETA: 0s - loss: 0.1054 - mae: 0.2678 - mse: 0.1054
 96/106 [==========================>...] - ETA: 0s - loss: 0.1041 - mae: 0.2647 - mse: 0.1041
106/106 [==============================] - 1s 6ms/step - loss: 0.1030 - mae: 0.2660 - mse: 0.1030 - val_loss: 0.1449 - val_mae: 0.3120 - val_mse: 0.1449
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1307 - mae: 0.2942 - mse: 0.1307
 64/106 [=================>............] - ETA: 0s - loss: 0.1146 - mae: 0.2744 - mse: 0.1146
 96/106 [==========================>...] - ETA: 0s - loss: 0.1088 - mae: 0.2655 - mse: 0.1088
106/106 [==============================] - 1s 6ms/step - loss: 0.1080 - mae: 0.2665 - mse: 0.1080 - val_loss: 0.1145 - val_mae: 0.2583 - val_mse: 0.1145
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0980 - mae: 0.2526 - mse: 0.0980
 64/106 [=================>............] - ETA: 0s - loss: 0.0912 - mae: 0.2461 - mse: 0.0912
 96/106 [==========================>...] - ETA: 0s - loss: 0.0913 - mae: 0.2447 - mse: 0.0913
106/106 [==============================] - 1s 6ms/step - loss: 0.0904 - mae: 0.2413 - mse: 0.0904 - val_loss: 0.0617 - val_mae: 0.2263 - val_mse: 0.0617
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0850 - mae: 0.2449 - mse: 0.0850
 64/106 [=================>............] - ETA: 0s - loss: 0.0863 - mae: 0.2523 - mse: 0.0863
 96/106 [==========================>...] - ETA: 0s - loss: 0.0770 - mae: 0.2342 - mse: 0.0770
106/106 [==============================] - 1s 6ms/step - loss: 0.0789 - mae: 0.2368 - mse: 0.0789 - val_loss: 0.0569 - val_mae: 0.2168 - val_mse: 0.0569
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0637 - mae: 0.2181 - mse: 0.0637
 64/106 [=================>............] - ETA: 0s - loss: 0.0561 - mae: 0.1939 - mse: 0.0561
 96/106 [==========================>...] - ETA: 0s - loss: 0.0640 - mae: 0.2065 - mse: 0.0640
106/106 [==============================] - 1s 6ms/step - loss: 0.0630 - mae: 0.2037 - mse: 0.0630 - val_loss: 0.0681 - val_mae: 0.2163 - val_mse: 0.0681
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0618 - mae: 0.2127 - mse: 0.0618
 64/106 [=================>............] - ETA: 0s - loss: 0.0648 - mae: 0.2058 - mse: 0.0648
 96/106 [==========================>...] - ETA: 0s - loss: 0.0648 - mae: 0.2086 - mse: 0.0648
106/106 [==============================] - 1s 6ms/step - loss: 0.0618 - mae: 0.2026 - mse: 0.0618 - val_loss: 0.0522 - val_mae: 0.2011 - val_mse: 0.0522
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0705 - mae: 0.2078 - mse: 0.0705
 64/106 [=================>............] - ETA: 0s - loss: 0.0585 - mae: 0.1846 - mse: 0.0585
 96/106 [==========================>...] - ETA: 0s - loss: 0.0546 - mae: 0.1803 - mse: 0.0546
106/106 [==============================] - 1s 6ms/step - loss: 0.0561 - mae: 0.1825 - mse: 0.0561 - val_loss: 0.0302 - val_mae: 0.1603 - val_mse: 0.0302
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0413 - mae: 0.1610 - mse: 0.0413
 64/106 [=================>............] - ETA: 0s - loss: 0.0455 - mae: 0.1584 - mse: 0.0455
 96/106 [==========================>...] - ETA: 0s - loss: 0.0482 - mae: 0.1672 - mse: 0.0482
106/106 [==============================] - 1s 6ms/step - loss: 0.0489 - mae: 0.1679 - mse: 0.0489 - val_loss: 0.0237 - val_mae: 0.1423 - val_mse: 0.0237
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0458 - mae: 0.1719 - mse: 0.0458
 64/106 [=================>............] - ETA: 0s - loss: 0.0498 - mae: 0.1634 - mse: 0.0498
 96/106 [==========================>...] - ETA: 0s - loss: 0.0498 - mae: 0.1704 - mse: 0.0498
106/106 [==============================] - 1s 6ms/step - loss: 0.0486 - mae: 0.1680 - mse: 0.0486 - val_loss: 0.0258 - val_mae: 0.1502 - val_mse: 0.0258
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0260 - mae: 0.1279 - mse: 0.0260
 64/106 [=================>............] - ETA: 0s - loss: 0.0362 - mae: 0.1435 - mse: 0.0362
 96/106 [==========================>...] - ETA: 0s - loss: 0.0417 - mae: 0.1516 - mse: 0.0417
106/106 [==============================] - 1s 6ms/step - loss: 0.0413 - mae: 0.1512 - mse: 0.0413 - val_loss: 0.0239 - val_mae: 0.1374 - val_mse: 0.0239
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0597 - mae: 0.1765 - mse: 0.0597
 64/106 [=================>............] - ETA: 0s - loss: 0.0491 - mae: 0.1596 - mse: 0.0491
 96/106 [==========================>...] - ETA: 0s - loss: 0.0480 - mae: 0.1657 - mse: 0.0480
106/106 [==============================] - 1s 6ms/step - loss: 0.0451 - mae: 0.1584 - mse: 0.0451 - val_loss: 0.0248 - val_mae: 0.1356 - val_mse: 0.0248
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0294 - mae: 0.1370 - mse: 0.0294
 64/106 [=================>............] - ETA: 0s - loss: 0.0463 - mae: 0.1564 - mse: 0.0463
 96/106 [==========================>...] - ETA: 0s - loss: 0.0381 - mae: 0.1453 - mse: 0.0381
106/106 [==============================] - 1s 6ms/step - loss: 0.0378 - mae: 0.1456 - mse: 0.0378 - val_loss: 0.0288 - val_mae: 0.1449 - val_mse: 0.0288
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0434 - mae: 0.1599 - mse: 0.0434
 64/106 [=================>............] - ETA: 0s - loss: 0.0393 - mae: 0.1498 - mse: 0.0393
 96/106 [==========================>...] - ETA: 0s - loss: 0.0425 - mae: 0.1553 - mse: 0.0425
106/106 [==============================] - 1s 6ms/step - loss: 0.0402 - mae: 0.1517 - mse: 0.0402 - val_loss: 0.0325 - val_mae: 0.1555 - val_mse: 0.0325
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0333 - mae: 0.1458 - mse: 0.0333
 64/106 [=================>............] - ETA: 0s - loss: 0.0301 - mae: 0.1342 - mse: 0.0301
 96/106 [==========================>...] - ETA: 0s - loss: 0.0373 - mae: 0.1429 - mse: 0.0373
106/106 [==============================] - 1s 5ms/step - loss: 0.0358 - mae: 0.1390 - mse: 0.0358 - val_loss: 0.0272 - val_mae: 0.1391 - val_mse: 0.0272
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0453 - mae: 0.1562 - mse: 0.0453
 64/106 [=================>............] - ETA: 0s - loss: 0.0411 - mae: 0.1432 - mse: 0.0411
 96/106 [==========================>...] - ETA: 0s - loss: 0.0394 - mae: 0.1428 - mse: 0.0394
106/106 [==============================] - 1s 6ms/step - loss: 0.0367 - mae: 0.1373 - mse: 0.0367 - val_loss: 0.0223 - val_mae: 0.1239 - val_mse: 0.0223
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0221 - mae: 0.1176 - mse: 0.0221
 64/106 [=================>............] - ETA: 0s - loss: 0.0407 - mae: 0.1385 - mse: 0.0407
 96/106 [==========================>...] - ETA: 0s - loss: 0.0341 - mae: 0.1322 - mse: 0.0341
106/106 [==============================] - 1s 6ms/step - loss: 0.0328 - mae: 0.1300 - mse: 0.0328 - val_loss: 0.0173 - val_mae: 0.1129 - val_mse: 0.0173
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0286 - mae: 0.1298 - mse: 0.0286
 64/106 [=================>............] - ETA: 0s - loss: 0.0312 - mae: 0.1322 - mse: 0.0312
 96/106 [==========================>...] - ETA: 0s - loss: 0.0323 - mae: 0.1303 - mse: 0.0323
106/106 [==============================] - 1s 5ms/step - loss: 0.0306 - mae: 0.1274 - mse: 0.0306 - val_loss: 0.0136 - val_mae: 0.0967 - val_mse: 0.0136
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0350 - mae: 0.1300 - mse: 0.0350
 64/106 [=================>............] - ETA: 0s - loss: 0.0378 - mae: 0.1396 - mse: 0.0378
 96/106 [==========================>...] - ETA: 0s - loss: 0.0377 - mae: 0.1474 - mse: 0.0377
106/106 [==============================] - 1s 6ms/step - loss: 0.0352 - mae: 0.1412 - mse: 0.0352 - val_loss: 0.0132 - val_mae: 0.0933 - val_mse: 0.0132
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0257 - mae: 0.1257 - mse: 0.0257
 64/106 [=================>............] - ETA: 0s - loss: 0.0219 - mae: 0.1207 - mse: 0.0219
 96/106 [==========================>...] - ETA: 0s - loss: 0.0346 - mae: 0.1330 - mse: 0.0346
106/106 [==============================] - 1s 6ms/step - loss: 0.0335 - mae: 0.1311 - mse: 0.0335 - val_loss: 0.0212 - val_mae: 0.1316 - val_mse: 0.0212
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0143 - mae: 0.0923 - mse: 0.0143
 64/106 [=================>............] - ETA: 0s - loss: 0.0249 - mae: 0.1155 - mse: 0.0249
 96/106 [==========================>...] - ETA: 0s - loss: 0.0249 - mae: 0.1167 - mse: 0.0249
106/106 [==============================] - 1s 6ms/step - loss: 0.0293 - mae: 0.1238 - mse: 0.0293 - val_loss: 0.0155 - val_mae: 0.0811 - val_mse: 0.0155
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0351 - mae: 0.1218 - mse: 0.0351
 64/106 [=================>............] - ETA: 0s - loss: 0.0426 - mae: 0.1484 - mse: 0.0426
 96/106 [==========================>...] - ETA: 0s - loss: 0.0422 - mae: 0.1515 - mse: 0.0422
106/106 [==============================] - 1s 6ms/step - loss: 0.0392 - mae: 0.1445 - mse: 0.0392 - val_loss: 0.0153 - val_mae: 0.1026 - val_mse: 0.0153
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0185 - mae: 0.1166 - mse: 0.0185
 64/106 [=================>............] - ETA: 0s - loss: 0.0272 - mae: 0.1312 - mse: 0.0272
 96/106 [==========================>...] - ETA: 0s - loss: 0.0232 - mae: 0.1184 - mse: 0.0232
106/106 [==============================] - 1s 6ms/step - loss: 0.0253 - mae: 0.1213 - mse: 0.0253 - val_loss: 0.0236 - val_mae: 0.1423 - val_mse: 0.0236
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0373 - mae: 0.1447 - mse: 0.0373
 64/106 [=================>............] - ETA: 0s - loss: 0.0311 - mae: 0.1259 - mse: 0.0311
 96/106 [==========================>...] - ETA: 0s - loss: 0.0289 - mae: 0.1244 - mse: 0.0289
106/106 [==============================] - 1s 6ms/step - loss: 0.0271 - mae: 0.1207 - mse: 0.0271 - val_loss: 0.0132 - val_mae: 0.0913 - val_mse: 0.0132
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0247 - mae: 0.1116 - mse: 0.0247
 64/106 [=================>............] - ETA: 0s - loss: 0.0242 - mae: 0.1104 - mse: 0.0242
 96/106 [==========================>...] - ETA: 0s - loss: 0.0258 - mae: 0.1153 - mse: 0.0258
106/106 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.1180 - mse: 0.0259 - val_loss: 0.0169 - val_mae: 0.1136 - val_mse: 0.0169
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0295 - mae: 0.1119 - mse: 0.0295
 64/106 [=================>............] - ETA: 0s - loss: 0.0228 - mae: 0.1060 - mse: 0.0228
 96/106 [==========================>...] - ETA: 0s - loss: 0.0246 - mae: 0.1167 - mse: 0.0246
106/106 [==============================] - 1s 6ms/step - loss: 0.0243 - mae: 0.1183 - mse: 0.0243 - val_loss: 0.0221 - val_mae: 0.1395 - val_mse: 0.0221
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0330 - mae: 0.1253 - mse: 0.0330
 64/106 [=================>............] - ETA: 0s - loss: 0.0320 - mae: 0.1217 - mse: 0.0320
 96/106 [==========================>...] - ETA: 0s - loss: 0.0293 - mae: 0.1204 - mse: 0.0293
106/106 [==============================] - 1s 5ms/step - loss: 0.0293 - mae: 0.1213 - mse: 0.0293 - val_loss: 0.0141 - val_mae: 0.0827 - val_mse: 0.0141
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0367 - mae: 0.1358 - mse: 0.0367
 64/106 [=================>............] - ETA: 0s - loss: 0.0241 - mae: 0.1094 - mse: 0.0241
 96/106 [==========================>...] - ETA: 0s - loss: 0.0217 - mae: 0.1060 - mse: 0.0217
106/106 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.1117 - mse: 0.0263 - val_loss: 0.0131 - val_mae: 0.1073 - val_mse: 0.0131
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0148 - mae: 0.0975 - mse: 0.0148
 64/106 [=================>............] - ETA: 0s - loss: 0.0164 - mae: 0.0981 - mse: 0.0164
 96/106 [==========================>...] - ETA: 0s - loss: 0.0171 - mae: 0.0962 - mse: 0.0171
106/106 [==============================] - 1s 6ms/step - loss: 0.0169 - mae: 0.0963 - mse: 0.0169 - val_loss: 0.0072 - val_mae: 0.0620 - val_mse: 0.0072
Saving trained model...
72
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         44.87579346]
average prediction= [2.846315]
baseline= 8.333333333333334
eachuser= [0. 0. 0. 0. 0. 6.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 7.479298909505208
['train-height-15.py', '0']
155 1
155 2
155 3
2_155_65_15_csi_a15_22.dat
155 5
155 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
2_155_65_15_csi_a15_1.dat
155 18
2_155_65_15_csi_a15_4.dat
155 20
155 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
155 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
165 41
1_165_65_15_csi_a15_12.dat
165 43
165 44
165 45
165 46
165 47
1_165_65_15_csi_a15_14.dat
165 49
165 50
1_165_65_15_csi_a15_18.dat
165 52
165 53
165 54
165 55
165 56
165 57
165 58
165 59
165 60
165 61
165 62
165 63
165 64
165 65
1_165_65_15_csi_a15_15.dat
165 67
165 68
165 69
165 70
165 71
2_165_50_15_csi_a15_10.dat
165 73
165 74
165 75
165 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
2_165_50_15_csi_a15_22.dat
165 91
165 92
165 93
2_165_50_15_csi_a15_14.dat
165 95
165 96
165 97
2_165_50_15_csi_a15_20.dat
165 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
1_175_70_15_csi_a15_28.dat
175 112
175 113
175 114
175 115
1_175_70_15_csi_a15_27.dat
175 117
175 118
175 119
1_175_70_15_csi_a15_29.dat
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
180 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
180 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
180 139
180 140
180 141
180 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
180 145
1_180_85_15_csi_a15_24.dat
180 147
180 148
180 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
180 152
180 153
180 154
1_180_85_15_csi_a15_27.dat
180 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
180 159
180 160
1_180_75_15_csi_a15_23.dat
180 162
1_180_75_15_csi_a15_17.dat
180 164
180 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
180 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
180 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
180 174
1_180_75_15_csi_a15_18.dat
180 176
1_180_75_15_csi_a15_15.dat
180 178
1_180_75_15_csi_a15_13.dat
180 180
1_180_75_15_csi_a15_3.dat
180 182
1_180_75_15_csi_a15_25.dat
180 184
180 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
180 190
173 191
1_173_85_15_csi_a15_7.dat
173 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
173 198
173 199
173 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
173 203
173 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
173 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
173 211
173 212
173 213
173 214
173 215
1_173_85_15_csi_a15_29.dat
173 217
173 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 170 170 170 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 173 173 173 173 173 173 173 173 173 173 173
 173 173 173 173]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.4247 - mae: 0.5722 - mse: 0.4247
 64/106 [=================>............] - ETA: 0s - loss: 0.4389 - mae: 0.5950 - mse: 0.4389
 96/106 [==========================>...] - ETA: 0s - loss: 0.3691 - mae: 0.5340 - mse: 0.3691
106/106 [==============================] - 1s 11ms/step - loss: 0.3538 - mae: 0.5179 - mse: 0.3538 - val_loss: 0.1583 - val_mae: 0.3582 - val_mse: 0.1583
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1224 - mae: 0.2863 - mse: 0.1224
 64/106 [=================>............] - ETA: 0s - loss: 0.1138 - mae: 0.2836 - mse: 0.1138
 96/106 [==========================>...] - ETA: 0s - loss: 0.1605 - mae: 0.3353 - mse: 0.1605
106/106 [==============================] - 1s 7ms/step - loss: 0.1644 - mae: 0.3408 - mse: 0.1644 - val_loss: 0.1524 - val_mae: 0.3061 - val_mse: 0.1524
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1255 - mae: 0.3093 - mse: 0.1255
 64/106 [=================>............] - ETA: 0s - loss: 0.1809 - mae: 0.3602 - mse: 0.1809
 96/106 [==========================>...] - ETA: 0s - loss: 0.1650 - mae: 0.3392 - mse: 0.1650
106/106 [==============================] - 1s 6ms/step - loss: 0.1546 - mae: 0.3251 - mse: 0.1546 - val_loss: 0.1408 - val_mae: 0.3404 - val_mse: 0.1408
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0913 - mae: 0.2571 - mse: 0.0913
 64/106 [=================>............] - ETA: 0s - loss: 0.0949 - mae: 0.2534 - mse: 0.0949
 96/106 [==========================>...] - ETA: 0s - loss: 0.0980 - mae: 0.2567 - mse: 0.0980
106/106 [==============================] - 1s 6ms/step - loss: 0.1029 - mae: 0.2631 - mse: 0.1029 - val_loss: 0.1478 - val_mae: 0.3557 - val_mse: 0.1478
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0914 - mae: 0.2420 - mse: 0.0914
 64/106 [=================>............] - ETA: 0s - loss: 0.0841 - mae: 0.2215 - mse: 0.0841
 96/106 [==========================>...] - ETA: 0s - loss: 0.0830 - mae: 0.2227 - mse: 0.0830
106/106 [==============================] - 1s 6ms/step - loss: 0.0835 - mae: 0.2261 - mse: 0.0835 - val_loss: 0.1135 - val_mae: 0.3022 - val_mse: 0.1135
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0465 - mae: 0.1563 - mse: 0.0465
 64/106 [=================>............] - ETA: 0s - loss: 0.0561 - mae: 0.1745 - mse: 0.0561
 96/106 [==========================>...] - ETA: 0s - loss: 0.0626 - mae: 0.1790 - mse: 0.0626
106/106 [==============================] - 1s 6ms/step - loss: 0.0586 - mae: 0.1720 - mse: 0.0586 - val_loss: 0.0981 - val_mae: 0.2411 - val_mse: 0.0981
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0631 - mae: 0.1901 - mse: 0.0631
 64/106 [=================>............] - ETA: 0s - loss: 0.0589 - mae: 0.1840 - mse: 0.0589
 96/106 [==========================>...] - ETA: 0s - loss: 0.0634 - mae: 0.1906 - mse: 0.0634
106/106 [==============================] - 1s 7ms/step - loss: 0.0643 - mae: 0.1917 - mse: 0.0643 - val_loss: 0.0939 - val_mae: 0.2563 - val_mse: 0.0939
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0402 - mae: 0.1469 - mse: 0.0402
 64/106 [=================>............] - ETA: 0s - loss: 0.0508 - mae: 0.1651 - mse: 0.0508
 96/106 [==========================>...] - ETA: 0s - loss: 0.0507 - mae: 0.1675 - mse: 0.0507
106/106 [==============================] - 1s 8ms/step - loss: 0.0561 - mae: 0.1757 - mse: 0.0561 - val_loss: 0.1088 - val_mae: 0.3055 - val_mse: 0.1088
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0338 - mae: 0.1303 - mse: 0.0338
 64/106 [=================>............] - ETA: 0s - loss: 0.0547 - mae: 0.1722 - mse: 0.0547
 96/106 [==========================>...] - ETA: 0s - loss: 0.0580 - mae: 0.1793 - mse: 0.0580
106/106 [==============================] - 1s 6ms/step - loss: 0.0610 - mae: 0.1854 - mse: 0.0610 - val_loss: 0.1092 - val_mae: 0.3058 - val_mse: 0.1092
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0533 - mae: 0.1720 - mse: 0.0533
 64/106 [=================>............] - ETA: 0s - loss: 0.0520 - mae: 0.1735 - mse: 0.0520
 96/106 [==========================>...] - ETA: 0s - loss: 0.0569 - mae: 0.1795 - mse: 0.0569
106/106 [==============================] - 1s 6ms/step - loss: 0.0546 - mae: 0.1747 - mse: 0.0546 - val_loss: 0.0917 - val_mae: 0.2723 - val_mse: 0.0917
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0667 - mae: 0.1912 - mse: 0.0667
 64/106 [=================>............] - ETA: 0s - loss: 0.0535 - mae: 0.1661 - mse: 0.0535
 96/106 [==========================>...] - ETA: 0s - loss: 0.0484 - mae: 0.1570 - mse: 0.0484
106/106 [==============================] - 1s 6ms/step - loss: 0.0490 - mae: 0.1585 - mse: 0.0490 - val_loss: 0.0841 - val_mae: 0.2548 - val_mse: 0.0841
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0368 - mae: 0.1342 - mse: 0.0368
 64/106 [=================>............] - ETA: 0s - loss: 0.0371 - mae: 0.1382 - mse: 0.0371
 96/106 [==========================>...] - ETA: 0s - loss: 0.0393 - mae: 0.1450 - mse: 0.0393
106/106 [==============================] - 1s 6ms/step - loss: 0.0443 - mae: 0.1542 - mse: 0.0443 - val_loss: 0.0918 - val_mae: 0.2744 - val_mse: 0.0918
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0405 - mae: 0.1465 - mse: 0.0405
 64/106 [=================>............] - ETA: 0s - loss: 0.0507 - mae: 0.1656 - mse: 0.0507
 96/106 [==========================>...] - ETA: 0s - loss: 0.0486 - mae: 0.1606 - mse: 0.0486
106/106 [==============================] - 1s 6ms/step - loss: 0.0502 - mae: 0.1616 - mse: 0.0502 - val_loss: 0.0855 - val_mae: 0.2617 - val_mse: 0.0855
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0553 - mae: 0.1708 - mse: 0.0553
 64/106 [=================>............] - ETA: 0s - loss: 0.0475 - mae: 0.1595 - mse: 0.0475
 96/106 [==========================>...] - ETA: 0s - loss: 0.0432 - mae: 0.1511 - mse: 0.0432
106/106 [==============================] - 1s 6ms/step - loss: 0.0451 - mae: 0.1544 - mse: 0.0451 - val_loss: 0.0819 - val_mae: 0.2559 - val_mse: 0.0819
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0538 - mae: 0.1786 - mse: 0.0538
 64/106 [=================>............] - ETA: 0s - loss: 0.0413 - mae: 0.1514 - mse: 0.0413
 96/106 [==========================>...] - ETA: 0s - loss: 0.0393 - mae: 0.1442 - mse: 0.0393
106/106 [==============================] - 1s 6ms/step - loss: 0.0414 - mae: 0.1476 - mse: 0.0414 - val_loss: 0.0745 - val_mae: 0.2409 - val_mse: 0.0745
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0544 - mae: 0.1719 - mse: 0.0544
 64/106 [=================>............] - ETA: 0s - loss: 0.0405 - mae: 0.1402 - mse: 0.0405
 96/106 [==========================>...] - ETA: 0s - loss: 0.0381 - mae: 0.1347 - mse: 0.0381
106/106 [==============================] - 1s 7ms/step - loss: 0.0385 - mae: 0.1352 - mse: 0.0385 - val_loss: 0.0666 - val_mae: 0.2225 - val_mse: 0.0666
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0365 - mae: 0.1396 - mse: 0.0365
 64/106 [=================>............] - ETA: 0s - loss: 0.0325 - mae: 0.1305 - mse: 0.0325
 96/106 [==========================>...] - ETA: 0s - loss: 0.0402 - mae: 0.1458 - mse: 0.0402
106/106 [==============================] - 1s 7ms/step - loss: 0.0414 - mae: 0.1509 - mse: 0.0414 - val_loss: 0.0680 - val_mae: 0.2307 - val_mse: 0.0680
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0294 - mae: 0.1187 - mse: 0.0294
 64/106 [=================>............] - ETA: 0s - loss: 0.0347 - mae: 0.1331 - mse: 0.0347
 96/106 [==========================>...] - ETA: 0s - loss: 0.0335 - mae: 0.1309 - mse: 0.0335
106/106 [==============================] - 1s 6ms/step - loss: 0.0390 - mae: 0.1392 - mse: 0.0390 - val_loss: 0.0626 - val_mae: 0.2184 - val_mse: 0.0626
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0311 - mae: 0.1366 - mse: 0.0311
 64/106 [=================>............] - ETA: 0s - loss: 0.0488 - mae: 0.1653 - mse: 0.0488
 96/106 [==========================>...] - ETA: 0s - loss: 0.0460 - mae: 0.1565 - mse: 0.0460
106/106 [==============================] - 1s 7ms/step - loss: 0.0438 - mae: 0.1501 - mse: 0.0438 - val_loss: 0.0625 - val_mae: 0.2190 - val_mse: 0.0625
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0301 - mae: 0.1223 - mse: 0.0301
 64/106 [=================>............] - ETA: 0s - loss: 0.0348 - mae: 0.1309 - mse: 0.0348
 96/106 [==========================>...] - ETA: 0s - loss: 0.0360 - mae: 0.1337 - mse: 0.0360
106/106 [==============================] - 1s 6ms/step - loss: 0.0341 - mae: 0.1302 - mse: 0.0341 - val_loss: 0.0710 - val_mae: 0.2481 - val_mse: 0.0710
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0484 - mae: 0.1575 - mse: 0.0484
 64/106 [=================>............] - ETA: 0s - loss: 0.0368 - mae: 0.1367 - mse: 0.0368
 96/106 [==========================>...] - ETA: 0s - loss: 0.0405 - mae: 0.1460 - mse: 0.0405
106/106 [==============================] - 1s 6ms/step - loss: 0.0391 - mae: 0.1428 - mse: 0.0391 - val_loss: 0.0622 - val_mae: 0.2302 - val_mse: 0.0622
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0224 - mae: 0.1162 - mse: 0.0224
 64/106 [=================>............] - ETA: 0s - loss: 0.0409 - mae: 0.1501 - mse: 0.0409
 96/106 [==========================>...] - ETA: 0s - loss: 0.0335 - mae: 0.1332 - mse: 0.0335
106/106 [==============================] - 1s 6ms/step - loss: 0.0334 - mae: 0.1317 - mse: 0.0334 - val_loss: 0.0507 - val_mae: 0.1989 - val_mse: 0.0507
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0615 - mae: 0.1922 - mse: 0.0615
 64/106 [=================>............] - ETA: 0s - loss: 0.0418 - mae: 0.1508 - mse: 0.0418
 96/106 [==========================>...] - ETA: 0s - loss: 0.0330 - mae: 0.1305 - mse: 0.0330
106/106 [==============================] - 1s 6ms/step - loss: 0.0317 - mae: 0.1305 - mse: 0.0317 - val_loss: 0.0499 - val_mae: 0.2017 - val_mse: 0.0499
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0302 - mae: 0.1237 - mse: 0.0302
 64/106 [=================>............] - ETA: 0s - loss: 0.0354 - mae: 0.1343 - mse: 0.0354
 96/106 [==========================>...] - ETA: 0s - loss: 0.0335 - mae: 0.1305 - mse: 0.0335
106/106 [==============================] - 1s 6ms/step - loss: 0.0315 - mae: 0.1259 - mse: 0.0315 - val_loss: 0.0571 - val_mae: 0.2220 - val_mse: 0.0571
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0181 - mae: 0.0989 - mse: 0.0181
 64/106 [=================>............] - ETA: 0s - loss: 0.0302 - mae: 0.1256 - mse: 0.0302
 96/106 [==========================>...] - ETA: 0s - loss: 0.0290 - mae: 0.1238 - mse: 0.0290
106/106 [==============================] - 1s 6ms/step - loss: 0.0330 - mae: 0.1291 - mse: 0.0330 - val_loss: 0.0442 - val_mae: 0.1851 - val_mse: 0.0442
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0409 - mae: 0.1316 - mse: 0.0409
 64/106 [=================>............] - ETA: 0s - loss: 0.0355 - mae: 0.1290 - mse: 0.0355
 96/106 [==========================>...] - ETA: 0s - loss: 0.0315 - mae: 0.1253 - mse: 0.0315
106/106 [==============================] - 1s 7ms/step - loss: 0.0315 - mae: 0.1262 - mse: 0.0315 - val_loss: 0.0447 - val_mae: 0.1699 - val_mse: 0.0447
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0379 - mae: 0.1491 - mse: 0.0379
 64/106 [=================>............] - ETA: 0s - loss: 0.0378 - mae: 0.1449 - mse: 0.0378
 96/106 [==========================>...] - ETA: 0s - loss: 0.0380 - mae: 0.1427 - mse: 0.0380
106/106 [==============================] - 1s 6ms/step - loss: 0.0367 - mae: 0.1398 - mse: 0.0367 - val_loss: 0.0565 - val_mae: 0.2256 - val_mse: 0.0565
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0312 - mae: 0.1372 - mse: 0.0312
 64/106 [=================>............] - ETA: 0s - loss: 0.0323 - mae: 0.1442 - mse: 0.0323
 96/106 [==========================>...] - ETA: 0s - loss: 0.0332 - mae: 0.1452 - mse: 0.0332
106/106 [==============================] - 1s 7ms/step - loss: 0.0317 - mae: 0.1410 - mse: 0.0317 - val_loss: 0.0449 - val_mae: 0.1946 - val_mse: 0.0449
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0316 - mae: 0.1367 - mse: 0.0316
 64/106 [=================>............] - ETA: 0s - loss: 0.0363 - mae: 0.1430 - mse: 0.0363
 96/106 [==========================>...] - ETA: 0s - loss: 0.0343 - mae: 0.1343 - mse: 0.0343
106/106 [==============================] - 1s 6ms/step - loss: 0.0328 - mae: 0.1315 - mse: 0.0328 - val_loss: 0.0403 - val_mae: 0.1661 - val_mse: 0.0403
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0350 - mae: 0.1381 - mse: 0.0350
 64/106 [=================>............] - ETA: 0s - loss: 0.0336 - mae: 0.1289 - mse: 0.0336
 96/106 [==========================>...] - ETA: 0s - loss: 0.0296 - mae: 0.1198 - mse: 0.0296
106/106 [==============================] - 1s 6ms/step - loss: 0.0277 - mae: 0.1157 - mse: 0.0277 - val_loss: 0.0461 - val_mae: 0.2054 - val_mse: 0.0461
Saving trained model...
72
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         36.54833984]
average prediction= [5.2810545]
baseline= 7.233333333333333
eachuser= [0. 0. 0. 0. 0. 6.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 6.091389973958333
['train-height-15.py', '0']
155 1
155 2
155 3
2_155_65_15_csi_a15_22.dat
155 5
155 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
2_155_65_15_csi_a15_1.dat
155 18
2_155_65_15_csi_a15_4.dat
155 20
155 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
155 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
165 41
1_165_65_15_csi_a15_12.dat
165 43
165 44
165 45
165 46
165 47
1_165_65_15_csi_a15_14.dat
165 49
165 50
1_165_65_15_csi_a15_18.dat
165 52
165 53
165 54
165 55
165 56
165 57
165 58
165 59
165 60
165 61
165 62
165 63
165 64
165 65
1_165_65_15_csi_a15_15.dat
165 67
165 68
165 69
165 70
165 71
2_165_50_15_csi_a15_10.dat
165 73
165 74
165 75
165 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
2_165_50_15_csi_a15_22.dat
165 91
165 92
165 93
2_165_50_15_csi_a15_14.dat
165 95
165 96
165 97
2_165_50_15_csi_a15_20.dat
165 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
1_175_70_15_csi_a15_28.dat
175 112
175 113
175 114
175 115
1_175_70_15_csi_a15_27.dat
175 117
175 118
175 119
1_175_70_15_csi_a15_29.dat
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
180 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
180 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
180 139
180 140
180 141
180 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
180 145
1_180_85_15_csi_a15_24.dat
180 147
180 148
180 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
180 152
180 153
180 154
1_180_85_15_csi_a15_27.dat
180 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
180 159
180 160
1_180_75_15_csi_a15_23.dat
180 162
1_180_75_15_csi_a15_17.dat
180 164
180 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
180 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
180 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
180 174
1_180_75_15_csi_a15_18.dat
180 176
1_180_75_15_csi_a15_15.dat
180 178
1_180_75_15_csi_a15_13.dat
180 180
1_180_75_15_csi_a15_3.dat
180 182
1_180_75_15_csi_a15_25.dat
180 184
180 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
180 190
173 191
1_173_85_15_csi_a15_7.dat
173 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
173 198
173 199
173 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
173 203
173 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
173 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
173 211
173 212
173 213
173 214
173 215
1_173_85_15_csi_a15_29.dat
173 217
173 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 170 170 170 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 173 173 173 173 173 173 173 173 173 173 173
 173 173 173 173]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.4578 - mae: 0.6262 - mse: 0.4578
 64/106 [=================>............] - ETA: 0s - loss: 0.3719 - mae: 0.5372 - mse: 0.3719
 96/106 [==========================>...] - ETA: 0s - loss: 0.3143 - mae: 0.4816 - mse: 0.3143
106/106 [==============================] - 1s 12ms/step - loss: 0.2966 - mae: 0.4647 - mse: 0.2966 - val_loss: 0.1149 - val_mae: 0.3112 - val_mse: 0.1149
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1174 - mae: 0.2974 - mse: 0.1174
 64/106 [=================>............] - ETA: 0s - loss: 0.1152 - mae: 0.2842 - mse: 0.1152
 96/106 [==========================>...] - ETA: 0s - loss: 0.1240 - mae: 0.2911 - mse: 0.1240
106/106 [==============================] - 1s 6ms/step - loss: 0.1165 - mae: 0.2794 - mse: 0.1165 - val_loss: 0.1469 - val_mae: 0.3083 - val_mse: 0.1469
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1264 - mae: 0.2947 - mse: 0.1264
 64/106 [=================>............] - ETA: 0s - loss: 0.1074 - mae: 0.2704 - mse: 0.1074
 96/106 [==========================>...] - ETA: 0s - loss: 0.1004 - mae: 0.2620 - mse: 0.1004
106/106 [==============================] - 1s 6ms/step - loss: 0.0976 - mae: 0.2586 - mse: 0.0976 - val_loss: 0.1077 - val_mae: 0.3021 - val_mse: 0.1077
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0989 - mae: 0.2544 - mse: 0.0989
 64/106 [=================>............] - ETA: 0s - loss: 0.0857 - mae: 0.2398 - mse: 0.0857
 96/106 [==========================>...] - ETA: 0s - loss: 0.0824 - mae: 0.2341 - mse: 0.0824
106/106 [==============================] - 1s 6ms/step - loss: 0.0897 - mae: 0.2446 - mse: 0.0897 - val_loss: 0.1118 - val_mae: 0.3042 - val_mse: 0.1118
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0830 - mae: 0.2179 - mse: 0.0830
 64/106 [=================>............] - ETA: 0s - loss: 0.0815 - mae: 0.2269 - mse: 0.0815
 96/106 [==========================>...] - ETA: 0s - loss: 0.0815 - mae: 0.2274 - mse: 0.0815
106/106 [==============================] - 1s 7ms/step - loss: 0.0785 - mae: 0.2214 - mse: 0.0785 - val_loss: 0.1007 - val_mae: 0.2906 - val_mse: 0.1007
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0577 - mae: 0.1951 - mse: 0.0577
 64/106 [=================>............] - ETA: 0s - loss: 0.0606 - mae: 0.2007 - mse: 0.0606
 96/106 [==========================>...] - ETA: 0s - loss: 0.0616 - mae: 0.2036 - mse: 0.0616
106/106 [==============================] - 1s 6ms/step - loss: 0.0599 - mae: 0.2002 - mse: 0.0599 - val_loss: 0.0994 - val_mae: 0.2776 - val_mse: 0.0994
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0669 - mae: 0.2185 - mse: 0.0669
 64/106 [=================>............] - ETA: 0s - loss: 0.0677 - mae: 0.1997 - mse: 0.0677
 96/106 [==========================>...] - ETA: 0s - loss: 0.0625 - mae: 0.1913 - mse: 0.0625
106/106 [==============================] - 1s 6ms/step - loss: 0.0680 - mae: 0.2010 - mse: 0.0680 - val_loss: 0.0903 - val_mae: 0.2676 - val_mse: 0.0903
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0538 - mae: 0.1785 - mse: 0.0538
 64/106 [=================>............] - ETA: 0s - loss: 0.0577 - mae: 0.1925 - mse: 0.0577
 96/106 [==========================>...] - ETA: 0s - loss: 0.0658 - mae: 0.2036 - mse: 0.0658
106/106 [==============================] - 1s 6ms/step - loss: 0.0641 - mae: 0.1992 - mse: 0.0641 - val_loss: 0.0891 - val_mae: 0.2725 - val_mse: 0.0891
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0728 - mae: 0.2152 - mse: 0.0728
 64/106 [=================>............] - ETA: 0s - loss: 0.0631 - mae: 0.1931 - mse: 0.0631
 96/106 [==========================>...] - ETA: 0s - loss: 0.0616 - mae: 0.1925 - mse: 0.0616
106/106 [==============================] - 1s 6ms/step - loss: 0.0614 - mae: 0.1939 - mse: 0.0614 - val_loss: 0.0822 - val_mae: 0.2578 - val_mse: 0.0822
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0454 - mae: 0.1624 - mse: 0.0454
 64/106 [=================>............] - ETA: 0s - loss: 0.0499 - mae: 0.1736 - mse: 0.0499
 96/106 [==========================>...] - ETA: 0s - loss: 0.0486 - mae: 0.1668 - mse: 0.0486
106/106 [==============================] - 1s 6ms/step - loss: 0.0535 - mae: 0.1739 - mse: 0.0535 - val_loss: 0.0727 - val_mae: 0.2235 - val_mse: 0.0727
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0520 - mae: 0.1638 - mse: 0.0520
 64/106 [=================>............] - ETA: 0s - loss: 0.0549 - mae: 0.1721 - mse: 0.0549
 96/106 [==========================>...] - ETA: 0s - loss: 0.0551 - mae: 0.1743 - mse: 0.0551
106/106 [==============================] - 1s 6ms/step - loss: 0.0515 - mae: 0.1672 - mse: 0.0515 - val_loss: 0.0691 - val_mae: 0.2166 - val_mse: 0.0691
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0646 - mae: 0.1956 - mse: 0.0646
 64/106 [=================>............] - ETA: 0s - loss: 0.0617 - mae: 0.1849 - mse: 0.0617
 96/106 [==========================>...] - ETA: 0s - loss: 0.0515 - mae: 0.1688 - mse: 0.0515
106/106 [==============================] - 1s 7ms/step - loss: 0.0486 - mae: 0.1631 - mse: 0.0486 - val_loss: 0.0675 - val_mae: 0.2272 - val_mse: 0.0675
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0446 - mae: 0.1496 - mse: 0.0446
 64/106 [=================>............] - ETA: 0s - loss: 0.0496 - mae: 0.1578 - mse: 0.0496
 96/106 [==========================>...] - ETA: 0s - loss: 0.0504 - mae: 0.1590 - mse: 0.0504
106/106 [==============================] - 1s 6ms/step - loss: 0.0528 - mae: 0.1633 - mse: 0.0528 - val_loss: 0.0667 - val_mae: 0.2282 - val_mse: 0.0667
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0743 - mae: 0.2006 - mse: 0.0743
 64/106 [=================>............] - ETA: 0s - loss: 0.0561 - mae: 0.1690 - mse: 0.0561
 96/106 [==========================>...] - ETA: 0s - loss: 0.0528 - mae: 0.1686 - mse: 0.0528
106/106 [==============================] - 1s 7ms/step - loss: 0.0531 - mae: 0.1696 - mse: 0.0531 - val_loss: 0.0613 - val_mae: 0.2081 - val_mse: 0.0613
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0363 - mae: 0.1362 - mse: 0.0363
 64/106 [=================>............] - ETA: 0s - loss: 0.0354 - mae: 0.1409 - mse: 0.0354
 96/106 [==========================>...] - ETA: 0s - loss: 0.0449 - mae: 0.1598 - mse: 0.0449
106/106 [==============================] - 1s 6ms/step - loss: 0.0470 - mae: 0.1643 - mse: 0.0470 - val_loss: 0.0608 - val_mae: 0.2097 - val_mse: 0.0608
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0539 - mae: 0.1649 - mse: 0.0539
 64/106 [=================>............] - ETA: 0s - loss: 0.0452 - mae: 0.1574 - mse: 0.0452
 96/106 [==========================>...] - ETA: 0s - loss: 0.0424 - mae: 0.1552 - mse: 0.0424
106/106 [==============================] - 1s 7ms/step - loss: 0.0434 - mae: 0.1558 - mse: 0.0434 - val_loss: 0.0656 - val_mae: 0.2257 - val_mse: 0.0656
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0582 - mae: 0.1665 - mse: 0.0582
 64/106 [=================>............] - ETA: 0s - loss: 0.0514 - mae: 0.1669 - mse: 0.0514
 96/106 [==========================>...] - ETA: 0s - loss: 0.0480 - mae: 0.1678 - mse: 0.0480
106/106 [==============================] - 1s 6ms/step - loss: 0.0464 - mae: 0.1671 - mse: 0.0464 - val_loss: 0.0591 - val_mae: 0.2067 - val_mse: 0.0591
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0376 - mae: 0.1436 - mse: 0.0376
 64/106 [=================>............] - ETA: 0s - loss: 0.0320 - mae: 0.1290 - mse: 0.0320
 96/106 [==========================>...] - ETA: 0s - loss: 0.0386 - mae: 0.1446 - mse: 0.0386
106/106 [==============================] - 1s 7ms/step - loss: 0.0365 - mae: 0.1399 - mse: 0.0365 - val_loss: 0.0549 - val_mae: 0.1979 - val_mse: 0.0549
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0308 - mae: 0.1214 - mse: 0.0308
 64/106 [=================>............] - ETA: 0s - loss: 0.0273 - mae: 0.1170 - mse: 0.0273
 96/106 [==========================>...] - ETA: 0s - loss: 0.0304 - mae: 0.1247 - mse: 0.0304
106/106 [==============================] - 1s 6ms/step - loss: 0.0332 - mae: 0.1286 - mse: 0.0332 - val_loss: 0.0554 - val_mae: 0.2049 - val_mse: 0.0554
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0300 - mae: 0.1458 - mse: 0.0300
 64/106 [=================>............] - ETA: 0s - loss: 0.0264 - mae: 0.1288 - mse: 0.0264
 96/106 [==========================>...] - ETA: 0s - loss: 0.0325 - mae: 0.1378 - mse: 0.0325
106/106 [==============================] - 1s 7ms/step - loss: 0.0365 - mae: 0.1429 - mse: 0.0365 - val_loss: 0.0538 - val_mae: 0.1928 - val_mse: 0.0538
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0351 - mae: 0.1320 - mse: 0.0351
 64/106 [=================>............] - ETA: 0s - loss: 0.0429 - mae: 0.1501 - mse: 0.0429
 96/106 [==========================>...] - ETA: 0s - loss: 0.0382 - mae: 0.1379 - mse: 0.0382
106/106 [==============================] - 1s 7ms/step - loss: 0.0400 - mae: 0.1423 - mse: 0.0400 - val_loss: 0.0572 - val_mae: 0.2067 - val_mse: 0.0572
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0375 - mae: 0.1468 - mse: 0.0375
 64/106 [=================>............] - ETA: 0s - loss: 0.0383 - mae: 0.1452 - mse: 0.0383
 96/106 [==========================>...] - ETA: 0s - loss: 0.0360 - mae: 0.1406 - mse: 0.0360
106/106 [==============================] - 1s 6ms/step - loss: 0.0366 - mae: 0.1389 - mse: 0.0366 - val_loss: 0.0641 - val_mae: 0.2265 - val_mse: 0.0641
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0369 - mae: 0.1557 - mse: 0.0369
 64/106 [=================>............] - ETA: 0s - loss: 0.0380 - mae: 0.1564 - mse: 0.0380
 96/106 [==========================>...] - ETA: 0s - loss: 0.0381 - mae: 0.1511 - mse: 0.0381
106/106 [==============================] - 1s 6ms/step - loss: 0.0379 - mae: 0.1493 - mse: 0.0379 - val_loss: 0.0480 - val_mae: 0.1891 - val_mse: 0.0480
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0153 - mae: 0.0809 - mse: 0.0153
 64/106 [=================>............] - ETA: 0s - loss: 0.0287 - mae: 0.1178 - mse: 0.0287
 96/106 [==========================>...] - ETA: 0s - loss: 0.0428 - mae: 0.1494 - mse: 0.0428
106/106 [==============================] - 1s 7ms/step - loss: 0.0428 - mae: 0.1496 - mse: 0.0428 - val_loss: 0.0517 - val_mae: 0.2044 - val_mse: 0.0517
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0389 - mae: 0.1376 - mse: 0.0389
 64/106 [=================>............] - ETA: 0s - loss: 0.0299 - mae: 0.1226 - mse: 0.0299
 96/106 [==========================>...] - ETA: 0s - loss: 0.0301 - mae: 0.1259 - mse: 0.0301
106/106 [==============================] - 1s 6ms/step - loss: 0.0319 - mae: 0.1324 - mse: 0.0319 - val_loss: 0.0595 - val_mae: 0.2207 - val_mse: 0.0595
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0340 - mae: 0.1379 - mse: 0.0340
 64/106 [=================>............] - ETA: 0s - loss: 0.0330 - mae: 0.1337 - mse: 0.0330
 96/106 [==========================>...] - ETA: 0s - loss: 0.0290 - mae: 0.1230 - mse: 0.0290
106/106 [==============================] - 1s 6ms/step - loss: 0.0303 - mae: 0.1275 - mse: 0.0303 - val_loss: 0.0475 - val_mae: 0.1954 - val_mse: 0.0475
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0270 - mae: 0.1103 - mse: 0.0270
 64/106 [=================>............] - ETA: 0s - loss: 0.0302 - mae: 0.1228 - mse: 0.0302
 96/106 [==========================>...] - ETA: 0s - loss: 0.0308 - mae: 0.1268 - mse: 0.0308
106/106 [==============================] - 1s 7ms/step - loss: 0.0303 - mae: 0.1256 - mse: 0.0303 - val_loss: 0.0425 - val_mae: 0.1845 - val_mse: 0.0425
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0257 - mae: 0.1130 - mse: 0.0257
 64/106 [=================>............] - ETA: 0s - loss: 0.0205 - mae: 0.1084 - mse: 0.0205
 96/106 [==========================>...] - ETA: 0s - loss: 0.0257 - mae: 0.1172 - mse: 0.0257
106/106 [==============================] - 1s 6ms/step - loss: 0.0263 - mae: 0.1186 - mse: 0.0263 - val_loss: 0.0500 - val_mae: 0.2018 - val_mse: 0.0500
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0314 - mae: 0.1274 - mse: 0.0314
 64/106 [=================>............] - ETA: 0s - loss: 0.0289 - mae: 0.1228 - mse: 0.0289
 96/106 [==========================>...] - ETA: 0s - loss: 0.0265 - mae: 0.1159 - mse: 0.0265
106/106 [==============================] - 1s 6ms/step - loss: 0.0274 - mae: 0.1170 - mse: 0.0274 - val_loss: 0.0393 - val_mae: 0.1635 - val_mse: 0.0393
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0287 - mae: 0.1227 - mse: 0.0287
 64/106 [=================>............] - ETA: 0s - loss: 0.0275 - mae: 0.1197 - mse: 0.0275
 96/106 [==========================>...] - ETA: 0s - loss: 0.0307 - mae: 0.1282 - mse: 0.0307
106/106 [==============================] - 1s 6ms/step - loss: 0.0310 - mae: 0.1302 - mse: 0.0310 - val_loss: 0.0422 - val_mae: 0.1905 - val_mse: 0.0422
Saving trained model...
72
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         25.97634888]
average prediction= [3.5259156]
baseline= 8.033333333333333
eachuser= [0. 0. 0. 0. 0. 6.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 4.3293914794921875
['train-height-15.py', '0']
155 1
155 2
155 3
2_155_65_15_csi_a15_22.dat
155 5
155 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
2_155_65_15_csi_a15_1.dat
155 18
2_155_65_15_csi_a15_4.dat
155 20
155 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
155 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
165 41
1_165_65_15_csi_a15_12.dat
165 43
165 44
165 45
165 46
165 47
1_165_65_15_csi_a15_14.dat
165 49
165 50
1_165_65_15_csi_a15_18.dat
165 52
165 53
165 54
165 55
165 56
165 57
165 58
165 59
165 60
165 61
165 62
165 63
165 64
165 65
1_165_65_15_csi_a15_15.dat
165 67
165 68
165 69
165 70
165 71
2_165_50_15_csi_a15_10.dat
165 73
165 74
165 75
165 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
2_165_50_15_csi_a15_22.dat
165 91
165 92
165 93
2_165_50_15_csi_a15_14.dat
165 95
165 96
165 97
2_165_50_15_csi_a15_20.dat
165 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
1_175_70_15_csi_a15_28.dat
175 112
175 113
175 114
175 115
1_175_70_15_csi_a15_27.dat
175 117
175 118
175 119
1_175_70_15_csi_a15_29.dat
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
175 129
175 130
180 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
180 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
180 139
180 140
180 141
180 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
180 145
1_180_85_15_csi_a15_24.dat
180 147
180 148
180 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
180 152
180 153
180 154
1_180_85_15_csi_a15_27.dat
180 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
180 159
180 160
1_180_75_15_csi_a15_23.dat
180 162
1_180_75_15_csi_a15_17.dat
180 164
180 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
180 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
180 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
180 174
1_180_75_15_csi_a15_18.dat
180 176
1_180_75_15_csi_a15_15.dat
180 178
1_180_75_15_csi_a15_13.dat
180 180
1_180_75_15_csi_a15_3.dat
180 182
1_180_75_15_csi_a15_25.dat
180 184
180 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
180 190
173 191
1_173_85_15_csi_a15_7.dat
173 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
173 198
173 199
173 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
173 203
173 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
173 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
173 211
173 212
173 213
173 214
173 215
1_173_85_15_csi_a15_29.dat
173 217
173 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 170 170 170 170 170 170 170 170 170 170 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 173 173 173 173 173 173 173 173 173 173 173
 173 173 173 173]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.3984 - mae: 0.5391 - mse: 0.3984
 64/106 [=================>............] - ETA: 0s - loss: 0.3169 - mae: 0.4824 - mse: 0.3169
 96/106 [==========================>...] - ETA: 0s - loss: 0.2670 - mae: 0.4369 - mse: 0.2670
106/106 [==============================] - 1s 10ms/step - loss: 0.2547 - mae: 0.4239 - mse: 0.2547 - val_loss: 0.0682 - val_mae: 0.2035 - val_mse: 0.0682
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0632 - mae: 0.2057 - mse: 0.0632
 64/106 [=================>............] - ETA: 0s - loss: 0.1019 - mae: 0.2638 - mse: 0.1019
 96/106 [==========================>...] - ETA: 0s - loss: 0.1159 - mae: 0.2838 - mse: 0.1159
106/106 [==============================] - 1s 6ms/step - loss: 0.1221 - mae: 0.2895 - mse: 0.1221 - val_loss: 0.0673 - val_mae: 0.2143 - val_mse: 0.0673
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1379 - mae: 0.3017 - mse: 0.1379
 64/106 [=================>............] - ETA: 0s - loss: 0.1157 - mae: 0.2664 - mse: 0.1157
 96/106 [==========================>...] - ETA: 0s - loss: 0.1037 - mae: 0.2513 - mse: 0.1037
106/106 [==============================] - 1s 6ms/step - loss: 0.0997 - mae: 0.2469 - mse: 0.0997 - val_loss: 0.0754 - val_mae: 0.2223 - val_mse: 0.0754
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1075 - mae: 0.2848 - mse: 0.1075
 64/106 [=================>............] - ETA: 0s - loss: 0.1084 - mae: 0.2807 - mse: 0.1084
 96/106 [==========================>...] - ETA: 0s - loss: 0.0914 - mae: 0.2531 - mse: 0.0914
106/106 [==============================] - 1s 6ms/step - loss: 0.0927 - mae: 0.2520 - mse: 0.0927 - val_loss: 0.0808 - val_mae: 0.2406 - val_mse: 0.0808
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0753 - mae: 0.2259 - mse: 0.0753
 64/106 [=================>............] - ETA: 0s - loss: 0.0751 - mae: 0.2301 - mse: 0.0751
 96/106 [==========================>...] - ETA: 0s - loss: 0.0724 - mae: 0.2204 - mse: 0.0724
106/106 [==============================] - 1s 6ms/step - loss: 0.0809 - mae: 0.2347 - mse: 0.0809 - val_loss: 0.0517 - val_mae: 0.1699 - val_mse: 0.0517
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0869 - mae: 0.2456 - mse: 0.0869
 64/106 [=================>............] - ETA: 0s - loss: 0.0820 - mae: 0.2264 - mse: 0.0820
 96/106 [==========================>...] - ETA: 0s - loss: 0.0654 - mae: 0.1951 - mse: 0.0654
106/106 [==============================] - 1s 6ms/step - loss: 0.0728 - mae: 0.2093 - mse: 0.0728 - val_loss: 0.0419 - val_mae: 0.1463 - val_mse: 0.0419
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0774 - mae: 0.2122 - mse: 0.0774
 64/106 [=================>............] - ETA: 0s - loss: 0.0768 - mae: 0.2180 - mse: 0.0768
 96/106 [==========================>...] - ETA: 0s - loss: 0.0655 - mae: 0.2010 - mse: 0.0655
106/106 [==============================] - 1s 6ms/step - loss: 0.0665 - mae: 0.2047 - mse: 0.0665 - val_loss: 0.0386 - val_mae: 0.1472 - val_mse: 0.0386
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0413 - mae: 0.1578 - mse: 0.0413
 64/106 [=================>............] - ETA: 0s - loss: 0.0380 - mae: 0.1524 - mse: 0.0380
 96/106 [==========================>...] - ETA: 0s - loss: 0.0424 - mae: 0.1617 - mse: 0.0424
106/106 [==============================] - 1s 6ms/step - loss: 0.0486 - mae: 0.1696 - mse: 0.0486 - val_loss: 0.0417 - val_mae: 0.1605 - val_mse: 0.0417
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0449 - mae: 0.1711 - mse: 0.0449
 64/106 [=================>............] - ETA: 0s - loss: 0.0484 - mae: 0.1671 - mse: 0.0484
 96/106 [==========================>...] - ETA: 0s - loss: 0.0506 - mae: 0.1722 - mse: 0.0506
106/106 [==============================] - 1s 7ms/step - loss: 0.0539 - mae: 0.1759 - mse: 0.0539 - val_loss: 0.0393 - val_mae: 0.1587 - val_mse: 0.0393
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0365 - mae: 0.1439 - mse: 0.0365
 64/106 [=================>............] - ETA: 0s - loss: 0.0512 - mae: 0.1687 - mse: 0.0512
 96/106 [==========================>...] - ETA: 0s - loss: 0.0507 - mae: 0.1674 - mse: 0.0507
106/106 [==============================] - 1s 6ms/step - loss: 0.0492 - mae: 0.1653 - mse: 0.0492 - val_loss: 0.0391 - val_mae: 0.1579 - val_mse: 0.0391
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0270 - mae: 0.1292 - mse: 0.0270
 64/106 [=================>............] - ETA: 0s - loss: 0.0306 - mae: 0.1412 - mse: 0.0306
 96/106 [==========================>...] - ETA: 0s - loss: 0.0393 - mae: 0.1453 - mse: 0.0393
106/106 [==============================] - 1s 6ms/step - loss: 0.0399 - mae: 0.1473 - mse: 0.0399 - val_loss: 0.0371 - val_mae: 0.1542 - val_mse: 0.0371
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0356 - mae: 0.1453 - mse: 0.0356
 64/106 [=================>............] - ETA: 0s - loss: 0.0453 - mae: 0.1541 - mse: 0.0453
 96/106 [==========================>...] - ETA: 0s - loss: 0.0432 - mae: 0.1535 - mse: 0.0432
106/106 [==============================] - 1s 6ms/step - loss: 0.0412 - mae: 0.1500 - mse: 0.0412 - val_loss: 0.0281 - val_mae: 0.1280 - val_mse: 0.0281
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0496 - mae: 0.1608 - mse: 0.0496
 64/106 [=================>............] - ETA: 0s - loss: 0.0388 - mae: 0.1504 - mse: 0.0388
 96/106 [==========================>...] - ETA: 0s - loss: 0.0369 - mae: 0.1407 - mse: 0.0369
106/106 [==============================] - 1s 6ms/step - loss: 0.0406 - mae: 0.1473 - mse: 0.0406 - val_loss: 0.0252 - val_mae: 0.1215 - val_mse: 0.0252
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0576 - mae: 0.1656 - mse: 0.0576
 64/106 [=================>............] - ETA: 0s - loss: 0.0461 - mae: 0.1581 - mse: 0.0461
 96/106 [==========================>...] - ETA: 0s - loss: 0.0455 - mae: 0.1626 - mse: 0.0455
106/106 [==============================] - 1s 7ms/step - loss: 0.0419 - mae: 0.1544 - mse: 0.0419 - val_loss: 0.0231 - val_mae: 0.1212 - val_mse: 0.0231
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0185 - mae: 0.1106 - mse: 0.0185
 64/106 [=================>............] - ETA: 0s - loss: 0.0442 - mae: 0.1542 - mse: 0.0442
 96/106 [==========================>...] - ETA: 0s - loss: 0.0381 - mae: 0.1443 - mse: 0.0381
106/106 [==============================] - 1s 6ms/step - loss: 0.0408 - mae: 0.1485 - mse: 0.0408 - val_loss: 0.0262 - val_mae: 0.1359 - val_mse: 0.0262
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0414 - mae: 0.1550 - mse: 0.0414
 64/106 [=================>............] - ETA: 0s - loss: 0.0323 - mae: 0.1415 - mse: 0.0323
 96/106 [==========================>...] - ETA: 0s - loss: 0.0406 - mae: 0.1583 - mse: 0.0406
106/106 [==============================] - 1s 6ms/step - loss: 0.0396 - mae: 0.1574 - mse: 0.0396 - val_loss: 0.0180 - val_mae: 0.1101 - val_mse: 0.0180
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0223 - mae: 0.1210 - mse: 0.0223
 64/106 [=================>............] - ETA: 0s - loss: 0.0299 - mae: 0.1376 - mse: 0.0299
 96/106 [==========================>...] - ETA: 0s - loss: 0.0386 - mae: 0.1499 - mse: 0.0386
106/106 [==============================] - 1s 6ms/step - loss: 0.0375 - mae: 0.1472 - mse: 0.0375 - val_loss: 0.0170 - val_mae: 0.1126 - val_mse: 0.0170
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0430 - mae: 0.1420 - mse: 0.0430
 64/106 [=================>............] - ETA: 0s - loss: 0.0384 - mae: 0.1422 - mse: 0.0384
 96/106 [==========================>...] - ETA: 0s - loss: 0.0314 - mae: 0.1290 - mse: 0.0314
106/106 [==============================] - 1s 6ms/step - loss: 0.0298 - mae: 0.1260 - mse: 0.0298 - val_loss: 0.0259 - val_mae: 0.1438 - val_mse: 0.0259
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0382 - mae: 0.1519 - mse: 0.0382
 64/106 [=================>............] - ETA: 0s - loss: 0.0315 - mae: 0.1392 - mse: 0.0315
 96/106 [==========================>...] - ETA: 0s - loss: 0.0344 - mae: 0.1405 - mse: 0.0344
106/106 [==============================] - 1s 6ms/step - loss: 0.0358 - mae: 0.1431 - mse: 0.0358 - val_loss: 0.0240 - val_mae: 0.1397 - val_mse: 0.0240
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0205 - mae: 0.1195 - mse: 0.0205
 64/106 [=================>............] - ETA: 0s - loss: 0.0240 - mae: 0.1230 - mse: 0.0240
 96/106 [==========================>...] - ETA: 0s - loss: 0.0301 - mae: 0.1346 - mse: 0.0301
106/106 [==============================] - 1s 6ms/step - loss: 0.0339 - mae: 0.1365 - mse: 0.0339 - val_loss: 0.0095 - val_mae: 0.0856 - val_mse: 0.0095
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0274 - mae: 0.1248 - mse: 0.0274
 64/106 [=================>............] - ETA: 0s - loss: 0.0334 - mae: 0.1439 - mse: 0.0334
 96/106 [==========================>...] - ETA: 0s - loss: 0.0308 - mae: 0.1347 - mse: 0.0308
106/106 [==============================] - 1s 6ms/step - loss: 0.0290 - mae: 0.1288 - mse: 0.0290 - val_loss: 0.0109 - val_mae: 0.0915 - val_mse: 0.0109
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0395 - mae: 0.1526 - mse: 0.0395
 64/106 [=================>............] - ETA: 0s - loss: 0.0274 - mae: 0.1248 - mse: 0.0274
 96/106 [==========================>...] - ETA: 0s - loss: 0.0324 - mae: 0.1299 - mse: 0.0324
106/106 [==============================] - 1s 6ms/step - loss: 0.0332 - mae: 0.1308 - mse: 0.0332 - val_loss: 0.0263 - val_mae: 0.1518 - val_mse: 0.0263
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0180 - mae: 0.1067 - mse: 0.0180
 64/106 [=================>............] - ETA: 0s - loss: 0.0336 - mae: 0.1325 - mse: 0.0336
 96/106 [==========================>...] - ETA: 0s - loss: 0.0278 - mae: 0.1247 - mse: 0.0278
106/106 [==============================] - 1s 6ms/step - loss: 0.0268 - mae: 0.1236 - mse: 0.0268 - val_loss: 0.0115 - val_mae: 0.1002 - val_mse: 0.0115
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0454 - mae: 0.1565 - mse: 0.0454
 64/106 [=================>............] - ETA: 0s - loss: 0.0304 - mae: 0.1258 - mse: 0.0304
 96/106 [==========================>...] - ETA: 0s - loss: 0.0309 - mae: 0.1265 - mse: 0.0309
106/106 [==============================] - 1s 6ms/step - loss: 0.0291 - mae: 0.1234 - mse: 0.0291 - val_loss: 0.0106 - val_mae: 0.0966 - val_mse: 0.0106
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0121 - mae: 0.0872 - mse: 0.0121
 64/106 [=================>............] - ETA: 0s - loss: 0.0201 - mae: 0.1046 - mse: 0.0201
 96/106 [==========================>...] - ETA: 0s - loss: 0.0196 - mae: 0.1045 - mse: 0.0196
106/106 [==============================] - 1s 6ms/step - loss: 0.0205 - mae: 0.1073 - mse: 0.0205 - val_loss: 0.0169 - val_mae: 0.1216 - val_mse: 0.0169
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0256 - mae: 0.1121 - mse: 0.0256
 64/106 [=================>............] - ETA: 0s - loss: 0.0242 - mae: 0.1145 - mse: 0.0242
 96/106 [==========================>...] - ETA: 0s - loss: 0.0246 - mae: 0.1158 - mse: 0.0246
106/106 [==============================] - 1s 6ms/step - loss: 0.0242 - mae: 0.1135 - mse: 0.0242 - val_loss: 0.0112 - val_mae: 0.0987 - val_mse: 0.0112
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0158 - mae: 0.1037 - mse: 0.0158
 64/106 [=================>............] - ETA: 0s - loss: 0.0171 - mae: 0.1034 - mse: 0.0171
 96/106 [==========================>...] - ETA: 0s - loss: 0.0193 - mae: 0.1086 - mse: 0.0193
106/106 [==============================] - 1s 6ms/step - loss: 0.0226 - mae: 0.1124 - mse: 0.0226 - val_loss: 0.0158 - val_mae: 0.1143 - val_mse: 0.0158
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0121 - mae: 0.0859 - mse: 0.0121
 64/106 [=================>............] - ETA: 0s - loss: 0.0204 - mae: 0.1021 - mse: 0.0204
 96/106 [==========================>...] - ETA: 0s - loss: 0.0177 - mae: 0.0976 - mse: 0.0177
106/106 [==============================] - 1s 6ms/step - loss: 0.0171 - mae: 0.0974 - mse: 0.0171 - val_loss: 0.0079 - val_mae: 0.0787 - val_mse: 0.0079
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0228 - mae: 0.1178 - mse: 0.0228
 64/106 [=================>............] - ETA: 0s - loss: 0.0204 - mae: 0.1089 - mse: 0.0204
 96/106 [==========================>...] - ETA: 0s - loss: 0.0196 - mae: 0.1071 - mse: 0.0196
106/106 [==============================] - 1s 6ms/step - loss: 0.0194 - mae: 0.1077 - mse: 0.0194 - val_loss: 0.0290 - val_mae: 0.1524 - val_mse: 0.0290
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0240 - mae: 0.1185 - mse: 0.0240
 64/106 [=================>............] - ETA: 0s - loss: 0.0286 - mae: 0.1327 - mse: 0.0286
 96/106 [==========================>...] - ETA: 0s - loss: 0.0236 - mae: 0.1226 - mse: 0.0236
106/106 [==============================] - 1s 6ms/step - loss: 0.0273 - mae: 0.1285 - mse: 0.0273 - val_loss: 0.0147 - val_mae: 0.1089 - val_mse: 0.0147
Saving trained model...
72
Testing...
heightdiff= [0.         0.         0.         0.         0.         0.36773682]
average prediction= [4.5427985]
baseline= 6.133333333333334
eachuser= [0. 0. 0. 0. 0. 1.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 0.36773681640625
