['train-height-4.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
1_165_65_4_csi_a4_18.dat
165 42
165 43
1_165_65_4_csi_a4_5.dat
165 45
165 46
165 47
165 48
165 49
1_165_65_4_csi_a4_24.dat
165 51
165 52
165 53
165 54
1_165_65_4_csi_a4_7.dat
165 56
165 57
165 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
165 61
165 62
165 63
165 64
165 65
165 66
165 67
165 68
1_165_65_4_csi_a4_29.dat
165 70
165 71
165 72
165 73
2_165_50_4_csi_a4_13.dat
165 75
165 76
165 77
165 78
2_165_50_4_csi_a4_15.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
2_165_50_4_csi_a4_25.dat
165 97
165 98
165 99
165 100
175 101
1_175_70_4_csi_a4_14.dat
175 103
1_175_70_4_csi_a4_16.dat
175 105
1_175_70_4_csi_a4_8.dat
175 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
175 111
175 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
175 115
1_175_70_4_csi_a4_28.dat
175 117
175 118
175 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
175 122
1_175_70_4_csi_a4_5.dat
175 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
175 127
1_175_70_4_csi_a4_22.dat
175 129
175 130
180 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
180 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
180 142
1_180_85_4_csi_a4_30.dat
180 144
180 145
180 146
180 147
1_180_85_4_csi_a4_20.dat
180 149
180 150
180 151
180 152
180 153
1_180_85_4_csi_a4_29.dat
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
180 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.4452 - mae: 0.5604 - mse: 0.4452
64/89 [====================>.........] - ETA: 0s - loss: 0.3802 - mae: 0.5068 - mse: 0.3802
89/89 [==============================] - 1s 10ms/step - loss: 0.3195 - mae: 0.4618 - mse: 0.3195 - val_loss: 0.1767 - val_mae: 0.3291 - val_mse: 0.1767
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1507 - mae: 0.3153 - mse: 0.1507
64/89 [====================>.........] - ETA: 0s - loss: 0.1353 - mae: 0.2883 - mse: 0.1353
89/89 [==============================] - 1s 7ms/step - loss: 0.1197 - mae: 0.2762 - mse: 0.1197 - val_loss: 0.1498 - val_mae: 0.3536 - val_mse: 0.1498
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1085 - mae: 0.2801 - mse: 0.1085
64/89 [====================>.........] - ETA: 0s - loss: 0.1304 - mae: 0.3096 - mse: 0.1304
89/89 [==============================] - 1s 7ms/step - loss: 0.1338 - mae: 0.3123 - mse: 0.1338 - val_loss: 0.1393 - val_mae: 0.3252 - val_mse: 0.1393
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1019 - mae: 0.2704 - mse: 0.1019
64/89 [====================>.........] - ETA: 0s - loss: 0.1109 - mae: 0.2787 - mse: 0.1109
89/89 [==============================] - 1s 6ms/step - loss: 0.1156 - mae: 0.2790 - mse: 0.1156 - val_loss: 0.1473 - val_mae: 0.2967 - val_mse: 0.1473
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0821 - mae: 0.2157 - mse: 0.0821
64/89 [====================>.........] - ETA: 0s - loss: 0.1038 - mae: 0.2474 - mse: 0.1038
89/89 [==============================] - 1s 7ms/step - loss: 0.1106 - mae: 0.2517 - mse: 0.1106 - val_loss: 0.1584 - val_mae: 0.3051 - val_mse: 0.1584
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1184 - mae: 0.2642 - mse: 0.1184
64/89 [====================>.........] - ETA: 0s - loss: 0.1192 - mae: 0.2615 - mse: 0.1192
89/89 [==============================] - 1s 7ms/step - loss: 0.1149 - mae: 0.2558 - mse: 0.1149 - val_loss: 0.1492 - val_mae: 0.2901 - val_mse: 0.1492
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0798 - mae: 0.2000 - mse: 0.0798
64/89 [====================>.........] - ETA: 0s - loss: 0.0937 - mae: 0.2262 - mse: 0.0937
89/89 [==============================] - 1s 7ms/step - loss: 0.0976 - mae: 0.2325 - mse: 0.0976 - val_loss: 0.1340 - val_mae: 0.2732 - val_mse: 0.1340
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0931 - mae: 0.2410 - mse: 0.0931
64/89 [====================>.........] - ETA: 0s - loss: 0.0974 - mae: 0.2439 - mse: 0.0974
89/89 [==============================] - 1s 7ms/step - loss: 0.0964 - mae: 0.2436 - mse: 0.0964 - val_loss: 0.1263 - val_mae: 0.2761 - val_mse: 0.1263
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0959 - mae: 0.2593 - mse: 0.0959
64/89 [====================>.........] - ETA: 0s - loss: 0.0862 - mae: 0.2390 - mse: 0.0862
89/89 [==============================] - 1s 8ms/step - loss: 0.0999 - mae: 0.2528 - mse: 0.0999 - val_loss: 0.1255 - val_mae: 0.2671 - val_mse: 0.1255
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1086 - mae: 0.2434 - mse: 0.1086
64/89 [====================>.........] - ETA: 0s - loss: 0.0898 - mae: 0.2291 - mse: 0.0898
89/89 [==============================] - 1s 8ms/step - loss: 0.0821 - mae: 0.2182 - mse: 0.0821 - val_loss: 0.1247 - val_mae: 0.2734 - val_mse: 0.1247
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0980 - mae: 0.2431 - mse: 0.0980
64/89 [====================>.........] - ETA: 0s - loss: 0.1081 - mae: 0.2581 - mse: 0.1081
89/89 [==============================] - 1s 7ms/step - loss: 0.0929 - mae: 0.2392 - mse: 0.0929 - val_loss: 0.1215 - val_mae: 0.2771 - val_mse: 0.1215
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1110 - mae: 0.2501 - mse: 0.1110
64/89 [====================>.........] - ETA: 0s - loss: 0.0885 - mae: 0.2276 - mse: 0.0885
89/89 [==============================] - 1s 6ms/step - loss: 0.0857 - mae: 0.2262 - mse: 0.0857 - val_loss: 0.1188 - val_mae: 0.2775 - val_mse: 0.1188
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0882 - mae: 0.2172 - mse: 0.0882
64/89 [====================>.........] - ETA: 0s - loss: 0.0991 - mae: 0.2393 - mse: 0.0991
89/89 [==============================] - 1s 7ms/step - loss: 0.0873 - mae: 0.2250 - mse: 0.0873 - val_loss: 0.1112 - val_mae: 0.2682 - val_mse: 0.1112
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1063 - mae: 0.2518 - mse: 0.1063
64/89 [====================>.........] - ETA: 0s - loss: 0.0860 - mae: 0.2142 - mse: 0.0860
89/89 [==============================] - 1s 7ms/step - loss: 0.0819 - mae: 0.2155 - mse: 0.0819 - val_loss: 0.1067 - val_mae: 0.2616 - val_mse: 0.1067
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0883 - mae: 0.2265 - mse: 0.0883
64/89 [====================>.........] - ETA: 0s - loss: 0.0723 - mae: 0.2075 - mse: 0.0723
89/89 [==============================] - 1s 7ms/step - loss: 0.0788 - mae: 0.2103 - mse: 0.0788 - val_loss: 0.1070 - val_mae: 0.2612 - val_mse: 0.1070
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1039 - mae: 0.2369 - mse: 0.1039
64/89 [====================>.........] - ETA: 0s - loss: 0.0746 - mae: 0.2007 - mse: 0.0746
89/89 [==============================] - 1s 7ms/step - loss: 0.0758 - mae: 0.2004 - mse: 0.0758 - val_loss: 0.1034 - val_mae: 0.2604 - val_mse: 0.1034
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0765 - mae: 0.2108 - mse: 0.0765
64/89 [====================>.........] - ETA: 0s - loss: 0.0872 - mae: 0.2149 - mse: 0.0872
89/89 [==============================] - 1s 6ms/step - loss: 0.0748 - mae: 0.2009 - mse: 0.0748 - val_loss: 0.0970 - val_mae: 0.2537 - val_mse: 0.0970
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0926 - mae: 0.2218 - mse: 0.0926
64/89 [====================>.........] - ETA: 0s - loss: 0.0807 - mae: 0.2097 - mse: 0.0807
89/89 [==============================] - 1s 7ms/step - loss: 0.0670 - mae: 0.1888 - mse: 0.0670 - val_loss: 0.0854 - val_mae: 0.2379 - val_mse: 0.0854
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0481 - mae: 0.1741 - mse: 0.0481
64/89 [====================>.........] - ETA: 0s - loss: 0.0588 - mae: 0.1886 - mse: 0.0588
89/89 [==============================] - 1s 8ms/step - loss: 0.0629 - mae: 0.1885 - mse: 0.0629 - val_loss: 0.0799 - val_mae: 0.2269 - val_mse: 0.0799
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0601 - mae: 0.1796 - mse: 0.0601
64/89 [====================>.........] - ETA: 0s - loss: 0.0655 - mae: 0.1961 - mse: 0.0655
89/89 [==============================] - 1s 7ms/step - loss: 0.0582 - mae: 0.1793 - mse: 0.0582 - val_loss: 0.0711 - val_mae: 0.2174 - val_mse: 0.0711
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0616 - mae: 0.1817 - mse: 0.0616
64/89 [====================>.........] - ETA: 0s - loss: 0.0634 - mae: 0.1888 - mse: 0.0634
89/89 [==============================] - 1s 8ms/step - loss: 0.0543 - mae: 0.1721 - mse: 0.0543 - val_loss: 0.0645 - val_mae: 0.2148 - val_mse: 0.0645
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0502 - mae: 0.1566 - mse: 0.0502
64/89 [====================>.........] - ETA: 0s - loss: 0.0443 - mae: 0.1526 - mse: 0.0443
89/89 [==============================] - 1s 7ms/step - loss: 0.0490 - mae: 0.1624 - mse: 0.0490 - val_loss: 0.0576 - val_mae: 0.2086 - val_mse: 0.0576
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0397 - mae: 0.1527 - mse: 0.0397
64/89 [====================>.........] - ETA: 0s - loss: 0.0454 - mae: 0.1617 - mse: 0.0454
89/89 [==============================] - 1s 7ms/step - loss: 0.0409 - mae: 0.1493 - mse: 0.0409 - val_loss: 0.0427 - val_mae: 0.1808 - val_mse: 0.0427
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0660 - mae: 0.2102 - mse: 0.0660
64/89 [====================>.........] - ETA: 0s - loss: 0.0387 - mae: 0.1472 - mse: 0.0387
89/89 [==============================] - 1s 7ms/step - loss: 0.0388 - mae: 0.1485 - mse: 0.0388 - val_loss: 0.0365 - val_mae: 0.1665 - val_mse: 0.0365
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0316 - mae: 0.1173 - mse: 0.0316
64/89 [====================>.........] - ETA: 0s - loss: 0.0305 - mae: 0.1282 - mse: 0.0305
89/89 [==============================] - 1s 7ms/step - loss: 0.0319 - mae: 0.1263 - mse: 0.0319 - val_loss: 0.0247 - val_mae: 0.1325 - val_mse: 0.0247
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0168 - mae: 0.0946 - mse: 0.0168
64/89 [====================>.........] - ETA: 0s - loss: 0.0176 - mae: 0.0987 - mse: 0.0176
89/89 [==============================] - 1s 7ms/step - loss: 0.0221 - mae: 0.1072 - mse: 0.0221 - val_loss: 0.0113 - val_mae: 0.0958 - val_mse: 0.0113
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0295 - mae: 0.1201 - mse: 0.0295
64/89 [====================>.........] - ETA: 0s - loss: 0.0195 - mae: 0.0991 - mse: 0.0195
89/89 [==============================] - 1s 8ms/step - loss: 0.0183 - mae: 0.0981 - mse: 0.0183 - val_loss: 0.0276 - val_mae: 0.1386 - val_mse: 0.0276
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0209 - mae: 0.1030 - mse: 0.0209
64/89 [====================>.........] - ETA: 0s - loss: 0.0194 - mae: 0.1051 - mse: 0.0194
89/89 [==============================] - 1s 7ms/step - loss: 0.0213 - mae: 0.1082 - mse: 0.0213 - val_loss: 0.0193 - val_mae: 0.1156 - val_mse: 0.0193
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0108 - mae: 0.0887 - mse: 0.0108
64/89 [====================>.........] - ETA: 0s - loss: 0.0117 - mae: 0.0848 - mse: 0.0117
89/89 [==============================] - 1s 7ms/step - loss: 0.0134 - mae: 0.0870 - mse: 0.0134 - val_loss: 0.0448 - val_mae: 0.1767 - val_mse: 0.0448
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0174 - mae: 0.0995 - mse: 0.0174
64/89 [====================>.........] - ETA: 0s - loss: 0.0201 - mae: 0.1039 - mse: 0.0201
89/89 [==============================] - 1s 7ms/step - loss: 0.0188 - mae: 0.0989 - mse: 0.0188 - val_loss: 0.0147 - val_mae: 0.1016 - val_mse: 0.0147
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         0.         6.19752502]
average prediction= [3.5331793]
baseline= 7.18
eachuser= [0. 0. 0. 0. 4.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.5493812561035156
['train-height-4.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
1_165_65_4_csi_a4_18.dat
165 42
165 43
1_165_65_4_csi_a4_5.dat
165 45
165 46
165 47
165 48
165 49
1_165_65_4_csi_a4_24.dat
165 51
165 52
165 53
165 54
1_165_65_4_csi_a4_7.dat
165 56
165 57
165 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
165 61
165 62
165 63
165 64
165 65
165 66
165 67
165 68
1_165_65_4_csi_a4_29.dat
165 70
165 71
165 72
165 73
2_165_50_4_csi_a4_13.dat
165 75
165 76
165 77
165 78
2_165_50_4_csi_a4_15.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
2_165_50_4_csi_a4_25.dat
165 97
165 98
165 99
165 100
175 101
1_175_70_4_csi_a4_14.dat
175 103
1_175_70_4_csi_a4_16.dat
175 105
1_175_70_4_csi_a4_8.dat
175 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
175 111
175 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
175 115
1_175_70_4_csi_a4_28.dat
175 117
175 118
175 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
175 122
1_175_70_4_csi_a4_5.dat
175 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
175 127
1_175_70_4_csi_a4_22.dat
175 129
175 130
180 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
180 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
180 142
1_180_85_4_csi_a4_30.dat
180 144
180 145
180 146
180 147
1_180_85_4_csi_a4_20.dat
180 149
180 150
180 151
180 152
180 153
1_180_85_4_csi_a4_29.dat
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
180 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.2841 - mae: 0.4396 - mse: 0.2841
64/89 [====================>.........] - ETA: 0s - loss: 0.2653 - mae: 0.4261 - mse: 0.2653
89/89 [==============================] - 1s 10ms/step - loss: 0.2553 - mae: 0.4130 - mse: 0.2553 - val_loss: 0.1571 - val_mae: 0.2954 - val_mse: 0.1571
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1530 - mae: 0.3248 - mse: 0.1530
64/89 [====================>.........] - ETA: 0s - loss: 0.1540 - mae: 0.3343 - mse: 0.1540
89/89 [==============================] - 1s 6ms/step - loss: 0.1516 - mae: 0.3327 - mse: 0.1516 - val_loss: 0.1131 - val_mae: 0.2803 - val_mse: 0.1131
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1602 - mae: 0.3498 - mse: 0.1602
64/89 [====================>.........] - ETA: 0s - loss: 0.1331 - mae: 0.3123 - mse: 0.1331
89/89 [==============================] - 0s 6ms/step - loss: 0.1391 - mae: 0.3198 - mse: 0.1391 - val_loss: 0.1356 - val_mae: 0.2681 - val_mse: 0.1356
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1266 - mae: 0.3023 - mse: 0.1266
64/89 [====================>.........] - ETA: 0s - loss: 0.1091 - mae: 0.2688 - mse: 0.1091
89/89 [==============================] - 1s 6ms/step - loss: 0.1158 - mae: 0.2710 - mse: 0.1158 - val_loss: 0.1781 - val_mae: 0.3278 - val_mse: 0.1781
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1432 - mae: 0.2901 - mse: 0.1432
64/89 [====================>.........] - ETA: 0s - loss: 0.1350 - mae: 0.2775 - mse: 0.1350
89/89 [==============================] - 0s 6ms/step - loss: 0.1250 - mae: 0.2723 - mse: 0.1250 - val_loss: 0.1819 - val_mae: 0.3341 - val_mse: 0.1819
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1002 - mae: 0.2299 - mse: 0.1002
64/89 [====================>.........] - ETA: 0s - loss: 0.1235 - mae: 0.2685 - mse: 0.1235
89/89 [==============================] - 0s 5ms/step - loss: 0.1114 - mae: 0.2494 - mse: 0.1114 - val_loss: 0.1574 - val_mae: 0.2907 - val_mse: 0.1574
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1314 - mae: 0.2834 - mse: 0.1314
64/89 [====================>.........] - ETA: 0s - loss: 0.1315 - mae: 0.2864 - mse: 0.1315
89/89 [==============================] - 1s 6ms/step - loss: 0.1140 - mae: 0.2594 - mse: 0.1140 - val_loss: 0.1315 - val_mae: 0.2439 - val_mse: 0.1315
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1045 - mae: 0.2594 - mse: 0.1045
64/89 [====================>.........] - ETA: 0s - loss: 0.1056 - mae: 0.2540 - mse: 0.1056
89/89 [==============================] - 1s 7ms/step - loss: 0.1125 - mae: 0.2659 - mse: 0.1125 - val_loss: 0.1213 - val_mae: 0.2317 - val_mse: 0.1213
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1000 - mae: 0.2449 - mse: 0.1000
64/89 [====================>.........] - ETA: 0s - loss: 0.0994 - mae: 0.2479 - mse: 0.0994
89/89 [==============================] - 1s 6ms/step - loss: 0.1021 - mae: 0.2546 - mse: 0.1021 - val_loss: 0.1243 - val_mae: 0.2287 - val_mse: 0.1243
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1423 - mae: 0.3192 - mse: 0.1423
64/89 [====================>.........] - ETA: 0s - loss: 0.1016 - mae: 0.2457 - mse: 0.1016
89/89 [==============================] - 1s 6ms/step - loss: 0.0964 - mae: 0.2415 - mse: 0.0964 - val_loss: 0.1329 - val_mae: 0.2420 - val_mse: 0.1329
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0689 - mae: 0.2014 - mse: 0.0689
64/89 [====================>.........] - ETA: 0s - loss: 0.1050 - mae: 0.2431 - mse: 0.1050
89/89 [==============================] - 1s 7ms/step - loss: 0.0969 - mae: 0.2353 - mse: 0.0969 - val_loss: 0.1396 - val_mae: 0.2608 - val_mse: 0.1396
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0504 - mae: 0.1665 - mse: 0.0504
64/89 [====================>.........] - ETA: 0s - loss: 0.0927 - mae: 0.2220 - mse: 0.0927
89/89 [==============================] - 1s 6ms/step - loss: 0.0950 - mae: 0.2256 - mse: 0.0950 - val_loss: 0.1351 - val_mae: 0.2535 - val_mse: 0.1351
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0770 - mae: 0.1914 - mse: 0.0770
64/89 [====================>.........] - ETA: 0s - loss: 0.0965 - mae: 0.2197 - mse: 0.0965
89/89 [==============================] - 1s 6ms/step - loss: 0.0980 - mae: 0.2289 - mse: 0.0980 - val_loss: 0.1217 - val_mae: 0.2311 - val_mse: 0.1217
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1069 - mae: 0.2635 - mse: 0.1069
64/89 [====================>.........] - ETA: 0s - loss: 0.0977 - mae: 0.2425 - mse: 0.0977
89/89 [==============================] - 1s 6ms/step - loss: 0.0860 - mae: 0.2234 - mse: 0.0860 - val_loss: 0.1132 - val_mae: 0.2213 - val_mse: 0.1132
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0698 - mae: 0.1963 - mse: 0.0698
64/89 [====================>.........] - ETA: 0s - loss: 0.0942 - mae: 0.2291 - mse: 0.0942
89/89 [==============================] - 1s 7ms/step - loss: 0.1001 - mae: 0.2385 - mse: 0.1001 - val_loss: 0.1131 - val_mae: 0.2224 - val_mse: 0.1131
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0995 - mae: 0.2455 - mse: 0.0995
64/89 [====================>.........] - ETA: 0s - loss: 0.0925 - mae: 0.2262 - mse: 0.0925
89/89 [==============================] - 1s 6ms/step - loss: 0.0969 - mae: 0.2308 - mse: 0.0969 - val_loss: 0.1214 - val_mae: 0.2362 - val_mse: 0.1214
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1031 - mae: 0.2416 - mse: 0.1031
64/89 [====================>.........] - ETA: 0s - loss: 0.0802 - mae: 0.1973 - mse: 0.0802
89/89 [==============================] - 1s 6ms/step - loss: 0.0819 - mae: 0.2088 - mse: 0.0819 - val_loss: 0.1182 - val_mae: 0.2313 - val_mse: 0.1182
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0851 - mae: 0.2275 - mse: 0.0851
64/89 [====================>.........] - ETA: 0s - loss: 0.0899 - mae: 0.2273 - mse: 0.0899
89/89 [==============================] - 0s 6ms/step - loss: 0.0805 - mae: 0.2083 - mse: 0.0805 - val_loss: 0.1102 - val_mae: 0.2173 - val_mse: 0.1102
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0633 - mae: 0.1856 - mse: 0.0633
64/89 [====================>.........] - ETA: 0s - loss: 0.0820 - mae: 0.2147 - mse: 0.0820
89/89 [==============================] - 0s 5ms/step - loss: 0.0789 - mae: 0.2150 - mse: 0.0789 - val_loss: 0.0984 - val_mae: 0.1975 - val_mse: 0.0984
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0736 - mae: 0.2236 - mse: 0.0736
64/89 [====================>.........] - ETA: 0s - loss: 0.0586 - mae: 0.1904 - mse: 0.0586
89/89 [==============================] - 0s 4ms/step - loss: 0.0764 - mae: 0.2143 - mse: 0.0764 - val_loss: 0.0992 - val_mae: 0.2083 - val_mse: 0.0992
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0954 - mae: 0.2305 - mse: 0.0954
64/89 [====================>.........] - ETA: 0s - loss: 0.0741 - mae: 0.2095 - mse: 0.0741
89/89 [==============================] - 0s 4ms/step - loss: 0.0641 - mae: 0.1897 - mse: 0.0641 - val_loss: 0.0916 - val_mae: 0.2091 - val_mse: 0.0916
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0736 - mae: 0.2087 - mse: 0.0736
64/89 [====================>.........] - ETA: 0s - loss: 0.0635 - mae: 0.1896 - mse: 0.0635
89/89 [==============================] - 0s 4ms/step - loss: 0.0687 - mae: 0.1958 - mse: 0.0687 - val_loss: 0.0845 - val_mae: 0.2091 - val_mse: 0.0845
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0615 - mae: 0.1826 - mse: 0.0615
64/89 [====================>.........] - ETA: 0s - loss: 0.0599 - mae: 0.1874 - mse: 0.0599
89/89 [==============================] - 0s 4ms/step - loss: 0.0624 - mae: 0.1872 - mse: 0.0624 - val_loss: 0.0814 - val_mae: 0.2122 - val_mse: 0.0814
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0355 - mae: 0.1570 - mse: 0.0355
64/89 [====================>.........] - ETA: 0s - loss: 0.0495 - mae: 0.1703 - mse: 0.0495
89/89 [==============================] - 0s 4ms/step - loss: 0.0591 - mae: 0.1871 - mse: 0.0591 - val_loss: 0.0643 - val_mae: 0.1872 - val_mse: 0.0643
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0328 - mae: 0.1401 - mse: 0.0328
64/89 [====================>.........] - ETA: 0s - loss: 0.0408 - mae: 0.1625 - mse: 0.0408
89/89 [==============================] - 0s 4ms/step - loss: 0.0491 - mae: 0.1708 - mse: 0.0491 - val_loss: 0.0531 - val_mae: 0.1670 - val_mse: 0.0531
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0512 - mae: 0.1781 - mse: 0.0512
64/89 [====================>.........] - ETA: 0s - loss: 0.0457 - mae: 0.1562 - mse: 0.0457
89/89 [==============================] - 0s 4ms/step - loss: 0.0420 - mae: 0.1504 - mse: 0.0420 - val_loss: 0.0587 - val_mae: 0.1845 - val_mse: 0.0587
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0399 - mae: 0.1465 - mse: 0.0399
64/89 [====================>.........] - ETA: 0s - loss: 0.0389 - mae: 0.1421 - mse: 0.0389
89/89 [==============================] - 0s 4ms/step - loss: 0.0349 - mae: 0.1350 - mse: 0.0349 - val_loss: 0.0319 - val_mae: 0.1543 - val_mse: 0.0319
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0311 - mae: 0.1269 - mse: 0.0311
64/89 [====================>.........] - ETA: 0s - loss: 0.0280 - mae: 0.1243 - mse: 0.0280
89/89 [==============================] - 0s 4ms/step - loss: 0.0279 - mae: 0.1224 - mse: 0.0279 - val_loss: 0.0459 - val_mae: 0.1956 - val_mse: 0.0459
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0385 - mae: 0.1442 - mse: 0.0385
64/89 [====================>.........] - ETA: 0s - loss: 0.0304 - mae: 0.1321 - mse: 0.0304
89/89 [==============================] - 0s 4ms/step - loss: 0.0255 - mae: 0.1174 - mse: 0.0255 - val_loss: 0.0135 - val_mae: 0.1085 - val_mse: 0.0135
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0244 - mae: 0.1231 - mse: 0.0244
64/89 [====================>.........] - ETA: 0s - loss: 0.0329 - mae: 0.1290 - mse: 0.0329
89/89 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1201 - mse: 0.0289 - val_loss: 0.0720 - val_mae: 0.2467 - val_mse: 0.0720
Saving trained model...
96
Testing...
heightdiff= [ 0.          0.          0.          0.         27.08114624]
average prediction= [5.063974]
baseline= 9.5
eachuser= [0. 0. 0. 0. 9.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 3.0090162489149304
['train-height-4.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
1_165_65_4_csi_a4_18.dat
165 42
165 43
1_165_65_4_csi_a4_5.dat
165 45
165 46
165 47
165 48
165 49
1_165_65_4_csi_a4_24.dat
165 51
165 52
165 53
165 54
1_165_65_4_csi_a4_7.dat
165 56
165 57
165 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
165 61
165 62
165 63
165 64
165 65
165 66
165 67
165 68
1_165_65_4_csi_a4_29.dat
165 70
165 71
165 72
165 73
2_165_50_4_csi_a4_13.dat
165 75
165 76
165 77
165 78
2_165_50_4_csi_a4_15.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
2_165_50_4_csi_a4_25.dat
165 97
165 98
165 99
165 100
175 101
1_175_70_4_csi_a4_14.dat
175 103
1_175_70_4_csi_a4_16.dat
175 105
1_175_70_4_csi_a4_8.dat
175 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
175 111
175 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
175 115
1_175_70_4_csi_a4_28.dat
175 117
175 118
175 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
175 122
1_175_70_4_csi_a4_5.dat
175 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
175 127
1_175_70_4_csi_a4_22.dat
175 129
175 130
180 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
180 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
180 142
1_180_85_4_csi_a4_30.dat
180 144
180 145
180 146
180 147
1_180_85_4_csi_a4_20.dat
180 149
180 150
180 151
180 152
180 153
1_180_85_4_csi_a4_29.dat
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
180 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.3843 - mae: 0.5387 - mse: 0.3843
64/89 [====================>.........] - ETA: 0s - loss: 0.3180 - mae: 0.4796 - mse: 0.3180
89/89 [==============================] - 1s 12ms/step - loss: 0.2710 - mae: 0.4359 - mse: 0.2710 - val_loss: 0.1949 - val_mae: 0.3604 - val_mse: 0.1949
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1682 - mae: 0.3403 - mse: 0.1682
64/89 [====================>.........] - ETA: 0s - loss: 0.1452 - mae: 0.3164 - mse: 0.1452
89/89 [==============================] - 1s 7ms/step - loss: 0.1451 - mae: 0.3177 - mse: 0.1451 - val_loss: 0.1226 - val_mae: 0.3187 - val_mse: 0.1226
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1287 - mae: 0.3153 - mse: 0.1287
64/89 [====================>.........] - ETA: 0s - loss: 0.1699 - mae: 0.3556 - mse: 0.1699
89/89 [==============================] - 0s 5ms/step - loss: 0.1630 - mae: 0.3430 - mse: 0.1630 - val_loss: 0.1017 - val_mae: 0.2874 - val_mse: 0.1017
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1828 - mae: 0.3806 - mse: 0.1828
64/89 [====================>.........] - ETA: 0s - loss: 0.1508 - mae: 0.3283 - mse: 0.1508
89/89 [==============================] - 0s 4ms/step - loss: 0.1360 - mae: 0.3129 - mse: 0.1360 - val_loss: 0.1176 - val_mae: 0.2647 - val_mse: 0.1176
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1372 - mae: 0.3059 - mse: 0.1372
64/89 [====================>.........] - ETA: 0s - loss: 0.1299 - mae: 0.2929 - mse: 0.1299
89/89 [==============================] - 0s 5ms/step - loss: 0.1152 - mae: 0.2671 - mse: 0.1152 - val_loss: 0.1280 - val_mae: 0.2870 - val_mse: 0.1280
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1661 - mae: 0.3348 - mse: 0.1661
64/89 [====================>.........] - ETA: 0s - loss: 0.1193 - mae: 0.2636 - mse: 0.1193
89/89 [==============================] - 0s 4ms/step - loss: 0.1064 - mae: 0.2465 - mse: 0.1064 - val_loss: 0.1062 - val_mae: 0.2556 - val_mse: 0.1062
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1155 - mae: 0.2545 - mse: 0.1155
64/89 [====================>.........] - ETA: 0s - loss: 0.1145 - mae: 0.2628 - mse: 0.1145
89/89 [==============================] - 0s 4ms/step - loss: 0.1063 - mae: 0.2518 - mse: 0.1063 - val_loss: 0.0719 - val_mae: 0.1995 - val_mse: 0.0719
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0934 - mae: 0.2411 - mse: 0.0934
64/89 [====================>.........] - ETA: 0s - loss: 0.1089 - mae: 0.2675 - mse: 0.1089
89/89 [==============================] - 0s 4ms/step - loss: 0.1011 - mae: 0.2590 - mse: 0.1011 - val_loss: 0.0555 - val_mae: 0.1697 - val_mse: 0.0555
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0738 - mae: 0.2143 - mse: 0.0738
64/89 [====================>.........] - ETA: 0s - loss: 0.0967 - mae: 0.2482 - mse: 0.0967
89/89 [==============================] - 0s 4ms/step - loss: 0.0975 - mae: 0.2517 - mse: 0.0975 - val_loss: 0.0546 - val_mae: 0.1573 - val_mse: 0.0546
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0995 - mae: 0.2475 - mse: 0.0995
64/89 [====================>.........] - ETA: 0s - loss: 0.0910 - mae: 0.2352 - mse: 0.0910
89/89 [==============================] - 0s 4ms/step - loss: 0.0919 - mae: 0.2324 - mse: 0.0919 - val_loss: 0.0640 - val_mae: 0.1872 - val_mse: 0.0640
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0629 - mae: 0.1840 - mse: 0.0629
64/89 [====================>.........] - ETA: 0s - loss: 0.0853 - mae: 0.2158 - mse: 0.0853
89/89 [==============================] - 0s 4ms/step - loss: 0.0814 - mae: 0.2125 - mse: 0.0814 - val_loss: 0.0625 - val_mae: 0.1891 - val_mse: 0.0625
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0622 - mae: 0.1706 - mse: 0.0622
64/89 [====================>.........] - ETA: 0s - loss: 0.0729 - mae: 0.1950 - mse: 0.0729
89/89 [==============================] - 0s 4ms/step - loss: 0.0784 - mae: 0.2036 - mse: 0.0784 - val_loss: 0.0480 - val_mae: 0.1515 - val_mse: 0.0480
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0718 - mae: 0.1922 - mse: 0.0718
64/89 [====================>.........] - ETA: 0s - loss: 0.0639 - mae: 0.1845 - mse: 0.0639
89/89 [==============================] - 0s 4ms/step - loss: 0.0668 - mae: 0.1925 - mse: 0.0668 - val_loss: 0.0360 - val_mae: 0.1103 - val_mse: 0.0360
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0754 - mae: 0.2117 - mse: 0.0754
64/89 [====================>.........] - ETA: 0s - loss: 0.0642 - mae: 0.1918 - mse: 0.0642
89/89 [==============================] - 0s 4ms/step - loss: 0.0663 - mae: 0.1945 - mse: 0.0663 - val_loss: 0.0360 - val_mae: 0.1170 - val_mse: 0.0360
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0715 - mae: 0.2180 - mse: 0.0715
64/89 [====================>.........] - ETA: 0s - loss: 0.0741 - mae: 0.2142 - mse: 0.0741
89/89 [==============================] - 0s 4ms/step - loss: 0.0677 - mae: 0.1983 - mse: 0.0677 - val_loss: 0.0361 - val_mae: 0.1254 - val_mse: 0.0361
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0894 - mae: 0.2327 - mse: 0.0894
64/89 [====================>.........] - ETA: 0s - loss: 0.0724 - mae: 0.2156 - mse: 0.0724
89/89 [==============================] - 0s 4ms/step - loss: 0.0583 - mae: 0.1828 - mse: 0.0583 - val_loss: 0.0334 - val_mae: 0.1269 - val_mse: 0.0334
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0643 - mae: 0.2017 - mse: 0.0643
64/89 [====================>.........] - ETA: 0s - loss: 0.0629 - mae: 0.1930 - mse: 0.0629
89/89 [==============================] - 0s 4ms/step - loss: 0.0556 - mae: 0.1821 - mse: 0.0556 - val_loss: 0.0301 - val_mae: 0.1274 - val_mse: 0.0301
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0536 - mae: 0.1842 - mse: 0.0536
64/89 [====================>.........] - ETA: 0s - loss: 0.0496 - mae: 0.1793 - mse: 0.0496
89/89 [==============================] - 0s 4ms/step - loss: 0.0428 - mae: 0.1657 - mse: 0.0428 - val_loss: 0.0233 - val_mae: 0.1181 - val_mse: 0.0233
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0351 - mae: 0.1386 - mse: 0.0351
64/89 [====================>.........] - ETA: 0s - loss: 0.0375 - mae: 0.1512 - mse: 0.0375
89/89 [==============================] - 0s 4ms/step - loss: 0.0358 - mae: 0.1501 - mse: 0.0358 - val_loss: 0.0196 - val_mae: 0.1130 - val_mse: 0.0196
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0326 - mae: 0.1483 - mse: 0.0326
64/89 [====================>.........] - ETA: 0s - loss: 0.0399 - mae: 0.1580 - mse: 0.0399
89/89 [==============================] - 0s 4ms/step - loss: 0.0359 - mae: 0.1471 - mse: 0.0359 - val_loss: 0.0120 - val_mae: 0.0877 - val_mse: 0.0120
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0254 - mae: 0.1115 - mse: 0.0254
64/89 [====================>.........] - ETA: 0s - loss: 0.0437 - mae: 0.1489 - mse: 0.0437
89/89 [==============================] - 0s 4ms/step - loss: 0.0402 - mae: 0.1440 - mse: 0.0402 - val_loss: 0.0172 - val_mae: 0.1133 - val_mse: 0.0172
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0209 - mae: 0.1122 - mse: 0.0209
64/89 [====================>.........] - ETA: 0s - loss: 0.0233 - mae: 0.1139 - mse: 0.0233
89/89 [==============================] - 0s 4ms/step - loss: 0.0223 - mae: 0.1153 - mse: 0.0223 - val_loss: 0.0136 - val_mae: 0.0988 - val_mse: 0.0136
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0255 - mae: 0.1187 - mse: 0.0255
64/89 [====================>.........] - ETA: 0s - loss: 0.0312 - mae: 0.1400 - mse: 0.0312
89/89 [==============================] - 0s 4ms/step - loss: 0.0290 - mae: 0.1352 - mse: 0.0290 - val_loss: 0.0110 - val_mae: 0.0907 - val_mse: 0.0110
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0252 - mae: 0.1290 - mse: 0.0252
64/89 [====================>.........] - ETA: 0s - loss: 0.0226 - mae: 0.1187 - mse: 0.0226
89/89 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.1121 - mse: 0.0194 - val_loss: 0.0181 - val_mae: 0.1194 - val_mse: 0.0181
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0119 - mae: 0.0852 - mse: 0.0119
64/89 [====================>.........] - ETA: 0s - loss: 0.0176 - mae: 0.1054 - mse: 0.0176
89/89 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.1076 - mse: 0.0191 - val_loss: 0.0061 - val_mae: 0.0588 - val_mse: 0.0061
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0236 - mae: 0.1206 - mse: 0.0236
64/89 [====================>.........] - ETA: 0s - loss: 0.0190 - mae: 0.1072 - mse: 0.0190
89/89 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0985 - mse: 0.0162 - val_loss: 0.0143 - val_mae: 0.0950 - val_mse: 0.0143
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0266 - mae: 0.1183 - mse: 0.0266
64/89 [====================>.........] - ETA: 0s - loss: 0.0198 - mae: 0.1026 - mse: 0.0198
89/89 [==============================] - 0s 4ms/step - loss: 0.0162 - mae: 0.0915 - mse: 0.0162 - val_loss: 0.0127 - val_mae: 0.0863 - val_mse: 0.0127
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0131 - mae: 0.0844 - mse: 0.0131
64/89 [====================>.........] - ETA: 0s - loss: 0.0199 - mae: 0.0904 - mse: 0.0199
89/89 [==============================] - 0s 4ms/step - loss: 0.0174 - mae: 0.0873 - mse: 0.0174 - val_loss: 0.0081 - val_mae: 0.0729 - val_mse: 0.0081
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0214 - mae: 0.0934 - mse: 0.0214
64/89 [====================>.........] - ETA: 0s - loss: 0.0148 - mae: 0.0833 - mse: 0.0148
89/89 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0810 - mse: 0.0136 - val_loss: 0.0094 - val_mae: 0.0704 - val_mse: 0.0094
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0188 - mae: 0.0998 - mse: 0.0188
64/89 [====================>.........] - ETA: 0s - loss: 0.0192 - mae: 0.1030 - mse: 0.0192
89/89 [==============================] - 1s 7ms/step - loss: 0.0174 - mae: 0.0981 - mse: 0.0174 - val_loss: 0.0079 - val_mae: 0.0566 - val_mse: 0.0079
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         0.         8.26097107]
average prediction= [2.390556]
baseline= 10.38
eachuser= [ 0.  0.  0.  0. 10.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 0.8260971069335937
['train-height-4.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
1_165_65_4_csi_a4_18.dat
165 42
165 43
1_165_65_4_csi_a4_5.dat
165 45
165 46
165 47
165 48
165 49
1_165_65_4_csi_a4_24.dat
165 51
165 52
165 53
165 54
1_165_65_4_csi_a4_7.dat
165 56
165 57
165 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
165 61
165 62
165 63
165 64
165 65
165 66
165 67
165 68
1_165_65_4_csi_a4_29.dat
165 70
165 71
165 72
165 73
2_165_50_4_csi_a4_13.dat
165 75
165 76
165 77
165 78
2_165_50_4_csi_a4_15.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
2_165_50_4_csi_a4_25.dat
165 97
165 98
165 99
165 100
175 101
1_175_70_4_csi_a4_14.dat
175 103
1_175_70_4_csi_a4_16.dat
175 105
1_175_70_4_csi_a4_8.dat
175 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
175 111
175 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
175 115
1_175_70_4_csi_a4_28.dat
175 117
175 118
175 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
175 122
1_175_70_4_csi_a4_5.dat
175 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
175 127
1_175_70_4_csi_a4_22.dat
175 129
175 130
180 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
180 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
180 142
1_180_85_4_csi_a4_30.dat
180 144
180 145
180 146
180 147
1_180_85_4_csi_a4_20.dat
180 149
180 150
180 151
180 152
180 153
1_180_85_4_csi_a4_29.dat
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
180 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.2367 - mae: 0.3873 - mse: 0.2367
64/89 [====================>.........] - ETA: 0s - loss: 0.2701 - mae: 0.4306 - mse: 0.2701
89/89 [==============================] - 1s 10ms/step - loss: 0.2474 - mae: 0.4161 - mse: 0.2474 - val_loss: 0.1335 - val_mae: 0.2995 - val_mse: 0.1335
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0919 - mae: 0.2351 - mse: 0.0919
64/89 [====================>.........] - ETA: 0s - loss: 0.1093 - mae: 0.2611 - mse: 0.1093
89/89 [==============================] - 1s 6ms/step - loss: 0.1300 - mae: 0.2863 - mse: 0.1300 - val_loss: 0.1527 - val_mae: 0.3414 - val_mse: 0.1527
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.2049 - mae: 0.3805 - mse: 0.2049
64/89 [====================>.........] - ETA: 0s - loss: 0.1789 - mae: 0.3450 - mse: 0.1789
89/89 [==============================] - 1s 6ms/step - loss: 0.1497 - mae: 0.3084 - mse: 0.1497 - val_loss: 0.1142 - val_mae: 0.2740 - val_mse: 0.1142
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1379 - mae: 0.3250 - mse: 0.1379
64/89 [====================>.........] - ETA: 0s - loss: 0.1121 - mae: 0.2658 - mse: 0.1121
89/89 [==============================] - 1s 7ms/step - loss: 0.1024 - mae: 0.2558 - mse: 0.1024 - val_loss: 0.1178 - val_mae: 0.2609 - val_mse: 0.1178
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1039 - mae: 0.2486 - mse: 0.1039
64/89 [====================>.........] - ETA: 0s - loss: 0.1271 - mae: 0.2802 - mse: 0.1271
89/89 [==============================] - 1s 6ms/step - loss: 0.1125 - mae: 0.2548 - mse: 0.1125 - val_loss: 0.1149 - val_mae: 0.2521 - val_mse: 0.1149
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0998 - mae: 0.2549 - mse: 0.0998
64/89 [====================>.........] - ETA: 0s - loss: 0.1087 - mae: 0.2469 - mse: 0.1087
89/89 [==============================] - 1s 6ms/step - loss: 0.1028 - mae: 0.2395 - mse: 0.1028 - val_loss: 0.1003 - val_mae: 0.2337 - val_mse: 0.1003
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0741 - mae: 0.1974 - mse: 0.0741
64/89 [====================>.........] - ETA: 0s - loss: 0.0840 - mae: 0.2190 - mse: 0.0840
89/89 [==============================] - 1s 6ms/step - loss: 0.0866 - mae: 0.2236 - mse: 0.0866 - val_loss: 0.0961 - val_mae: 0.2494 - val_mse: 0.0961
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0891 - mae: 0.2471 - mse: 0.0891
64/89 [====================>.........] - ETA: 0s - loss: 0.0894 - mae: 0.2402 - mse: 0.0894
89/89 [==============================] - 1s 6ms/step - loss: 0.0941 - mae: 0.2433 - mse: 0.0941 - val_loss: 0.0922 - val_mae: 0.2347 - val_mse: 0.0922
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1011 - mae: 0.2593 - mse: 0.1011
64/89 [====================>.........] - ETA: 0s - loss: 0.0833 - mae: 0.2180 - mse: 0.0833
89/89 [==============================] - 1s 6ms/step - loss: 0.0815 - mae: 0.2197 - mse: 0.0815 - val_loss: 0.0887 - val_mae: 0.2204 - val_mse: 0.0887
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0531 - mae: 0.1609 - mse: 0.0531
64/89 [====================>.........] - ETA: 0s - loss: 0.0755 - mae: 0.1977 - mse: 0.0755
89/89 [==============================] - 1s 6ms/step - loss: 0.0749 - mae: 0.1951 - mse: 0.0749 - val_loss: 0.0885 - val_mae: 0.2297 - val_mse: 0.0885
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0779 - mae: 0.2144 - mse: 0.0779
64/89 [====================>.........] - ETA: 0s - loss: 0.0837 - mae: 0.2196 - mse: 0.0837
89/89 [==============================] - 0s 5ms/step - loss: 0.0753 - mae: 0.2053 - mse: 0.0753 - val_loss: 0.0824 - val_mae: 0.2246 - val_mse: 0.0824
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0669 - mae: 0.2077 - mse: 0.0669
64/89 [====================>.........] - ETA: 0s - loss: 0.0715 - mae: 0.2121 - mse: 0.0715
89/89 [==============================] - 1s 7ms/step - loss: 0.0718 - mae: 0.2100 - mse: 0.0718 - val_loss: 0.0758 - val_mae: 0.2127 - val_mse: 0.0758
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0647 - mae: 0.1916 - mse: 0.0647
64/89 [====================>.........] - ETA: 0s - loss: 0.0585 - mae: 0.1809 - mse: 0.0585
89/89 [==============================] - 1s 6ms/step - loss: 0.0602 - mae: 0.1839 - mse: 0.0602 - val_loss: 0.0690 - val_mae: 0.2028 - val_mse: 0.0690
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0511 - mae: 0.1625 - mse: 0.0511
64/89 [====================>.........] - ETA: 0s - loss: 0.0492 - mae: 0.1651 - mse: 0.0492
89/89 [==============================] - 0s 5ms/step - loss: 0.0534 - mae: 0.1736 - mse: 0.0534 - val_loss: 0.0631 - val_mae: 0.2009 - val_mse: 0.0631
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0556 - mae: 0.1761 - mse: 0.0556
64/89 [====================>.........] - ETA: 0s - loss: 0.0600 - mae: 0.1906 - mse: 0.0600
89/89 [==============================] - 0s 6ms/step - loss: 0.0557 - mae: 0.1825 - mse: 0.0557 - val_loss: 0.0551 - val_mae: 0.1898 - val_mse: 0.0551
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0481 - mae: 0.1682 - mse: 0.0481
64/89 [====================>.........] - ETA: 0s - loss: 0.0450 - mae: 0.1571 - mse: 0.0450
89/89 [==============================] - 0s 5ms/step - loss: 0.0467 - mae: 0.1604 - mse: 0.0467 - val_loss: 0.0463 - val_mae: 0.1718 - val_mse: 0.0463
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0357 - mae: 0.1427 - mse: 0.0357
64/89 [====================>.........] - ETA: 0s - loss: 0.0392 - mae: 0.1548 - mse: 0.0392
89/89 [==============================] - 1s 6ms/step - loss: 0.0408 - mae: 0.1547 - mse: 0.0408 - val_loss: 0.0384 - val_mae: 0.1580 - val_mse: 0.0384
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0311 - mae: 0.1325 - mse: 0.0311
64/89 [====================>.........] - ETA: 0s - loss: 0.0298 - mae: 0.1299 - mse: 0.0298
89/89 [==============================] - 1s 6ms/step - loss: 0.0386 - mae: 0.1445 - mse: 0.0386 - val_loss: 0.0319 - val_mae: 0.1459 - val_mse: 0.0319
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0330 - mae: 0.1408 - mse: 0.0330
64/89 [====================>.........] - ETA: 0s - loss: 0.0357 - mae: 0.1441 - mse: 0.0357
89/89 [==============================] - 1s 6ms/step - loss: 0.0356 - mae: 0.1419 - mse: 0.0356 - val_loss: 0.0285 - val_mae: 0.1423 - val_mse: 0.0285
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0277 - mae: 0.1269 - mse: 0.0277
64/89 [====================>.........] - ETA: 0s - loss: 0.0325 - mae: 0.1341 - mse: 0.0325
89/89 [==============================] - 0s 5ms/step - loss: 0.0333 - mae: 0.1388 - mse: 0.0333 - val_loss: 0.0232 - val_mae: 0.1287 - val_mse: 0.0232
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0203 - mae: 0.1037 - mse: 0.0203
64/89 [====================>.........] - ETA: 0s - loss: 0.0218 - mae: 0.1150 - mse: 0.0218
89/89 [==============================] - 1s 6ms/step - loss: 0.0247 - mae: 0.1214 - mse: 0.0247 - val_loss: 0.0189 - val_mae: 0.1131 - val_mse: 0.0189
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0152 - mae: 0.1004 - mse: 0.0152
64/89 [====================>.........] - ETA: 0s - loss: 0.0249 - mae: 0.1141 - mse: 0.0249
89/89 [==============================] - 0s 5ms/step - loss: 0.0222 - mae: 0.1094 - mse: 0.0222 - val_loss: 0.0207 - val_mae: 0.1162 - val_mse: 0.0207
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0242 - mae: 0.1184 - mse: 0.0242
64/89 [====================>.........] - ETA: 0s - loss: 0.0254 - mae: 0.1208 - mse: 0.0254
89/89 [==============================] - 0s 4ms/step - loss: 0.0245 - mae: 0.1202 - mse: 0.0245 - val_loss: 0.0260 - val_mae: 0.1228 - val_mse: 0.0260
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0148 - mae: 0.1041 - mse: 0.0148
64/89 [====================>.........] - ETA: 0s - loss: 0.0133 - mae: 0.0944 - mse: 0.0133
89/89 [==============================] - 0s 4ms/step - loss: 0.0163 - mae: 0.0998 - mse: 0.0163 - val_loss: 0.0167 - val_mae: 0.1012 - val_mse: 0.0167
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0168 - mae: 0.0870 - mse: 0.0168
64/89 [====================>.........] - ETA: 0s - loss: 0.0189 - mae: 0.0921 - mse: 0.0189
89/89 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0972 - mse: 0.0189 - val_loss: 0.0161 - val_mae: 0.0999 - val_mse: 0.0161
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0063 - mae: 0.0621 - mse: 0.0063
64/89 [====================>.........] - ETA: 0s - loss: 0.0127 - mae: 0.0857 - mse: 0.0127
89/89 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0802 - mse: 0.0112 - val_loss: 0.0175 - val_mae: 0.1025 - val_mse: 0.0175
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0287 - mae: 0.1171 - mse: 0.0287
64/89 [====================>.........] - ETA: 0s - loss: 0.0172 - mae: 0.0885 - mse: 0.0172
89/89 [==============================] - 0s 4ms/step - loss: 0.0166 - mae: 0.0909 - mse: 0.0166 - val_loss: 0.0269 - val_mae: 0.1148 - val_mse: 0.0269
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0143 - mae: 0.0962 - mse: 0.0143
64/89 [====================>.........] - ETA: 0s - loss: 0.0152 - mae: 0.0955 - mse: 0.0152
89/89 [==============================] - 0s 4ms/step - loss: 0.0143 - mae: 0.0933 - mse: 0.0143 - val_loss: 0.0196 - val_mae: 0.0930 - val_mse: 0.0196
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0155 - mae: 0.0949 - mse: 0.0155
64/89 [====================>.........] - ETA: 0s - loss: 0.0122 - mae: 0.0804 - mse: 0.0122
89/89 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0894 - mse: 0.0134 - val_loss: 0.0137 - val_mae: 0.0865 - val_mse: 0.0137
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0131 - mae: 0.0900 - mse: 0.0131
64/89 [====================>.........] - ETA: 0s - loss: 0.0115 - mae: 0.0808 - mse: 0.0115
89/89 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0756 - mse: 0.0102 - val_loss: 0.0225 - val_mae: 0.1166 - val_mse: 0.0225
Saving trained model...
96
Testing...
heightdiff= [ 0.          0.          0.          0.         11.30537415]
average prediction= [3.1594806]
baseline= 9.62
eachuser= [0. 0. 0. 0. 9.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.2561526828342013
['train-height-4.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
1_165_65_4_csi_a4_18.dat
165 42
165 43
1_165_65_4_csi_a4_5.dat
165 45
165 46
165 47
165 48
165 49
1_165_65_4_csi_a4_24.dat
165 51
165 52
165 53
165 54
1_165_65_4_csi_a4_7.dat
165 56
165 57
165 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
165 61
165 62
165 63
165 64
165 65
165 66
165 67
165 68
1_165_65_4_csi_a4_29.dat
165 70
165 71
165 72
165 73
2_165_50_4_csi_a4_13.dat
165 75
165 76
165 77
165 78
2_165_50_4_csi_a4_15.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
2_165_50_4_csi_a4_25.dat
165 97
165 98
165 99
165 100
175 101
1_175_70_4_csi_a4_14.dat
175 103
1_175_70_4_csi_a4_16.dat
175 105
1_175_70_4_csi_a4_8.dat
175 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
175 111
175 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
175 115
1_175_70_4_csi_a4_28.dat
175 117
175 118
175 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
175 122
1_175_70_4_csi_a4_5.dat
175 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
175 127
1_175_70_4_csi_a4_22.dat
175 129
175 130
180 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
180 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
180 142
1_180_85_4_csi_a4_30.dat
180 144
180 145
180 146
180 147
1_180_85_4_csi_a4_20.dat
180 149
180 150
180 151
180 152
180 153
1_180_85_4_csi_a4_29.dat
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
180 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.3233 - mae: 0.4794 - mse: 0.3233
64/89 [====================>.........] - ETA: 0s - loss: 0.3291 - mae: 0.4727 - mse: 0.3291
89/89 [==============================] - 1s 10ms/step - loss: 0.2955 - mae: 0.4410 - mse: 0.2955 - val_loss: 0.1351 - val_mae: 0.3089 - val_mse: 0.1351
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1122 - mae: 0.2926 - mse: 0.1122
64/89 [====================>.........] - ETA: 0s - loss: 0.1298 - mae: 0.2993 - mse: 0.1298
89/89 [==============================] - 1s 6ms/step - loss: 0.1378 - mae: 0.3111 - mse: 0.1378 - val_loss: 0.1470 - val_mae: 0.3509 - val_mse: 0.1470
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.2120 - mae: 0.4103 - mse: 0.2120
64/89 [====================>.........] - ETA: 0s - loss: 0.1729 - mae: 0.3621 - mse: 0.1729
89/89 [==============================] - 1s 6ms/step - loss: 0.1553 - mae: 0.3412 - mse: 0.1553 - val_loss: 0.1321 - val_mae: 0.2942 - val_mse: 0.1321
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1301 - mae: 0.2952 - mse: 0.1301
64/89 [====================>.........] - ETA: 0s - loss: 0.1115 - mae: 0.2665 - mse: 0.1115
89/89 [==============================] - 0s 5ms/step - loss: 0.1198 - mae: 0.2819 - mse: 0.1198 - val_loss: 0.1596 - val_mae: 0.3132 - val_mse: 0.1596
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0751 - mae: 0.2276 - mse: 0.0751
64/89 [====================>.........] - ETA: 0s - loss: 0.1058 - mae: 0.2554 - mse: 0.1058
89/89 [==============================] - 0s 5ms/step - loss: 0.1293 - mae: 0.2823 - mse: 0.1293 - val_loss: 0.1778 - val_mae: 0.3334 - val_mse: 0.1778
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1122 - mae: 0.2598 - mse: 0.1122
64/89 [====================>.........] - ETA: 0s - loss: 0.1215 - mae: 0.2750 - mse: 0.1215
89/89 [==============================] - 0s 4ms/step - loss: 0.1376 - mae: 0.2905 - mse: 0.1376 - val_loss: 0.1621 - val_mae: 0.3147 - val_mse: 0.1621
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1417 - mae: 0.2904 - mse: 0.1417
64/89 [====================>.........] - ETA: 0s - loss: 0.1141 - mae: 0.2584 - mse: 0.1141
89/89 [==============================] - 0s 4ms/step - loss: 0.1158 - mae: 0.2567 - mse: 0.1158 - val_loss: 0.1373 - val_mae: 0.2805 - val_mse: 0.1373
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0910 - mae: 0.2079 - mse: 0.0910
64/89 [====================>.........] - ETA: 0s - loss: 0.1041 - mae: 0.2425 - mse: 0.1041
89/89 [==============================] - 0s 5ms/step - loss: 0.1028 - mae: 0.2435 - mse: 0.1028 - val_loss: 0.1243 - val_mae: 0.2745 - val_mse: 0.1243
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0771 - mae: 0.2084 - mse: 0.0771
64/89 [====================>.........] - ETA: 0s - loss: 0.1022 - mae: 0.2645 - mse: 0.1022
89/89 [==============================] - 0s 4ms/step - loss: 0.1034 - mae: 0.2674 - mse: 0.1034 - val_loss: 0.1215 - val_mae: 0.2733 - val_mse: 0.1215
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0804 - mae: 0.2271 - mse: 0.0804
64/89 [====================>.........] - ETA: 0s - loss: 0.0859 - mae: 0.2348 - mse: 0.0859
89/89 [==============================] - 0s 4ms/step - loss: 0.0960 - mae: 0.2559 - mse: 0.0960 - val_loss: 0.1220 - val_mae: 0.2590 - val_mse: 0.1220
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0421 - mae: 0.1528 - mse: 0.0421
64/89 [====================>.........] - ETA: 0s - loss: 0.0681 - mae: 0.1923 - mse: 0.0681
89/89 [==============================] - 0s 4ms/step - loss: 0.0877 - mae: 0.2277 - mse: 0.0877 - val_loss: 0.1262 - val_mae: 0.2597 - val_mse: 0.1262
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0974 - mae: 0.2175 - mse: 0.0974
64/89 [====================>.........] - ETA: 0s - loss: 0.0795 - mae: 0.1979 - mse: 0.0795
89/89 [==============================] - 0s 4ms/step - loss: 0.0942 - mae: 0.2222 - mse: 0.0942 - val_loss: 0.1278 - val_mae: 0.2590 - val_mse: 0.1278
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0933 - mae: 0.2257 - mse: 0.0933
64/89 [====================>.........] - ETA: 0s - loss: 0.0917 - mae: 0.2279 - mse: 0.0917
89/89 [==============================] - 0s 4ms/step - loss: 0.0892 - mae: 0.2199 - mse: 0.0892 - val_loss: 0.1233 - val_mae: 0.2508 - val_mse: 0.1233
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1096 - mae: 0.2405 - mse: 0.1096
64/89 [====================>.........] - ETA: 0s - loss: 0.0986 - mae: 0.2258 - mse: 0.0986
89/89 [==============================] - 0s 4ms/step - loss: 0.0845 - mae: 0.2154 - mse: 0.0845 - val_loss: 0.1162 - val_mae: 0.2394 - val_mse: 0.1162
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0858 - mae: 0.2277 - mse: 0.0858
64/89 [====================>.........] - ETA: 0s - loss: 0.0880 - mae: 0.2264 - mse: 0.0880
89/89 [==============================] - 0s 4ms/step - loss: 0.0891 - mae: 0.2225 - mse: 0.0891 - val_loss: 0.1161 - val_mae: 0.2376 - val_mse: 0.1161
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0869 - mae: 0.2156 - mse: 0.0869
64/89 [====================>.........] - ETA: 0s - loss: 0.0886 - mae: 0.2171 - mse: 0.0886
89/89 [==============================] - 0s 4ms/step - loss: 0.0815 - mae: 0.2050 - mse: 0.0815 - val_loss: 0.1144 - val_mae: 0.2362 - val_mse: 0.1144
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0667 - mae: 0.2023 - mse: 0.0667
64/89 [====================>.........] - ETA: 0s - loss: 0.0823 - mae: 0.2198 - mse: 0.0823
89/89 [==============================] - 0s 5ms/step - loss: 0.0836 - mae: 0.2132 - mse: 0.0836 - val_loss: 0.1141 - val_mae: 0.2380 - val_mse: 0.1141
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1045 - mae: 0.2330 - mse: 0.1045
64/89 [====================>.........] - ETA: 0s - loss: 0.0953 - mae: 0.2200 - mse: 0.0953
89/89 [==============================] - 0s 4ms/step - loss: 0.0821 - mae: 0.1988 - mse: 0.0821 - val_loss: 0.1095 - val_mae: 0.2334 - val_mse: 0.1095
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1011 - mae: 0.2362 - mse: 0.1011
64/89 [====================>.........] - ETA: 0s - loss: 0.0795 - mae: 0.1988 - mse: 0.0795
89/89 [==============================] - 0s 4ms/step - loss: 0.0764 - mae: 0.1963 - mse: 0.0764 - val_loss: 0.1013 - val_mae: 0.2225 - val_mse: 0.1013
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0486 - mae: 0.1736 - mse: 0.0486
64/89 [====================>.........] - ETA: 0s - loss: 0.0629 - mae: 0.1908 - mse: 0.0629
89/89 [==============================] - 0s 4ms/step - loss: 0.0742 - mae: 0.2027 - mse: 0.0742 - val_loss: 0.1000 - val_mae: 0.2231 - val_mse: 0.1000
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0841 - mae: 0.2080 - mse: 0.0841
64/89 [====================>.........] - ETA: 0s - loss: 0.0643 - mae: 0.1783 - mse: 0.0643
89/89 [==============================] - 0s 4ms/step - loss: 0.0671 - mae: 0.1845 - mse: 0.0671 - val_loss: 0.0948 - val_mae: 0.2228 - val_mse: 0.0948
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0587 - mae: 0.1590 - mse: 0.0587
64/89 [====================>.........] - ETA: 0s - loss: 0.0633 - mae: 0.1715 - mse: 0.0633
89/89 [==============================] - 0s 4ms/step - loss: 0.0664 - mae: 0.1823 - mse: 0.0664 - val_loss: 0.0896 - val_mae: 0.2207 - val_mse: 0.0896
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0890 - mae: 0.2255 - mse: 0.0890
64/89 [====================>.........] - ETA: 0s - loss: 0.0721 - mae: 0.1975 - mse: 0.0721
89/89 [==============================] - 0s 4ms/step - loss: 0.0679 - mae: 0.1956 - mse: 0.0679 - val_loss: 0.0807 - val_mae: 0.2120 - val_mse: 0.0807
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0686 - mae: 0.1982 - mse: 0.0686
64/89 [====================>.........] - ETA: 0s - loss: 0.0627 - mae: 0.1835 - mse: 0.0627
89/89 [==============================] - 0s 4ms/step - loss: 0.0634 - mae: 0.1822 - mse: 0.0634 - val_loss: 0.0821 - val_mae: 0.2206 - val_mse: 0.0821
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0560 - mae: 0.1604 - mse: 0.0560
64/89 [====================>.........] - ETA: 0s - loss: 0.0514 - mae: 0.1608 - mse: 0.0514
89/89 [==============================] - 0s 4ms/step - loss: 0.0507 - mae: 0.1644 - mse: 0.0507 - val_loss: 0.0701 - val_mae: 0.2024 - val_mse: 0.0701
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0605 - mae: 0.1696 - mse: 0.0605
64/89 [====================>.........] - ETA: 0s - loss: 0.0532 - mae: 0.1628 - mse: 0.0532
89/89 [==============================] - 0s 4ms/step - loss: 0.0505 - mae: 0.1622 - mse: 0.0505 - val_loss: 0.0561 - val_mae: 0.1735 - val_mse: 0.0561
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0464 - mae: 0.1690 - mse: 0.0464
64/89 [====================>.........] - ETA: 0s - loss: 0.0381 - mae: 0.1496 - mse: 0.0381
89/89 [==============================] - 0s 4ms/step - loss: 0.0465 - mae: 0.1607 - mse: 0.0465 - val_loss: 0.0483 - val_mae: 0.1645 - val_mse: 0.0483
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0388 - mae: 0.1406 - mse: 0.0388
64/89 [====================>.........] - ETA: 0s - loss: 0.0442 - mae: 0.1554 - mse: 0.0442
89/89 [==============================] - 0s 4ms/step - loss: 0.0383 - mae: 0.1455 - mse: 0.0383 - val_loss: 0.0317 - val_mae: 0.1401 - val_mse: 0.0317
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0267 - mae: 0.1355 - mse: 0.0267
64/89 [====================>.........] - ETA: 0s - loss: 0.0270 - mae: 0.1319 - mse: 0.0270
89/89 [==============================] - 0s 4ms/step - loss: 0.0348 - mae: 0.1429 - mse: 0.0348 - val_loss: 0.0336 - val_mae: 0.1585 - val_mse: 0.0336
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0374 - mae: 0.1364 - mse: 0.0374
64/89 [====================>.........] - ETA: 0s - loss: 0.0302 - mae: 0.1288 - mse: 0.0302
89/89 [==============================] - 0s 4ms/step - loss: 0.0310 - mae: 0.1314 - mse: 0.0310 - val_loss: 0.0241 - val_mae: 0.1453 - val_mse: 0.0241
Saving trained model...
96
Testing...
heightdiff= [ 0.          0.          0.          0.         22.31866455]
average prediction= [3.9326458]
baseline= 8.22
eachuser= [0. 0. 0. 0. 6.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 3.7197774251302085
['train-height-4.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
1_165_65_4_csi_a4_18.dat
165 42
165 43
1_165_65_4_csi_a4_5.dat
165 45
165 46
165 47
165 48
165 49
1_165_65_4_csi_a4_24.dat
165 51
165 52
165 53
165 54
1_165_65_4_csi_a4_7.dat
165 56
165 57
165 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
165 61
165 62
165 63
165 64
165 65
165 66
165 67
165 68
1_165_65_4_csi_a4_29.dat
165 70
165 71
165 72
165 73
2_165_50_4_csi_a4_13.dat
165 75
165 76
165 77
165 78
2_165_50_4_csi_a4_15.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
2_165_50_4_csi_a4_25.dat
165 97
165 98
165 99
165 100
175 101
1_175_70_4_csi_a4_14.dat
175 103
1_175_70_4_csi_a4_16.dat
175 105
1_175_70_4_csi_a4_8.dat
175 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
175 111
175 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
175 115
1_175_70_4_csi_a4_28.dat
175 117
175 118
175 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
175 122
1_175_70_4_csi_a4_5.dat
175 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
175 127
1_175_70_4_csi_a4_22.dat
175 129
175 130
180 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
180 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
180 142
1_180_85_4_csi_a4_30.dat
180 144
180 145
180 146
180 147
1_180_85_4_csi_a4_20.dat
180 149
180 150
180 151
180 152
180 153
1_180_85_4_csi_a4_29.dat
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
180 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.3012 - mae: 0.4444 - mse: 0.3012
64/89 [====================>.........] - ETA: 0s - loss: 0.2367 - mae: 0.3928 - mse: 0.2367
89/89 [==============================] - 1s 9ms/step - loss: 0.2051 - mae: 0.3556 - mse: 0.2051 - val_loss: 0.1860 - val_mae: 0.3760 - val_mse: 0.1860
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0779 - mae: 0.2168 - mse: 0.0779
64/89 [====================>.........] - ETA: 0s - loss: 0.1176 - mae: 0.2840 - mse: 0.1176
89/89 [==============================] - 0s 5ms/step - loss: 0.1278 - mae: 0.2994 - mse: 0.1278 - val_loss: 0.1402 - val_mae: 0.3273 - val_mse: 0.1402
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1328 - mae: 0.3149 - mse: 0.1328
64/89 [====================>.........] - ETA: 0s - loss: 0.1186 - mae: 0.2926 - mse: 0.1186
89/89 [==============================] - 0s 5ms/step - loss: 0.1215 - mae: 0.2946 - mse: 0.1215 - val_loss: 0.2130 - val_mae: 0.3814 - val_mse: 0.2130
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0926 - mae: 0.2310 - mse: 0.0926
64/89 [====================>.........] - ETA: 0s - loss: 0.0914 - mae: 0.2299 - mse: 0.0914
89/89 [==============================] - 0s 4ms/step - loss: 0.1027 - mae: 0.2454 - mse: 0.1027 - val_loss: 0.2551 - val_mae: 0.4328 - val_mse: 0.2551
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0868 - mae: 0.2233 - mse: 0.0868
64/89 [====================>.........] - ETA: 0s - loss: 0.1186 - mae: 0.2710 - mse: 0.1186
89/89 [==============================] - 0s 4ms/step - loss: 0.1119 - mae: 0.2532 - mse: 0.1119 - val_loss: 0.2380 - val_mae: 0.4091 - val_mse: 0.2380
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1058 - mae: 0.2523 - mse: 0.1058
64/89 [====================>.........] - ETA: 0s - loss: 0.0922 - mae: 0.2378 - mse: 0.0922
89/89 [==============================] - 0s 5ms/step - loss: 0.0950 - mae: 0.2391 - mse: 0.0950 - val_loss: 0.1912 - val_mae: 0.3483 - val_mse: 0.1912
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0911 - mae: 0.2264 - mse: 0.0911
64/89 [====================>.........] - ETA: 0s - loss: 0.1008 - mae: 0.2469 - mse: 0.1008
89/89 [==============================] - 0s 4ms/step - loss: 0.0984 - mae: 0.2451 - mse: 0.0984 - val_loss: 0.1607 - val_mae: 0.3181 - val_mse: 0.1607
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0929 - mae: 0.2343 - mse: 0.0929
64/89 [====================>.........] - ETA: 0s - loss: 0.0796 - mae: 0.2211 - mse: 0.0796
89/89 [==============================] - 0s 4ms/step - loss: 0.0983 - mae: 0.2502 - mse: 0.0983 - val_loss: 0.1623 - val_mae: 0.3120 - val_mse: 0.1623
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0638 - mae: 0.2070 - mse: 0.0638
64/89 [====================>.........] - ETA: 0s - loss: 0.0706 - mae: 0.2145 - mse: 0.0706
89/89 [==============================] - 0s 5ms/step - loss: 0.0921 - mae: 0.2392 - mse: 0.0921 - val_loss: 0.1852 - val_mae: 0.3320 - val_mse: 0.1852
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0960 - mae: 0.2317 - mse: 0.0960
64/89 [====================>.........] - ETA: 0s - loss: 0.0986 - mae: 0.2285 - mse: 0.0986
89/89 [==============================] - 0s 5ms/step - loss: 0.0870 - mae: 0.2075 - mse: 0.0870 - val_loss: 0.1953 - val_mae: 0.3504 - val_mse: 0.1953
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0889 - mae: 0.2138 - mse: 0.0889
64/89 [====================>.........] - ETA: 0s - loss: 0.0915 - mae: 0.2149 - mse: 0.0915
89/89 [==============================] - 0s 4ms/step - loss: 0.0801 - mae: 0.2005 - mse: 0.0801 - val_loss: 0.1795 - val_mae: 0.3293 - val_mse: 0.1795
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0661 - mae: 0.1755 - mse: 0.0661
64/89 [====================>.........] - ETA: 0s - loss: 0.0732 - mae: 0.1984 - mse: 0.0732
89/89 [==============================] - 0s 5ms/step - loss: 0.0756 - mae: 0.1979 - mse: 0.0756 - val_loss: 0.1610 - val_mae: 0.2969 - val_mse: 0.1610
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0595 - mae: 0.1962 - mse: 0.0595
64/89 [====================>.........] - ETA: 0s - loss: 0.0593 - mae: 0.1786 - mse: 0.0593
89/89 [==============================] - 0s 5ms/step - loss: 0.0732 - mae: 0.1953 - mse: 0.0732 - val_loss: 0.1478 - val_mae: 0.2673 - val_mse: 0.1478
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0633 - mae: 0.1919 - mse: 0.0633
64/89 [====================>.........] - ETA: 0s - loss: 0.0741 - mae: 0.2050 - mse: 0.0741
89/89 [==============================] - 0s 5ms/step - loss: 0.0764 - mae: 0.2039 - mse: 0.0764 - val_loss: 0.1454 - val_mae: 0.2724 - val_mse: 0.1454
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1010 - mae: 0.2312 - mse: 0.1010
64/89 [====================>.........] - ETA: 0s - loss: 0.0883 - mae: 0.2161 - mse: 0.0883
89/89 [==============================] - 0s 4ms/step - loss: 0.0820 - mae: 0.2091 - mse: 0.0820 - val_loss: 0.1506 - val_mae: 0.2934 - val_mse: 0.1506
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0447 - mae: 0.1381 - mse: 0.0447
64/89 [====================>.........] - ETA: 0s - loss: 0.0539 - mae: 0.1540 - mse: 0.0539
89/89 [==============================] - 0s 4ms/step - loss: 0.0737 - mae: 0.1847 - mse: 0.0737 - val_loss: 0.1547 - val_mae: 0.3073 - val_mse: 0.1547
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0847 - mae: 0.1948 - mse: 0.0847
64/89 [====================>.........] - ETA: 0s - loss: 0.0797 - mae: 0.2028 - mse: 0.0797
89/89 [==============================] - 0s 4ms/step - loss: 0.0718 - mae: 0.1940 - mse: 0.0718 - val_loss: 0.1468 - val_mae: 0.3041 - val_mse: 0.1468
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0780 - mae: 0.2028 - mse: 0.0780
64/89 [====================>.........] - ETA: 0s - loss: 0.0601 - mae: 0.1682 - mse: 0.0601
89/89 [==============================] - 0s 4ms/step - loss: 0.0698 - mae: 0.1847 - mse: 0.0698 - val_loss: 0.1348 - val_mae: 0.2924 - val_mse: 0.1348
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0562 - mae: 0.1768 - mse: 0.0562
64/89 [====================>.........] - ETA: 0s - loss: 0.0591 - mae: 0.1786 - mse: 0.0591
89/89 [==============================] - 0s 4ms/step - loss: 0.0563 - mae: 0.1691 - mse: 0.0563 - val_loss: 0.1089 - val_mae: 0.2504 - val_mse: 0.1089
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0788 - mae: 0.2107 - mse: 0.0788
64/89 [====================>.........] - ETA: 0s - loss: 0.0722 - mae: 0.2035 - mse: 0.0722
89/89 [==============================] - 0s 4ms/step - loss: 0.0610 - mae: 0.1832 - mse: 0.0610 - val_loss: 0.0938 - val_mae: 0.2344 - val_mse: 0.0938
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0437 - mae: 0.1582 - mse: 0.0437
64/89 [====================>.........] - ETA: 0s - loss: 0.0489 - mae: 0.1673 - mse: 0.0489
89/89 [==============================] - 0s 4ms/step - loss: 0.0550 - mae: 0.1755 - mse: 0.0550 - val_loss: 0.1093 - val_mae: 0.2716 - val_mse: 0.1093
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0600 - mae: 0.1778 - mse: 0.0600
64/89 [====================>.........] - ETA: 0s - loss: 0.0590 - mae: 0.1715 - mse: 0.0590
89/89 [==============================] - 0s 4ms/step - loss: 0.0542 - mae: 0.1673 - mse: 0.0542 - val_loss: 0.0894 - val_mae: 0.2471 - val_mse: 0.0894
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0524 - mae: 0.1689 - mse: 0.0524
64/89 [====================>.........] - ETA: 0s - loss: 0.0384 - mae: 0.1450 - mse: 0.0384
89/89 [==============================] - 0s 4ms/step - loss: 0.0422 - mae: 0.1518 - mse: 0.0422 - val_loss: 0.0677 - val_mae: 0.2100 - val_mse: 0.0677
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0287 - mae: 0.1365 - mse: 0.0287
64/89 [====================>.........] - ETA: 0s - loss: 0.0440 - mae: 0.1620 - mse: 0.0440
89/89 [==============================] - 0s 4ms/step - loss: 0.0385 - mae: 0.1492 - mse: 0.0385 - val_loss: 0.0472 - val_mae: 0.1726 - val_mse: 0.0472
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0407 - mae: 0.1546 - mse: 0.0407
64/89 [====================>.........] - ETA: 0s - loss: 0.0403 - mae: 0.1497 - mse: 0.0403
89/89 [==============================] - 0s 5ms/step - loss: 0.0368 - mae: 0.1419 - mse: 0.0368 - val_loss: 0.0357 - val_mae: 0.1491 - val_mse: 0.0357
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0332 - mae: 0.1362 - mse: 0.0332
64/89 [====================>.........] - ETA: 0s - loss: 0.0269 - mae: 0.1232 - mse: 0.0269
89/89 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.1231 - mse: 0.0275 - val_loss: 0.0281 - val_mae: 0.1420 - val_mse: 0.0281
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0185 - mae: 0.1021 - mse: 0.0185
64/89 [====================>.........] - ETA: 0s - loss: 0.0216 - mae: 0.1094 - mse: 0.0216
89/89 [==============================] - 1s 6ms/step - loss: 0.0216 - mae: 0.1070 - mse: 0.0216 - val_loss: 0.0178 - val_mae: 0.1251 - val_mse: 0.0178
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0152 - mae: 0.0957 - mse: 0.0152
64/89 [====================>.........] - ETA: 0s - loss: 0.0138 - mae: 0.0914 - mse: 0.0138
89/89 [==============================] - 1s 6ms/step - loss: 0.0131 - mae: 0.0906 - mse: 0.0131 - val_loss: 0.0174 - val_mae: 0.1156 - val_mse: 0.0174
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0151 - mae: 0.0851 - mse: 0.0151
64/89 [====================>.........] - ETA: 0s - loss: 0.0158 - mae: 0.0896 - mse: 0.0158
89/89 [==============================] - 1s 6ms/step - loss: 0.0147 - mae: 0.0891 - mse: 0.0147 - val_loss: 0.0242 - val_mae: 0.1461 - val_mse: 0.0242
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0150 - mae: 0.0904 - mse: 0.0150
64/89 [====================>.........] - ETA: 0s - loss: 0.0106 - mae: 0.0775 - mse: 0.0106
89/89 [==============================] - 1s 6ms/step - loss: 0.0093 - mae: 0.0735 - mse: 0.0093 - val_loss: 0.0173 - val_mae: 0.1195 - val_mse: 0.0173
Saving trained model...
96
Testing...
heightdiff= [ 0.          0.          0.          0.         19.63015747]
average prediction= [3.370645]
baseline= 9.02
eachuser= [0. 0. 0. 0. 7.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 2.8043082101004466
['train-height-4.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
1_165_65_4_csi_a4_18.dat
165 42
165 43
1_165_65_4_csi_a4_5.dat
165 45
165 46
165 47
165 48
165 49
1_165_65_4_csi_a4_24.dat
165 51
165 52
165 53
165 54
1_165_65_4_csi_a4_7.dat
165 56
165 57
165 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
165 61
165 62
165 63
165 64
165 65
165 66
165 67
165 68
1_165_65_4_csi_a4_29.dat
165 70
165 71
165 72
165 73
2_165_50_4_csi_a4_13.dat
165 75
165 76
165 77
165 78
2_165_50_4_csi_a4_15.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
2_165_50_4_csi_a4_25.dat
165 97
165 98
165 99
165 100
175 101
1_175_70_4_csi_a4_14.dat
175 103
1_175_70_4_csi_a4_16.dat
175 105
1_175_70_4_csi_a4_8.dat
175 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
175 111
175 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
175 115
1_175_70_4_csi_a4_28.dat
175 117
175 118
175 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
175 122
1_175_70_4_csi_a4_5.dat
175 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
175 127
1_175_70_4_csi_a4_22.dat
175 129
175 130
180 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
180 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
180 142
1_180_85_4_csi_a4_30.dat
180 144
180 145
180 146
180 147
1_180_85_4_csi_a4_20.dat
180 149
180 150
180 151
180 152
180 153
1_180_85_4_csi_a4_29.dat
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
180 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.5200 - mae: 0.6503 - mse: 0.5200
64/89 [====================>.........] - ETA: 0s - loss: 0.4247 - mae: 0.5636 - mse: 0.4247
89/89 [==============================] - 1s 9ms/step - loss: 0.3801 - mae: 0.5267 - mse: 0.3801 - val_loss: 0.2334 - val_mae: 0.4127 - val_mse: 0.2334
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1610 - mae: 0.3203 - mse: 0.1610
64/89 [====================>.........] - ETA: 0s - loss: 0.1409 - mae: 0.3045 - mse: 0.1409
89/89 [==============================] - 1s 6ms/step - loss: 0.1524 - mae: 0.3188 - mse: 0.1524 - val_loss: 0.1536 - val_mae: 0.3606 - val_mse: 0.1536
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1405 - mae: 0.3223 - mse: 0.1405
64/89 [====================>.........] - ETA: 0s - loss: 0.1688 - mae: 0.3521 - mse: 0.1688
89/89 [==============================] - 0s 5ms/step - loss: 0.1627 - mae: 0.3501 - mse: 0.1627 - val_loss: 0.1513 - val_mae: 0.3448 - val_mse: 0.1513
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1427 - mae: 0.3184 - mse: 0.1427
64/89 [====================>.........] - ETA: 0s - loss: 0.1391 - mae: 0.3188 - mse: 0.1391
89/89 [==============================] - 0s 5ms/step - loss: 0.1244 - mae: 0.2972 - mse: 0.1244 - val_loss: 0.1713 - val_mae: 0.3415 - val_mse: 0.1713
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1189 - mae: 0.2916 - mse: 0.1189
64/89 [====================>.........] - ETA: 0s - loss: 0.1085 - mae: 0.2698 - mse: 0.1085
89/89 [==============================] - 0s 5ms/step - loss: 0.1135 - mae: 0.2744 - mse: 0.1135 - val_loss: 0.1882 - val_mae: 0.3694 - val_mse: 0.1882
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1397 - mae: 0.3038 - mse: 0.1397
64/89 [====================>.........] - ETA: 0s - loss: 0.1265 - mae: 0.2875 - mse: 0.1265
89/89 [==============================] - 0s 5ms/step - loss: 0.1225 - mae: 0.2729 - mse: 0.1225 - val_loss: 0.1760 - val_mae: 0.3562 - val_mse: 0.1760
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1230 - mae: 0.2549 - mse: 0.1230
64/89 [====================>.........] - ETA: 0s - loss: 0.1336 - mae: 0.2719 - mse: 0.1336
89/89 [==============================] - 0s 5ms/step - loss: 0.1138 - mae: 0.2527 - mse: 0.1138 - val_loss: 0.1432 - val_mae: 0.3121 - val_mse: 0.1432
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1097 - mae: 0.2430 - mse: 0.1097
64/89 [====================>.........] - ETA: 0s - loss: 0.1030 - mae: 0.2385 - mse: 0.1030
89/89 [==============================] - 0s 4ms/step - loss: 0.0981 - mae: 0.2334 - mse: 0.0981 - val_loss: 0.1119 - val_mae: 0.2654 - val_mse: 0.1119
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0750 - mae: 0.2192 - mse: 0.0750
64/89 [====================>.........] - ETA: 0s - loss: 0.1042 - mae: 0.2612 - mse: 0.1042
89/89 [==============================] - 0s 4ms/step - loss: 0.1029 - mae: 0.2493 - mse: 0.1029 - val_loss: 0.0965 - val_mae: 0.2390 - val_mse: 0.0965
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1158 - mae: 0.2839 - mse: 0.1158
64/89 [====================>.........] - ETA: 0s - loss: 0.1103 - mae: 0.2721 - mse: 0.1103
89/89 [==============================] - 0s 4ms/step - loss: 0.0977 - mae: 0.2527 - mse: 0.0977 - val_loss: 0.0905 - val_mae: 0.2198 - val_mse: 0.0905
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0832 - mae: 0.2178 - mse: 0.0832
64/89 [====================>.........] - ETA: 0s - loss: 0.0913 - mae: 0.2291 - mse: 0.0913
89/89 [==============================] - 0s 4ms/step - loss: 0.0914 - mae: 0.2284 - mse: 0.0914 - val_loss: 0.0948 - val_mae: 0.2304 - val_mse: 0.0948
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0454 - mae: 0.1420 - mse: 0.0454
64/89 [====================>.........] - ETA: 0s - loss: 0.0771 - mae: 0.1997 - mse: 0.0771
89/89 [==============================] - 0s 4ms/step - loss: 0.0950 - mae: 0.2234 - mse: 0.0950 - val_loss: 0.1058 - val_mae: 0.2612 - val_mse: 0.1058
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0680 - mae: 0.1875 - mse: 0.0680
64/89 [====================>.........] - ETA: 0s - loss: 0.0748 - mae: 0.2048 - mse: 0.0748
89/89 [==============================] - 0s 4ms/step - loss: 0.0849 - mae: 0.2170 - mse: 0.0849 - val_loss: 0.1026 - val_mae: 0.2559 - val_mse: 0.1026
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0760 - mae: 0.1914 - mse: 0.0760
64/89 [====================>.........] - ETA: 0s - loss: 0.0781 - mae: 0.1958 - mse: 0.0781
89/89 [==============================] - 0s 4ms/step - loss: 0.0832 - mae: 0.2074 - mse: 0.0832 - val_loss: 0.0907 - val_mae: 0.2268 - val_mse: 0.0907
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0914 - mae: 0.2218 - mse: 0.0914
64/89 [====================>.........] - ETA: 0s - loss: 0.0918 - mae: 0.2290 - mse: 0.0918
89/89 [==============================] - 0s 4ms/step - loss: 0.0858 - mae: 0.2151 - mse: 0.0858 - val_loss: 0.0833 - val_mae: 0.2045 - val_mse: 0.0833
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0767 - mae: 0.2051 - mse: 0.0767
64/89 [====================>.........] - ETA: 0s - loss: 0.0738 - mae: 0.2017 - mse: 0.0738
89/89 [==============================] - 0s 5ms/step - loss: 0.0850 - mae: 0.2188 - mse: 0.0850 - val_loss: 0.0856 - val_mae: 0.2129 - val_mse: 0.0856
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1036 - mae: 0.2487 - mse: 0.1036
64/89 [====================>.........] - ETA: 0s - loss: 0.0851 - mae: 0.2175 - mse: 0.0851
89/89 [==============================] - 0s 4ms/step - loss: 0.0839 - mae: 0.2151 - mse: 0.0839 - val_loss: 0.0891 - val_mae: 0.2270 - val_mse: 0.0891
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0831 - mae: 0.2053 - mse: 0.0831
64/89 [====================>.........] - ETA: 0s - loss: 0.0922 - mae: 0.2242 - mse: 0.0922
89/89 [==============================] - 0s 4ms/step - loss: 0.0829 - mae: 0.2090 - mse: 0.0829 - val_loss: 0.0920 - val_mae: 0.2369 - val_mse: 0.0920
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1093 - mae: 0.2618 - mse: 0.1093
64/89 [====================>.........] - ETA: 0s - loss: 0.0812 - mae: 0.2075 - mse: 0.0812
89/89 [==============================] - 0s 4ms/step - loss: 0.0763 - mae: 0.2011 - mse: 0.0763 - val_loss: 0.0886 - val_mae: 0.2279 - val_mse: 0.0886
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1041 - mae: 0.2479 - mse: 0.1041
64/89 [====================>.........] - ETA: 0s - loss: 0.0833 - mae: 0.2128 - mse: 0.0833
89/89 [==============================] - 0s 4ms/step - loss: 0.0788 - mae: 0.2048 - mse: 0.0788 - val_loss: 0.0798 - val_mae: 0.2036 - val_mse: 0.0798
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0657 - mae: 0.2042 - mse: 0.0657
64/89 [====================>.........] - ETA: 0s - loss: 0.0662 - mae: 0.1992 - mse: 0.0662
89/89 [==============================] - 0s 5ms/step - loss: 0.0677 - mae: 0.1961 - mse: 0.0677 - val_loss: 0.0777 - val_mae: 0.2035 - val_mse: 0.0777
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0652 - mae: 0.1871 - mse: 0.0652
64/89 [====================>.........] - ETA: 0s - loss: 0.0738 - mae: 0.2078 - mse: 0.0738
89/89 [==============================] - 0s 5ms/step - loss: 0.0657 - mae: 0.1916 - mse: 0.0657 - val_loss: 0.0829 - val_mae: 0.2259 - val_mse: 0.0829
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0949 - mae: 0.2406 - mse: 0.0949
64/89 [====================>.........] - ETA: 0s - loss: 0.0717 - mae: 0.1963 - mse: 0.0717
89/89 [==============================] - 0s 4ms/step - loss: 0.0690 - mae: 0.1966 - mse: 0.0690 - val_loss: 0.0759 - val_mae: 0.2142 - val_mse: 0.0759
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0485 - mae: 0.1690 - mse: 0.0485
64/89 [====================>.........] - ETA: 0s - loss: 0.0556 - mae: 0.1793 - mse: 0.0556
89/89 [==============================] - 0s 4ms/step - loss: 0.0597 - mae: 0.1872 - mse: 0.0597 - val_loss: 0.0704 - val_mae: 0.2077 - val_mse: 0.0704
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0365 - mae: 0.1342 - mse: 0.0365
64/89 [====================>.........] - ETA: 0s - loss: 0.0519 - mae: 0.1719 - mse: 0.0519
89/89 [==============================] - 0s 4ms/step - loss: 0.0467 - mae: 0.1616 - mse: 0.0467 - val_loss: 0.0646 - val_mae: 0.2008 - val_mse: 0.0646
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0536 - mae: 0.1801 - mse: 0.0536
64/89 [====================>.........] - ETA: 0s - loss: 0.0471 - mae: 0.1640 - mse: 0.0471
89/89 [==============================] - 0s 4ms/step - loss: 0.0458 - mae: 0.1621 - mse: 0.0458 - val_loss: 0.0657 - val_mae: 0.2082 - val_mse: 0.0657
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0398 - mae: 0.1450 - mse: 0.0398
64/89 [====================>.........] - ETA: 0s - loss: 0.0387 - mae: 0.1403 - mse: 0.0387
89/89 [==============================] - 0s 4ms/step - loss: 0.0385 - mae: 0.1413 - mse: 0.0385 - val_loss: 0.0641 - val_mae: 0.2024 - val_mse: 0.0641
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0430 - mae: 0.1510 - mse: 0.0430
64/89 [====================>.........] - ETA: 0s - loss: 0.0371 - mae: 0.1431 - mse: 0.0371
89/89 [==============================] - 0s 4ms/step - loss: 0.0371 - mae: 0.1444 - mse: 0.0371 - val_loss: 0.0635 - val_mae: 0.1972 - val_mse: 0.0635
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0364 - mae: 0.1442 - mse: 0.0364
64/89 [====================>.........] - ETA: 0s - loss: 0.0284 - mae: 0.1239 - mse: 0.0284
89/89 [==============================] - 0s 4ms/step - loss: 0.0295 - mae: 0.1286 - mse: 0.0295 - val_loss: 0.0537 - val_mae: 0.1748 - val_mse: 0.0537
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0247 - mae: 0.1186 - mse: 0.0247
64/89 [====================>.........] - ETA: 0s - loss: 0.0262 - mae: 0.1225 - mse: 0.0262
89/89 [==============================] - 0s 4ms/step - loss: 0.0230 - mae: 0.1152 - mse: 0.0230 - val_loss: 0.0530 - val_mae: 0.1729 - val_mse: 0.0530
Saving trained model...
96
Testing...
heightdiff= [ 0.          0.          0.          0.         28.62771606]
average prediction= [3.0821905]
baseline= 10.1
eachuser= [ 0.  0.  0.  0. 10.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 2.8627716064453126
['train-height-4.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
1_165_65_4_csi_a4_18.dat
165 42
165 43
1_165_65_4_csi_a4_5.dat
165 45
165 46
165 47
165 48
165 49
1_165_65_4_csi_a4_24.dat
165 51
165 52
165 53
165 54
1_165_65_4_csi_a4_7.dat
165 56
165 57
165 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
165 61
165 62
165 63
165 64
165 65
165 66
165 67
165 68
1_165_65_4_csi_a4_29.dat
165 70
165 71
165 72
165 73
2_165_50_4_csi_a4_13.dat
165 75
165 76
165 77
165 78
2_165_50_4_csi_a4_15.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
2_165_50_4_csi_a4_25.dat
165 97
165 98
165 99
165 100
175 101
1_175_70_4_csi_a4_14.dat
175 103
1_175_70_4_csi_a4_16.dat
175 105
1_175_70_4_csi_a4_8.dat
175 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
175 111
175 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
175 115
1_175_70_4_csi_a4_28.dat
175 117
175 118
175 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
175 122
1_175_70_4_csi_a4_5.dat
175 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
175 127
1_175_70_4_csi_a4_22.dat
175 129
175 130
180 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
180 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
180 142
1_180_85_4_csi_a4_30.dat
180 144
180 145
180 146
180 147
1_180_85_4_csi_a4_20.dat
180 149
180 150
180 151
180 152
180 153
1_180_85_4_csi_a4_29.dat
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
180 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.3084 - mae: 0.4425 - mse: 0.3084
64/89 [====================>.........] - ETA: 0s - loss: 0.2540 - mae: 0.4103 - mse: 0.2540
89/89 [==============================] - 1s 8ms/step - loss: 0.2195 - mae: 0.3801 - mse: 0.2195 - val_loss: 0.1079 - val_mae: 0.2880 - val_mse: 0.1079
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1426 - mae: 0.3276 - mse: 0.1426
64/89 [====================>.........] - ETA: 0s - loss: 0.1466 - mae: 0.3208 - mse: 0.1466
89/89 [==============================] - 0s 5ms/step - loss: 0.1397 - mae: 0.3096 - mse: 0.1397 - val_loss: 0.1213 - val_mae: 0.2828 - val_mse: 0.1213
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1254 - mae: 0.3032 - mse: 0.1254
64/89 [====================>.........] - ETA: 0s - loss: 0.1210 - mae: 0.2913 - mse: 0.1210
89/89 [==============================] - 0s 5ms/step - loss: 0.1249 - mae: 0.2895 - mse: 0.1249 - val_loss: 0.0905 - val_mae: 0.2375 - val_mse: 0.0905
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0933 - mae: 0.2399 - mse: 0.0933
64/89 [====================>.........] - ETA: 0s - loss: 0.1252 - mae: 0.2723 - mse: 0.1252
89/89 [==============================] - 0s 5ms/step - loss: 0.1116 - mae: 0.2531 - mse: 0.1116 - val_loss: 0.0945 - val_mae: 0.2597 - val_mse: 0.0945
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1259 - mae: 0.2641 - mse: 0.1259
64/89 [====================>.........] - ETA: 0s - loss: 0.1023 - mae: 0.2370 - mse: 0.1023
89/89 [==============================] - 0s 5ms/step - loss: 0.0942 - mae: 0.2279 - mse: 0.0942 - val_loss: 0.0841 - val_mae: 0.2354 - val_mse: 0.0841
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0749 - mae: 0.1952 - mse: 0.0749
64/89 [====================>.........] - ETA: 0s - loss: 0.0872 - mae: 0.2244 - mse: 0.0872
89/89 [==============================] - 0s 4ms/step - loss: 0.0839 - mae: 0.2209 - mse: 0.0839 - val_loss: 0.0812 - val_mae: 0.2057 - val_mse: 0.0812
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0882 - mae: 0.2436 - mse: 0.0882
64/89 [====================>.........] - ETA: 0s - loss: 0.0757 - mae: 0.2122 - mse: 0.0757
89/89 [==============================] - 0s 4ms/step - loss: 0.0841 - mae: 0.2224 - mse: 0.0841 - val_loss: 0.0813 - val_mae: 0.2123 - val_mse: 0.0813
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1021 - mae: 0.2550 - mse: 0.1021
64/89 [====================>.........] - ETA: 0s - loss: 0.0767 - mae: 0.2097 - mse: 0.0767
89/89 [==============================] - 0s 5ms/step - loss: 0.0859 - mae: 0.2247 - mse: 0.0859 - val_loss: 0.0755 - val_mae: 0.1992 - val_mse: 0.0755
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0952 - mae: 0.2577 - mse: 0.0952
64/89 [====================>.........] - ETA: 0s - loss: 0.0840 - mae: 0.2274 - mse: 0.0840
89/89 [==============================] - 0s 5ms/step - loss: 0.0811 - mae: 0.2205 - mse: 0.0811 - val_loss: 0.0703 - val_mae: 0.2070 - val_mse: 0.0703
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0917 - mae: 0.2458 - mse: 0.0917
64/89 [====================>.........] - ETA: 0s - loss: 0.0815 - mae: 0.2236 - mse: 0.0815
89/89 [==============================] - 0s 5ms/step - loss: 0.0782 - mae: 0.2142 - mse: 0.0782 - val_loss: 0.0650 - val_mae: 0.1885 - val_mse: 0.0650
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0668 - mae: 0.1820 - mse: 0.0668
64/89 [====================>.........] - ETA: 0s - loss: 0.0681 - mae: 0.1912 - mse: 0.0681
89/89 [==============================] - 0s 5ms/step - loss: 0.0692 - mae: 0.1970 - mse: 0.0692 - val_loss: 0.0632 - val_mae: 0.1829 - val_mse: 0.0632
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0372 - mae: 0.1370 - mse: 0.0372
64/89 [====================>.........] - ETA: 0s - loss: 0.0804 - mae: 0.2057 - mse: 0.0804
89/89 [==============================] - 0s 4ms/step - loss: 0.0783 - mae: 0.2046 - mse: 0.0783 - val_loss: 0.0607 - val_mae: 0.1815 - val_mse: 0.0607
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0637 - mae: 0.2025 - mse: 0.0637
64/89 [====================>.........] - ETA: 0s - loss: 0.0616 - mae: 0.1897 - mse: 0.0616
89/89 [==============================] - 0s 4ms/step - loss: 0.0584 - mae: 0.1855 - mse: 0.0584 - val_loss: 0.0544 - val_mae: 0.1646 - val_mse: 0.0544
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0743 - mae: 0.1922 - mse: 0.0743
64/89 [====================>.........] - ETA: 0s - loss: 0.0649 - mae: 0.1859 - mse: 0.0649
89/89 [==============================] - 0s 4ms/step - loss: 0.0747 - mae: 0.2067 - mse: 0.0747 - val_loss: 0.0525 - val_mae: 0.1767 - val_mse: 0.0525
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0564 - mae: 0.1882 - mse: 0.0564
64/89 [====================>.........] - ETA: 0s - loss: 0.0680 - mae: 0.1960 - mse: 0.0680
89/89 [==============================] - 0s 5ms/step - loss: 0.0611 - mae: 0.1860 - mse: 0.0611 - val_loss: 0.0491 - val_mae: 0.1605 - val_mse: 0.0491
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0437 - mae: 0.1556 - mse: 0.0437
64/89 [====================>.........] - ETA: 0s - loss: 0.0586 - mae: 0.1816 - mse: 0.0586
89/89 [==============================] - 0s 4ms/step - loss: 0.0551 - mae: 0.1741 - mse: 0.0551 - val_loss: 0.0543 - val_mae: 0.1878 - val_mse: 0.0543
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0625 - mae: 0.2029 - mse: 0.0625
64/89 [====================>.........] - ETA: 0s - loss: 0.0558 - mae: 0.1859 - mse: 0.0558
89/89 [==============================] - 0s 4ms/step - loss: 0.0526 - mae: 0.1774 - mse: 0.0526 - val_loss: 0.0411 - val_mae: 0.1658 - val_mse: 0.0411
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0321 - mae: 0.1442 - mse: 0.0321
64/89 [====================>.........] - ETA: 0s - loss: 0.0476 - mae: 0.1733 - mse: 0.0476
89/89 [==============================] - 0s 4ms/step - loss: 0.0414 - mae: 0.1601 - mse: 0.0414 - val_loss: 0.0358 - val_mae: 0.1578 - val_mse: 0.0358
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0431 - mae: 0.1594 - mse: 0.0431
64/89 [====================>.........] - ETA: 0s - loss: 0.0491 - mae: 0.1732 - mse: 0.0491
89/89 [==============================] - 0s 5ms/step - loss: 0.0441 - mae: 0.1614 - mse: 0.0441 - val_loss: 0.0258 - val_mae: 0.1290 - val_mse: 0.0258
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0468 - mae: 0.1722 - mse: 0.0468
64/89 [====================>.........] - ETA: 0s - loss: 0.0375 - mae: 0.1484 - mse: 0.0375
89/89 [==============================] - 0s 4ms/step - loss: 0.0359 - mae: 0.1484 - mse: 0.0359 - val_loss: 0.0201 - val_mae: 0.1165 - val_mse: 0.0201
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0311 - mae: 0.1379 - mse: 0.0311
64/89 [====================>.........] - ETA: 0s - loss: 0.0225 - mae: 0.1148 - mse: 0.0225
89/89 [==============================] - 0s 5ms/step - loss: 0.0254 - mae: 0.1219 - mse: 0.0254 - val_loss: 0.0151 - val_mae: 0.1037 - val_mse: 0.0151
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0291 - mae: 0.1266 - mse: 0.0291
64/89 [====================>.........] - ETA: 0s - loss: 0.0289 - mae: 0.1303 - mse: 0.0289
89/89 [==============================] - 0s 4ms/step - loss: 0.0281 - mae: 0.1263 - mse: 0.0281 - val_loss: 0.0110 - val_mae: 0.0888 - val_mse: 0.0110
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0187 - mae: 0.1172 - mse: 0.0187
64/89 [====================>.........] - ETA: 0s - loss: 0.0189 - mae: 0.1130 - mse: 0.0189
89/89 [==============================] - 0s 4ms/step - loss: 0.0179 - mae: 0.1069 - mse: 0.0179 - val_loss: 0.0191 - val_mae: 0.1048 - val_mse: 0.0191
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0251 - mae: 0.1039 - mse: 0.0251
64/89 [====================>.........] - ETA: 0s - loss: 0.0259 - mae: 0.1180 - mse: 0.0259
89/89 [==============================] - 0s 4ms/step - loss: 0.0265 - mae: 0.1150 - mse: 0.0265 - val_loss: 0.0122 - val_mae: 0.0980 - val_mse: 0.0122
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0231 - mae: 0.1160 - mse: 0.0231
64/89 [====================>.........] - ETA: 0s - loss: 0.0238 - mae: 0.1186 - mse: 0.0238
89/89 [==============================] - 0s 5ms/step - loss: 0.0262 - mae: 0.1267 - mse: 0.0262 - val_loss: 0.0076 - val_mae: 0.0755 - val_mse: 0.0076
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0147 - mae: 0.0947 - mse: 0.0147
64/89 [====================>.........] - ETA: 0s - loss: 0.0193 - mae: 0.1020 - mse: 0.0193
89/89 [==============================] - 0s 4ms/step - loss: 0.0191 - mae: 0.1063 - mse: 0.0191 - val_loss: 0.0060 - val_mae: 0.0618 - val_mse: 0.0060
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0176 - mae: 0.1110 - mse: 0.0176
64/89 [====================>.........] - ETA: 0s - loss: 0.0217 - mae: 0.1155 - mse: 0.0217
89/89 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 0.1107 - mse: 0.0205 - val_loss: 0.0143 - val_mae: 0.0994 - val_mse: 0.0143
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0233 - mae: 0.1111 - mse: 0.0233
64/89 [====================>.........] - ETA: 0s - loss: 0.0215 - mae: 0.1098 - mse: 0.0215
89/89 [==============================] - 0s 4ms/step - loss: 0.0194 - mae: 0.1022 - mse: 0.0194 - val_loss: 0.0107 - val_mae: 0.0868 - val_mse: 0.0107
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0103 - mae: 0.0781 - mse: 0.0103
64/89 [====================>.........] - ETA: 0s - loss: 0.0093 - mae: 0.0767 - mse: 0.0093
89/89 [==============================] - 0s 4ms/step - loss: 0.0147 - mae: 0.0877 - mse: 0.0147 - val_loss: 0.0112 - val_mae: 0.0924 - val_mse: 0.0112
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0101 - mae: 0.0764 - mse: 0.0101
64/89 [====================>.........] - ETA: 0s - loss: 0.0156 - mae: 0.0868 - mse: 0.0156
89/89 [==============================] - 0s 4ms/step - loss: 0.0200 - mae: 0.0984 - mse: 0.0200 - val_loss: 0.0167 - val_mae: 0.1102 - val_mse: 0.0167
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         0.         9.87651062]
average prediction= [2.5337434]
baseline= 9.98
eachuser= [0. 0. 0. 0. 9.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.0973900689019098
['train-height-4.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
1_165_65_4_csi_a4_18.dat
165 42
165 43
1_165_65_4_csi_a4_5.dat
165 45
165 46
165 47
165 48
165 49
1_165_65_4_csi_a4_24.dat
165 51
165 52
165 53
165 54
1_165_65_4_csi_a4_7.dat
165 56
165 57
165 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
165 61
165 62
165 63
165 64
165 65
165 66
165 67
165 68
1_165_65_4_csi_a4_29.dat
165 70
165 71
165 72
165 73
2_165_50_4_csi_a4_13.dat
165 75
165 76
165 77
165 78
2_165_50_4_csi_a4_15.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
2_165_50_4_csi_a4_25.dat
165 97
165 98
165 99
165 100
175 101
1_175_70_4_csi_a4_14.dat
175 103
1_175_70_4_csi_a4_16.dat
175 105
1_175_70_4_csi_a4_8.dat
175 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
175 111
175 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
175 115
1_175_70_4_csi_a4_28.dat
175 117
175 118
175 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
175 122
1_175_70_4_csi_a4_5.dat
175 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
175 127
1_175_70_4_csi_a4_22.dat
175 129
175 130
180 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
180 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
180 142
1_180_85_4_csi_a4_30.dat
180 144
180 145
180 146
180 147
1_180_85_4_csi_a4_20.dat
180 149
180 150
180 151
180 152
180 153
1_180_85_4_csi_a4_29.dat
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
180 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.2862 - mae: 0.4265 - mse: 0.2862
64/89 [====================>.........] - ETA: 0s - loss: 0.2615 - mae: 0.4215 - mse: 0.2615
89/89 [==============================] - 1s 8ms/step - loss: 0.2215 - mae: 0.3800 - mse: 0.2215 - val_loss: 0.1417 - val_mae: 0.3221 - val_mse: 0.1417
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1472 - mae: 0.3195 - mse: 0.1472
64/89 [====================>.........] - ETA: 0s - loss: 0.1532 - mae: 0.3326 - mse: 0.1532
89/89 [==============================] - 0s 4ms/step - loss: 0.1770 - mae: 0.3572 - mse: 0.1770 - val_loss: 0.1043 - val_mae: 0.2745 - val_mse: 0.1043
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1639 - mae: 0.3459 - mse: 0.1639
64/89 [====================>.........] - ETA: 0s - loss: 0.1639 - mae: 0.3466 - mse: 0.1639
89/89 [==============================] - 0s 5ms/step - loss: 0.1447 - mae: 0.3190 - mse: 0.1447 - val_loss: 0.1048 - val_mae: 0.2645 - val_mse: 0.1048
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0818 - mae: 0.2242 - mse: 0.0818
64/89 [====================>.........] - ETA: 0s - loss: 0.0997 - mae: 0.2568 - mse: 0.0997
89/89 [==============================] - 0s 4ms/step - loss: 0.1059 - mae: 0.2619 - mse: 0.1059 - val_loss: 0.1189 - val_mae: 0.2812 - val_mse: 0.1189
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1334 - mae: 0.2950 - mse: 0.1334
64/89 [====================>.........] - ETA: 0s - loss: 0.1403 - mae: 0.3018 - mse: 0.1403
89/89 [==============================] - 0s 4ms/step - loss: 0.1237 - mae: 0.2770 - mse: 0.1237 - val_loss: 0.1080 - val_mae: 0.2589 - val_mse: 0.1080
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0843 - mae: 0.2157 - mse: 0.0843
64/89 [====================>.........] - ETA: 0s - loss: 0.1233 - mae: 0.2588 - mse: 0.1233
89/89 [==============================] - 0s 4ms/step - loss: 0.1171 - mae: 0.2537 - mse: 0.1171 - val_loss: 0.0844 - val_mae: 0.2140 - val_mse: 0.0844
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1034 - mae: 0.2534 - mse: 0.1034
64/89 [====================>.........] - ETA: 0s - loss: 0.1103 - mae: 0.2585 - mse: 0.1103
89/89 [==============================] - 0s 4ms/step - loss: 0.1103 - mae: 0.2567 - mse: 0.1103 - val_loss: 0.0729 - val_mae: 0.1791 - val_mse: 0.0729
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1304 - mae: 0.2906 - mse: 0.1304
64/89 [====================>.........] - ETA: 0s - loss: 0.1016 - mae: 0.2574 - mse: 0.1016
89/89 [==============================] - 0s 4ms/step - loss: 0.1007 - mae: 0.2483 - mse: 0.1007 - val_loss: 0.0701 - val_mae: 0.1753 - val_mse: 0.0701
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0950 - mae: 0.2332 - mse: 0.0950
64/89 [====================>.........] - ETA: 0s - loss: 0.1078 - mae: 0.2487 - mse: 0.1078
89/89 [==============================] - 0s 4ms/step - loss: 0.0985 - mae: 0.2337 - mse: 0.0985 - val_loss: 0.0751 - val_mae: 0.2014 - val_mse: 0.0751
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1214 - mae: 0.2634 - mse: 0.1214
64/89 [====================>.........] - ETA: 0s - loss: 0.0945 - mae: 0.2293 - mse: 0.0945
89/89 [==============================] - 0s 5ms/step - loss: 0.0970 - mae: 0.2301 - mse: 0.0970 - val_loss: 0.0820 - val_mae: 0.2183 - val_mse: 0.0820
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0799 - mae: 0.1964 - mse: 0.0799
64/89 [====================>.........] - ETA: 0s - loss: 0.0811 - mae: 0.2033 - mse: 0.0811
89/89 [==============================] - 0s 4ms/step - loss: 0.0883 - mae: 0.2194 - mse: 0.0883 - val_loss: 0.0778 - val_mae: 0.2118 - val_mse: 0.0778
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0918 - mae: 0.2134 - mse: 0.0918
64/89 [====================>.........] - ETA: 0s - loss: 0.0749 - mae: 0.1988 - mse: 0.0749
89/89 [==============================] - 0s 4ms/step - loss: 0.0869 - mae: 0.2156 - mse: 0.0869 - val_loss: 0.0699 - val_mae: 0.1945 - val_mse: 0.0699
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1142 - mae: 0.2687 - mse: 0.1142
64/89 [====================>.........] - ETA: 0s - loss: 0.0960 - mae: 0.2368 - mse: 0.0960
89/89 [==============================] - 0s 4ms/step - loss: 0.0869 - mae: 0.2264 - mse: 0.0869 - val_loss: 0.0637 - val_mae: 0.1842 - val_mse: 0.0637
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1103 - mae: 0.2851 - mse: 0.1103
64/89 [====================>.........] - ETA: 0s - loss: 0.0893 - mae: 0.2423 - mse: 0.0893
89/89 [==============================] - 0s 5ms/step - loss: 0.0912 - mae: 0.2401 - mse: 0.0912 - val_loss: 0.0684 - val_mae: 0.1935 - val_mse: 0.0684
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1169 - mae: 0.2478 - mse: 0.1169
64/89 [====================>.........] - ETA: 0s - loss: 0.0887 - mae: 0.2202 - mse: 0.0887
89/89 [==============================] - 0s 5ms/step - loss: 0.0867 - mae: 0.2166 - mse: 0.0867 - val_loss: 0.0690 - val_mae: 0.1916 - val_mse: 0.0690
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0675 - mae: 0.2073 - mse: 0.0675
64/89 [====================>.........] - ETA: 0s - loss: 0.0792 - mae: 0.2164 - mse: 0.0792
89/89 [==============================] - 0s 4ms/step - loss: 0.0797 - mae: 0.2062 - mse: 0.0797 - val_loss: 0.0624 - val_mae: 0.1665 - val_mse: 0.0624
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0758 - mae: 0.2113 - mse: 0.0758
64/89 [====================>.........] - ETA: 0s - loss: 0.0832 - mae: 0.2118 - mse: 0.0832
89/89 [==============================] - 0s 5ms/step - loss: 0.0763 - mae: 0.2007 - mse: 0.0763 - val_loss: 0.0525 - val_mae: 0.1470 - val_mse: 0.0525
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0602 - mae: 0.1803 - mse: 0.0602
64/89 [====================>.........] - ETA: 0s - loss: 0.0787 - mae: 0.2136 - mse: 0.0787
89/89 [==============================] - 0s 5ms/step - loss: 0.0704 - mae: 0.2026 - mse: 0.0704 - val_loss: 0.0452 - val_mae: 0.1413 - val_mse: 0.0452
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0725 - mae: 0.2020 - mse: 0.0725
64/89 [====================>.........] - ETA: 0s - loss: 0.0681 - mae: 0.1939 - mse: 0.0681
89/89 [==============================] - 0s 4ms/step - loss: 0.0644 - mae: 0.1933 - mse: 0.0644 - val_loss: 0.0440 - val_mae: 0.1516 - val_mse: 0.0440
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0319 - mae: 0.1284 - mse: 0.0319
64/89 [====================>.........] - ETA: 0s - loss: 0.0437 - mae: 0.1465 - mse: 0.0437
89/89 [==============================] - 0s 4ms/step - loss: 0.0493 - mae: 0.1594 - mse: 0.0493 - val_loss: 0.0441 - val_mae: 0.1508 - val_mse: 0.0441
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0712 - mae: 0.2085 - mse: 0.0712
64/89 [====================>.........] - ETA: 0s - loss: 0.0526 - mae: 0.1720 - mse: 0.0526
89/89 [==============================] - 0s 4ms/step - loss: 0.0511 - mae: 0.1727 - mse: 0.0511 - val_loss: 0.0232 - val_mae: 0.1140 - val_mse: 0.0232
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0298 - mae: 0.1281 - mse: 0.0298
64/89 [====================>.........] - ETA: 0s - loss: 0.0280 - mae: 0.1294 - mse: 0.0280
89/89 [==============================] - 0s 4ms/step - loss: 0.0363 - mae: 0.1458 - mse: 0.0363 - val_loss: 0.0269 - val_mae: 0.1339 - val_mse: 0.0269
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0211 - mae: 0.1020 - mse: 0.0211
64/89 [====================>.........] - ETA: 0s - loss: 0.0328 - mae: 0.1333 - mse: 0.0328
89/89 [==============================] - 0s 4ms/step - loss: 0.0322 - mae: 0.1352 - mse: 0.0322 - val_loss: 0.0127 - val_mae: 0.0962 - val_mse: 0.0127
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0256 - mae: 0.1226 - mse: 0.0256
64/89 [====================>.........] - ETA: 0s - loss: 0.0215 - mae: 0.1115 - mse: 0.0215
89/89 [==============================] - 0s 5ms/step - loss: 0.0204 - mae: 0.1121 - mse: 0.0204 - val_loss: 0.0223 - val_mae: 0.1346 - val_mse: 0.0223
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0154 - mae: 0.0932 - mse: 0.0154
64/89 [====================>.........] - ETA: 0s - loss: 0.0183 - mae: 0.1049 - mse: 0.0183
89/89 [==============================] - 0s 4ms/step - loss: 0.0207 - mae: 0.1099 - mse: 0.0207 - val_loss: 0.0325 - val_mae: 0.1671 - val_mse: 0.0325
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0176 - mae: 0.1075 - mse: 0.0176
64/89 [====================>.........] - ETA: 0s - loss: 0.0196 - mae: 0.1111 - mse: 0.0196
89/89 [==============================] - 0s 4ms/step - loss: 0.0213 - mae: 0.1170 - mse: 0.0213 - val_loss: 0.0190 - val_mae: 0.1236 - val_mse: 0.0190
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0170 - mae: 0.0948 - mse: 0.0170
64/89 [====================>.........] - ETA: 0s - loss: 0.0129 - mae: 0.0816 - mse: 0.0129
89/89 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0889 - mse: 0.0146 - val_loss: 0.0109 - val_mae: 0.0887 - val_mse: 0.0109
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0143 - mae: 0.0931 - mse: 0.0143
64/89 [====================>.........] - ETA: 0s - loss: 0.0142 - mae: 0.0922 - mse: 0.0142
89/89 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0953 - mse: 0.0151 - val_loss: 0.0193 - val_mae: 0.1243 - val_mse: 0.0193
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0109 - mae: 0.0832 - mse: 0.0109
64/89 [====================>.........] - ETA: 0s - loss: 0.0106 - mae: 0.0766 - mse: 0.0106
89/89 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0831 - mse: 0.0129 - val_loss: 0.0185 - val_mae: 0.1214 - val_mse: 0.0185
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0148 - mae: 0.0942 - mse: 0.0148
64/89 [====================>.........] - ETA: 0s - loss: 0.0151 - mae: 0.0946 - mse: 0.0151
89/89 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0940 - mse: 0.0145 - val_loss: 0.0188 - val_mae: 0.1211 - val_mse: 0.0188
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         0.         4.15966797]
average prediction= [3.2446837]
baseline= 7.98
eachuser= [0. 0. 0. 0. 4.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.0399169921875
['train-height-4.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
170 31
170 32
170 33
170 34
170 35
170 36
170 37
170 38
170 39
170 40
1_165_65_4_csi_a4_18.dat
165 42
165 43
1_165_65_4_csi_a4_5.dat
165 45
165 46
165 47
165 48
165 49
1_165_65_4_csi_a4_24.dat
165 51
165 52
165 53
165 54
1_165_65_4_csi_a4_7.dat
165 56
165 57
165 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
165 61
165 62
165 63
165 64
165 65
165 66
165 67
165 68
1_165_65_4_csi_a4_29.dat
165 70
165 71
165 72
165 73
2_165_50_4_csi_a4_13.dat
165 75
165 76
165 77
165 78
2_165_50_4_csi_a4_15.dat
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
2_165_50_4_csi_a4_25.dat
165 97
165 98
165 99
165 100
175 101
1_175_70_4_csi_a4_14.dat
175 103
1_175_70_4_csi_a4_16.dat
175 105
1_175_70_4_csi_a4_8.dat
175 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
175 111
175 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
175 115
1_175_70_4_csi_a4_28.dat
175 117
175 118
175 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
175 122
1_175_70_4_csi_a4_5.dat
175 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
175 127
1_175_70_4_csi_a4_22.dat
175 129
175 130
180 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
180 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
180 142
1_180_85_4_csi_a4_30.dat
180 144
180 145
180 146
180 147
1_180_85_4_csi_a4_20.dat
180 149
180 150
180 151
180 152
180 153
1_180_85_4_csi_a4_29.dat
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
180 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180 180]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.4093 - mae: 0.5375 - mse: 0.4093
64/89 [====================>.........] - ETA: 0s - loss: 0.3445 - mae: 0.4992 - mse: 0.3445
89/89 [==============================] - 1s 9ms/step - loss: 0.2818 - mae: 0.4374 - mse: 0.2818 - val_loss: 0.0206 - val_mae: 0.0579 - val_mse: 0.0206
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1235 - mae: 0.2808 - mse: 0.1235
64/89 [====================>.........] - ETA: 0s - loss: 0.1271 - mae: 0.2958 - mse: 0.1271
89/89 [==============================] - 0s 5ms/step - loss: 0.1667 - mae: 0.3275 - mse: 0.1667 - val_loss: 0.0447 - val_mae: 0.2059 - val_mse: 0.0447
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1710 - mae: 0.3223 - mse: 0.1710
64/89 [====================>.........] - ETA: 0s - loss: 0.1762 - mae: 0.3311 - mse: 0.1762
89/89 [==============================] - 0s 6ms/step - loss: 0.1645 - mae: 0.3241 - mse: 0.1645 - val_loss: 0.0180 - val_mae: 0.0704 - val_mse: 0.0180
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1515 - mae: 0.3094 - mse: 0.1515
64/89 [====================>.........] - ETA: 0s - loss: 0.1489 - mae: 0.3170 - mse: 0.1489
89/89 [==============================] - 0s 6ms/step - loss: 0.1432 - mae: 0.3087 - mse: 0.1432 - val_loss: 0.0333 - val_mae: 0.1365 - val_mse: 0.0333
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1127 - mae: 0.2628 - mse: 0.1127
64/89 [====================>.........] - ETA: 0s - loss: 0.1268 - mae: 0.2835 - mse: 0.1268
89/89 [==============================] - 1s 6ms/step - loss: 0.1406 - mae: 0.3050 - mse: 0.1406 - val_loss: 0.0338 - val_mae: 0.1420 - val_mse: 0.0338
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1442 - mae: 0.3182 - mse: 0.1442
64/89 [====================>.........] - ETA: 0s - loss: 0.1372 - mae: 0.3023 - mse: 0.1372
89/89 [==============================] - 0s 5ms/step - loss: 0.1460 - mae: 0.3112 - mse: 0.1460 - val_loss: 0.0186 - val_mae: 0.0706 - val_mse: 0.0186
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0966 - mae: 0.2388 - mse: 0.0966
64/89 [====================>.........] - ETA: 0s - loss: 0.1225 - mae: 0.2929 - mse: 0.1225
89/89 [==============================] - 0s 5ms/step - loss: 0.1233 - mae: 0.2911 - mse: 0.1233 - val_loss: 0.0155 - val_mae: 0.1037 - val_mse: 0.0155
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1194 - mae: 0.2658 - mse: 0.1194
64/89 [====================>.........] - ETA: 0s - loss: 0.1109 - mae: 0.2643 - mse: 0.1109
89/89 [==============================] - 0s 4ms/step - loss: 0.1183 - mae: 0.2816 - mse: 0.1183 - val_loss: 0.0187 - val_mae: 0.1261 - val_mse: 0.0187
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1259 - mae: 0.2942 - mse: 0.1259
64/89 [====================>.........] - ETA: 0s - loss: 0.1035 - mae: 0.2578 - mse: 0.1035
89/89 [==============================] - 0s 4ms/step - loss: 0.1207 - mae: 0.2850 - mse: 0.1207 - val_loss: 0.0116 - val_mae: 0.0936 - val_mse: 0.0116
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0797 - mae: 0.2346 - mse: 0.0797
64/89 [====================>.........] - ETA: 0s - loss: 0.0877 - mae: 0.2502 - mse: 0.0877
89/89 [==============================] - 0s 4ms/step - loss: 0.0897 - mae: 0.2499 - mse: 0.0897 - val_loss: 0.0086 - val_mae: 0.0462 - val_mse: 0.0086
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0941 - mae: 0.2592 - mse: 0.0941
64/89 [====================>.........] - ETA: 0s - loss: 0.0906 - mae: 0.2353 - mse: 0.0906
89/89 [==============================] - 0s 4ms/step - loss: 0.0983 - mae: 0.2471 - mse: 0.0983 - val_loss: 0.0099 - val_mae: 0.0647 - val_mse: 0.0099
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0892 - mae: 0.2339 - mse: 0.0892
64/89 [====================>.........] - ETA: 0s - loss: 0.0834 - mae: 0.2181 - mse: 0.0834
89/89 [==============================] - 0s 4ms/step - loss: 0.0870 - mae: 0.2297 - mse: 0.0870 - val_loss: 0.0063 - val_mae: 0.0492 - val_mse: 0.0063
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0854 - mae: 0.2391 - mse: 0.0854
64/89 [====================>.........] - ETA: 0s - loss: 0.0822 - mae: 0.2289 - mse: 0.0822
89/89 [==============================] - 0s 4ms/step - loss: 0.0791 - mae: 0.2274 - mse: 0.0791 - val_loss: 0.0029 - val_mae: 0.0376 - val_mse: 0.0029
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0654 - mae: 0.1945 - mse: 0.0654
64/89 [====================>.........] - ETA: 0s - loss: 0.0708 - mae: 0.2089 - mse: 0.0708
89/89 [==============================] - 0s 4ms/step - loss: 0.0728 - mae: 0.2158 - mse: 0.0728 - val_loss: 0.0024 - val_mae: 0.0329 - val_mse: 0.0024
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0535 - mae: 0.1599 - mse: 0.0535
64/89 [====================>.........] - ETA: 0s - loss: 0.0573 - mae: 0.1781 - mse: 0.0573
89/89 [==============================] - 0s 4ms/step - loss: 0.0638 - mae: 0.1971 - mse: 0.0638 - val_loss: 0.0060 - val_mae: 0.0707 - val_mse: 0.0060
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0517 - mae: 0.1624 - mse: 0.0517
64/89 [====================>.........] - ETA: 0s - loss: 0.0542 - mae: 0.1717 - mse: 0.0542
89/89 [==============================] - 0s 4ms/step - loss: 0.0560 - mae: 0.1794 - mse: 0.0560 - val_loss: 0.0080 - val_mae: 0.0837 - val_mse: 0.0080
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0570 - mae: 0.1928 - mse: 0.0570
64/89 [====================>.........] - ETA: 0s - loss: 0.0466 - mae: 0.1691 - mse: 0.0466
89/89 [==============================] - 0s 4ms/step - loss: 0.0536 - mae: 0.1764 - mse: 0.0536 - val_loss: 0.0038 - val_mae: 0.0390 - val_mse: 0.0038
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0505 - mae: 0.1745 - mse: 0.0505
64/89 [====================>.........] - ETA: 0s - loss: 0.0377 - mae: 0.1474 - mse: 0.0377
89/89 [==============================] - 0s 4ms/step - loss: 0.0448 - mae: 0.1624 - mse: 0.0448 - val_loss: 0.0047 - val_mae: 0.0500 - val_mse: 0.0047
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0515 - mae: 0.1796 - mse: 0.0515
64/89 [====================>.........] - ETA: 0s - loss: 0.0405 - mae: 0.1490 - mse: 0.0405
89/89 [==============================] - 0s 4ms/step - loss: 0.0411 - mae: 0.1524 - mse: 0.0411 - val_loss: 0.0103 - val_mae: 0.0943 - val_mse: 0.0103
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0423 - mae: 0.1389 - mse: 0.0423
64/89 [====================>.........] - ETA: 0s - loss: 0.0406 - mae: 0.1513 - mse: 0.0406
89/89 [==============================] - 0s 4ms/step - loss: 0.0391 - mae: 0.1515 - mse: 0.0391 - val_loss: 0.0099 - val_mae: 0.0950 - val_mse: 0.0099
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0486 - mae: 0.1891 - mse: 0.0486
64/89 [====================>.........] - ETA: 0s - loss: 0.0345 - mae: 0.1510 - mse: 0.0345
89/89 [==============================] - 0s 4ms/step - loss: 0.0311 - mae: 0.1410 - mse: 0.0311 - val_loss: 0.0051 - val_mae: 0.0657 - val_mse: 0.0051
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0331 - mae: 0.1436 - mse: 0.0331
64/89 [====================>.........] - ETA: 0s - loss: 0.0310 - mae: 0.1414 - mse: 0.0310
89/89 [==============================] - 0s 4ms/step - loss: 0.0294 - mae: 0.1369 - mse: 0.0294 - val_loss: 0.0033 - val_mae: 0.0481 - val_mse: 0.0033
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0189 - mae: 0.1011 - mse: 0.0189
64/89 [====================>.........] - ETA: 0s - loss: 0.0209 - mae: 0.1061 - mse: 0.0209
89/89 [==============================] - 0s 4ms/step - loss: 0.0257 - mae: 0.1206 - mse: 0.0257 - val_loss: 0.0289 - val_mae: 0.1650 - val_mse: 0.0289
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0386 - mae: 0.1549 - mse: 0.0386
64/89 [====================>.........] - ETA: 0s - loss: 0.0269 - mae: 0.1245 - mse: 0.0269
89/89 [==============================] - 0s 4ms/step - loss: 0.0251 - mae: 0.1152 - mse: 0.0251 - val_loss: 0.0079 - val_mae: 0.0806 - val_mse: 0.0079
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0123 - mae: 0.0893 - mse: 0.0123
64/89 [====================>.........] - ETA: 0s - loss: 0.0167 - mae: 0.1020 - mse: 0.0167
89/89 [==============================] - 0s 4ms/step - loss: 0.0262 - mae: 0.1232 - mse: 0.0262 - val_loss: 0.0050 - val_mae: 0.0623 - val_mse: 0.0050
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0112 - mae: 0.0789 - mse: 0.0112
64/89 [====================>.........] - ETA: 0s - loss: 0.0124 - mae: 0.0884 - mse: 0.0124
89/89 [==============================] - 0s 5ms/step - loss: 0.0147 - mae: 0.0897 - mse: 0.0147 - val_loss: 0.0254 - val_mae: 0.1579 - val_mse: 0.0254
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0234 - mae: 0.1132 - mse: 0.0234
64/89 [====================>.........] - ETA: 0s - loss: 0.0276 - mae: 0.1162 - mse: 0.0276
89/89 [==============================] - 0s 5ms/step - loss: 0.0249 - mae: 0.1097 - mse: 0.0249 - val_loss: 0.0053 - val_mae: 0.0678 - val_mse: 0.0053
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0175 - mae: 0.0980 - mse: 0.0175
64/89 [====================>.........] - ETA: 0s - loss: 0.0170 - mae: 0.0941 - mse: 0.0170
89/89 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 0.0999 - mse: 0.0178 - val_loss: 9.5319e-04 - val_mae: 0.0213 - val_mse: 9.5319e-04
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0136 - mae: 0.0880 - mse: 0.0136
64/89 [====================>.........] - ETA: 0s - loss: 0.0231 - mae: 0.0994 - mse: 0.0231
89/89 [==============================] - 0s 4ms/step - loss: 0.0186 - mae: 0.0892 - mse: 0.0186 - val_loss: 0.0177 - val_mae: 0.1297 - val_mse: 0.0177
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0188 - mae: 0.1020 - mse: 0.0188
64/89 [====================>.........] - ETA: 0s - loss: 0.0225 - mae: 0.1085 - mse: 0.0225
89/89 [==============================] - 0s 4ms/step - loss: 0.0205 - mae: 0.1051 - mse: 0.0205 - val_loss: 0.0114 - val_mae: 0.1031 - val_mse: 0.0114
Saving trained model...
96
Testing...
heightdiff= [ 0.          0.          0.          0.         10.74085999]
average prediction= [1.7945575]
baseline= 9.42
eachuser= [ 0.  0.  0.  0. 10.]
165 -:- nan
170 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.0740859985351563
