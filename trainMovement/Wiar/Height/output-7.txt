['train-height-7.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_7_csi_a7_8.dat
170 32
170 33
170 34
170 35
170 36
170 37
2_170_60_7_csi_a7_6.dat
170 39
170 40
1_165_65_7_csi_a7_2.dat
165 42
165 43
165 44
1_165_65_7_csi_a7_5.dat
1_165_65_7_csi_a7_7.dat
165 47
165 48
165 49
1_165_65_7_csi_a7_3.dat
165 51
165 52
165 53
165 54
165 55
165 56
1_165_65_7_csi_a7_23.dat
165 58
165 59
165 60
165 61
165 62
165 63
165 64
1_165_65_7_csi_a7_1.dat
1_165_65_7_csi_a7_30.dat
165 67
165 68
165 69
1_165_65_7_csi_a7_21.dat
165 71
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
165 97
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
1_175_70_7_csi_a7_21.dat
1_175_70_7_csi_a7_13.dat
1_180_85_7_csi_a7_10.dat
180 132
180 133
180 134
180 135
180 136
180 137
1_180_85_7_csi_a7_14.dat
180 139
1_180_85_7_csi_a7_30.dat
180 141
1_180_85_7_csi_a7_1.dat
180 143
1_180_85_7_csi_a7_12.dat
180 145
180 146
1_180_85_7_csi_a7_9.dat
180 148
180 149
180 150
1_180_85_7_csi_a7_29.dat
1_180_85_7_csi_a7_24.dat
1_180_85_7_csi_a7_15.dat
180 154
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_7_csi_a7_25.dat
1_180_75_7_csi_a7_19.dat
1_180_75_7_csi_a7_9.dat
1_180_75_7_csi_a7_14.dat
1_180_75_7_csi_a7_3.dat
1_180_75_7_csi_a7_21.dat
1_180_75_7_csi_a7_22.dat
1_180_75_7_csi_a7_4.dat
1_180_75_7_csi_a7_11.dat
1_180_75_7_csi_a7_20.dat
1_180_75_7_csi_a7_28.dat
1_180_75_7_csi_a7_24.dat
1_180_75_7_csi_a7_5.dat
1_180_75_7_csi_a7_1.dat
1_180_75_7_csi_a7_15.dat
1_180_75_7_csi_a7_16.dat
1_180_75_7_csi_a7_17.dat
1_180_75_7_csi_a7_27.dat
1_180_75_7_csi_a7_26.dat
1_180_75_7_csi_a7_12.dat
1_180_75_7_csi_a7_7.dat
1_180_75_7_csi_a7_30.dat
1_180_75_7_csi_a7_23.dat
1_180_75_7_csi_a7_10.dat
1_180_75_7_csi_a7_29.dat
1_180_75_7_csi_a7_13.dat
1_180_75_7_csi_a7_2.dat
1_180_75_7_csi_a7_8.dat
1_180_75_7_csi_a7_6.dat
1_180_75_7_csi_a7_18.dat
173 191
1_173_85_7_csi_a7_9.dat
1_173_85_7_csi_a7_12.dat
1_173_85_7_csi_a7_8.dat
173 195
1_173_85_7_csi_a7_25.dat
173 197
1_173_85_7_csi_a7_20.dat
173 199
1_173_85_7_csi_a7_22.dat
1_173_85_7_csi_a7_19.dat
173 202
1_173_85_7_csi_a7_11.dat
1_173_85_7_csi_a7_7.dat
1_173_85_7_csi_a7_6.dat
173 206
1_173_85_7_csi_a7_21.dat
1_173_85_7_csi_a7_17.dat
173 209
173 210
173 211
1_173_85_7_csi_a7_23.dat
1_173_85_7_csi_a7_18.dat
173 214
173 215
173 216
173 217
1_173_85_7_csi_a7_16.dat
173 219
1_173_85_7_csi_a7_10.dat
(153, 30, 3)
(153, 443, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173 173 173
 173 173 173 173 173 173 173 173 173]
(153, 443, 30, 3, 1)

Loaded dataset of 153 samples, each sized (443, 30, 3, 1)


Train on 122 samples
Test on 31 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 443, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 443, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 443, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 443, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 443, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 443, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 443, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 109 samples, validate on 13 samples
Epoch 1/30

 32/109 [=======>......................] - ETA: 1s - loss: 0.5145 - mae: 0.6325 - mse: 0.5145
 64/109 [================>.............] - ETA: 0s - loss: 0.4126 - mae: 0.5443 - mse: 0.4126
 96/109 [=========================>....] - ETA: 0s - loss: 0.3250 - mae: 0.4718 - mse: 0.3250
109/109 [==============================] - 1s 10ms/step - loss: 0.3045 - mae: 0.4559 - mse: 0.3045 - val_loss: 0.1449 - val_mae: 0.3280 - val_mse: 0.1449
Epoch 2/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1654 - mae: 0.3589 - mse: 0.1654
 64/109 [================>.............] - ETA: 0s - loss: 0.1485 - mae: 0.3466 - mse: 0.1485
 96/109 [=========================>....] - ETA: 0s - loss: 0.1410 - mae: 0.3258 - mse: 0.1410
109/109 [==============================] - 1s 7ms/step - loss: 0.1480 - mae: 0.3341 - mse: 0.1480 - val_loss: 0.1222 - val_mae: 0.3087 - val_mse: 0.1222
Epoch 3/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0971 - mae: 0.2691 - mse: 0.0971
 64/109 [================>.............] - ETA: 0s - loss: 0.1199 - mae: 0.2926 - mse: 0.1199
 96/109 [=========================>....] - ETA: 0s - loss: 0.1178 - mae: 0.2904 - mse: 0.1178
109/109 [==============================] - 1s 7ms/step - loss: 0.1205 - mae: 0.2973 - mse: 0.1205 - val_loss: 0.1800 - val_mae: 0.3566 - val_mse: 0.1800
Epoch 4/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0980 - mae: 0.2503 - mse: 0.0980
 64/109 [================>.............] - ETA: 0s - loss: 0.1056 - mae: 0.2669 - mse: 0.1056
 96/109 [=========================>....] - ETA: 0s - loss: 0.1044 - mae: 0.2646 - mse: 0.1044
109/109 [==============================] - 1s 7ms/step - loss: 0.1108 - mae: 0.2764 - mse: 0.1108 - val_loss: 0.1823 - val_mae: 0.3581 - val_mse: 0.1823
Epoch 5/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1288 - mae: 0.3317 - mse: 0.1288
 64/109 [================>.............] - ETA: 0s - loss: 0.1003 - mae: 0.2772 - mse: 0.1003
 96/109 [=========================>....] - ETA: 0s - loss: 0.1051 - mae: 0.2765 - mse: 0.1051
109/109 [==============================] - 1s 7ms/step - loss: 0.1048 - mae: 0.2750 - mse: 0.1048 - val_loss: 0.1430 - val_mae: 0.3286 - val_mse: 0.1430
Epoch 6/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0860 - mae: 0.2382 - mse: 0.0860
 64/109 [================>.............] - ETA: 0s - loss: 0.0936 - mae: 0.2587 - mse: 0.0936
 96/109 [=========================>....] - ETA: 0s - loss: 0.0962 - mae: 0.2616 - mse: 0.0962
109/109 [==============================] - 1s 7ms/step - loss: 0.0950 - mae: 0.2597 - mse: 0.0950 - val_loss: 0.1302 - val_mae: 0.3189 - val_mse: 0.1302
Epoch 7/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1033 - mae: 0.2766 - mse: 0.1033
 64/109 [================>.............] - ETA: 0s - loss: 0.0964 - mae: 0.2680 - mse: 0.0964
 96/109 [=========================>....] - ETA: 0s - loss: 0.0912 - mae: 0.2577 - mse: 0.0912
109/109 [==============================] - 1s 7ms/step - loss: 0.0897 - mae: 0.2553 - mse: 0.0897 - val_loss: 0.1348 - val_mae: 0.3175 - val_mse: 0.1348
Epoch 8/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0665 - mae: 0.2102 - mse: 0.0665
 64/109 [================>.............] - ETA: 0s - loss: 0.0692 - mae: 0.2125 - mse: 0.0692
 96/109 [=========================>....] - ETA: 0s - loss: 0.0826 - mae: 0.2381 - mse: 0.0826
109/109 [==============================] - 1s 7ms/step - loss: 0.0854 - mae: 0.2463 - mse: 0.0854 - val_loss: 0.1447 - val_mae: 0.3175 - val_mse: 0.1447
Epoch 9/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1062 - mae: 0.2784 - mse: 0.1062
 64/109 [================>.............] - ETA: 0s - loss: 0.0939 - mae: 0.2555 - mse: 0.0939
 96/109 [=========================>....] - ETA: 0s - loss: 0.0928 - mae: 0.2523 - mse: 0.0928
109/109 [==============================] - 1s 7ms/step - loss: 0.0941 - mae: 0.2513 - mse: 0.0941 - val_loss: 0.1506 - val_mae: 0.3134 - val_mse: 0.1506
Epoch 10/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0803 - mae: 0.2421 - mse: 0.0803
 64/109 [================>.............] - ETA: 0s - loss: 0.0714 - mae: 0.2250 - mse: 0.0714
 96/109 [=========================>....] - ETA: 0s - loss: 0.0776 - mae: 0.2298 - mse: 0.0776
109/109 [==============================] - 1s 7ms/step - loss: 0.0773 - mae: 0.2297 - mse: 0.0773 - val_loss: 0.1287 - val_mae: 0.2910 - val_mse: 0.1287
Epoch 11/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0761 - mae: 0.2205 - mse: 0.0761
 64/109 [================>.............] - ETA: 0s - loss: 0.0779 - mae: 0.2248 - mse: 0.0779
 96/109 [=========================>....] - ETA: 0s - loss: 0.0738 - mae: 0.2160 - mse: 0.0738
109/109 [==============================] - 1s 7ms/step - loss: 0.0718 - mae: 0.2139 - mse: 0.0718 - val_loss: 0.1186 - val_mae: 0.2711 - val_mse: 0.1186
Epoch 12/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0544 - mae: 0.1803 - mse: 0.0544
 64/109 [================>.............] - ETA: 0s - loss: 0.0690 - mae: 0.2126 - mse: 0.0690
 96/109 [=========================>....] - ETA: 0s - loss: 0.0681 - mae: 0.2131 - mse: 0.0681
109/109 [==============================] - 1s 7ms/step - loss: 0.0709 - mae: 0.2174 - mse: 0.0709 - val_loss: 0.1283 - val_mae: 0.2696 - val_mse: 0.1283
Epoch 13/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0658 - mae: 0.1909 - mse: 0.0658
 64/109 [================>.............] - ETA: 0s - loss: 0.0689 - mae: 0.2052 - mse: 0.0689
 96/109 [=========================>....] - ETA: 0s - loss: 0.0632 - mae: 0.1968 - mse: 0.0632
109/109 [==============================] - 1s 7ms/step - loss: 0.0590 - mae: 0.1894 - mse: 0.0590 - val_loss: 0.1324 - val_mae: 0.2650 - val_mse: 0.1324
Epoch 14/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0567 - mae: 0.1898 - mse: 0.0567
 64/109 [================>.............] - ETA: 0s - loss: 0.0551 - mae: 0.1823 - mse: 0.0551
 96/109 [=========================>....] - ETA: 0s - loss: 0.0502 - mae: 0.1756 - mse: 0.0502
109/109 [==============================] - 1s 7ms/step - loss: 0.0505 - mae: 0.1761 - mse: 0.0505 - val_loss: 0.1126 - val_mae: 0.2412 - val_mse: 0.1126
Epoch 15/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0671 - mae: 0.1991 - mse: 0.0671
 64/109 [================>.............] - ETA: 0s - loss: 0.0484 - mae: 0.1713 - mse: 0.0484
 96/109 [=========================>....] - ETA: 0s - loss: 0.0576 - mae: 0.1876 - mse: 0.0576
109/109 [==============================] - 1s 8ms/step - loss: 0.0542 - mae: 0.1791 - mse: 0.0542 - val_loss: 0.1198 - val_mae: 0.2390 - val_mse: 0.1198
Epoch 16/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0384 - mae: 0.1533 - mse: 0.0384
 64/109 [================>.............] - ETA: 0s - loss: 0.0421 - mae: 0.1577 - mse: 0.0421
 96/109 [=========================>....] - ETA: 0s - loss: 0.0533 - mae: 0.1726 - mse: 0.0533
109/109 [==============================] - 1s 7ms/step - loss: 0.0523 - mae: 0.1716 - mse: 0.0523 - val_loss: 0.1411 - val_mae: 0.2805 - val_mse: 0.1411
Epoch 17/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0440 - mae: 0.1642 - mse: 0.0440
 64/109 [================>.............] - ETA: 0s - loss: 0.0408 - mae: 0.1528 - mse: 0.0408
 96/109 [=========================>....] - ETA: 0s - loss: 0.0398 - mae: 0.1559 - mse: 0.0398
109/109 [==============================] - 1s 7ms/step - loss: 0.0374 - mae: 0.1509 - mse: 0.0374 - val_loss: 0.1027 - val_mae: 0.2044 - val_mse: 0.1027
Epoch 18/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0718 - mae: 0.1610 - mse: 0.0718
 64/109 [================>.............] - ETA: 0s - loss: 0.0538 - mae: 0.1485 - mse: 0.0538
 96/109 [=========================>....] - ETA: 0s - loss: 0.0440 - mae: 0.1372 - mse: 0.0440
109/109 [==============================] - 1s 7ms/step - loss: 0.0453 - mae: 0.1435 - mse: 0.0453 - val_loss: 0.1493 - val_mae: 0.2818 - val_mse: 0.1493
Epoch 19/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0555 - mae: 0.1577 - mse: 0.0555
 64/109 [================>.............] - ETA: 0s - loss: 0.0535 - mae: 0.1632 - mse: 0.0535
 96/109 [=========================>....] - ETA: 0s - loss: 0.0444 - mae: 0.1457 - mse: 0.0444
109/109 [==============================] - 1s 7ms/step - loss: 0.0448 - mae: 0.1476 - mse: 0.0448 - val_loss: 0.1165 - val_mae: 0.2127 - val_mse: 0.1165
Epoch 20/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0404 - mae: 0.1203 - mse: 0.0404
 64/109 [================>.............] - ETA: 0s - loss: 0.0337 - mae: 0.1195 - mse: 0.0337
 96/109 [=========================>....] - ETA: 0s - loss: 0.0395 - mae: 0.1336 - mse: 0.0395
109/109 [==============================] - 1s 7ms/step - loss: 0.0379 - mae: 0.1316 - mse: 0.0379 - val_loss: 0.1279 - val_mae: 0.2286 - val_mse: 0.1279
Epoch 21/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0261 - mae: 0.1051 - mse: 0.0261
 64/109 [================>.............] - ETA: 0s - loss: 0.0277 - mae: 0.1178 - mse: 0.0277
 96/109 [=========================>....] - ETA: 0s - loss: 0.0350 - mae: 0.1244 - mse: 0.0350
109/109 [==============================] - 1s 8ms/step - loss: 0.0335 - mae: 0.1242 - mse: 0.0335 - val_loss: 0.1176 - val_mae: 0.2084 - val_mse: 0.1176
Epoch 22/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0183 - mae: 0.1090 - mse: 0.0183
 64/109 [================>.............] - ETA: 0s - loss: 0.0249 - mae: 0.1181 - mse: 0.0249
 96/109 [=========================>....] - ETA: 0s - loss: 0.0377 - mae: 0.1324 - mse: 0.0377
109/109 [==============================] - 1s 8ms/step - loss: 0.0369 - mae: 0.1314 - mse: 0.0369 - val_loss: 0.1684 - val_mae: 0.2900 - val_mse: 0.1684
Epoch 23/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0569 - mae: 0.1708 - mse: 0.0569
 64/109 [================>.............] - ETA: 0s - loss: 0.0419 - mae: 0.1477 - mse: 0.0419
 96/109 [=========================>....] - ETA: 0s - loss: 0.0424 - mae: 0.1417 - mse: 0.0424
109/109 [==============================] - 1s 6ms/step - loss: 0.0396 - mae: 0.1382 - mse: 0.0396 - val_loss: 0.1115 - val_mae: 0.2033 - val_mse: 0.1115
Epoch 24/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0271 - mae: 0.1015 - mse: 0.0271
 64/109 [================>.............] - ETA: 0s - loss: 0.0240 - mae: 0.1019 - mse: 0.0240
 96/109 [=========================>....] - ETA: 0s - loss: 0.0322 - mae: 0.1178 - mse: 0.0322
109/109 [==============================] - 1s 5ms/step - loss: 0.0361 - mae: 0.1236 - mse: 0.0361 - val_loss: 0.1297 - val_mae: 0.2519 - val_mse: 0.1297
Epoch 25/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0426 - mae: 0.1389 - mse: 0.0426
 64/109 [================>.............] - ETA: 0s - loss: 0.0385 - mae: 0.1312 - mse: 0.0385
 96/109 [=========================>....] - ETA: 0s - loss: 0.0354 - mae: 0.1306 - mse: 0.0354
109/109 [==============================] - 1s 5ms/step - loss: 0.0341 - mae: 0.1293 - mse: 0.0341 - val_loss: 0.1409 - val_mae: 0.2572 - val_mse: 0.1409
Epoch 26/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0255 - mae: 0.1184 - mse: 0.0255
 64/109 [================>.............] - ETA: 0s - loss: 0.0386 - mae: 0.1415 - mse: 0.0386
 96/109 [=========================>....] - ETA: 0s - loss: 0.0355 - mae: 0.1292 - mse: 0.0355
109/109 [==============================] - 1s 5ms/step - loss: 0.0324 - mae: 0.1241 - mse: 0.0324 - val_loss: 0.1135 - val_mae: 0.2169 - val_mse: 0.1135
Epoch 27/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0356 - mae: 0.1314 - mse: 0.0356
 64/109 [================>.............] - ETA: 0s - loss: 0.0253 - mae: 0.1125 - mse: 0.0253
 96/109 [=========================>....] - ETA: 0s - loss: 0.0260 - mae: 0.1122 - mse: 0.0260
109/109 [==============================] - 1s 5ms/step - loss: 0.0265 - mae: 0.1124 - mse: 0.0265 - val_loss: 0.1380 - val_mae: 0.2377 - val_mse: 0.1380
Epoch 28/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0314 - mae: 0.1051 - mse: 0.0314
 64/109 [================>.............] - ETA: 0s - loss: 0.0339 - mae: 0.1211 - mse: 0.0339
 96/109 [=========================>....] - ETA: 0s - loss: 0.0378 - mae: 0.1292 - mse: 0.0378
109/109 [==============================] - 1s 5ms/step - loss: 0.0359 - mae: 0.1273 - mse: 0.0359 - val_loss: 0.1195 - val_mae: 0.2250 - val_mse: 0.1195
Epoch 29/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0173 - mae: 0.1019 - mse: 0.0173
 64/109 [================>.............] - ETA: 0s - loss: 0.0195 - mae: 0.0968 - mse: 0.0195
 96/109 [=========================>....] - ETA: 0s - loss: 0.0322 - mae: 0.1203 - mse: 0.0322
109/109 [==============================] - 1s 5ms/step - loss: 0.0316 - mae: 0.1227 - mse: 0.0316 - val_loss: 0.1013 - val_mae: 0.1908 - val_mse: 0.1013
Epoch 30/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0530 - mae: 0.1417 - mse: 0.0530
 64/109 [================>.............] - ETA: 0s - loss: 0.0335 - mae: 0.1163 - mse: 0.0335
 96/109 [=========================>....] - ETA: 0s - loss: 0.0298 - mae: 0.1093 - mse: 0.0298
109/109 [==============================] - 1s 5ms/step - loss: 0.0284 - mae: 0.1079 - mse: 0.0284 - val_loss: 0.1322 - val_mae: 0.2448 - val_mse: 0.1322
Saving trained model...
67
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         30.91665649]
average prediction= [4.8247232]
baseline= 7.467741935483871
eachuser= [0. 0. 0. 0. 0. 6.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 5.1527760823567705
['train-height-7.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_7_csi_a7_8.dat
170 32
170 33
170 34
170 35
170 36
170 37
2_170_60_7_csi_a7_6.dat
170 39
170 40
1_165_65_7_csi_a7_2.dat
165 42
165 43
165 44
1_165_65_7_csi_a7_5.dat
1_165_65_7_csi_a7_7.dat
165 47
165 48
165 49
1_165_65_7_csi_a7_3.dat
165 51
165 52
165 53
165 54
165 55
165 56
1_165_65_7_csi_a7_23.dat
165 58
165 59
165 60
165 61
165 62
165 63
165 64
1_165_65_7_csi_a7_1.dat
1_165_65_7_csi_a7_30.dat
165 67
165 68
165 69
1_165_65_7_csi_a7_21.dat
165 71
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
165 97
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
1_175_70_7_csi_a7_21.dat
1_175_70_7_csi_a7_13.dat
1_180_85_7_csi_a7_10.dat
180 132
180 133
180 134
180 135
180 136
180 137
1_180_85_7_csi_a7_14.dat
180 139
1_180_85_7_csi_a7_30.dat
180 141
1_180_85_7_csi_a7_1.dat
180 143
1_180_85_7_csi_a7_12.dat
180 145
180 146
1_180_85_7_csi_a7_9.dat
180 148
180 149
180 150
1_180_85_7_csi_a7_29.dat
1_180_85_7_csi_a7_24.dat
1_180_85_7_csi_a7_15.dat
180 154
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_7_csi_a7_25.dat
1_180_75_7_csi_a7_19.dat
1_180_75_7_csi_a7_9.dat
1_180_75_7_csi_a7_14.dat
1_180_75_7_csi_a7_3.dat
1_180_75_7_csi_a7_21.dat
1_180_75_7_csi_a7_22.dat
1_180_75_7_csi_a7_4.dat
1_180_75_7_csi_a7_11.dat
1_180_75_7_csi_a7_20.dat
1_180_75_7_csi_a7_28.dat
1_180_75_7_csi_a7_24.dat
1_180_75_7_csi_a7_5.dat
1_180_75_7_csi_a7_1.dat
1_180_75_7_csi_a7_15.dat
1_180_75_7_csi_a7_16.dat
1_180_75_7_csi_a7_17.dat
1_180_75_7_csi_a7_27.dat
1_180_75_7_csi_a7_26.dat
1_180_75_7_csi_a7_12.dat
1_180_75_7_csi_a7_7.dat
1_180_75_7_csi_a7_30.dat
1_180_75_7_csi_a7_23.dat
1_180_75_7_csi_a7_10.dat
1_180_75_7_csi_a7_29.dat
1_180_75_7_csi_a7_13.dat
1_180_75_7_csi_a7_2.dat
1_180_75_7_csi_a7_8.dat
1_180_75_7_csi_a7_6.dat
1_180_75_7_csi_a7_18.dat
173 191
1_173_85_7_csi_a7_9.dat
1_173_85_7_csi_a7_12.dat
1_173_85_7_csi_a7_8.dat
173 195
1_173_85_7_csi_a7_25.dat
173 197
1_173_85_7_csi_a7_20.dat
173 199
1_173_85_7_csi_a7_22.dat
1_173_85_7_csi_a7_19.dat
173 202
1_173_85_7_csi_a7_11.dat
1_173_85_7_csi_a7_7.dat
1_173_85_7_csi_a7_6.dat
173 206
1_173_85_7_csi_a7_21.dat
1_173_85_7_csi_a7_17.dat
173 209
173 210
173 211
1_173_85_7_csi_a7_23.dat
1_173_85_7_csi_a7_18.dat
173 214
173 215
173 216
173 217
1_173_85_7_csi_a7_16.dat
173 219
1_173_85_7_csi_a7_10.dat
(153, 30, 3)
(153, 443, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173 173 173
 173 173 173 173 173 173 173 173 173]
(153, 443, 30, 3, 1)

Loaded dataset of 153 samples, each sized (443, 30, 3, 1)


Train on 122 samples
Test on 31 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 443, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 443, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 443, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 443, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 443, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 443, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 443, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 109 samples, validate on 13 samples
Epoch 1/30

 32/109 [=======>......................] - ETA: 1s - loss: 0.3561 - mae: 0.5056 - mse: 0.3561
 64/109 [================>.............] - ETA: 0s - loss: 0.2775 - mae: 0.4265 - mse: 0.2775
 96/109 [=========================>....] - ETA: 0s - loss: 0.2338 - mae: 0.3869 - mse: 0.2338
109/109 [==============================] - 1s 10ms/step - loss: 0.2198 - mae: 0.3750 - mse: 0.2198 - val_loss: 0.1591 - val_mae: 0.3560 - val_mse: 0.1591
Epoch 2/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1484 - mae: 0.3473 - mse: 0.1484
 64/109 [================>.............] - ETA: 0s - loss: 0.1307 - mae: 0.3240 - mse: 0.1307
 96/109 [=========================>....] - ETA: 0s - loss: 0.1301 - mae: 0.3230 - mse: 0.1301
109/109 [==============================] - 1s 7ms/step - loss: 0.1336 - mae: 0.3246 - mse: 0.1336 - val_loss: 0.1590 - val_mae: 0.3543 - val_mse: 0.1590
Epoch 3/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1317 - mae: 0.3266 - mse: 0.1317
 64/109 [================>.............] - ETA: 0s - loss: 0.1219 - mae: 0.3041 - mse: 0.1219
 96/109 [=========================>....] - ETA: 0s - loss: 0.1230 - mae: 0.2986 - mse: 0.1230
109/109 [==============================] - 1s 8ms/step - loss: 0.1191 - mae: 0.2907 - mse: 0.1191 - val_loss: 0.1827 - val_mae: 0.3733 - val_mse: 0.1827
Epoch 4/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0954 - mae: 0.2528 - mse: 0.0954
 64/109 [================>.............] - ETA: 0s - loss: 0.0949 - mae: 0.2510 - mse: 0.0949
 96/109 [=========================>....] - ETA: 0s - loss: 0.1095 - mae: 0.2716 - mse: 0.1095
109/109 [==============================] - 1s 7ms/step - loss: 0.1146 - mae: 0.2786 - mse: 0.1146 - val_loss: 0.1612 - val_mae: 0.3584 - val_mse: 0.1612
Epoch 5/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1188 - mae: 0.2777 - mse: 0.1188
 64/109 [================>.............] - ETA: 0s - loss: 0.1053 - mae: 0.2699 - mse: 0.1053
 96/109 [=========================>....] - ETA: 0s - loss: 0.0945 - mae: 0.2565 - mse: 0.0945
109/109 [==============================] - 1s 7ms/step - loss: 0.0959 - mae: 0.2562 - mse: 0.0959 - val_loss: 0.1384 - val_mae: 0.3296 - val_mse: 0.1384
Epoch 6/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0871 - mae: 0.2349 - mse: 0.0871
 64/109 [================>.............] - ETA: 0s - loss: 0.0929 - mae: 0.2452 - mse: 0.0929
 96/109 [=========================>....] - ETA: 0s - loss: 0.0978 - mae: 0.2494 - mse: 0.0978
109/109 [==============================] - 1s 7ms/step - loss: 0.0958 - mae: 0.2482 - mse: 0.0958 - val_loss: 0.1435 - val_mae: 0.3332 - val_mse: 0.1435
Epoch 7/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0843 - mae: 0.2184 - mse: 0.0843
 64/109 [================>.............] - ETA: 0s - loss: 0.0878 - mae: 0.2280 - mse: 0.0878
 96/109 [=========================>....] - ETA: 0s - loss: 0.0865 - mae: 0.2315 - mse: 0.0865
109/109 [==============================] - 1s 7ms/step - loss: 0.0883 - mae: 0.2337 - mse: 0.0883 - val_loss: 0.1453 - val_mae: 0.3278 - val_mse: 0.1453
Epoch 8/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0545 - mae: 0.1849 - mse: 0.0545
 64/109 [================>.............] - ETA: 0s - loss: 0.0802 - mae: 0.2261 - mse: 0.0802
 96/109 [=========================>....] - ETA: 0s - loss: 0.0858 - mae: 0.2286 - mse: 0.0858
109/109 [==============================] - 1s 7ms/step - loss: 0.0831 - mae: 0.2261 - mse: 0.0831 - val_loss: 0.1374 - val_mae: 0.3130 - val_mse: 0.1374
Epoch 9/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0659 - mae: 0.2090 - mse: 0.0659
 64/109 [================>.............] - ETA: 0s - loss: 0.0723 - mae: 0.2163 - mse: 0.0723
 96/109 [=========================>....] - ETA: 0s - loss: 0.0754 - mae: 0.2181 - mse: 0.0754
109/109 [==============================] - 1s 8ms/step - loss: 0.0771 - mae: 0.2197 - mse: 0.0771 - val_loss: 0.1227 - val_mae: 0.2888 - val_mse: 0.1227
Epoch 10/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0729 - mae: 0.2009 - mse: 0.0729
 64/109 [================>.............] - ETA: 0s - loss: 0.0628 - mae: 0.1912 - mse: 0.0628
 96/109 [=========================>....] - ETA: 0s - loss: 0.0666 - mae: 0.1944 - mse: 0.0666
109/109 [==============================] - 1s 7ms/step - loss: 0.0651 - mae: 0.1909 - mse: 0.0651 - val_loss: 0.1211 - val_mae: 0.2816 - val_mse: 0.1211
Epoch 11/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0709 - mae: 0.2074 - mse: 0.0709
 64/109 [================>.............] - ETA: 0s - loss: 0.0624 - mae: 0.1966 - mse: 0.0624
 96/109 [=========================>....] - ETA: 0s - loss: 0.0607 - mae: 0.1892 - mse: 0.0607
109/109 [==============================] - 1s 8ms/step - loss: 0.0598 - mae: 0.1845 - mse: 0.0598 - val_loss: 0.1180 - val_mae: 0.2743 - val_mse: 0.1180
Epoch 12/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0810 - mae: 0.2225 - mse: 0.0810
 64/109 [================>.............] - ETA: 0s - loss: 0.0730 - mae: 0.2021 - mse: 0.0730
 96/109 [=========================>....] - ETA: 0s - loss: 0.0661 - mae: 0.1925 - mse: 0.0661
109/109 [==============================] - 1s 7ms/step - loss: 0.0634 - mae: 0.1876 - mse: 0.0634 - val_loss: 0.1164 - val_mae: 0.2718 - val_mse: 0.1164
Epoch 13/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0404 - mae: 0.1544 - mse: 0.0404
 64/109 [================>.............] - ETA: 0s - loss: 0.0585 - mae: 0.1869 - mse: 0.0585
 96/109 [=========================>....] - ETA: 0s - loss: 0.0589 - mae: 0.1842 - mse: 0.0589
109/109 [==============================] - 1s 6ms/step - loss: 0.0659 - mae: 0.1914 - mse: 0.0659 - val_loss: 0.1142 - val_mae: 0.2695 - val_mse: 0.1142
Epoch 14/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0671 - mae: 0.1933 - mse: 0.0671
 64/109 [================>.............] - ETA: 0s - loss: 0.0651 - mae: 0.1866 - mse: 0.0651
 96/109 [=========================>....] - ETA: 0s - loss: 0.0549 - mae: 0.1666 - mse: 0.0549
109/109 [==============================] - 1s 5ms/step - loss: 0.0577 - mae: 0.1692 - mse: 0.0577 - val_loss: 0.1161 - val_mae: 0.2811 - val_mse: 0.1161
Epoch 15/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0662 - mae: 0.1904 - mse: 0.0662
 64/109 [================>.............] - ETA: 0s - loss: 0.0591 - mae: 0.1803 - mse: 0.0591
 96/109 [=========================>....] - ETA: 0s - loss: 0.0570 - mae: 0.1730 - mse: 0.0570
109/109 [==============================] - 1s 5ms/step - loss: 0.0560 - mae: 0.1691 - mse: 0.0560 - val_loss: 0.1137 - val_mae: 0.2814 - val_mse: 0.1137
Epoch 16/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0568 - mae: 0.1765 - mse: 0.0568
 64/109 [================>.............] - ETA: 0s - loss: 0.0551 - mae: 0.1606 - mse: 0.0551
 96/109 [=========================>....] - ETA: 0s - loss: 0.0498 - mae: 0.1563 - mse: 0.0498
109/109 [==============================] - 1s 5ms/step - loss: 0.0531 - mae: 0.1617 - mse: 0.0531 - val_loss: 0.1066 - val_mae: 0.2660 - val_mse: 0.1066
Epoch 17/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0534 - mae: 0.1724 - mse: 0.0534
 64/109 [================>.............] - ETA: 0s - loss: 0.0508 - mae: 0.1610 - mse: 0.0508
 96/109 [=========================>....] - ETA: 0s - loss: 0.0600 - mae: 0.1731 - mse: 0.0600
109/109 [==============================] - 1s 5ms/step - loss: 0.0546 - mae: 0.1642 - mse: 0.0546 - val_loss: 0.1056 - val_mae: 0.2614 - val_mse: 0.1056
Epoch 18/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0420 - mae: 0.1418 - mse: 0.0420
 64/109 [================>.............] - ETA: 0s - loss: 0.0389 - mae: 0.1426 - mse: 0.0389
 96/109 [=========================>....] - ETA: 0s - loss: 0.0410 - mae: 0.1451 - mse: 0.0410
109/109 [==============================] - 1s 5ms/step - loss: 0.0482 - mae: 0.1525 - mse: 0.0482 - val_loss: 0.1181 - val_mae: 0.2842 - val_mse: 0.1181
Epoch 19/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0727 - mae: 0.1892 - mse: 0.0727
 64/109 [================>.............] - ETA: 0s - loss: 0.0528 - mae: 0.1564 - mse: 0.0528
 96/109 [=========================>....] - ETA: 0s - loss: 0.0480 - mae: 0.1519 - mse: 0.0480
109/109 [==============================] - 1s 5ms/step - loss: 0.0454 - mae: 0.1480 - mse: 0.0454 - val_loss: 0.0960 - val_mae: 0.2522 - val_mse: 0.0960
Epoch 20/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0678 - mae: 0.2012 - mse: 0.0678
 64/109 [================>.............] - ETA: 0s - loss: 0.0589 - mae: 0.1717 - mse: 0.0589
 96/109 [=========================>....] - ETA: 0s - loss: 0.0561 - mae: 0.1672 - mse: 0.0561
109/109 [==============================] - 1s 5ms/step - loss: 0.0503 - mae: 0.1562 - mse: 0.0503 - val_loss: 0.0999 - val_mae: 0.2692 - val_mse: 0.0999
Epoch 21/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0577 - mae: 0.1672 - mse: 0.0577
 64/109 [================>.............] - ETA: 0s - loss: 0.0428 - mae: 0.1472 - mse: 0.0428
 96/109 [=========================>....] - ETA: 0s - loss: 0.0502 - mae: 0.1588 - mse: 0.0502
109/109 [==============================] - 1s 5ms/step - loss: 0.0500 - mae: 0.1607 - mse: 0.0500 - val_loss: 0.0970 - val_mae: 0.2593 - val_mse: 0.0970
Epoch 22/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0573 - mae: 0.1647 - mse: 0.0573
 64/109 [================>.............] - ETA: 0s - loss: 0.0678 - mae: 0.1701 - mse: 0.0678
 96/109 [=========================>....] - ETA: 0s - loss: 0.0529 - mae: 0.1548 - mse: 0.0529
109/109 [==============================] - 1s 5ms/step - loss: 0.0497 - mae: 0.1518 - mse: 0.0497 - val_loss: 0.0937 - val_mae: 0.2494 - val_mse: 0.0937
Epoch 23/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0448 - mae: 0.1394 - mse: 0.0448
 64/109 [================>.............] - ETA: 0s - loss: 0.0313 - mae: 0.1220 - mse: 0.0313
 96/109 [=========================>....] - ETA: 0s - loss: 0.0401 - mae: 0.1333 - mse: 0.0401
109/109 [==============================] - 1s 5ms/step - loss: 0.0423 - mae: 0.1394 - mse: 0.0423 - val_loss: 0.0954 - val_mae: 0.2572 - val_mse: 0.0954
Epoch 24/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0455 - mae: 0.1354 - mse: 0.0455
 64/109 [================>.............] - ETA: 0s - loss: 0.0327 - mae: 0.1188 - mse: 0.0327
 96/109 [=========================>....] - ETA: 0s - loss: 0.0429 - mae: 0.1241 - mse: 0.0429
109/109 [==============================] - 1s 5ms/step - loss: 0.0407 - mae: 0.1237 - mse: 0.0407 - val_loss: 0.0993 - val_mae: 0.2714 - val_mse: 0.0993
Epoch 25/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0465 - mae: 0.1413 - mse: 0.0465
 64/109 [================>.............] - ETA: 0s - loss: 0.0419 - mae: 0.1375 - mse: 0.0419
 96/109 [=========================>....] - ETA: 0s - loss: 0.0512 - mae: 0.1509 - mse: 0.0512
109/109 [==============================] - 1s 5ms/step - loss: 0.0486 - mae: 0.1487 - mse: 0.0486 - val_loss: 0.1064 - val_mae: 0.2783 - val_mse: 0.1064
Epoch 26/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0422 - mae: 0.1437 - mse: 0.0422
 64/109 [================>.............] - ETA: 0s - loss: 0.0478 - mae: 0.1427 - mse: 0.0478
 96/109 [=========================>....] - ETA: 0s - loss: 0.0442 - mae: 0.1400 - mse: 0.0442
109/109 [==============================] - 1s 5ms/step - loss: 0.0411 - mae: 0.1360 - mse: 0.0411 - val_loss: 0.0897 - val_mae: 0.2425 - val_mse: 0.0897
Epoch 27/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0397 - mae: 0.1245 - mse: 0.0397
 64/109 [================>.............] - ETA: 0s - loss: 0.0472 - mae: 0.1416 - mse: 0.0472
 96/109 [=========================>....] - ETA: 0s - loss: 0.0418 - mae: 0.1283 - mse: 0.0418
109/109 [==============================] - 1s 5ms/step - loss: 0.0395 - mae: 0.1281 - mse: 0.0395 - val_loss: 0.1064 - val_mae: 0.2905 - val_mse: 0.1064
Epoch 28/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0453 - mae: 0.1360 - mse: 0.0453
 64/109 [================>.............] - ETA: 0s - loss: 0.0467 - mae: 0.1417 - mse: 0.0467
 96/109 [=========================>....] - ETA: 0s - loss: 0.0368 - mae: 0.1254 - mse: 0.0368
109/109 [==============================] - 1s 5ms/step - loss: 0.0344 - mae: 0.1214 - mse: 0.0344 - val_loss: 0.0808 - val_mae: 0.2143 - val_mse: 0.0808
Epoch 29/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0266 - mae: 0.1290 - mse: 0.0266
 64/109 [================>.............] - ETA: 0s - loss: 0.0311 - mae: 0.1264 - mse: 0.0311
 96/109 [=========================>....] - ETA: 0s - loss: 0.0376 - mae: 0.1294 - mse: 0.0376
109/109 [==============================] - 1s 5ms/step - loss: 0.0375 - mae: 0.1290 - mse: 0.0375 - val_loss: 0.1066 - val_mae: 0.2912 - val_mse: 0.1066
Epoch 30/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0138 - mae: 0.0881 - mse: 0.0138
 64/109 [================>.............] - ETA: 0s - loss: 0.0500 - mae: 0.1452 - mse: 0.0500
 96/109 [=========================>....] - ETA: 0s - loss: 0.0435 - mae: 0.1346 - mse: 0.0435
109/109 [==============================] - 1s 6ms/step - loss: 0.0391 - mae: 0.1258 - mse: 0.0391 - val_loss: 0.0824 - val_mae: 0.2412 - val_mse: 0.0824
Saving trained model...
67
Testing...
heightdiff= [0.         0.         0.         0.         0.         6.50944519]
average prediction= [4.3977046]
baseline= 6.338709677419355
eachuser= [0. 0. 0. 0. 0. 4.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.6273612976074219
['train-height-7.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_7_csi_a7_8.dat
170 32
170 33
170 34
170 35
170 36
170 37
2_170_60_7_csi_a7_6.dat
170 39
170 40
1_165_65_7_csi_a7_2.dat
165 42
165 43
165 44
1_165_65_7_csi_a7_5.dat
1_165_65_7_csi_a7_7.dat
165 47
165 48
165 49
1_165_65_7_csi_a7_3.dat
165 51
165 52
165 53
165 54
165 55
165 56
1_165_65_7_csi_a7_23.dat
165 58
165 59
165 60
165 61
165 62
165 63
165 64
1_165_65_7_csi_a7_1.dat
1_165_65_7_csi_a7_30.dat
165 67
165 68
165 69
1_165_65_7_csi_a7_21.dat
165 71
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
165 97
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
1_175_70_7_csi_a7_21.dat
1_175_70_7_csi_a7_13.dat
1_180_85_7_csi_a7_10.dat
180 132
180 133
180 134
180 135
180 136
180 137
1_180_85_7_csi_a7_14.dat
180 139
1_180_85_7_csi_a7_30.dat
180 141
1_180_85_7_csi_a7_1.dat
180 143
1_180_85_7_csi_a7_12.dat
180 145
180 146
1_180_85_7_csi_a7_9.dat
180 148
180 149
180 150
1_180_85_7_csi_a7_29.dat
1_180_85_7_csi_a7_24.dat
1_180_85_7_csi_a7_15.dat
180 154
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_7_csi_a7_25.dat
1_180_75_7_csi_a7_19.dat
1_180_75_7_csi_a7_9.dat
1_180_75_7_csi_a7_14.dat
1_180_75_7_csi_a7_3.dat
1_180_75_7_csi_a7_21.dat
1_180_75_7_csi_a7_22.dat
1_180_75_7_csi_a7_4.dat
1_180_75_7_csi_a7_11.dat
1_180_75_7_csi_a7_20.dat
1_180_75_7_csi_a7_28.dat
1_180_75_7_csi_a7_24.dat
1_180_75_7_csi_a7_5.dat
1_180_75_7_csi_a7_1.dat
1_180_75_7_csi_a7_15.dat
1_180_75_7_csi_a7_16.dat
1_180_75_7_csi_a7_17.dat
1_180_75_7_csi_a7_27.dat
1_180_75_7_csi_a7_26.dat
1_180_75_7_csi_a7_12.dat
1_180_75_7_csi_a7_7.dat
1_180_75_7_csi_a7_30.dat
1_180_75_7_csi_a7_23.dat
1_180_75_7_csi_a7_10.dat
1_180_75_7_csi_a7_29.dat
1_180_75_7_csi_a7_13.dat
1_180_75_7_csi_a7_2.dat
1_180_75_7_csi_a7_8.dat
1_180_75_7_csi_a7_6.dat
1_180_75_7_csi_a7_18.dat
173 191
1_173_85_7_csi_a7_9.dat
1_173_85_7_csi_a7_12.dat
1_173_85_7_csi_a7_8.dat
173 195
1_173_85_7_csi_a7_25.dat
173 197
1_173_85_7_csi_a7_20.dat
173 199
1_173_85_7_csi_a7_22.dat
1_173_85_7_csi_a7_19.dat
173 202
1_173_85_7_csi_a7_11.dat
1_173_85_7_csi_a7_7.dat
1_173_85_7_csi_a7_6.dat
173 206
1_173_85_7_csi_a7_21.dat
1_173_85_7_csi_a7_17.dat
173 209
173 210
173 211
1_173_85_7_csi_a7_23.dat
1_173_85_7_csi_a7_18.dat
173 214
173 215
173 216
173 217
1_173_85_7_csi_a7_16.dat
173 219
1_173_85_7_csi_a7_10.dat
(153, 30, 3)
(153, 443, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173 173 173
 173 173 173 173 173 173 173 173 173]
(153, 443, 30, 3, 1)

Loaded dataset of 153 samples, each sized (443, 30, 3, 1)


Train on 122 samples
Test on 31 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 443, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 443, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 443, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 443, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 443, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 443, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 443, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 109 samples, validate on 13 samples
Epoch 1/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.4026 - mae: 0.5641 - mse: 0.4026
 64/109 [================>.............] - ETA: 0s - loss: 0.3483 - mae: 0.5068 - mse: 0.3483
 96/109 [=========================>....] - ETA: 0s - loss: 0.2743 - mae: 0.4347 - mse: 0.2743
109/109 [==============================] - 1s 8ms/step - loss: 0.2664 - mae: 0.4289 - mse: 0.2664 - val_loss: 0.0878 - val_mae: 0.2823 - val_mse: 0.0878
Epoch 2/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1676 - mae: 0.3685 - mse: 0.1676
 64/109 [================>.............] - ETA: 0s - loss: 0.1658 - mae: 0.3399 - mse: 0.1658
 96/109 [=========================>....] - ETA: 0s - loss: 0.1674 - mae: 0.3470 - mse: 0.1674
109/109 [==============================] - 1s 5ms/step - loss: 0.1608 - mae: 0.3387 - mse: 0.1608 - val_loss: 0.1060 - val_mae: 0.2765 - val_mse: 0.1060
Epoch 3/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0906 - mae: 0.2529 - mse: 0.0906
 64/109 [================>.............] - ETA: 0s - loss: 0.1071 - mae: 0.2745 - mse: 0.1071
 96/109 [=========================>....] - ETA: 0s - loss: 0.1198 - mae: 0.2884 - mse: 0.1198
109/109 [==============================] - 1s 5ms/step - loss: 0.1242 - mae: 0.2945 - mse: 0.1242 - val_loss: 0.1496 - val_mae: 0.2896 - val_mse: 0.1496
Epoch 4/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1604 - mae: 0.3407 - mse: 0.1604
 64/109 [================>.............] - ETA: 0s - loss: 0.1434 - mae: 0.3140 - mse: 0.1434
 96/109 [=========================>....] - ETA: 0s - loss: 0.1330 - mae: 0.3024 - mse: 0.1330
109/109 [==============================] - 1s 5ms/step - loss: 0.1306 - mae: 0.3038 - mse: 0.1306 - val_loss: 0.1587 - val_mae: 0.3007 - val_mse: 0.1587
Epoch 5/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1302 - mae: 0.3221 - mse: 0.1302
 64/109 [================>.............] - ETA: 0s - loss: 0.1238 - mae: 0.2961 - mse: 0.1238
 96/109 [=========================>....] - ETA: 0s - loss: 0.1181 - mae: 0.2828 - mse: 0.1181
109/109 [==============================] - 1s 5ms/step - loss: 0.1224 - mae: 0.2903 - mse: 0.1224 - val_loss: 0.1378 - val_mae: 0.2795 - val_mse: 0.1378
Epoch 6/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1197 - mae: 0.2895 - mse: 0.1197
 64/109 [================>.............] - ETA: 0s - loss: 0.1296 - mae: 0.3102 - mse: 0.1296
 96/109 [=========================>....] - ETA: 0s - loss: 0.1234 - mae: 0.3032 - mse: 0.1234
109/109 [==============================] - 1s 5ms/step - loss: 0.1204 - mae: 0.2993 - mse: 0.1204 - val_loss: 0.1176 - val_mae: 0.2749 - val_mse: 0.1176
Epoch 7/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0755 - mae: 0.2343 - mse: 0.0755
 64/109 [================>.............] - ETA: 0s - loss: 0.1103 - mae: 0.2775 - mse: 0.1103
 96/109 [=========================>....] - ETA: 0s - loss: 0.1176 - mae: 0.2863 - mse: 0.1176
109/109 [==============================] - 1s 5ms/step - loss: 0.1125 - mae: 0.2803 - mse: 0.1125 - val_loss: 0.1295 - val_mae: 0.2775 - val_mse: 0.1295
Epoch 8/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1088 - mae: 0.2802 - mse: 0.1088
 64/109 [================>.............] - ETA: 0s - loss: 0.1088 - mae: 0.2714 - mse: 0.1088
 96/109 [=========================>....] - ETA: 0s - loss: 0.1023 - mae: 0.2614 - mse: 0.1023
109/109 [==============================] - 1s 5ms/step - loss: 0.1060 - mae: 0.2672 - mse: 0.1060 - val_loss: 0.1345 - val_mae: 0.2775 - val_mse: 0.1345
Epoch 9/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1037 - mae: 0.2620 - mse: 0.1037
 64/109 [================>.............] - ETA: 0s - loss: 0.1200 - mae: 0.2931 - mse: 0.1200
 96/109 [=========================>....] - ETA: 0s - loss: 0.1028 - mae: 0.2616 - mse: 0.1028
109/109 [==============================] - 1s 5ms/step - loss: 0.0994 - mae: 0.2538 - mse: 0.0994 - val_loss: 0.1355 - val_mae: 0.2835 - val_mse: 0.1355
Epoch 10/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1044 - mae: 0.2698 - mse: 0.1044
 64/109 [================>.............] - ETA: 0s - loss: 0.0957 - mae: 0.2541 - mse: 0.0957
 96/109 [=========================>....] - ETA: 0s - loss: 0.0921 - mae: 0.2445 - mse: 0.0921
109/109 [==============================] - 1s 5ms/step - loss: 0.0922 - mae: 0.2447 - mse: 0.0922 - val_loss: 0.1239 - val_mae: 0.2820 - val_mse: 0.1239
Epoch 11/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1111 - mae: 0.2667 - mse: 0.1111
 64/109 [================>.............] - ETA: 0s - loss: 0.0903 - mae: 0.2470 - mse: 0.0903
 96/109 [=========================>....] - ETA: 0s - loss: 0.0925 - mae: 0.2456 - mse: 0.0925
109/109 [==============================] - 1s 5ms/step - loss: 0.0925 - mae: 0.2440 - mse: 0.0925 - val_loss: 0.1124 - val_mae: 0.2692 - val_mse: 0.1124
Epoch 12/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0715 - mae: 0.2261 - mse: 0.0715
 64/109 [================>.............] - ETA: 0s - loss: 0.0796 - mae: 0.2383 - mse: 0.0796
 96/109 [=========================>....] - ETA: 0s - loss: 0.0926 - mae: 0.2493 - mse: 0.0926
109/109 [==============================] - 1s 5ms/step - loss: 0.0917 - mae: 0.2480 - mse: 0.0917 - val_loss: 0.1258 - val_mae: 0.2617 - val_mse: 0.1258
Epoch 13/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0672 - mae: 0.2117 - mse: 0.0672
 64/109 [================>.............] - ETA: 0s - loss: 0.0837 - mae: 0.2307 - mse: 0.0837
 96/109 [=========================>....] - ETA: 0s - loss: 0.0981 - mae: 0.2494 - mse: 0.0981
109/109 [==============================] - 1s 5ms/step - loss: 0.0917 - mae: 0.2402 - mse: 0.0917 - val_loss: 0.1049 - val_mae: 0.2427 - val_mse: 0.1049
Epoch 14/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0671 - mae: 0.1984 - mse: 0.0671
 64/109 [================>.............] - ETA: 0s - loss: 0.0806 - mae: 0.2269 - mse: 0.0806
 96/109 [=========================>....] - ETA: 0s - loss: 0.0794 - mae: 0.2207 - mse: 0.0794
109/109 [==============================] - 1s 5ms/step - loss: 0.0813 - mae: 0.2217 - mse: 0.0813 - val_loss: 0.1013 - val_mae: 0.2326 - val_mse: 0.1013
Epoch 15/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0942 - mae: 0.2493 - mse: 0.0942
 64/109 [================>.............] - ETA: 0s - loss: 0.0772 - mae: 0.2161 - mse: 0.0772
 96/109 [=========================>....] - ETA: 0s - loss: 0.0707 - mae: 0.2074 - mse: 0.0707
109/109 [==============================] - 1s 5ms/step - loss: 0.0748 - mae: 0.2120 - mse: 0.0748 - val_loss: 0.1018 - val_mae: 0.2222 - val_mse: 0.1018
Epoch 16/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0481 - mae: 0.1674 - mse: 0.0481
 64/109 [================>.............] - ETA: 0s - loss: 0.0683 - mae: 0.1896 - mse: 0.0683
 96/109 [=========================>....] - ETA: 0s - loss: 0.0783 - mae: 0.2102 - mse: 0.0783
109/109 [==============================] - 1s 5ms/step - loss: 0.0764 - mae: 0.2096 - mse: 0.0764 - val_loss: 0.0860 - val_mae: 0.2075 - val_mse: 0.0860
Epoch 17/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1094 - mae: 0.2475 - mse: 0.1094
 64/109 [================>.............] - ETA: 0s - loss: 0.0958 - mae: 0.2415 - mse: 0.0958
 96/109 [=========================>....] - ETA: 0s - loss: 0.0760 - mae: 0.2109 - mse: 0.0760
109/109 [==============================] - 1s 7ms/step - loss: 0.0731 - mae: 0.2090 - mse: 0.0731 - val_loss: 0.1010 - val_mae: 0.2086 - val_mse: 0.1010
Epoch 18/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0642 - mae: 0.2102 - mse: 0.0642
 64/109 [================>.............] - ETA: 0s - loss: 0.0701 - mae: 0.1983 - mse: 0.0701
 96/109 [=========================>....] - ETA: 0s - loss: 0.0779 - mae: 0.2049 - mse: 0.0779
109/109 [==============================] - 1s 7ms/step - loss: 0.0702 - mae: 0.1912 - mse: 0.0702 - val_loss: 0.1066 - val_mae: 0.2242 - val_mse: 0.1066
Epoch 19/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1102 - mae: 0.2441 - mse: 0.1102
 64/109 [================>.............] - ETA: 0s - loss: 0.0736 - mae: 0.1975 - mse: 0.0736
 96/109 [=========================>....] - ETA: 0s - loss: 0.0720 - mae: 0.2000 - mse: 0.0720
109/109 [==============================] - 1s 7ms/step - loss: 0.0672 - mae: 0.1933 - mse: 0.0672 - val_loss: 0.0962 - val_mae: 0.2177 - val_mse: 0.0962
Epoch 20/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0704 - mae: 0.1955 - mse: 0.0704
 64/109 [================>.............] - ETA: 0s - loss: 0.0532 - mae: 0.1714 - mse: 0.0532
 96/109 [=========================>....] - ETA: 0s - loss: 0.0564 - mae: 0.1768 - mse: 0.0564
109/109 [==============================] - 1s 7ms/step - loss: 0.0622 - mae: 0.1834 - mse: 0.0622 - val_loss: 0.0780 - val_mae: 0.1911 - val_mse: 0.0780
Epoch 21/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0613 - mae: 0.1937 - mse: 0.0613
 64/109 [================>.............] - ETA: 0s - loss: 0.0507 - mae: 0.1626 - mse: 0.0507
 96/109 [=========================>....] - ETA: 0s - loss: 0.0585 - mae: 0.1760 - mse: 0.0585
109/109 [==============================] - 1s 7ms/step - loss: 0.0593 - mae: 0.1768 - mse: 0.0593 - val_loss: 0.0689 - val_mae: 0.1701 - val_mse: 0.0689
Epoch 22/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0476 - mae: 0.1679 - mse: 0.0476
 64/109 [================>.............] - ETA: 0s - loss: 0.0479 - mae: 0.1581 - mse: 0.0479
 96/109 [=========================>....] - ETA: 0s - loss: 0.0632 - mae: 0.1831 - mse: 0.0632
109/109 [==============================] - 1s 7ms/step - loss: 0.0593 - mae: 0.1771 - mse: 0.0593 - val_loss: 0.0859 - val_mae: 0.2128 - val_mse: 0.0859
Epoch 23/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0970 - mae: 0.2173 - mse: 0.0970
 64/109 [================>.............] - ETA: 0s - loss: 0.0734 - mae: 0.1891 - mse: 0.0734
 96/109 [=========================>....] - ETA: 0s - loss: 0.0640 - mae: 0.1762 - mse: 0.0640
109/109 [==============================] - 1s 7ms/step - loss: 0.0601 - mae: 0.1693 - mse: 0.0601 - val_loss: 0.0718 - val_mae: 0.1839 - val_mse: 0.0718
Epoch 24/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0348 - mae: 0.1285 - mse: 0.0348
 64/109 [================>.............] - ETA: 0s - loss: 0.0444 - mae: 0.1399 - mse: 0.0444
 96/109 [=========================>....] - ETA: 0s - loss: 0.0509 - mae: 0.1492 - mse: 0.0509
109/109 [==============================] - 1s 7ms/step - loss: 0.0560 - mae: 0.1570 - mse: 0.0560 - val_loss: 0.1088 - val_mae: 0.2515 - val_mse: 0.1088
Epoch 25/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0494 - mae: 0.1665 - mse: 0.0494
 64/109 [================>.............] - ETA: 0s - loss: 0.0468 - mae: 0.1654 - mse: 0.0468
 96/109 [=========================>....] - ETA: 0s - loss: 0.0586 - mae: 0.1821 - mse: 0.0586
109/109 [==============================] - 1s 7ms/step - loss: 0.0635 - mae: 0.1823 - mse: 0.0635 - val_loss: 0.0619 - val_mae: 0.1667 - val_mse: 0.0619
Epoch 26/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0446 - mae: 0.1525 - mse: 0.0446
 64/109 [================>.............] - ETA: 0s - loss: 0.0530 - mae: 0.1751 - mse: 0.0530
 96/109 [=========================>....] - ETA: 0s - loss: 0.0710 - mae: 0.1960 - mse: 0.0710
109/109 [==============================] - 1s 7ms/step - loss: 0.0687 - mae: 0.1918 - mse: 0.0687 - val_loss: 0.0544 - val_mae: 0.1738 - val_mse: 0.0544
Epoch 27/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0608 - mae: 0.1728 - mse: 0.0608
 64/109 [================>.............] - ETA: 0s - loss: 0.0569 - mae: 0.1713 - mse: 0.0569
 96/109 [=========================>....] - ETA: 0s - loss: 0.0490 - mae: 0.1592 - mse: 0.0490
109/109 [==============================] - 1s 7ms/step - loss: 0.0501 - mae: 0.1616 - mse: 0.0501 - val_loss: 0.1023 - val_mae: 0.2753 - val_mse: 0.1023
Epoch 28/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0694 - mae: 0.2072 - mse: 0.0694
 64/109 [================>.............] - ETA: 0s - loss: 0.0618 - mae: 0.1935 - mse: 0.0618
 96/109 [=========================>....] - ETA: 0s - loss: 0.0562 - mae: 0.1789 - mse: 0.0562
109/109 [==============================] - 1s 7ms/step - loss: 0.0562 - mae: 0.1801 - mse: 0.0562 - val_loss: 0.0444 - val_mae: 0.1506 - val_mse: 0.0444
Epoch 29/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0632 - mae: 0.1693 - mse: 0.0632
 64/109 [================>.............] - ETA: 0s - loss: 0.0538 - mae: 0.1626 - mse: 0.0538
 96/109 [=========================>....] - ETA: 0s - loss: 0.0551 - mae: 0.1604 - mse: 0.0551
109/109 [==============================] - 1s 9ms/step - loss: 0.0519 - mae: 0.1577 - mse: 0.0519 - val_loss: 0.0657 - val_mae: 0.1874 - val_mse: 0.0657
Epoch 30/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0447 - mae: 0.1510 - mse: 0.0447
 64/109 [================>.............] - ETA: 0s - loss: 0.0395 - mae: 0.1331 - mse: 0.0395
 96/109 [=========================>....] - ETA: 0s - loss: 0.0482 - mae: 0.1409 - mse: 0.0482
109/109 [==============================] - 1s 7ms/step - loss: 0.0514 - mae: 0.1503 - mse: 0.0514 - val_loss: 0.0917 - val_mae: 0.2351 - val_mse: 0.0917
Saving trained model...
67
Testing...
heightdiff= [0.        0.        0.        0.        0.        5.9138031]
average prediction= [4.1774664]
baseline= 5.887096774193548
eachuser= [0. 0. 0. 0. 0. 4.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.4784507751464844
['train-height-7.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_7_csi_a7_8.dat
170 32
170 33
170 34
170 35
170 36
170 37
2_170_60_7_csi_a7_6.dat
170 39
170 40
1_165_65_7_csi_a7_2.dat
165 42
165 43
165 44
1_165_65_7_csi_a7_5.dat
1_165_65_7_csi_a7_7.dat
165 47
165 48
165 49
1_165_65_7_csi_a7_3.dat
165 51
165 52
165 53
165 54
165 55
165 56
1_165_65_7_csi_a7_23.dat
165 58
165 59
165 60
165 61
165 62
165 63
165 64
1_165_65_7_csi_a7_1.dat
1_165_65_7_csi_a7_30.dat
165 67
165 68
165 69
1_165_65_7_csi_a7_21.dat
165 71
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
165 97
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
1_175_70_7_csi_a7_21.dat
1_175_70_7_csi_a7_13.dat
1_180_85_7_csi_a7_10.dat
180 132
180 133
180 134
180 135
180 136
180 137
1_180_85_7_csi_a7_14.dat
180 139
1_180_85_7_csi_a7_30.dat
180 141
1_180_85_7_csi_a7_1.dat
180 143
1_180_85_7_csi_a7_12.dat
180 145
180 146
1_180_85_7_csi_a7_9.dat
180 148
180 149
180 150
1_180_85_7_csi_a7_29.dat
1_180_85_7_csi_a7_24.dat
1_180_85_7_csi_a7_15.dat
180 154
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_7_csi_a7_25.dat
1_180_75_7_csi_a7_19.dat
1_180_75_7_csi_a7_9.dat
1_180_75_7_csi_a7_14.dat
1_180_75_7_csi_a7_3.dat
1_180_75_7_csi_a7_21.dat
1_180_75_7_csi_a7_22.dat
1_180_75_7_csi_a7_4.dat
1_180_75_7_csi_a7_11.dat
1_180_75_7_csi_a7_20.dat
1_180_75_7_csi_a7_28.dat
1_180_75_7_csi_a7_24.dat
1_180_75_7_csi_a7_5.dat
1_180_75_7_csi_a7_1.dat
1_180_75_7_csi_a7_15.dat
1_180_75_7_csi_a7_16.dat
1_180_75_7_csi_a7_17.dat
1_180_75_7_csi_a7_27.dat
1_180_75_7_csi_a7_26.dat
1_180_75_7_csi_a7_12.dat
1_180_75_7_csi_a7_7.dat
1_180_75_7_csi_a7_30.dat
1_180_75_7_csi_a7_23.dat
1_180_75_7_csi_a7_10.dat
1_180_75_7_csi_a7_29.dat
1_180_75_7_csi_a7_13.dat
1_180_75_7_csi_a7_2.dat
1_180_75_7_csi_a7_8.dat
1_180_75_7_csi_a7_6.dat
1_180_75_7_csi_a7_18.dat
173 191
1_173_85_7_csi_a7_9.dat
1_173_85_7_csi_a7_12.dat
1_173_85_7_csi_a7_8.dat
173 195
1_173_85_7_csi_a7_25.dat
173 197
1_173_85_7_csi_a7_20.dat
173 199
1_173_85_7_csi_a7_22.dat
1_173_85_7_csi_a7_19.dat
173 202
1_173_85_7_csi_a7_11.dat
1_173_85_7_csi_a7_7.dat
1_173_85_7_csi_a7_6.dat
173 206
1_173_85_7_csi_a7_21.dat
1_173_85_7_csi_a7_17.dat
173 209
173 210
173 211
1_173_85_7_csi_a7_23.dat
1_173_85_7_csi_a7_18.dat
173 214
173 215
173 216
173 217
1_173_85_7_csi_a7_16.dat
173 219
1_173_85_7_csi_a7_10.dat
(153, 30, 3)
(153, 443, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173 173 173
 173 173 173 173 173 173 173 173 173]
(153, 443, 30, 3, 1)

Loaded dataset of 153 samples, each sized (443, 30, 3, 1)


Train on 122 samples
Test on 31 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 443, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 443, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 443, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 443, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 443, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 443, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 443, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 109 samples, validate on 13 samples
Epoch 1/30

 32/109 [=======>......................] - ETA: 1s - loss: 0.3442 - mae: 0.4939 - mse: 0.3442
 64/109 [================>.............] - ETA: 0s - loss: 0.2733 - mae: 0.4494 - mse: 0.2733
 96/109 [=========================>....] - ETA: 0s - loss: 0.2399 - mae: 0.4217 - mse: 0.2399
109/109 [==============================] - 1s 10ms/step - loss: 0.2201 - mae: 0.3965 - mse: 0.2201 - val_loss: 0.1959 - val_mae: 0.4118 - val_mse: 0.1959
Epoch 2/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1156 - mae: 0.2569 - mse: 0.1156
 64/109 [================>.............] - ETA: 0s - loss: 0.1524 - mae: 0.2853 - mse: 0.1524
 96/109 [=========================>....] - ETA: 0s - loss: 0.1437 - mae: 0.2816 - mse: 0.1437
109/109 [==============================] - 1s 8ms/step - loss: 0.1584 - mae: 0.2966 - mse: 0.1584 - val_loss: 0.1653 - val_mae: 0.3824 - val_mse: 0.1653
Epoch 3/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1312 - mae: 0.2708 - mse: 0.1312
 64/109 [================>.............] - ETA: 0s - loss: 0.1387 - mae: 0.2840 - mse: 0.1387
 96/109 [=========================>....] - ETA: 0s - loss: 0.1184 - mae: 0.2581 - mse: 0.1184
109/109 [==============================] - 1s 7ms/step - loss: 0.1152 - mae: 0.2580 - mse: 0.1152 - val_loss: 0.1741 - val_mae: 0.3764 - val_mse: 0.1741
Epoch 4/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1277 - mae: 0.3035 - mse: 0.1277
 64/109 [================>.............] - ETA: 0s - loss: 0.0998 - mae: 0.2632 - mse: 0.0998
 96/109 [=========================>....] - ETA: 0s - loss: 0.1072 - mae: 0.2693 - mse: 0.1072
109/109 [==============================] - 1s 7ms/step - loss: 0.1087 - mae: 0.2710 - mse: 0.1087 - val_loss: 0.1637 - val_mae: 0.3554 - val_mse: 0.1637
Epoch 5/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0859 - mae: 0.2486 - mse: 0.0859
 64/109 [================>.............] - ETA: 0s - loss: 0.1056 - mae: 0.2647 - mse: 0.1056
 96/109 [=========================>....] - ETA: 0s - loss: 0.0930 - mae: 0.2412 - mse: 0.0930
109/109 [==============================] - 1s 8ms/step - loss: 0.0894 - mae: 0.2367 - mse: 0.0894 - val_loss: 0.1257 - val_mae: 0.3161 - val_mse: 0.1257
Epoch 6/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0792 - mae: 0.2158 - mse: 0.0792
 64/109 [================>.............] - ETA: 0s - loss: 0.0724 - mae: 0.2048 - mse: 0.0724
 96/109 [=========================>....] - ETA: 0s - loss: 0.0766 - mae: 0.2110 - mse: 0.0766
109/109 [==============================] - 1s 7ms/step - loss: 0.0787 - mae: 0.2161 - mse: 0.0787 - val_loss: 0.1068 - val_mae: 0.2759 - val_mse: 0.1068
Epoch 7/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0982 - mae: 0.2726 - mse: 0.0982
 64/109 [================>.............] - ETA: 0s - loss: 0.0889 - mae: 0.2431 - mse: 0.0889
 96/109 [=========================>....] - ETA: 0s - loss: 0.0925 - mae: 0.2453 - mse: 0.0925
109/109 [==============================] - 1s 7ms/step - loss: 0.0914 - mae: 0.2434 - mse: 0.0914 - val_loss: 0.1126 - val_mae: 0.2928 - val_mse: 0.1126
Epoch 8/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0660 - mae: 0.1725 - mse: 0.0660
 64/109 [================>.............] - ETA: 0s - loss: 0.0784 - mae: 0.2056 - mse: 0.0784
 96/109 [=========================>....] - ETA: 0s - loss: 0.0769 - mae: 0.2101 - mse: 0.0769
109/109 [==============================] - 1s 7ms/step - loss: 0.0745 - mae: 0.2060 - mse: 0.0745 - val_loss: 0.1265 - val_mae: 0.3127 - val_mse: 0.1265
Epoch 9/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0819 - mae: 0.2135 - mse: 0.0819
 64/109 [================>.............] - ETA: 0s - loss: 0.0736 - mae: 0.2033 - mse: 0.0736
 96/109 [=========================>....] - ETA: 0s - loss: 0.0744 - mae: 0.2071 - mse: 0.0744
109/109 [==============================] - 1s 7ms/step - loss: 0.0688 - mae: 0.1978 - mse: 0.0688 - val_loss: 0.1213 - val_mae: 0.3077 - val_mse: 0.1213
Epoch 10/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0922 - mae: 0.2269 - mse: 0.0922
 64/109 [================>.............] - ETA: 0s - loss: 0.0671 - mae: 0.1917 - mse: 0.0671
 96/109 [=========================>....] - ETA: 0s - loss: 0.0663 - mae: 0.1914 - mse: 0.0663
109/109 [==============================] - 1s 7ms/step - loss: 0.0708 - mae: 0.2010 - mse: 0.0708 - val_loss: 0.1049 - val_mae: 0.2837 - val_mse: 0.1049
Epoch 11/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0594 - mae: 0.1765 - mse: 0.0594
 64/109 [================>.............] - ETA: 0s - loss: 0.0646 - mae: 0.1837 - mse: 0.0646
 96/109 [=========================>....] - ETA: 0s - loss: 0.0657 - mae: 0.1915 - mse: 0.0657
109/109 [==============================] - 1s 8ms/step - loss: 0.0614 - mae: 0.1831 - mse: 0.0614 - val_loss: 0.0940 - val_mae: 0.2600 - val_mse: 0.0940
Epoch 12/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0801 - mae: 0.2299 - mse: 0.0801
 64/109 [================>.............] - ETA: 0s - loss: 0.0832 - mae: 0.2278 - mse: 0.0832
 96/109 [=========================>....] - ETA: 0s - loss: 0.0730 - mae: 0.2077 - mse: 0.0730
109/109 [==============================] - 1s 7ms/step - loss: 0.0710 - mae: 0.2032 - mse: 0.0710 - val_loss: 0.0928 - val_mae: 0.2624 - val_mse: 0.0928
Epoch 13/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0547 - mae: 0.1653 - mse: 0.0547
 64/109 [================>.............] - ETA: 0s - loss: 0.0545 - mae: 0.1709 - mse: 0.0545
 96/109 [=========================>....] - ETA: 0s - loss: 0.0611 - mae: 0.1814 - mse: 0.0611
109/109 [==============================] - 1s 7ms/step - loss: 0.0618 - mae: 0.1828 - mse: 0.0618 - val_loss: 0.0931 - val_mae: 0.2637 - val_mse: 0.0931
Epoch 14/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0509 - mae: 0.1513 - mse: 0.0509
 64/109 [================>.............] - ETA: 0s - loss: 0.0641 - mae: 0.1767 - mse: 0.0641
 96/109 [=========================>....] - ETA: 0s - loss: 0.0541 - mae: 0.1645 - mse: 0.0541
109/109 [==============================] - 1s 7ms/step - loss: 0.0565 - mae: 0.1695 - mse: 0.0565 - val_loss: 0.0875 - val_mae: 0.2561 - val_mse: 0.0875
Epoch 15/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0472 - mae: 0.1566 - mse: 0.0472
 64/109 [================>.............] - ETA: 0s - loss: 0.0414 - mae: 0.1477 - mse: 0.0414
 96/109 [=========================>....] - ETA: 0s - loss: 0.0495 - mae: 0.1612 - mse: 0.0495
109/109 [==============================] - 1s 7ms/step - loss: 0.0529 - mae: 0.1667 - mse: 0.0529 - val_loss: 0.0753 - val_mae: 0.2343 - val_mse: 0.0753
Epoch 16/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0477 - mae: 0.1529 - mse: 0.0477
 64/109 [================>.............] - ETA: 0s - loss: 0.0525 - mae: 0.1654 - mse: 0.0525
 96/109 [=========================>....] - ETA: 0s - loss: 0.0533 - mae: 0.1657 - mse: 0.0533
109/109 [==============================] - 1s 7ms/step - loss: 0.0557 - mae: 0.1706 - mse: 0.0557 - val_loss: 0.0737 - val_mae: 0.2323 - val_mse: 0.0737
Epoch 17/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0400 - mae: 0.1553 - mse: 0.0400
 64/109 [================>.............] - ETA: 0s - loss: 0.0611 - mae: 0.1822 - mse: 0.0611
 96/109 [=========================>....] - ETA: 0s - loss: 0.0515 - mae: 0.1602 - mse: 0.0515
109/109 [==============================] - 1s 7ms/step - loss: 0.0501 - mae: 0.1612 - mse: 0.0501 - val_loss: 0.0795 - val_mae: 0.2390 - val_mse: 0.0795
Epoch 18/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0413 - mae: 0.1532 - mse: 0.0413
 64/109 [================>.............] - ETA: 0s - loss: 0.0448 - mae: 0.1610 - mse: 0.0448
 96/109 [=========================>....] - ETA: 0s - loss: 0.0463 - mae: 0.1619 - mse: 0.0463
109/109 [==============================] - 1s 7ms/step - loss: 0.0474 - mae: 0.1625 - mse: 0.0474 - val_loss: 0.0743 - val_mae: 0.2206 - val_mse: 0.0743
Epoch 19/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0433 - mae: 0.1634 - mse: 0.0433
 64/109 [================>.............] - ETA: 0s - loss: 0.0437 - mae: 0.1559 - mse: 0.0437
 96/109 [=========================>....] - ETA: 0s - loss: 0.0464 - mae: 0.1625 - mse: 0.0464
109/109 [==============================] - 1s 9ms/step - loss: 0.0427 - mae: 0.1545 - mse: 0.0427 - val_loss: 0.0637 - val_mae: 0.1993 - val_mse: 0.0637
Epoch 20/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0402 - mae: 0.1349 - mse: 0.0402
 64/109 [================>.............] - ETA: 0s - loss: 0.0425 - mae: 0.1410 - mse: 0.0425
 96/109 [=========================>....] - ETA: 0s - loss: 0.0456 - mae: 0.1510 - mse: 0.0456
109/109 [==============================] - 1s 9ms/step - loss: 0.0427 - mae: 0.1447 - mse: 0.0427 - val_loss: 0.0662 - val_mae: 0.2120 - val_mse: 0.0662
Epoch 21/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0421 - mae: 0.1352 - mse: 0.0421
 64/109 [================>.............] - ETA: 0s - loss: 0.0418 - mae: 0.1356 - mse: 0.0418
 96/109 [=========================>....] - ETA: 0s - loss: 0.0346 - mae: 0.1272 - mse: 0.0346
109/109 [==============================] - 1s 9ms/step - loss: 0.0393 - mae: 0.1353 - mse: 0.0393 - val_loss: 0.0635 - val_mae: 0.2075 - val_mse: 0.0635
Epoch 22/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0188 - mae: 0.0938 - mse: 0.0188
 64/109 [================>.............] - ETA: 0s - loss: 0.0416 - mae: 0.1411 - mse: 0.0416
 96/109 [=========================>....] - ETA: 0s - loss: 0.0414 - mae: 0.1413 - mse: 0.0414
109/109 [==============================] - 1s 9ms/step - loss: 0.0390 - mae: 0.1373 - mse: 0.0390 - val_loss: 0.0596 - val_mae: 0.1974 - val_mse: 0.0596
Epoch 23/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0247 - mae: 0.1165 - mse: 0.0247
 64/109 [================>.............] - ETA: 0s - loss: 0.0530 - mae: 0.1489 - mse: 0.0530
 96/109 [=========================>....] - ETA: 0s - loss: 0.0416 - mae: 0.1310 - mse: 0.0416
109/109 [==============================] - 1s 9ms/step - loss: 0.0410 - mae: 0.1331 - mse: 0.0410 - val_loss: 0.0637 - val_mae: 0.1960 - val_mse: 0.0637
Epoch 24/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0212 - mae: 0.1013 - mse: 0.0212
 64/109 [================>.............] - ETA: 0s - loss: 0.0277 - mae: 0.1089 - mse: 0.0277
 96/109 [=========================>....] - ETA: 0s - loss: 0.0355 - mae: 0.1257 - mse: 0.0355
109/109 [==============================] - 1s 9ms/step - loss: 0.0411 - mae: 0.1316 - mse: 0.0411 - val_loss: 0.0622 - val_mae: 0.1860 - val_mse: 0.0622
Epoch 25/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0373 - mae: 0.1250 - mse: 0.0373
 64/109 [================>.............] - ETA: 0s - loss: 0.0319 - mae: 0.1177 - mse: 0.0319
 96/109 [=========================>....] - ETA: 0s - loss: 0.0362 - mae: 0.1310 - mse: 0.0362
109/109 [==============================] - 1s 9ms/step - loss: 0.0369 - mae: 0.1332 - mse: 0.0369 - val_loss: 0.0645 - val_mae: 0.1858 - val_mse: 0.0645
Epoch 26/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0478 - mae: 0.1474 - mse: 0.0478
 64/109 [================>.............] - ETA: 0s - loss: 0.0338 - mae: 0.1250 - mse: 0.0338
 96/109 [=========================>....] - ETA: 0s - loss: 0.0332 - mae: 0.1201 - mse: 0.0332
109/109 [==============================] - 1s 9ms/step - loss: 0.0316 - mae: 0.1193 - mse: 0.0316 - val_loss: 0.0472 - val_mae: 0.1405 - val_mse: 0.0472
Epoch 27/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0507 - mae: 0.1412 - mse: 0.0507
 64/109 [================>.............] - ETA: 0s - loss: 0.0607 - mae: 0.1538 - mse: 0.0607
 96/109 [=========================>....] - ETA: 0s - loss: 0.0495 - mae: 0.1424 - mse: 0.0495
109/109 [==============================] - 1s 7ms/step - loss: 0.0474 - mae: 0.1415 - mse: 0.0474 - val_loss: 0.0609 - val_mae: 0.1870 - val_mse: 0.0609
Epoch 28/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0398 - mae: 0.1450 - mse: 0.0398
 64/109 [================>.............] - ETA: 0s - loss: 0.0490 - mae: 0.1592 - mse: 0.0490
 96/109 [=========================>....] - ETA: 0s - loss: 0.0462 - mae: 0.1531 - mse: 0.0462
109/109 [==============================] - 1s 7ms/step - loss: 0.0449 - mae: 0.1516 - mse: 0.0449 - val_loss: 0.0582 - val_mae: 0.1765 - val_mse: 0.0582
Epoch 29/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0387 - mae: 0.1333 - mse: 0.0387
 64/109 [================>.............] - ETA: 0s - loss: 0.0375 - mae: 0.1213 - mse: 0.0375
 96/109 [=========================>....] - ETA: 0s - loss: 0.0395 - mae: 0.1301 - mse: 0.0395
109/109 [==============================] - 1s 7ms/step - loss: 0.0361 - mae: 0.1248 - mse: 0.0361 - val_loss: 0.0516 - val_mae: 0.1567 - val_mse: 0.0516
Epoch 30/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0145 - mae: 0.0921 - mse: 0.0145
 64/109 [================>.............] - ETA: 0s - loss: 0.0285 - mae: 0.1183 - mse: 0.0285
 96/109 [=========================>....] - ETA: 0s - loss: 0.0313 - mae: 0.1168 - mse: 0.0313
109/109 [==============================] - 1s 7ms/step - loss: 0.0298 - mae: 0.1144 - mse: 0.0298 - val_loss: 0.0571 - val_mae: 0.1695 - val_mse: 0.0571
Saving trained model...
67
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         11.46463013]
average prediction= [5.501444]
baseline= 7.951612903225806
eachuser= [0. 0. 0. 0. 0. 6.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 1.9107716878255208
['train-height-7.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_7_csi_a7_8.dat
170 32
170 33
170 34
170 35
170 36
170 37
2_170_60_7_csi_a7_6.dat
170 39
170 40
1_165_65_7_csi_a7_2.dat
165 42
165 43
165 44
1_165_65_7_csi_a7_5.dat
1_165_65_7_csi_a7_7.dat
165 47
165 48
165 49
1_165_65_7_csi_a7_3.dat
165 51
165 52
165 53
165 54
165 55
165 56
1_165_65_7_csi_a7_23.dat
165 58
165 59
165 60
165 61
165 62
165 63
165 64
1_165_65_7_csi_a7_1.dat
1_165_65_7_csi_a7_30.dat
165 67
165 68
165 69
1_165_65_7_csi_a7_21.dat
165 71
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
165 97
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
1_175_70_7_csi_a7_21.dat
1_175_70_7_csi_a7_13.dat
1_180_85_7_csi_a7_10.dat
180 132
180 133
180 134
180 135
180 136
180 137
1_180_85_7_csi_a7_14.dat
180 139
1_180_85_7_csi_a7_30.dat
180 141
1_180_85_7_csi_a7_1.dat
180 143
1_180_85_7_csi_a7_12.dat
180 145
180 146
1_180_85_7_csi_a7_9.dat
180 148
180 149
180 150
1_180_85_7_csi_a7_29.dat
1_180_85_7_csi_a7_24.dat
1_180_85_7_csi_a7_15.dat
180 154
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_7_csi_a7_25.dat
1_180_75_7_csi_a7_19.dat
1_180_75_7_csi_a7_9.dat
1_180_75_7_csi_a7_14.dat
1_180_75_7_csi_a7_3.dat
1_180_75_7_csi_a7_21.dat
1_180_75_7_csi_a7_22.dat
1_180_75_7_csi_a7_4.dat
1_180_75_7_csi_a7_11.dat
1_180_75_7_csi_a7_20.dat
1_180_75_7_csi_a7_28.dat
1_180_75_7_csi_a7_24.dat
1_180_75_7_csi_a7_5.dat
1_180_75_7_csi_a7_1.dat
1_180_75_7_csi_a7_15.dat
1_180_75_7_csi_a7_16.dat
1_180_75_7_csi_a7_17.dat
1_180_75_7_csi_a7_27.dat
1_180_75_7_csi_a7_26.dat
1_180_75_7_csi_a7_12.dat
1_180_75_7_csi_a7_7.dat
1_180_75_7_csi_a7_30.dat
1_180_75_7_csi_a7_23.dat
1_180_75_7_csi_a7_10.dat
1_180_75_7_csi_a7_29.dat
1_180_75_7_csi_a7_13.dat
1_180_75_7_csi_a7_2.dat
1_180_75_7_csi_a7_8.dat
1_180_75_7_csi_a7_6.dat
1_180_75_7_csi_a7_18.dat
173 191
1_173_85_7_csi_a7_9.dat
1_173_85_7_csi_a7_12.dat
1_173_85_7_csi_a7_8.dat
173 195
1_173_85_7_csi_a7_25.dat
173 197
1_173_85_7_csi_a7_20.dat
173 199
1_173_85_7_csi_a7_22.dat
1_173_85_7_csi_a7_19.dat
173 202
1_173_85_7_csi_a7_11.dat
1_173_85_7_csi_a7_7.dat
1_173_85_7_csi_a7_6.dat
173 206
1_173_85_7_csi_a7_21.dat
1_173_85_7_csi_a7_17.dat
173 209
173 210
173 211
1_173_85_7_csi_a7_23.dat
1_173_85_7_csi_a7_18.dat
173 214
173 215
173 216
173 217
1_173_85_7_csi_a7_16.dat
173 219
1_173_85_7_csi_a7_10.dat
(153, 30, 3)
(153, 443, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173 173 173
 173 173 173 173 173 173 173 173 173]
(153, 443, 30, 3, 1)

Loaded dataset of 153 samples, each sized (443, 30, 3, 1)


Train on 122 samples
Test on 31 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 443, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 443, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 443, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 443, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 443, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 443, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 443, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 109 samples, validate on 13 samples
Epoch 1/30

 32/109 [=======>......................] - ETA: 1s - loss: 0.3029 - mae: 0.4642 - mse: 0.3029
 64/109 [================>.............] - ETA: 0s - loss: 0.2905 - mae: 0.4562 - mse: 0.2905
 96/109 [=========================>....] - ETA: 0s - loss: 0.2348 - mae: 0.4031 - mse: 0.2348
109/109 [==============================] - 2s 14ms/step - loss: 0.2247 - mae: 0.3947 - mse: 0.2247 - val_loss: 0.1120 - val_mae: 0.2987 - val_mse: 0.1120
Epoch 2/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1893 - mae: 0.3526 - mse: 0.1893
 64/109 [================>.............] - ETA: 0s - loss: 0.1575 - mae: 0.3211 - mse: 0.1575
 96/109 [=========================>....] - ETA: 0s - loss: 0.1504 - mae: 0.3197 - mse: 0.1504
109/109 [==============================] - 1s 9ms/step - loss: 0.1475 - mae: 0.3180 - mse: 0.1475 - val_loss: 0.0673 - val_mae: 0.2208 - val_mse: 0.0673
Epoch 3/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1199 - mae: 0.3092 - mse: 0.1199
 64/109 [================>.............] - ETA: 0s - loss: 0.1212 - mae: 0.3123 - mse: 0.1212
 96/109 [=========================>....] - ETA: 0s - loss: 0.1221 - mae: 0.3046 - mse: 0.1221
109/109 [==============================] - 1s 9ms/step - loss: 0.1226 - mae: 0.3017 - mse: 0.1226 - val_loss: 0.0732 - val_mae: 0.2042 - val_mse: 0.0732
Epoch 4/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1373 - mae: 0.3067 - mse: 0.1373
 64/109 [================>.............] - ETA: 0s - loss: 0.1160 - mae: 0.2793 - mse: 0.1160
 96/109 [=========================>....] - ETA: 0s - loss: 0.1178 - mae: 0.2875 - mse: 0.1178
109/109 [==============================] - 1s 9ms/step - loss: 0.1108 - mae: 0.2775 - mse: 0.1108 - val_loss: 0.0621 - val_mae: 0.2022 - val_mse: 0.0621
Epoch 5/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1249 - mae: 0.3013 - mse: 0.1249
 64/109 [================>.............] - ETA: 0s - loss: 0.1184 - mae: 0.2864 - mse: 0.1184
 96/109 [=========================>....] - ETA: 0s - loss: 0.1064 - mae: 0.2681 - mse: 0.1064
109/109 [==============================] - 1s 9ms/step - loss: 0.1062 - mae: 0.2687 - mse: 0.1062 - val_loss: 0.0583 - val_mae: 0.2009 - val_mse: 0.0583
Epoch 6/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1141 - mae: 0.2739 - mse: 0.1141
 64/109 [================>.............] - ETA: 0s - loss: 0.0991 - mae: 0.2507 - mse: 0.0991
 96/109 [=========================>....] - ETA: 0s - loss: 0.0866 - mae: 0.2300 - mse: 0.0866
109/109 [==============================] - 1s 9ms/step - loss: 0.0877 - mae: 0.2352 - mse: 0.0877 - val_loss: 0.0551 - val_mae: 0.2008 - val_mse: 0.0551
Epoch 7/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0999 - mae: 0.2559 - mse: 0.0999
 64/109 [================>.............] - ETA: 0s - loss: 0.0714 - mae: 0.2131 - mse: 0.0714
 96/109 [=========================>....] - ETA: 0s - loss: 0.0787 - mae: 0.2212 - mse: 0.0787
109/109 [==============================] - 1s 9ms/step - loss: 0.0813 - mae: 0.2239 - mse: 0.0813 - val_loss: 0.0586 - val_mae: 0.1974 - val_mse: 0.0586
Epoch 8/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0987 - mae: 0.2667 - mse: 0.0987
 64/109 [================>.............] - ETA: 0s - loss: 0.0973 - mae: 0.2533 - mse: 0.0973
 96/109 [=========================>....] - ETA: 0s - loss: 0.0939 - mae: 0.2494 - mse: 0.0939
109/109 [==============================] - 1s 9ms/step - loss: 0.0916 - mae: 0.2483 - mse: 0.0916 - val_loss: 0.0537 - val_mae: 0.1900 - val_mse: 0.0537
Epoch 9/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0990 - mae: 0.2424 - mse: 0.0990
 64/109 [================>.............] - ETA: 0s - loss: 0.0839 - mae: 0.2270 - mse: 0.0839
 96/109 [=========================>....] - ETA: 0s - loss: 0.0798 - mae: 0.2212 - mse: 0.0798
109/109 [==============================] - 1s 9ms/step - loss: 0.0841 - mae: 0.2271 - mse: 0.0841 - val_loss: 0.0390 - val_mae: 0.1637 - val_mse: 0.0390
Epoch 10/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0786 - mae: 0.2387 - mse: 0.0786
 64/109 [================>.............] - ETA: 0s - loss: 0.0790 - mae: 0.2349 - mse: 0.0790
 96/109 [=========================>....] - ETA: 0s - loss: 0.0841 - mae: 0.2328 - mse: 0.0841
109/109 [==============================] - 1s 9ms/step - loss: 0.0822 - mae: 0.2335 - mse: 0.0822 - val_loss: 0.0334 - val_mae: 0.1460 - val_mse: 0.0334
Epoch 11/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0587 - mae: 0.1922 - mse: 0.0587
 64/109 [================>.............] - ETA: 0s - loss: 0.0718 - mae: 0.2062 - mse: 0.0718
 96/109 [=========================>....] - ETA: 0s - loss: 0.0742 - mae: 0.2080 - mse: 0.0742
109/109 [==============================] - 1s 9ms/step - loss: 0.0792 - mae: 0.2161 - mse: 0.0792 - val_loss: 0.0424 - val_mae: 0.1744 - val_mse: 0.0424
Epoch 12/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1058 - mae: 0.2806 - mse: 0.1058
 64/109 [================>.............] - ETA: 0s - loss: 0.0799 - mae: 0.2316 - mse: 0.0799
 96/109 [=========================>....] - ETA: 0s - loss: 0.0734 - mae: 0.2192 - mse: 0.0734
109/109 [==============================] - 1s 9ms/step - loss: 0.0731 - mae: 0.2176 - mse: 0.0731 - val_loss: 0.0323 - val_mae: 0.1521 - val_mse: 0.0323
Epoch 13/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0586 - mae: 0.1946 - mse: 0.0586
 64/109 [================>.............] - ETA: 0s - loss: 0.0709 - mae: 0.1917 - mse: 0.0709
 96/109 [=========================>....] - ETA: 0s - loss: 0.0728 - mae: 0.2021 - mse: 0.0728
109/109 [==============================] - 1s 9ms/step - loss: 0.0715 - mae: 0.2006 - mse: 0.0715 - val_loss: 0.0251 - val_mae: 0.1173 - val_mse: 0.0251
Epoch 14/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0799 - mae: 0.2212 - mse: 0.0799
 64/109 [================>.............] - ETA: 0s - loss: 0.0762 - mae: 0.2172 - mse: 0.0762
 96/109 [=========================>....] - ETA: 0s - loss: 0.0834 - mae: 0.2195 - mse: 0.0834
109/109 [==============================] - 1s 9ms/step - loss: 0.0778 - mae: 0.2116 - mse: 0.0778 - val_loss: 0.0331 - val_mae: 0.1590 - val_mse: 0.0331
Epoch 15/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0932 - mae: 0.2296 - mse: 0.0932
 64/109 [================>.............] - ETA: 0s - loss: 0.0721 - mae: 0.2018 - mse: 0.0721
 96/109 [=========================>....] - ETA: 0s - loss: 0.0644 - mae: 0.1880 - mse: 0.0644
109/109 [==============================] - 1s 7ms/step - loss: 0.0624 - mae: 0.1864 - mse: 0.0624 - val_loss: 0.0444 - val_mae: 0.1897 - val_mse: 0.0444
Epoch 16/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0452 - mae: 0.1677 - mse: 0.0452
 64/109 [================>.............] - ETA: 0s - loss: 0.0605 - mae: 0.1866 - mse: 0.0605
 96/109 [=========================>....] - ETA: 0s - loss: 0.0618 - mae: 0.1882 - mse: 0.0618
109/109 [==============================] - 1s 5ms/step - loss: 0.0616 - mae: 0.1880 - mse: 0.0616 - val_loss: 0.0199 - val_mae: 0.1192 - val_mse: 0.0199
Epoch 17/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0622 - mae: 0.1792 - mse: 0.0622
 64/109 [================>.............] - ETA: 0s - loss: 0.0705 - mae: 0.2030 - mse: 0.0705
 96/109 [=========================>....] - ETA: 0s - loss: 0.0699 - mae: 0.2036 - mse: 0.0699
109/109 [==============================] - 1s 5ms/step - loss: 0.0657 - mae: 0.1966 - mse: 0.0657 - val_loss: 0.0224 - val_mae: 0.1339 - val_mse: 0.0224
Epoch 18/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0662 - mae: 0.1670 - mse: 0.0662
 64/109 [================>.............] - ETA: 0s - loss: 0.0682 - mae: 0.1803 - mse: 0.0682
 96/109 [=========================>....] - ETA: 0s - loss: 0.0563 - mae: 0.1628 - mse: 0.0563
109/109 [==============================] - 1s 5ms/step - loss: 0.0569 - mae: 0.1656 - mse: 0.0569 - val_loss: 0.0378 - val_mae: 0.1807 - val_mse: 0.0378
Epoch 19/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0310 - mae: 0.1390 - mse: 0.0310
 64/109 [================>.............] - ETA: 0s - loss: 0.0563 - mae: 0.1751 - mse: 0.0563
 96/109 [=========================>....] - ETA: 0s - loss: 0.0487 - mae: 0.1668 - mse: 0.0487
109/109 [==============================] - 1s 5ms/step - loss: 0.0539 - mae: 0.1687 - mse: 0.0539 - val_loss: 0.0244 - val_mae: 0.1442 - val_mse: 0.0244
Epoch 20/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0414 - mae: 0.1601 - mse: 0.0414
 64/109 [================>.............] - ETA: 0s - loss: 0.0568 - mae: 0.1762 - mse: 0.0568
 96/109 [=========================>....] - ETA: 0s - loss: 0.0520 - mae: 0.1618 - mse: 0.0520
109/109 [==============================] - 1s 5ms/step - loss: 0.0526 - mae: 0.1617 - mse: 0.0526 - val_loss: 0.0316 - val_mae: 0.1648 - val_mse: 0.0316
Epoch 21/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0579 - mae: 0.1525 - mse: 0.0579
 64/109 [================>.............] - ETA: 0s - loss: 0.0619 - mae: 0.1753 - mse: 0.0619
 96/109 [=========================>....] - ETA: 0s - loss: 0.0530 - mae: 0.1615 - mse: 0.0530
109/109 [==============================] - 1s 5ms/step - loss: 0.0511 - mae: 0.1592 - mse: 0.0511 - val_loss: 0.0240 - val_mae: 0.1463 - val_mse: 0.0240
Epoch 22/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0524 - mae: 0.1740 - mse: 0.0524
 64/109 [================>.............] - ETA: 0s - loss: 0.0508 - mae: 0.1676 - mse: 0.0508
 96/109 [=========================>....] - ETA: 0s - loss: 0.0433 - mae: 0.1531 - mse: 0.0433
109/109 [==============================] - 1s 5ms/step - loss: 0.0431 - mae: 0.1512 - mse: 0.0431 - val_loss: 0.0282 - val_mae: 0.1565 - val_mse: 0.0282
Epoch 23/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0335 - mae: 0.1184 - mse: 0.0335
 64/109 [================>.............] - ETA: 0s - loss: 0.0487 - mae: 0.1467 - mse: 0.0487
 96/109 [=========================>....] - ETA: 0s - loss: 0.0426 - mae: 0.1419 - mse: 0.0426
109/109 [==============================] - 1s 5ms/step - loss: 0.0468 - mae: 0.1490 - mse: 0.0468 - val_loss: 0.0216 - val_mae: 0.1385 - val_mse: 0.0216
Epoch 24/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0351 - mae: 0.1254 - mse: 0.0351
 64/109 [================>.............] - ETA: 0s - loss: 0.0314 - mae: 0.1200 - mse: 0.0314
 96/109 [=========================>....] - ETA: 0s - loss: 0.0465 - mae: 0.1455 - mse: 0.0465
109/109 [==============================] - 1s 5ms/step - loss: 0.0449 - mae: 0.1458 - mse: 0.0449 - val_loss: 0.0340 - val_mae: 0.1630 - val_mse: 0.0340
Epoch 25/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0579 - mae: 0.1719 - mse: 0.0579
 64/109 [================>.............] - ETA: 0s - loss: 0.0565 - mae: 0.1692 - mse: 0.0565
 96/109 [=========================>....] - ETA: 0s - loss: 0.0498 - mae: 0.1600 - mse: 0.0498
109/109 [==============================] - 1s 5ms/step - loss: 0.0456 - mae: 0.1518 - mse: 0.0456 - val_loss: 0.0218 - val_mae: 0.1310 - val_mse: 0.0218
Epoch 26/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0259 - mae: 0.1227 - mse: 0.0259
 64/109 [================>.............] - ETA: 0s - loss: 0.0582 - mae: 0.1606 - mse: 0.0582
 96/109 [=========================>....] - ETA: 0s - loss: 0.0539 - mae: 0.1565 - mse: 0.0539
109/109 [==============================] - 1s 5ms/step - loss: 0.0479 - mae: 0.1435 - mse: 0.0479 - val_loss: 0.0380 - val_mae: 0.1734 - val_mse: 0.0380
Epoch 27/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0314 - mae: 0.1399 - mse: 0.0314
 64/109 [================>.............] - ETA: 0s - loss: 0.0450 - mae: 0.1463 - mse: 0.0450
 96/109 [=========================>....] - ETA: 0s - loss: 0.0405 - mae: 0.1389 - mse: 0.0405
109/109 [==============================] - 1s 5ms/step - loss: 0.0429 - mae: 0.1434 - mse: 0.0429 - val_loss: 0.0495 - val_mae: 0.1982 - val_mse: 0.0495
Epoch 28/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0324 - mae: 0.1260 - mse: 0.0324
 64/109 [================>.............] - ETA: 0s - loss: 0.0408 - mae: 0.1385 - mse: 0.0408
 96/109 [=========================>....] - ETA: 0s - loss: 0.0385 - mae: 0.1368 - mse: 0.0385
109/109 [==============================] - 1s 5ms/step - loss: 0.0384 - mae: 0.1376 - mse: 0.0384 - val_loss: 0.0235 - val_mae: 0.1241 - val_mse: 0.0235
Epoch 29/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0520 - mae: 0.1507 - mse: 0.0520
 64/109 [================>.............] - ETA: 0s - loss: 0.0733 - mae: 0.1897 - mse: 0.0733
 96/109 [=========================>....] - ETA: 0s - loss: 0.0535 - mae: 0.1549 - mse: 0.0535
109/109 [==============================] - 1s 5ms/step - loss: 0.0499 - mae: 0.1491 - mse: 0.0499 - val_loss: 0.0565 - val_mae: 0.1989 - val_mse: 0.0565
Epoch 30/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0360 - mae: 0.1355 - mse: 0.0360
 64/109 [================>.............] - ETA: 0s - loss: 0.0473 - mae: 0.1504 - mse: 0.0473
 96/109 [=========================>....] - ETA: 0s - loss: 0.0396 - mae: 0.1415 - mse: 0.0396
109/109 [==============================] - 1s 5ms/step - loss: 0.0423 - mae: 0.1471 - mse: 0.0423 - val_loss: 0.0191 - val_mae: 0.1098 - val_mse: 0.0191
Saving trained model...
67
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         34.79060364]
average prediction= [4.308614]
baseline= 7.209677419354839
eachuser= [0. 0. 0. 0. 0. 6.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 5.798433939615886
['train-height-7.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_7_csi_a7_8.dat
170 32
170 33
170 34
170 35
170 36
170 37
2_170_60_7_csi_a7_6.dat
170 39
170 40
1_165_65_7_csi_a7_2.dat
165 42
165 43
165 44
1_165_65_7_csi_a7_5.dat
1_165_65_7_csi_a7_7.dat
165 47
165 48
165 49
1_165_65_7_csi_a7_3.dat
165 51
165 52
165 53
165 54
165 55
165 56
1_165_65_7_csi_a7_23.dat
165 58
165 59
165 60
165 61
165 62
165 63
165 64
1_165_65_7_csi_a7_1.dat
1_165_65_7_csi_a7_30.dat
165 67
165 68
165 69
1_165_65_7_csi_a7_21.dat
165 71
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
165 97
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
1_175_70_7_csi_a7_21.dat
1_175_70_7_csi_a7_13.dat
1_180_85_7_csi_a7_10.dat
180 132
180 133
180 134
180 135
180 136
180 137
1_180_85_7_csi_a7_14.dat
180 139
1_180_85_7_csi_a7_30.dat
180 141
1_180_85_7_csi_a7_1.dat
180 143
1_180_85_7_csi_a7_12.dat
180 145
180 146
1_180_85_7_csi_a7_9.dat
180 148
180 149
180 150
1_180_85_7_csi_a7_29.dat
1_180_85_7_csi_a7_24.dat
1_180_85_7_csi_a7_15.dat
180 154
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_7_csi_a7_25.dat
1_180_75_7_csi_a7_19.dat
1_180_75_7_csi_a7_9.dat
1_180_75_7_csi_a7_14.dat
1_180_75_7_csi_a7_3.dat
1_180_75_7_csi_a7_21.dat
1_180_75_7_csi_a7_22.dat
1_180_75_7_csi_a7_4.dat
1_180_75_7_csi_a7_11.dat
1_180_75_7_csi_a7_20.dat
1_180_75_7_csi_a7_28.dat
1_180_75_7_csi_a7_24.dat
1_180_75_7_csi_a7_5.dat
1_180_75_7_csi_a7_1.dat
1_180_75_7_csi_a7_15.dat
1_180_75_7_csi_a7_16.dat
1_180_75_7_csi_a7_17.dat
1_180_75_7_csi_a7_27.dat
1_180_75_7_csi_a7_26.dat
1_180_75_7_csi_a7_12.dat
1_180_75_7_csi_a7_7.dat
1_180_75_7_csi_a7_30.dat
1_180_75_7_csi_a7_23.dat
1_180_75_7_csi_a7_10.dat
1_180_75_7_csi_a7_29.dat
1_180_75_7_csi_a7_13.dat
1_180_75_7_csi_a7_2.dat
1_180_75_7_csi_a7_8.dat
1_180_75_7_csi_a7_6.dat
1_180_75_7_csi_a7_18.dat
173 191
1_173_85_7_csi_a7_9.dat
1_173_85_7_csi_a7_12.dat
1_173_85_7_csi_a7_8.dat
173 195
1_173_85_7_csi_a7_25.dat
173 197
1_173_85_7_csi_a7_20.dat
173 199
1_173_85_7_csi_a7_22.dat
1_173_85_7_csi_a7_19.dat
173 202
1_173_85_7_csi_a7_11.dat
1_173_85_7_csi_a7_7.dat
1_173_85_7_csi_a7_6.dat
173 206
1_173_85_7_csi_a7_21.dat
1_173_85_7_csi_a7_17.dat
173 209
173 210
173 211
1_173_85_7_csi_a7_23.dat
1_173_85_7_csi_a7_18.dat
173 214
173 215
173 216
173 217
1_173_85_7_csi_a7_16.dat
173 219
1_173_85_7_csi_a7_10.dat
(153, 30, 3)
(153, 443, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173 173 173
 173 173 173 173 173 173 173 173 173]
(153, 443, 30, 3, 1)

Loaded dataset of 153 samples, each sized (443, 30, 3, 1)


Train on 122 samples
Test on 31 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 443, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 443, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 443, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 443, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 443, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 443, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 443, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 109 samples, validate on 13 samples
Epoch 1/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.4407 - mae: 0.5893 - mse: 0.4407
 64/109 [================>.............] - ETA: 0s - loss: 0.3499 - mae: 0.5068 - mse: 0.3499
 96/109 [=========================>....] - ETA: 0s - loss: 0.2841 - mae: 0.4472 - mse: 0.2841
109/109 [==============================] - 1s 8ms/step - loss: 0.2632 - mae: 0.4288 - mse: 0.2632 - val_loss: 0.1080 - val_mae: 0.3056 - val_mse: 0.1080
Epoch 2/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1512 - mae: 0.3032 - mse: 0.1512
 64/109 [================>.............] - ETA: 0s - loss: 0.1384 - mae: 0.3052 - mse: 0.1384
 96/109 [=========================>....] - ETA: 0s - loss: 0.1505 - mae: 0.3224 - mse: 0.1505
109/109 [==============================] - 1s 5ms/step - loss: 0.1518 - mae: 0.3238 - mse: 0.1518 - val_loss: 0.0539 - val_mae: 0.1866 - val_mse: 0.0539
Epoch 3/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0806 - mae: 0.2336 - mse: 0.0806
 64/109 [================>.............] - ETA: 0s - loss: 0.0993 - mae: 0.2597 - mse: 0.0993
 96/109 [=========================>....] - ETA: 0s - loss: 0.1121 - mae: 0.2750 - mse: 0.1121
109/109 [==============================] - 1s 5ms/step - loss: 0.1077 - mae: 0.2711 - mse: 0.1077 - val_loss: 0.0455 - val_mae: 0.1688 - val_mse: 0.0455
Epoch 4/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1106 - mae: 0.2764 - mse: 0.1106
 64/109 [================>.............] - ETA: 0s - loss: 0.1032 - mae: 0.2689 - mse: 0.1032
 96/109 [=========================>....] - ETA: 0s - loss: 0.1058 - mae: 0.2715 - mse: 0.1058
109/109 [==============================] - 1s 5ms/step - loss: 0.1067 - mae: 0.2724 - mse: 0.1067 - val_loss: 0.0446 - val_mae: 0.1810 - val_mse: 0.0446
Epoch 5/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0929 - mae: 0.2523 - mse: 0.0929
 64/109 [================>.............] - ETA: 0s - loss: 0.0924 - mae: 0.2562 - mse: 0.0924
 96/109 [=========================>....] - ETA: 0s - loss: 0.0964 - mae: 0.2571 - mse: 0.0964
109/109 [==============================] - 1s 5ms/step - loss: 0.0993 - mae: 0.2613 - mse: 0.0993 - val_loss: 0.0440 - val_mae: 0.1834 - val_mse: 0.0440
Epoch 6/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1201 - mae: 0.2944 - mse: 0.1201
 64/109 [================>.............] - ETA: 0s - loss: 0.1128 - mae: 0.2889 - mse: 0.1128
 96/109 [=========================>....] - ETA: 0s - loss: 0.1028 - mae: 0.2684 - mse: 0.1028
109/109 [==============================] - 1s 5ms/step - loss: 0.0989 - mae: 0.2603 - mse: 0.0989 - val_loss: 0.0352 - val_mae: 0.1635 - val_mse: 0.0352
Epoch 7/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1015 - mae: 0.2518 - mse: 0.1015
 64/109 [================>.............] - ETA: 0s - loss: 0.0905 - mae: 0.2350 - mse: 0.0905
 96/109 [=========================>....] - ETA: 0s - loss: 0.0831 - mae: 0.2275 - mse: 0.0831
109/109 [==============================] - 1s 6ms/step - loss: 0.0869 - mae: 0.2314 - mse: 0.0869 - val_loss: 0.0309 - val_mae: 0.1471 - val_mse: 0.0309
Epoch 8/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0854 - mae: 0.2360 - mse: 0.0854
 64/109 [================>.............] - ETA: 0s - loss: 0.0820 - mae: 0.2221 - mse: 0.0820
 96/109 [=========================>....] - ETA: 0s - loss: 0.0852 - mae: 0.2253 - mse: 0.0852
109/109 [==============================] - 1s 7ms/step - loss: 0.0798 - mae: 0.2156 - mse: 0.0798 - val_loss: 0.0279 - val_mae: 0.1396 - val_mse: 0.0279
Epoch 9/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0662 - mae: 0.1967 - mse: 0.0662
 64/109 [================>.............] - ETA: 0s - loss: 0.0793 - mae: 0.2092 - mse: 0.0793
 96/109 [=========================>....] - ETA: 0s - loss: 0.0693 - mae: 0.1952 - mse: 0.0693
109/109 [==============================] - 1s 8ms/step - loss: 0.0747 - mae: 0.2058 - mse: 0.0747 - val_loss: 0.0252 - val_mae: 0.1219 - val_mse: 0.0252
Epoch 10/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1008 - mae: 0.2440 - mse: 0.1008
 64/109 [================>.............] - ETA: 0s - loss: 0.0926 - mae: 0.2370 - mse: 0.0926
 96/109 [=========================>....] - ETA: 0s - loss: 0.0819 - mae: 0.2201 - mse: 0.0819
109/109 [==============================] - 1s 7ms/step - loss: 0.0780 - mae: 0.2128 - mse: 0.0780 - val_loss: 0.0212 - val_mae: 0.1226 - val_mse: 0.0212
Epoch 11/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0498 - mae: 0.1539 - mse: 0.0498
 64/109 [================>.............] - ETA: 0s - loss: 0.0565 - mae: 0.1766 - mse: 0.0565
 96/109 [=========================>....] - ETA: 0s - loss: 0.0653 - mae: 0.1932 - mse: 0.0653
109/109 [==============================] - 1s 7ms/step - loss: 0.0649 - mae: 0.1931 - mse: 0.0649 - val_loss: 0.0184 - val_mae: 0.1155 - val_mse: 0.0184
Epoch 12/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0458 - mae: 0.1667 - mse: 0.0458
 64/109 [================>.............] - ETA: 0s - loss: 0.0684 - mae: 0.1948 - mse: 0.0684
 96/109 [=========================>....] - ETA: 0s - loss: 0.0659 - mae: 0.1940 - mse: 0.0659
109/109 [==============================] - 1s 7ms/step - loss: 0.0610 - mae: 0.1842 - mse: 0.0610 - val_loss: 0.0155 - val_mae: 0.1091 - val_mse: 0.0155
Epoch 13/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0683 - mae: 0.2054 - mse: 0.0683
 64/109 [================>.............] - ETA: 0s - loss: 0.0517 - mae: 0.1822 - mse: 0.0517
 96/109 [=========================>....] - ETA: 0s - loss: 0.0558 - mae: 0.1788 - mse: 0.0558
109/109 [==============================] - 1s 7ms/step - loss: 0.0564 - mae: 0.1786 - mse: 0.0564 - val_loss: 0.0142 - val_mae: 0.1043 - val_mse: 0.0142
Epoch 14/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0725 - mae: 0.2043 - mse: 0.0725
 64/109 [================>.............] - ETA: 0s - loss: 0.0673 - mae: 0.1931 - mse: 0.0673
 96/109 [=========================>....] - ETA: 0s - loss: 0.0652 - mae: 0.1845 - mse: 0.0652
109/109 [==============================] - 1s 7ms/step - loss: 0.0611 - mae: 0.1800 - mse: 0.0611 - val_loss: 0.0189 - val_mae: 0.1295 - val_mse: 0.0189
Epoch 15/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0352 - mae: 0.1360 - mse: 0.0352
 64/109 [================>.............] - ETA: 0s - loss: 0.0581 - mae: 0.1690 - mse: 0.0581
 96/109 [=========================>....] - ETA: 0s - loss: 0.0534 - mae: 0.1639 - mse: 0.0534
109/109 [==============================] - 1s 7ms/step - loss: 0.0548 - mae: 0.1697 - mse: 0.0548 - val_loss: 0.0213 - val_mae: 0.1393 - val_mse: 0.0213
Epoch 16/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0270 - mae: 0.1276 - mse: 0.0270
 64/109 [================>.............] - ETA: 0s - loss: 0.0514 - mae: 0.1592 - mse: 0.0514
 96/109 [=========================>....] - ETA: 0s - loss: 0.0657 - mae: 0.1664 - mse: 0.0657
109/109 [==============================] - 1s 7ms/step - loss: 0.0619 - mae: 0.1641 - mse: 0.0619 - val_loss: 0.0197 - val_mae: 0.1369 - val_mse: 0.0197
Epoch 17/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0555 - mae: 0.1574 - mse: 0.0555
 64/109 [================>.............] - ETA: 0s - loss: 0.0542 - mae: 0.1583 - mse: 0.0542
 96/109 [=========================>....] - ETA: 0s - loss: 0.0526 - mae: 0.1589 - mse: 0.0526
109/109 [==============================] - 1s 7ms/step - loss: 0.0522 - mae: 0.1580 - mse: 0.0522 - val_loss: 0.0195 - val_mae: 0.1344 - val_mse: 0.0195
Epoch 18/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0567 - mae: 0.1495 - mse: 0.0567
 64/109 [================>.............] - ETA: 0s - loss: 0.0580 - mae: 0.1574 - mse: 0.0580
 96/109 [=========================>....] - ETA: 0s - loss: 0.0486 - mae: 0.1488 - mse: 0.0486
109/109 [==============================] - 1s 7ms/step - loss: 0.0495 - mae: 0.1512 - mse: 0.0495 - val_loss: 0.0094 - val_mae: 0.0811 - val_mse: 0.0094
Epoch 19/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0451 - mae: 0.1492 - mse: 0.0451
 64/109 [================>.............] - ETA: 0s - loss: 0.0554 - mae: 0.1610 - mse: 0.0554
 96/109 [=========================>....] - ETA: 0s - loss: 0.0466 - mae: 0.1495 - mse: 0.0466
109/109 [==============================] - 1s 7ms/step - loss: 0.0498 - mae: 0.1565 - mse: 0.0498 - val_loss: 0.0146 - val_mae: 0.1125 - val_mse: 0.0146
Epoch 20/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0579 - mae: 0.1691 - mse: 0.0579
 64/109 [================>.............] - ETA: 0s - loss: 0.0715 - mae: 0.1795 - mse: 0.0715
 96/109 [=========================>....] - ETA: 0s - loss: 0.0626 - mae: 0.1725 - mse: 0.0626
109/109 [==============================] - 1s 7ms/step - loss: 0.0590 - mae: 0.1686 - mse: 0.0590 - val_loss: 0.0225 - val_mae: 0.1456 - val_mse: 0.0225
Epoch 21/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0271 - mae: 0.1343 - mse: 0.0271
 64/109 [================>.............] - ETA: 0s - loss: 0.0368 - mae: 0.1393 - mse: 0.0368
 96/109 [=========================>....] - ETA: 0s - loss: 0.0394 - mae: 0.1442 - mse: 0.0394
109/109 [==============================] - 1s 7ms/step - loss: 0.0467 - mae: 0.1504 - mse: 0.0467 - val_loss: 0.0132 - val_mae: 0.1087 - val_mse: 0.0132
Epoch 22/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0519 - mae: 0.1383 - mse: 0.0519
 64/109 [================>.............] - ETA: 0s - loss: 0.0642 - mae: 0.1503 - mse: 0.0642
 96/109 [=========================>....] - ETA: 0s - loss: 0.0679 - mae: 0.1565 - mse: 0.0679
109/109 [==============================] - 1s 7ms/step - loss: 0.0633 - mae: 0.1539 - mse: 0.0633 - val_loss: 0.0143 - val_mae: 0.1150 - val_mse: 0.0143
Epoch 23/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0490 - mae: 0.1587 - mse: 0.0490
 64/109 [================>.............] - ETA: 0s - loss: 0.0433 - mae: 0.1484 - mse: 0.0433
 96/109 [=========================>....] - ETA: 0s - loss: 0.0468 - mae: 0.1472 - mse: 0.0468
109/109 [==============================] - 1s 7ms/step - loss: 0.0500 - mae: 0.1509 - mse: 0.0500 - val_loss: 0.0103 - val_mae: 0.0977 - val_mse: 0.0103
Epoch 24/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0448 - mae: 0.1414 - mse: 0.0448
 64/109 [================>.............] - ETA: 0s - loss: 0.0364 - mae: 0.1294 - mse: 0.0364
 96/109 [=========================>....] - ETA: 0s - loss: 0.0373 - mae: 0.1370 - mse: 0.0373
109/109 [==============================] - 1s 7ms/step - loss: 0.0462 - mae: 0.1463 - mse: 0.0462 - val_loss: 0.0100 - val_mae: 0.0803 - val_mse: 0.0100
Epoch 25/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0532 - mae: 0.1580 - mse: 0.0532
 64/109 [================>.............] - ETA: 0s - loss: 0.0660 - mae: 0.1782 - mse: 0.0660
 96/109 [=========================>....] - ETA: 0s - loss: 0.0573 - mae: 0.1658 - mse: 0.0573
109/109 [==============================] - 1s 7ms/step - loss: 0.0518 - mae: 0.1565 - mse: 0.0518 - val_loss: 0.0177 - val_mae: 0.1270 - val_mse: 0.0177
Epoch 26/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0479 - mae: 0.1439 - mse: 0.0479
 64/109 [================>.............] - ETA: 0s - loss: 0.0555 - mae: 0.1645 - mse: 0.0555
 96/109 [=========================>....] - ETA: 0s - loss: 0.0540 - mae: 0.1650 - mse: 0.0540
109/109 [==============================] - 1s 7ms/step - loss: 0.0548 - mae: 0.1646 - mse: 0.0548 - val_loss: 0.0216 - val_mae: 0.1439 - val_mse: 0.0216
Epoch 27/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0386 - mae: 0.1426 - mse: 0.0386
 64/109 [================>.............] - ETA: 0s - loss: 0.0432 - mae: 0.1471 - mse: 0.0432
 96/109 [=========================>....] - ETA: 0s - loss: 0.0528 - mae: 0.1620 - mse: 0.0528
109/109 [==============================] - 1s 7ms/step - loss: 0.0477 - mae: 0.1527 - mse: 0.0477 - val_loss: 0.0141 - val_mae: 0.1136 - val_mse: 0.0141
Epoch 28/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0267 - mae: 0.1169 - mse: 0.0267
 64/109 [================>.............] - ETA: 0s - loss: 0.0308 - mae: 0.1160 - mse: 0.0308
 96/109 [=========================>....] - ETA: 0s - loss: 0.0435 - mae: 0.1326 - mse: 0.0435
109/109 [==============================] - 1s 7ms/step - loss: 0.0398 - mae: 0.1268 - mse: 0.0398 - val_loss: 0.0116 - val_mae: 0.1025 - val_mse: 0.0116
Epoch 29/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0713 - mae: 0.1866 - mse: 0.0713
 64/109 [================>.............] - ETA: 0s - loss: 0.0564 - mae: 0.1591 - mse: 0.0564
 96/109 [=========================>....] - ETA: 0s - loss: 0.0469 - mae: 0.1499 - mse: 0.0469
109/109 [==============================] - 1s 6ms/step - loss: 0.0432 - mae: 0.1434 - mse: 0.0432 - val_loss: 0.0133 - val_mae: 0.1099 - val_mse: 0.0133
Epoch 30/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0473 - mae: 0.1406 - mse: 0.0473
 64/109 [================>.............] - ETA: 0s - loss: 0.0460 - mae: 0.1397 - mse: 0.0460
 96/109 [=========================>....] - ETA: 0s - loss: 0.0433 - mae: 0.1384 - mse: 0.0433
109/109 [==============================] - 1s 5ms/step - loss: 0.0456 - mae: 0.1416 - mse: 0.0456 - val_loss: 0.0129 - val_mae: 0.1070 - val_mse: 0.0129
Saving trained model...
67
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         32.78947449]
average prediction= [4.9771786]
baseline= 6.919354838709677
eachuser= [0. 0. 0. 0. 0. 5.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 6.557894897460938
['train-height-7.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_7_csi_a7_8.dat
170 32
170 33
170 34
170 35
170 36
170 37
2_170_60_7_csi_a7_6.dat
170 39
170 40
1_165_65_7_csi_a7_2.dat
165 42
165 43
165 44
1_165_65_7_csi_a7_5.dat
1_165_65_7_csi_a7_7.dat
165 47
165 48
165 49
1_165_65_7_csi_a7_3.dat
165 51
165 52
165 53
165 54
165 55
165 56
1_165_65_7_csi_a7_23.dat
165 58
165 59
165 60
165 61
165 62
165 63
165 64
1_165_65_7_csi_a7_1.dat
1_165_65_7_csi_a7_30.dat
165 67
165 68
165 69
1_165_65_7_csi_a7_21.dat
165 71
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
165 97
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
1_175_70_7_csi_a7_21.dat
1_175_70_7_csi_a7_13.dat
1_180_85_7_csi_a7_10.dat
180 132
180 133
180 134
180 135
180 136
180 137
1_180_85_7_csi_a7_14.dat
180 139
1_180_85_7_csi_a7_30.dat
180 141
1_180_85_7_csi_a7_1.dat
180 143
1_180_85_7_csi_a7_12.dat
180 145
180 146
1_180_85_7_csi_a7_9.dat
180 148
180 149
180 150
1_180_85_7_csi_a7_29.dat
1_180_85_7_csi_a7_24.dat
1_180_85_7_csi_a7_15.dat
180 154
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_7_csi_a7_25.dat
1_180_75_7_csi_a7_19.dat
1_180_75_7_csi_a7_9.dat
1_180_75_7_csi_a7_14.dat
1_180_75_7_csi_a7_3.dat
1_180_75_7_csi_a7_21.dat
1_180_75_7_csi_a7_22.dat
1_180_75_7_csi_a7_4.dat
1_180_75_7_csi_a7_11.dat
1_180_75_7_csi_a7_20.dat
1_180_75_7_csi_a7_28.dat
1_180_75_7_csi_a7_24.dat
1_180_75_7_csi_a7_5.dat
1_180_75_7_csi_a7_1.dat
1_180_75_7_csi_a7_15.dat
1_180_75_7_csi_a7_16.dat
1_180_75_7_csi_a7_17.dat
1_180_75_7_csi_a7_27.dat
1_180_75_7_csi_a7_26.dat
1_180_75_7_csi_a7_12.dat
1_180_75_7_csi_a7_7.dat
1_180_75_7_csi_a7_30.dat
1_180_75_7_csi_a7_23.dat
1_180_75_7_csi_a7_10.dat
1_180_75_7_csi_a7_29.dat
1_180_75_7_csi_a7_13.dat
1_180_75_7_csi_a7_2.dat
1_180_75_7_csi_a7_8.dat
1_180_75_7_csi_a7_6.dat
1_180_75_7_csi_a7_18.dat
173 191
1_173_85_7_csi_a7_9.dat
1_173_85_7_csi_a7_12.dat
1_173_85_7_csi_a7_8.dat
173 195
1_173_85_7_csi_a7_25.dat
173 197
1_173_85_7_csi_a7_20.dat
173 199
1_173_85_7_csi_a7_22.dat
1_173_85_7_csi_a7_19.dat
173 202
1_173_85_7_csi_a7_11.dat
1_173_85_7_csi_a7_7.dat
1_173_85_7_csi_a7_6.dat
173 206
1_173_85_7_csi_a7_21.dat
1_173_85_7_csi_a7_17.dat
173 209
173 210
173 211
1_173_85_7_csi_a7_23.dat
1_173_85_7_csi_a7_18.dat
173 214
173 215
173 216
173 217
1_173_85_7_csi_a7_16.dat
173 219
1_173_85_7_csi_a7_10.dat
(153, 30, 3)
(153, 443, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173 173 173
 173 173 173 173 173 173 173 173 173]
(153, 443, 30, 3, 1)

Loaded dataset of 153 samples, each sized (443, 30, 3, 1)


Train on 122 samples
Test on 31 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 443, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 443, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 443, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 443, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 443, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 443, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 443, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 109 samples, validate on 13 samples
Epoch 1/30

 32/109 [=======>......................] - ETA: 1s - loss: 0.4216 - mae: 0.5753 - mse: 0.4216
 64/109 [================>.............] - ETA: 0s - loss: 0.3224 - mae: 0.4923 - mse: 0.3224
 96/109 [=========================>....] - ETA: 0s - loss: 0.2789 - mae: 0.4556 - mse: 0.2789
109/109 [==============================] - 1s 9ms/step - loss: 0.2664 - mae: 0.4430 - mse: 0.2664 - val_loss: 0.2030 - val_mae: 0.3563 - val_mse: 0.2030
Epoch 2/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.2460 - mae: 0.3993 - mse: 0.2460
 64/109 [================>.............] - ETA: 0s - loss: 0.2378 - mae: 0.3937 - mse: 0.2378
 96/109 [=========================>....] - ETA: 0s - loss: 0.2141 - mae: 0.3739 - mse: 0.2141
109/109 [==============================] - 1s 6ms/step - loss: 0.2019 - mae: 0.3602 - mse: 0.2019 - val_loss: 0.1472 - val_mae: 0.2976 - val_mse: 0.1472
Epoch 3/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1133 - mae: 0.2805 - mse: 0.1133
 64/109 [================>.............] - ETA: 0s - loss: 0.1382 - mae: 0.3029 - mse: 0.1382
 96/109 [=========================>....] - ETA: 0s - loss: 0.1333 - mae: 0.3042 - mse: 0.1333
109/109 [==============================] - 1s 5ms/step - loss: 0.1351 - mae: 0.3082 - mse: 0.1351 - val_loss: 0.0847 - val_mae: 0.2479 - val_mse: 0.0847
Epoch 4/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1360 - mae: 0.3096 - mse: 0.1360
 64/109 [================>.............] - ETA: 0s - loss: 0.1374 - mae: 0.3142 - mse: 0.1374
 96/109 [=========================>....] - ETA: 0s - loss: 0.1271 - mae: 0.2954 - mse: 0.1271
109/109 [==============================] - 1s 5ms/step - loss: 0.1326 - mae: 0.3074 - mse: 0.1326 - val_loss: 0.0730 - val_mae: 0.2275 - val_mse: 0.0730
Epoch 5/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1067 - mae: 0.2652 - mse: 0.1067
 64/109 [================>.............] - ETA: 0s - loss: 0.1046 - mae: 0.2616 - mse: 0.1046
 96/109 [=========================>....] - ETA: 0s - loss: 0.1125 - mae: 0.2759 - mse: 0.1125
109/109 [==============================] - 1s 5ms/step - loss: 0.1097 - mae: 0.2726 - mse: 0.1097 - val_loss: 0.0905 - val_mae: 0.2217 - val_mse: 0.0905
Epoch 6/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1128 - mae: 0.2743 - mse: 0.1128
 64/109 [================>.............] - ETA: 0s - loss: 0.1295 - mae: 0.2866 - mse: 0.1295
 96/109 [=========================>....] - ETA: 0s - loss: 0.1213 - mae: 0.2727 - mse: 0.1213
109/109 [==============================] - 1s 5ms/step - loss: 0.1182 - mae: 0.2720 - mse: 0.1182 - val_loss: 0.1110 - val_mae: 0.2640 - val_mse: 0.1110
Epoch 7/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1426 - mae: 0.2910 - mse: 0.1426
 64/109 [================>.............] - ETA: 0s - loss: 0.1158 - mae: 0.2673 - mse: 0.1158
 96/109 [=========================>....] - ETA: 0s - loss: 0.1242 - mae: 0.2803 - mse: 0.1242
109/109 [==============================] - 1s 6ms/step - loss: 0.1125 - mae: 0.2612 - mse: 0.1125 - val_loss: 0.0767 - val_mae: 0.2116 - val_mse: 0.0767
Epoch 8/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1087 - mae: 0.2563 - mse: 0.1087
 64/109 [================>.............] - ETA: 0s - loss: 0.1021 - mae: 0.2523 - mse: 0.1021
 96/109 [=========================>....] - ETA: 0s - loss: 0.0997 - mae: 0.2508 - mse: 0.0997
109/109 [==============================] - 1s 5ms/step - loss: 0.0995 - mae: 0.2535 - mse: 0.0995 - val_loss: 0.0635 - val_mae: 0.1962 - val_mse: 0.0635
Epoch 9/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1258 - mae: 0.2864 - mse: 0.1258
 64/109 [================>.............] - ETA: 0s - loss: 0.1073 - mae: 0.2611 - mse: 0.1073
 96/109 [=========================>....] - ETA: 0s - loss: 0.1052 - mae: 0.2562 - mse: 0.1052
109/109 [==============================] - 1s 5ms/step - loss: 0.1027 - mae: 0.2523 - mse: 0.1027 - val_loss: 0.0627 - val_mae: 0.1971 - val_mse: 0.0627
Epoch 10/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1153 - mae: 0.2837 - mse: 0.1153
 64/109 [================>.............] - ETA: 0s - loss: 0.0853 - mae: 0.2311 - mse: 0.0853
 96/109 [=========================>....] - ETA: 0s - loss: 0.0964 - mae: 0.2448 - mse: 0.0964
109/109 [==============================] - 1s 5ms/step - loss: 0.0880 - mae: 0.2300 - mse: 0.0880 - val_loss: 0.0793 - val_mae: 0.2214 - val_mse: 0.0793
Epoch 11/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0692 - mae: 0.1888 - mse: 0.0692
 64/109 [================>.............] - ETA: 0s - loss: 0.0828 - mae: 0.2157 - mse: 0.0828
 96/109 [=========================>....] - ETA: 0s - loss: 0.0852 - mae: 0.2175 - mse: 0.0852
109/109 [==============================] - 1s 5ms/step - loss: 0.0924 - mae: 0.2279 - mse: 0.0924 - val_loss: 0.0755 - val_mae: 0.2133 - val_mse: 0.0755
Epoch 12/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0787 - mae: 0.2215 - mse: 0.0787
 64/109 [================>.............] - ETA: 0s - loss: 0.0832 - mae: 0.2243 - mse: 0.0832
 96/109 [=========================>....] - ETA: 0s - loss: 0.0842 - mae: 0.2230 - mse: 0.0842
109/109 [==============================] - 1s 5ms/step - loss: 0.0793 - mae: 0.2156 - mse: 0.0793 - val_loss: 0.0649 - val_mae: 0.1913 - val_mse: 0.0649
Epoch 13/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0933 - mae: 0.2509 - mse: 0.0933
 64/109 [================>.............] - ETA: 0s - loss: 0.0878 - mae: 0.2384 - mse: 0.0878
 96/109 [=========================>....] - ETA: 0s - loss: 0.0887 - mae: 0.2357 - mse: 0.0887
109/109 [==============================] - 1s 5ms/step - loss: 0.0852 - mae: 0.2307 - mse: 0.0852 - val_loss: 0.0717 - val_mae: 0.1953 - val_mse: 0.0717
Epoch 14/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0785 - mae: 0.2302 - mse: 0.0785
 64/109 [================>.............] - ETA: 0s - loss: 0.0706 - mae: 0.2073 - mse: 0.0706
 96/109 [=========================>....] - ETA: 0s - loss: 0.0653 - mae: 0.1943 - mse: 0.0653
109/109 [==============================] - 1s 6ms/step - loss: 0.0691 - mae: 0.1980 - mse: 0.0691 - val_loss: 0.0914 - val_mae: 0.2122 - val_mse: 0.0914
Epoch 15/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0885 - mae: 0.2380 - mse: 0.0885
 64/109 [================>.............] - ETA: 0s - loss: 0.0725 - mae: 0.2050 - mse: 0.0725
 96/109 [=========================>....] - ETA: 0s - loss: 0.0679 - mae: 0.1953 - mse: 0.0679
109/109 [==============================] - 1s 5ms/step - loss: 0.0723 - mae: 0.2046 - mse: 0.0723 - val_loss: 0.0814 - val_mae: 0.1949 - val_mse: 0.0814
Epoch 16/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1014 - mae: 0.2368 - mse: 0.1014
 64/109 [================>.............] - ETA: 0s - loss: 0.0757 - mae: 0.2027 - mse: 0.0757
 96/109 [=========================>....] - ETA: 0s - loss: 0.0710 - mae: 0.1995 - mse: 0.0710
109/109 [==============================] - 1s 5ms/step - loss: 0.0677 - mae: 0.1940 - mse: 0.0677 - val_loss: 0.0815 - val_mae: 0.2096 - val_mse: 0.0815
Epoch 17/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0662 - mae: 0.1869 - mse: 0.0662
 64/109 [================>.............] - ETA: 0s - loss: 0.0704 - mae: 0.1964 - mse: 0.0704
 96/109 [=========================>....] - ETA: 0s - loss: 0.0637 - mae: 0.1827 - mse: 0.0637
109/109 [==============================] - 1s 5ms/step - loss: 0.0629 - mae: 0.1823 - mse: 0.0629 - val_loss: 0.0999 - val_mae: 0.2200 - val_mse: 0.0999
Epoch 18/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0351 - mae: 0.1411 - mse: 0.0351
 64/109 [================>.............] - ETA: 0s - loss: 0.0666 - mae: 0.1894 - mse: 0.0666
 96/109 [=========================>....] - ETA: 0s - loss: 0.0578 - mae: 0.1772 - mse: 0.0578
109/109 [==============================] - 1s 5ms/step - loss: 0.0587 - mae: 0.1822 - mse: 0.0587 - val_loss: 0.1011 - val_mae: 0.2215 - val_mse: 0.1011
Epoch 19/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0498 - mae: 0.1715 - mse: 0.0498
 64/109 [================>.............] - ETA: 0s - loss: 0.0733 - mae: 0.1952 - mse: 0.0733
 96/109 [=========================>....] - ETA: 0s - loss: 0.0615 - mae: 0.1766 - mse: 0.0615
109/109 [==============================] - 1s 5ms/step - loss: 0.0598 - mae: 0.1747 - mse: 0.0598 - val_loss: 0.1019 - val_mae: 0.2083 - val_mse: 0.1019
Epoch 20/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0345 - mae: 0.1411 - mse: 0.0345
 64/109 [================>.............] - ETA: 0s - loss: 0.0442 - mae: 0.1601 - mse: 0.0442
 96/109 [=========================>....] - ETA: 0s - loss: 0.0523 - mae: 0.1677 - mse: 0.0523
109/109 [==============================] - 1s 5ms/step - loss: 0.0571 - mae: 0.1751 - mse: 0.0571 - val_loss: 0.1146 - val_mae: 0.2023 - val_mse: 0.1146
Epoch 21/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0528 - mae: 0.1692 - mse: 0.0528
 64/109 [================>.............] - ETA: 0s - loss: 0.0486 - mae: 0.1546 - mse: 0.0486
 96/109 [=========================>....] - ETA: 0s - loss: 0.0526 - mae: 0.1629 - mse: 0.0526
109/109 [==============================] - 1s 5ms/step - loss: 0.0492 - mae: 0.1584 - mse: 0.0492 - val_loss: 0.1306 - val_mae: 0.2284 - val_mse: 0.1306
Epoch 22/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0526 - mae: 0.1480 - mse: 0.0526
 64/109 [================>.............] - ETA: 0s - loss: 0.0545 - mae: 0.1546 - mse: 0.0545
 96/109 [=========================>....] - ETA: 0s - loss: 0.0525 - mae: 0.1587 - mse: 0.0525
109/109 [==============================] - 1s 5ms/step - loss: 0.0500 - mae: 0.1564 - mse: 0.0500 - val_loss: 0.1293 - val_mae: 0.2565 - val_mse: 0.1293
Epoch 23/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0508 - mae: 0.1613 - mse: 0.0508
 64/109 [================>.............] - ETA: 0s - loss: 0.0495 - mae: 0.1591 - mse: 0.0495
 96/109 [=========================>....] - ETA: 0s - loss: 0.0485 - mae: 0.1606 - mse: 0.0485
109/109 [==============================] - 1s 5ms/step - loss: 0.0480 - mae: 0.1595 - mse: 0.0480 - val_loss: 0.1470 - val_mae: 0.2599 - val_mse: 0.1470
Epoch 24/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0425 - mae: 0.1583 - mse: 0.0425
 64/109 [================>.............] - ETA: 0s - loss: 0.0347 - mae: 0.1486 - mse: 0.0347
 96/109 [=========================>....] - ETA: 0s - loss: 0.0484 - mae: 0.1640 - mse: 0.0484
109/109 [==============================] - 1s 5ms/step - loss: 0.0501 - mae: 0.1675 - mse: 0.0501 - val_loss: 0.1144 - val_mae: 0.2310 - val_mse: 0.1144
Epoch 25/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0460 - mae: 0.1564 - mse: 0.0460
 64/109 [================>.............] - ETA: 0s - loss: 0.0565 - mae: 0.1694 - mse: 0.0565
 96/109 [=========================>....] - ETA: 0s - loss: 0.0527 - mae: 0.1652 - mse: 0.0527
109/109 [==============================] - 1s 5ms/step - loss: 0.0484 - mae: 0.1578 - mse: 0.0484 - val_loss: 0.0994 - val_mae: 0.2065 - val_mse: 0.0994
Epoch 26/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0397 - mae: 0.1590 - mse: 0.0397
 64/109 [================>.............] - ETA: 0s - loss: 0.0360 - mae: 0.1445 - mse: 0.0360
 96/109 [=========================>....] - ETA: 0s - loss: 0.0411 - mae: 0.1448 - mse: 0.0411
109/109 [==============================] - 1s 5ms/step - loss: 0.0485 - mae: 0.1533 - mse: 0.0485 - val_loss: 0.0991 - val_mae: 0.2178 - val_mse: 0.0991
Epoch 27/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0223 - mae: 0.1173 - mse: 0.0223
 64/109 [================>.............] - ETA: 0s - loss: 0.0271 - mae: 0.1335 - mse: 0.0271
 96/109 [=========================>....] - ETA: 0s - loss: 0.0513 - mae: 0.1677 - mse: 0.0513
109/109 [==============================] - 1s 5ms/step - loss: 0.0573 - mae: 0.1733 - mse: 0.0573 - val_loss: 0.0898 - val_mae: 0.2346 - val_mse: 0.0898
Epoch 28/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0419 - mae: 0.1601 - mse: 0.0419
 64/109 [================>.............] - ETA: 0s - loss: 0.0449 - mae: 0.1523 - mse: 0.0449
 96/109 [=========================>....] - ETA: 0s - loss: 0.0515 - mae: 0.1684 - mse: 0.0515
109/109 [==============================] - 1s 5ms/step - loss: 0.0483 - mae: 0.1613 - mse: 0.0483 - val_loss: 0.1594 - val_mae: 0.2527 - val_mse: 0.1594
Epoch 29/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0392 - mae: 0.1452 - mse: 0.0392
 64/109 [================>.............] - ETA: 0s - loss: 0.0592 - mae: 0.1670 - mse: 0.0592
 96/109 [=========================>....] - ETA: 0s - loss: 0.0496 - mae: 0.1562 - mse: 0.0496
109/109 [==============================] - 1s 5ms/step - loss: 0.0472 - mae: 0.1561 - mse: 0.0472 - val_loss: 0.0961 - val_mae: 0.2517 - val_mse: 0.0961
Epoch 30/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0783 - mae: 0.2314 - mse: 0.0783
 64/109 [================>.............] - ETA: 0s - loss: 0.0717 - mae: 0.2223 - mse: 0.0717
 96/109 [=========================>....] - ETA: 0s - loss: 0.0586 - mae: 0.1925 - mse: 0.0586
109/109 [==============================] - 1s 5ms/step - loss: 0.0652 - mae: 0.2002 - mse: 0.0652 - val_loss: 0.1101 - val_mae: 0.2299 - val_mse: 0.1101
Saving trained model...
67
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         33.27444458]
average prediction= [3.8754222]
baseline= 7.403225806451613
eachuser= [0. 0. 0. 0. 0. 6.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 5.5457407633463545
['train-height-7.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_7_csi_a7_8.dat
170 32
170 33
170 34
170 35
170 36
170 37
2_170_60_7_csi_a7_6.dat
170 39
170 40
1_165_65_7_csi_a7_2.dat
165 42
165 43
165 44
1_165_65_7_csi_a7_5.dat
1_165_65_7_csi_a7_7.dat
165 47
165 48
165 49
1_165_65_7_csi_a7_3.dat
165 51
165 52
165 53
165 54
165 55
165 56
1_165_65_7_csi_a7_23.dat
165 58
165 59
165 60
165 61
165 62
165 63
165 64
1_165_65_7_csi_a7_1.dat
1_165_65_7_csi_a7_30.dat
165 67
165 68
165 69
1_165_65_7_csi_a7_21.dat
165 71
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
165 97
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
1_175_70_7_csi_a7_21.dat
1_175_70_7_csi_a7_13.dat
1_180_85_7_csi_a7_10.dat
180 132
180 133
180 134
180 135
180 136
180 137
1_180_85_7_csi_a7_14.dat
180 139
1_180_85_7_csi_a7_30.dat
180 141
1_180_85_7_csi_a7_1.dat
180 143
1_180_85_7_csi_a7_12.dat
180 145
180 146
1_180_85_7_csi_a7_9.dat
180 148
180 149
180 150
1_180_85_7_csi_a7_29.dat
1_180_85_7_csi_a7_24.dat
1_180_85_7_csi_a7_15.dat
180 154
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_7_csi_a7_25.dat
1_180_75_7_csi_a7_19.dat
1_180_75_7_csi_a7_9.dat
1_180_75_7_csi_a7_14.dat
1_180_75_7_csi_a7_3.dat
1_180_75_7_csi_a7_21.dat
1_180_75_7_csi_a7_22.dat
1_180_75_7_csi_a7_4.dat
1_180_75_7_csi_a7_11.dat
1_180_75_7_csi_a7_20.dat
1_180_75_7_csi_a7_28.dat
1_180_75_7_csi_a7_24.dat
1_180_75_7_csi_a7_5.dat
1_180_75_7_csi_a7_1.dat
1_180_75_7_csi_a7_15.dat
1_180_75_7_csi_a7_16.dat
1_180_75_7_csi_a7_17.dat
1_180_75_7_csi_a7_27.dat
1_180_75_7_csi_a7_26.dat
1_180_75_7_csi_a7_12.dat
1_180_75_7_csi_a7_7.dat
1_180_75_7_csi_a7_30.dat
1_180_75_7_csi_a7_23.dat
1_180_75_7_csi_a7_10.dat
1_180_75_7_csi_a7_29.dat
1_180_75_7_csi_a7_13.dat
1_180_75_7_csi_a7_2.dat
1_180_75_7_csi_a7_8.dat
1_180_75_7_csi_a7_6.dat
1_180_75_7_csi_a7_18.dat
173 191
1_173_85_7_csi_a7_9.dat
1_173_85_7_csi_a7_12.dat
1_173_85_7_csi_a7_8.dat
173 195
1_173_85_7_csi_a7_25.dat
173 197
1_173_85_7_csi_a7_20.dat
173 199
1_173_85_7_csi_a7_22.dat
1_173_85_7_csi_a7_19.dat
173 202
1_173_85_7_csi_a7_11.dat
1_173_85_7_csi_a7_7.dat
1_173_85_7_csi_a7_6.dat
173 206
1_173_85_7_csi_a7_21.dat
1_173_85_7_csi_a7_17.dat
173 209
173 210
173 211
1_173_85_7_csi_a7_23.dat
1_173_85_7_csi_a7_18.dat
173 214
173 215
173 216
173 217
1_173_85_7_csi_a7_16.dat
173 219
1_173_85_7_csi_a7_10.dat
(153, 30, 3)
(153, 443, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173 173 173
 173 173 173 173 173 173 173 173 173]
(153, 443, 30, 3, 1)

Loaded dataset of 153 samples, each sized (443, 30, 3, 1)


Train on 122 samples
Test on 31 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 443, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 443, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 443, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 443, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 443, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 443, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 443, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 109 samples, validate on 13 samples
Epoch 1/30

 32/109 [=======>......................] - ETA: 1s - loss: 0.4446 - mae: 0.5871 - mse: 0.4446
 64/109 [================>.............] - ETA: 0s - loss: 0.3747 - mae: 0.5211 - mse: 0.3747
 96/109 [=========================>....] - ETA: 0s - loss: 0.3317 - mae: 0.4951 - mse: 0.3317
109/109 [==============================] - 1s 10ms/step - loss: 0.3093 - mae: 0.4751 - mse: 0.3093 - val_loss: 0.1124 - val_mae: 0.2708 - val_mse: 0.1124
Epoch 2/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1654 - mae: 0.3437 - mse: 0.1654
 64/109 [================>.............] - ETA: 0s - loss: 0.2187 - mae: 0.3811 - mse: 0.2187
 96/109 [=========================>....] - ETA: 0s - loss: 0.2170 - mae: 0.3723 - mse: 0.2170
109/109 [==============================] - 1s 6ms/step - loss: 0.2132 - mae: 0.3689 - mse: 0.2132 - val_loss: 0.1053 - val_mae: 0.2617 - val_mse: 0.1053
Epoch 3/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1917 - mae: 0.3610 - mse: 0.1917
 64/109 [================>.............] - ETA: 0s - loss: 0.1728 - mae: 0.3431 - mse: 0.1728
 96/109 [=========================>....] - ETA: 0s - loss: 0.1630 - mae: 0.3329 - mse: 0.1630
109/109 [==============================] - 1s 6ms/step - loss: 0.1646 - mae: 0.3368 - mse: 0.1646 - val_loss: 0.1127 - val_mae: 0.2699 - val_mse: 0.1127
Epoch 4/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1531 - mae: 0.3352 - mse: 0.1531
 64/109 [================>.............] - ETA: 0s - loss: 0.1592 - mae: 0.3430 - mse: 0.1592
 96/109 [=========================>....] - ETA: 0s - loss: 0.1503 - mae: 0.3253 - mse: 0.1503
109/109 [==============================] - 1s 5ms/step - loss: 0.1455 - mae: 0.3209 - mse: 0.1455 - val_loss: 0.1003 - val_mae: 0.2495 - val_mse: 0.1003
Epoch 5/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1553 - mae: 0.3524 - mse: 0.1553
 64/109 [================>.............] - ETA: 0s - loss: 0.1253 - mae: 0.3060 - mse: 0.1253
 96/109 [=========================>....] - ETA: 0s - loss: 0.1202 - mae: 0.2966 - mse: 0.1202
109/109 [==============================] - 1s 5ms/step - loss: 0.1217 - mae: 0.3002 - mse: 0.1217 - val_loss: 0.0788 - val_mae: 0.2257 - val_mse: 0.0788
Epoch 6/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1053 - mae: 0.2866 - mse: 0.1053
 64/109 [================>.............] - ETA: 0s - loss: 0.1195 - mae: 0.2888 - mse: 0.1195
 96/109 [=========================>....] - ETA: 0s - loss: 0.1202 - mae: 0.2942 - mse: 0.1202
109/109 [==============================] - 1s 5ms/step - loss: 0.1271 - mae: 0.3048 - mse: 0.1271 - val_loss: 0.0739 - val_mae: 0.2258 - val_mse: 0.0739
Epoch 7/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1241 - mae: 0.3063 - mse: 0.1241
 64/109 [================>.............] - ETA: 0s - loss: 0.1307 - mae: 0.3147 - mse: 0.1307
 96/109 [=========================>....] - ETA: 0s - loss: 0.1356 - mae: 0.3200 - mse: 0.1356
109/109 [==============================] - 1s 6ms/step - loss: 0.1247 - mae: 0.3038 - mse: 0.1247 - val_loss: 0.0739 - val_mae: 0.2096 - val_mse: 0.0739
Epoch 8/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0755 - mae: 0.2374 - mse: 0.0755
 64/109 [================>.............] - ETA: 0s - loss: 0.1039 - mae: 0.2729 - mse: 0.1039
 96/109 [=========================>....] - ETA: 0s - loss: 0.1103 - mae: 0.2791 - mse: 0.1103
109/109 [==============================] - 1s 5ms/step - loss: 0.1076 - mae: 0.2757 - mse: 0.1076 - val_loss: 0.0795 - val_mae: 0.2041 - val_mse: 0.0795
Epoch 9/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1160 - mae: 0.2698 - mse: 0.1160
 64/109 [================>.............] - ETA: 0s - loss: 0.1053 - mae: 0.2634 - mse: 0.1053
 96/109 [=========================>....] - ETA: 0s - loss: 0.0979 - mae: 0.2521 - mse: 0.0979
109/109 [==============================] - 1s 5ms/step - loss: 0.0975 - mae: 0.2544 - mse: 0.0975 - val_loss: 0.0728 - val_mae: 0.1992 - val_mse: 0.0728
Epoch 10/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1103 - mae: 0.2886 - mse: 0.1103
 64/109 [================>.............] - ETA: 0s - loss: 0.1062 - mae: 0.2745 - mse: 0.1062
 96/109 [=========================>....] - ETA: 0s - loss: 0.0982 - mae: 0.2639 - mse: 0.0982
109/109 [==============================] - 1s 5ms/step - loss: 0.0991 - mae: 0.2663 - mse: 0.0991 - val_loss: 0.0662 - val_mae: 0.1971 - val_mse: 0.0662
Epoch 11/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0906 - mae: 0.2550 - mse: 0.0906
 64/109 [================>.............] - ETA: 0s - loss: 0.1026 - mae: 0.2691 - mse: 0.1026
 96/109 [=========================>....] - ETA: 0s - loss: 0.0932 - mae: 0.2562 - mse: 0.0932
109/109 [==============================] - 1s 5ms/step - loss: 0.1025 - mae: 0.2670 - mse: 0.1025 - val_loss: 0.0612 - val_mae: 0.1876 - val_mse: 0.0612
Epoch 12/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0841 - mae: 0.2363 - mse: 0.0841
 64/109 [================>.............] - ETA: 0s - loss: 0.0949 - mae: 0.2558 - mse: 0.0949
 96/109 [=========================>....] - ETA: 0s - loss: 0.0909 - mae: 0.2508 - mse: 0.0909
109/109 [==============================] - 1s 6ms/step - loss: 0.0874 - mae: 0.2435 - mse: 0.0874 - val_loss: 0.0614 - val_mae: 0.1817 - val_mse: 0.0614
Epoch 13/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0907 - mae: 0.2529 - mse: 0.0907
 64/109 [================>.............] - ETA: 0s - loss: 0.0807 - mae: 0.2319 - mse: 0.0807
 96/109 [=========================>....] - ETA: 0s - loss: 0.0844 - mae: 0.2323 - mse: 0.0844
109/109 [==============================] - 1s 5ms/step - loss: 0.0867 - mae: 0.2348 - mse: 0.0867 - val_loss: 0.0587 - val_mae: 0.1786 - val_mse: 0.0587
Epoch 14/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1010 - mae: 0.2551 - mse: 0.1010
 64/109 [================>.............] - ETA: 0s - loss: 0.0949 - mae: 0.2464 - mse: 0.0949
 96/109 [=========================>....] - ETA: 0s - loss: 0.0887 - mae: 0.2393 - mse: 0.0887
109/109 [==============================] - 1s 5ms/step - loss: 0.0905 - mae: 0.2395 - mse: 0.0905 - val_loss: 0.0464 - val_mae: 0.1651 - val_mse: 0.0464
Epoch 15/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0919 - mae: 0.2582 - mse: 0.0919
 64/109 [================>.............] - ETA: 0s - loss: 0.0909 - mae: 0.2509 - mse: 0.0909
 96/109 [=========================>....] - ETA: 0s - loss: 0.0800 - mae: 0.2280 - mse: 0.0800
109/109 [==============================] - 1s 5ms/step - loss: 0.0890 - mae: 0.2378 - mse: 0.0890 - val_loss: 0.0432 - val_mae: 0.1532 - val_mse: 0.0432
Epoch 16/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0620 - mae: 0.2023 - mse: 0.0620
 64/109 [================>.............] - ETA: 0s - loss: 0.0815 - mae: 0.2269 - mse: 0.0815
 96/109 [=========================>....] - ETA: 0s - loss: 0.0803 - mae: 0.2231 - mse: 0.0803
109/109 [==============================] - 1s 6ms/step - loss: 0.0863 - mae: 0.2329 - mse: 0.0863 - val_loss: 0.0552 - val_mae: 0.1813 - val_mse: 0.0552
Epoch 17/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0898 - mae: 0.2378 - mse: 0.0898
 64/109 [================>.............] - ETA: 0s - loss: 0.0946 - mae: 0.2460 - mse: 0.0946
 96/109 [=========================>....] - ETA: 0s - loss: 0.0844 - mae: 0.2265 - mse: 0.0844
109/109 [==============================] - 1s 5ms/step - loss: 0.0819 - mae: 0.2231 - mse: 0.0819 - val_loss: 0.0361 - val_mae: 0.1332 - val_mse: 0.0361
Epoch 18/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0814 - mae: 0.2233 - mse: 0.0814
 64/109 [================>.............] - ETA: 0s - loss: 0.0750 - mae: 0.1971 - mse: 0.0750
 96/109 [=========================>....] - ETA: 0s - loss: 0.0764 - mae: 0.2090 - mse: 0.0764
109/109 [==============================] - 1s 5ms/step - loss: 0.0780 - mae: 0.2142 - mse: 0.0780 - val_loss: 0.0301 - val_mae: 0.1189 - val_mse: 0.0301
Epoch 19/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1002 - mae: 0.2567 - mse: 0.1002
 64/109 [================>.............] - ETA: 0s - loss: 0.0758 - mae: 0.2100 - mse: 0.0758
 96/109 [=========================>....] - ETA: 0s - loss: 0.0742 - mae: 0.2110 - mse: 0.0742
109/109 [==============================] - 1s 6ms/step - loss: 0.0774 - mae: 0.2161 - mse: 0.0774 - val_loss: 0.0527 - val_mae: 0.1853 - val_mse: 0.0527
Epoch 20/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0718 - mae: 0.2008 - mse: 0.0718
 64/109 [================>.............] - ETA: 0s - loss: 0.0700 - mae: 0.1961 - mse: 0.0700
 96/109 [=========================>....] - ETA: 0s - loss: 0.0754 - mae: 0.2042 - mse: 0.0754
109/109 [==============================] - 1s 5ms/step - loss: 0.0785 - mae: 0.2099 - mse: 0.0785 - val_loss: 0.0361 - val_mae: 0.1469 - val_mse: 0.0361
Epoch 21/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0696 - mae: 0.2112 - mse: 0.0696
 64/109 [================>.............] - ETA: 0s - loss: 0.0691 - mae: 0.2028 - mse: 0.0691
 96/109 [=========================>....] - ETA: 0s - loss: 0.0639 - mae: 0.1892 - mse: 0.0639
109/109 [==============================] - 1s 5ms/step - loss: 0.0662 - mae: 0.1906 - mse: 0.0662 - val_loss: 0.0218 - val_mae: 0.1036 - val_mse: 0.0218
Epoch 22/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0432 - mae: 0.1611 - mse: 0.0432
 64/109 [================>.............] - ETA: 0s - loss: 0.0532 - mae: 0.1762 - mse: 0.0532
 96/109 [=========================>....] - ETA: 0s - loss: 0.0617 - mae: 0.1851 - mse: 0.0617
109/109 [==============================] - 1s 5ms/step - loss: 0.0613 - mae: 0.1839 - mse: 0.0613 - val_loss: 0.0357 - val_mae: 0.1563 - val_mse: 0.0357
Epoch 23/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0644 - mae: 0.1863 - mse: 0.0644
 64/109 [================>.............] - ETA: 0s - loss: 0.0762 - mae: 0.2031 - mse: 0.0762
 96/109 [=========================>....] - ETA: 0s - loss: 0.0718 - mae: 0.1978 - mse: 0.0718
109/109 [==============================] - 1s 5ms/step - loss: 0.0703 - mae: 0.1957 - mse: 0.0703 - val_loss: 0.0241 - val_mae: 0.1203 - val_mse: 0.0241
Epoch 24/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0775 - mae: 0.1895 - mse: 0.0775
 64/109 [================>.............] - ETA: 0s - loss: 0.0583 - mae: 0.1691 - mse: 0.0583
 96/109 [=========================>....] - ETA: 0s - loss: 0.0540 - mae: 0.1658 - mse: 0.0540
109/109 [==============================] - 1s 5ms/step - loss: 0.0563 - mae: 0.1658 - mse: 0.0563 - val_loss: 0.0155 - val_mae: 0.0833 - val_mse: 0.0155
Epoch 25/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0694 - mae: 0.1575 - mse: 0.0694
 64/109 [================>.............] - ETA: 0s - loss: 0.0749 - mae: 0.1865 - mse: 0.0749
 96/109 [=========================>....] - ETA: 0s - loss: 0.0614 - mae: 0.1713 - mse: 0.0614
109/109 [==============================] - 1s 6ms/step - loss: 0.0658 - mae: 0.1799 - mse: 0.0658 - val_loss: 0.0371 - val_mae: 0.1567 - val_mse: 0.0371
Epoch 26/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0474 - mae: 0.1730 - mse: 0.0474
 64/109 [================>.............] - ETA: 0s - loss: 0.0602 - mae: 0.1744 - mse: 0.0602
 96/109 [=========================>....] - ETA: 0s - loss: 0.0600 - mae: 0.1715 - mse: 0.0600
109/109 [==============================] - 1s 5ms/step - loss: 0.0577 - mae: 0.1678 - mse: 0.0577 - val_loss: 0.0119 - val_mae: 0.0811 - val_mse: 0.0119
Epoch 27/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0544 - mae: 0.1625 - mse: 0.0544
 64/109 [================>.............] - ETA: 0s - loss: 0.0610 - mae: 0.1875 - mse: 0.0610
 96/109 [=========================>....] - ETA: 0s - loss: 0.0602 - mae: 0.1767 - mse: 0.0602
109/109 [==============================] - 1s 6ms/step - loss: 0.0545 - mae: 0.1659 - mse: 0.0545 - val_loss: 0.0179 - val_mae: 0.0991 - val_mse: 0.0179
Epoch 28/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0427 - mae: 0.1549 - mse: 0.0427
 64/109 [================>.............] - ETA: 0s - loss: 0.0416 - mae: 0.1409 - mse: 0.0416
 96/109 [=========================>....] - ETA: 0s - loss: 0.0471 - mae: 0.1483 - mse: 0.0471
109/109 [==============================] - 1s 5ms/step - loss: 0.0504 - mae: 0.1558 - mse: 0.0504 - val_loss: 0.0238 - val_mae: 0.1248 - val_mse: 0.0238
Epoch 29/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0381 - mae: 0.1565 - mse: 0.0381
 64/109 [================>.............] - ETA: 0s - loss: 0.0412 - mae: 0.1442 - mse: 0.0412
 96/109 [=========================>....] - ETA: 0s - loss: 0.0334 - mae: 0.1322 - mse: 0.0334
109/109 [==============================] - 1s 6ms/step - loss: 0.0459 - mae: 0.1420 - mse: 0.0459 - val_loss: 0.0105 - val_mae: 0.0820 - val_mse: 0.0105
Epoch 30/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0643 - mae: 0.1740 - mse: 0.0643
 64/109 [================>.............] - ETA: 0s - loss: 0.0534 - mae: 0.1631 - mse: 0.0534
 96/109 [=========================>....] - ETA: 0s - loss: 0.0549 - mae: 0.1686 - mse: 0.0549
109/109 [==============================] - 1s 5ms/step - loss: 0.0529 - mae: 0.1690 - mse: 0.0529 - val_loss: 0.0434 - val_mae: 0.1824 - val_mse: 0.0434
Saving trained model...
67
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         12.29992676]
average prediction= [4.573528]
baseline= 7.435483870967742
eachuser= [0. 0. 0. 0. 0. 5.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 2.4599853515625
['train-height-7.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_7_csi_a7_8.dat
170 32
170 33
170 34
170 35
170 36
170 37
2_170_60_7_csi_a7_6.dat
170 39
170 40
1_165_65_7_csi_a7_2.dat
165 42
165 43
165 44
1_165_65_7_csi_a7_5.dat
1_165_65_7_csi_a7_7.dat
165 47
165 48
165 49
1_165_65_7_csi_a7_3.dat
165 51
165 52
165 53
165 54
165 55
165 56
1_165_65_7_csi_a7_23.dat
165 58
165 59
165 60
165 61
165 62
165 63
165 64
1_165_65_7_csi_a7_1.dat
1_165_65_7_csi_a7_30.dat
165 67
165 68
165 69
1_165_65_7_csi_a7_21.dat
165 71
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
165 97
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
1_175_70_7_csi_a7_21.dat
1_175_70_7_csi_a7_13.dat
1_180_85_7_csi_a7_10.dat
180 132
180 133
180 134
180 135
180 136
180 137
1_180_85_7_csi_a7_14.dat
180 139
1_180_85_7_csi_a7_30.dat
180 141
1_180_85_7_csi_a7_1.dat
180 143
1_180_85_7_csi_a7_12.dat
180 145
180 146
1_180_85_7_csi_a7_9.dat
180 148
180 149
180 150
1_180_85_7_csi_a7_29.dat
1_180_85_7_csi_a7_24.dat
1_180_85_7_csi_a7_15.dat
180 154
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_7_csi_a7_25.dat
1_180_75_7_csi_a7_19.dat
1_180_75_7_csi_a7_9.dat
1_180_75_7_csi_a7_14.dat
1_180_75_7_csi_a7_3.dat
1_180_75_7_csi_a7_21.dat
1_180_75_7_csi_a7_22.dat
1_180_75_7_csi_a7_4.dat
1_180_75_7_csi_a7_11.dat
1_180_75_7_csi_a7_20.dat
1_180_75_7_csi_a7_28.dat
1_180_75_7_csi_a7_24.dat
1_180_75_7_csi_a7_5.dat
1_180_75_7_csi_a7_1.dat
1_180_75_7_csi_a7_15.dat
1_180_75_7_csi_a7_16.dat
1_180_75_7_csi_a7_17.dat
1_180_75_7_csi_a7_27.dat
1_180_75_7_csi_a7_26.dat
1_180_75_7_csi_a7_12.dat
1_180_75_7_csi_a7_7.dat
1_180_75_7_csi_a7_30.dat
1_180_75_7_csi_a7_23.dat
1_180_75_7_csi_a7_10.dat
1_180_75_7_csi_a7_29.dat
1_180_75_7_csi_a7_13.dat
1_180_75_7_csi_a7_2.dat
1_180_75_7_csi_a7_8.dat
1_180_75_7_csi_a7_6.dat
1_180_75_7_csi_a7_18.dat
173 191
1_173_85_7_csi_a7_9.dat
1_173_85_7_csi_a7_12.dat
1_173_85_7_csi_a7_8.dat
173 195
1_173_85_7_csi_a7_25.dat
173 197
1_173_85_7_csi_a7_20.dat
173 199
1_173_85_7_csi_a7_22.dat
1_173_85_7_csi_a7_19.dat
173 202
1_173_85_7_csi_a7_11.dat
1_173_85_7_csi_a7_7.dat
1_173_85_7_csi_a7_6.dat
173 206
1_173_85_7_csi_a7_21.dat
1_173_85_7_csi_a7_17.dat
173 209
173 210
173 211
1_173_85_7_csi_a7_23.dat
1_173_85_7_csi_a7_18.dat
173 214
173 215
173 216
173 217
1_173_85_7_csi_a7_16.dat
173 219
1_173_85_7_csi_a7_10.dat
(153, 30, 3)
(153, 443, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173 173 173
 173 173 173 173 173 173 173 173 173]
(153, 443, 30, 3, 1)

Loaded dataset of 153 samples, each sized (443, 30, 3, 1)


Train on 122 samples
Test on 31 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 443, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 443, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 443, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 443, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 443, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 443, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 443, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 109 samples, validate on 13 samples
Epoch 1/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.2713 - mae: 0.4308 - mse: 0.2713
 64/109 [================>.............] - ETA: 0s - loss: 0.1959 - mae: 0.3584 - mse: 0.1959
 96/109 [=========================>....] - ETA: 0s - loss: 0.1724 - mae: 0.3416 - mse: 0.1724
109/109 [==============================] - 1s 9ms/step - loss: 0.1728 - mae: 0.3430 - mse: 0.1728 - val_loss: 0.1088 - val_mae: 0.2846 - val_mse: 0.1088
Epoch 2/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1389 - mae: 0.3191 - mse: 0.1389
 64/109 [================>.............] - ETA: 0s - loss: 0.1387 - mae: 0.3231 - mse: 0.1387
 96/109 [=========================>....] - ETA: 0s - loss: 0.1205 - mae: 0.2998 - mse: 0.1205
109/109 [==============================] - 1s 6ms/step - loss: 0.1247 - mae: 0.3033 - mse: 0.1247 - val_loss: 0.2048 - val_mae: 0.3955 - val_mse: 0.2048
Epoch 3/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0948 - mae: 0.2525 - mse: 0.0948
 64/109 [================>.............] - ETA: 0s - loss: 0.1271 - mae: 0.2980 - mse: 0.1271
 96/109 [=========================>....] - ETA: 0s - loss: 0.1233 - mae: 0.2872 - mse: 0.1233
109/109 [==============================] - 1s 5ms/step - loss: 0.1157 - mae: 0.2769 - mse: 0.1157 - val_loss: 0.1792 - val_mae: 0.3577 - val_mse: 0.1792
Epoch 4/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1087 - mae: 0.2741 - mse: 0.1087
 64/109 [================>.............] - ETA: 0s - loss: 0.0867 - mae: 0.2394 - mse: 0.0867
 96/109 [=========================>....] - ETA: 0s - loss: 0.0845 - mae: 0.2346 - mse: 0.0845
109/109 [==============================] - 1s 5ms/step - loss: 0.0923 - mae: 0.2461 - mse: 0.0923 - val_loss: 0.1162 - val_mae: 0.2658 - val_mse: 0.1162
Epoch 5/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0876 - mae: 0.2474 - mse: 0.0876
 64/109 [================>.............] - ETA: 0s - loss: 0.0778 - mae: 0.2279 - mse: 0.0778
 96/109 [=========================>....] - ETA: 0s - loss: 0.0817 - mae: 0.2305 - mse: 0.0817
109/109 [==============================] - 1s 5ms/step - loss: 0.0779 - mae: 0.2240 - mse: 0.0779 - val_loss: 0.1085 - val_mae: 0.2481 - val_mse: 0.1085
Epoch 6/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0551 - mae: 0.1691 - mse: 0.0551
 64/109 [================>.............] - ETA: 0s - loss: 0.0602 - mae: 0.1857 - mse: 0.0602
 96/109 [=========================>....] - ETA: 0s - loss: 0.0665 - mae: 0.1923 - mse: 0.0665
109/109 [==============================] - 1s 5ms/step - loss: 0.0666 - mae: 0.1956 - mse: 0.0666 - val_loss: 0.1381 - val_mae: 0.2851 - val_mse: 0.1381
Epoch 7/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0626 - mae: 0.1793 - mse: 0.0626
 64/109 [================>.............] - ETA: 0s - loss: 0.0722 - mae: 0.1971 - mse: 0.0722
 96/109 [=========================>....] - ETA: 0s - loss: 0.0685 - mae: 0.1935 - mse: 0.0685
109/109 [==============================] - 1s 5ms/step - loss: 0.0771 - mae: 0.2054 - mse: 0.0771 - val_loss: 0.1365 - val_mae: 0.2780 - val_mse: 0.1365
Epoch 8/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0760 - mae: 0.2047 - mse: 0.0760
 64/109 [================>.............] - ETA: 0s - loss: 0.0614 - mae: 0.1860 - mse: 0.0614
 96/109 [=========================>....] - ETA: 0s - loss: 0.0667 - mae: 0.1937 - mse: 0.0667
109/109 [==============================] - 1s 5ms/step - loss: 0.0629 - mae: 0.1868 - mse: 0.0629 - val_loss: 0.1003 - val_mae: 0.2122 - val_mse: 0.1003
Epoch 9/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0612 - mae: 0.1973 - mse: 0.0612
 64/109 [================>.............] - ETA: 0s - loss: 0.0651 - mae: 0.2032 - mse: 0.0651
 96/109 [=========================>....] - ETA: 0s - loss: 0.0707 - mae: 0.2099 - mse: 0.0707
109/109 [==============================] - 1s 5ms/step - loss: 0.0769 - mae: 0.2176 - mse: 0.0769 - val_loss: 0.1065 - val_mae: 0.2062 - val_mse: 0.1065
Epoch 10/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0575 - mae: 0.1779 - mse: 0.0575
 64/109 [================>.............] - ETA: 0s - loss: 0.0683 - mae: 0.1897 - mse: 0.0683
 96/109 [=========================>....] - ETA: 0s - loss: 0.0605 - mae: 0.1764 - mse: 0.0605
109/109 [==============================] - 1s 5ms/step - loss: 0.0626 - mae: 0.1829 - mse: 0.0626 - val_loss: 0.1224 - val_mae: 0.2597 - val_mse: 0.1224
Epoch 11/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0580 - mae: 0.1737 - mse: 0.0580
 64/109 [================>.............] - ETA: 0s - loss: 0.0450 - mae: 0.1608 - mse: 0.0450
 96/109 [=========================>....] - ETA: 0s - loss: 0.0565 - mae: 0.1742 - mse: 0.0565
109/109 [==============================] - 1s 5ms/step - loss: 0.0631 - mae: 0.1822 - mse: 0.0631 - val_loss: 0.1107 - val_mae: 0.2365 - val_mse: 0.1107
Epoch 12/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0570 - mae: 0.1653 - mse: 0.0570
 64/109 [================>.............] - ETA: 0s - loss: 0.0653 - mae: 0.1783 - mse: 0.0653
 96/109 [=========================>....] - ETA: 0s - loss: 0.0626 - mae: 0.1757 - mse: 0.0626
109/109 [==============================] - 1s 5ms/step - loss: 0.0629 - mae: 0.1757 - mse: 0.0629 - val_loss: 0.0880 - val_mae: 0.1851 - val_mse: 0.0880
Epoch 13/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0737 - mae: 0.2099 - mse: 0.0737
 64/109 [================>.............] - ETA: 0s - loss: 0.0711 - mae: 0.1986 - mse: 0.0711
 96/109 [=========================>....] - ETA: 0s - loss: 0.0662 - mae: 0.1867 - mse: 0.0662
109/109 [==============================] - 1s 5ms/step - loss: 0.0628 - mae: 0.1796 - mse: 0.0628 - val_loss: 0.1153 - val_mae: 0.2591 - val_mse: 0.1153
Epoch 14/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0263 - mae: 0.1247 - mse: 0.0263
 64/109 [================>.............] - ETA: 0s - loss: 0.0614 - mae: 0.1812 - mse: 0.0614
 96/109 [=========================>....] - ETA: 0s - loss: 0.0648 - mae: 0.1855 - mse: 0.0648
109/109 [==============================] - 1s 5ms/step - loss: 0.0635 - mae: 0.1818 - mse: 0.0635 - val_loss: 0.1127 - val_mae: 0.2582 - val_mse: 0.1127
Epoch 15/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0641 - mae: 0.1665 - mse: 0.0641
 64/109 [================>.............] - ETA: 0s - loss: 0.0596 - mae: 0.1699 - mse: 0.0596
 96/109 [=========================>....] - ETA: 0s - loss: 0.0516 - mae: 0.1606 - mse: 0.0516
109/109 [==============================] - 1s 5ms/step - loss: 0.0548 - mae: 0.1680 - mse: 0.0548 - val_loss: 0.0753 - val_mae: 0.1871 - val_mse: 0.0753
Epoch 16/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0412 - mae: 0.1594 - mse: 0.0412
 64/109 [================>.............] - ETA: 0s - loss: 0.0337 - mae: 0.1481 - mse: 0.0337
 96/109 [=========================>....] - ETA: 0s - loss: 0.0475 - mae: 0.1663 - mse: 0.0475
109/109 [==============================] - 1s 5ms/step - loss: 0.0512 - mae: 0.1723 - mse: 0.0512 - val_loss: 0.0813 - val_mae: 0.2084 - val_mse: 0.0813
Epoch 17/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0251 - mae: 0.1028 - mse: 0.0251
 64/109 [================>.............] - ETA: 0s - loss: 0.0243 - mae: 0.1124 - mse: 0.0243
 96/109 [=========================>....] - ETA: 0s - loss: 0.0398 - mae: 0.1411 - mse: 0.0398
109/109 [==============================] - 1s 5ms/step - loss: 0.0518 - mae: 0.1564 - mse: 0.0518 - val_loss: 0.1091 - val_mae: 0.2621 - val_mse: 0.1091
Epoch 18/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0314 - mae: 0.1312 - mse: 0.0314
 64/109 [================>.............] - ETA: 0s - loss: 0.0390 - mae: 0.1491 - mse: 0.0390
 96/109 [=========================>....] - ETA: 0s - loss: 0.0444 - mae: 0.1488 - mse: 0.0444
109/109 [==============================] - 1s 5ms/step - loss: 0.0455 - mae: 0.1501 - mse: 0.0455 - val_loss: 0.0590 - val_mae: 0.1644 - val_mse: 0.0590
Epoch 19/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0848 - mae: 0.2262 - mse: 0.0848
 64/109 [================>.............] - ETA: 0s - loss: 0.0561 - mae: 0.1712 - mse: 0.0561
 96/109 [=========================>....] - ETA: 0s - loss: 0.0467 - mae: 0.1564 - mse: 0.0467
109/109 [==============================] - 1s 5ms/step - loss: 0.0554 - mae: 0.1666 - mse: 0.0554 - val_loss: 0.0595 - val_mae: 0.1768 - val_mse: 0.0595
Epoch 20/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0187 - mae: 0.1059 - mse: 0.0187
 64/109 [================>.............] - ETA: 0s - loss: 0.0331 - mae: 0.1319 - mse: 0.0331
 96/109 [=========================>....] - ETA: 0s - loss: 0.0445 - mae: 0.1437 - mse: 0.0445
109/109 [==============================] - 1s 5ms/step - loss: 0.0456 - mae: 0.1492 - mse: 0.0456 - val_loss: 0.0976 - val_mae: 0.2643 - val_mse: 0.0976
Epoch 21/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0734 - mae: 0.1819 - mse: 0.0734
 64/109 [================>.............] - ETA: 0s - loss: 0.0513 - mae: 0.1574 - mse: 0.0513
 96/109 [=========================>....] - ETA: 0s - loss: 0.0515 - mae: 0.1608 - mse: 0.0515
109/109 [==============================] - 1s 5ms/step - loss: 0.0478 - mae: 0.1544 - mse: 0.0478 - val_loss: 0.0832 - val_mae: 0.2354 - val_mse: 0.0832
Epoch 22/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0386 - mae: 0.1389 - mse: 0.0386
 64/109 [================>.............] - ETA: 0s - loss: 0.0452 - mae: 0.1410 - mse: 0.0452
 96/109 [=========================>....] - ETA: 0s - loss: 0.0445 - mae: 0.1350 - mse: 0.0445
109/109 [==============================] - 0s 4ms/step - loss: 0.0432 - mae: 0.1320 - mse: 0.0432 - val_loss: 0.0697 - val_mae: 0.1950 - val_mse: 0.0697
Epoch 23/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0312 - mae: 0.1173 - mse: 0.0312
 64/109 [================>.............] - ETA: 0s - loss: 0.0477 - mae: 0.1363 - mse: 0.0477
 96/109 [=========================>....] - ETA: 0s - loss: 0.0471 - mae: 0.1369 - mse: 0.0471
109/109 [==============================] - 1s 5ms/step - loss: 0.0478 - mae: 0.1405 - mse: 0.0478 - val_loss: 0.0750 - val_mae: 0.2048 - val_mse: 0.0750
Epoch 24/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0765 - mae: 0.1761 - mse: 0.0765
 64/109 [================>.............] - ETA: 0s - loss: 0.0467 - mae: 0.1381 - mse: 0.0467
 96/109 [=========================>....] - ETA: 0s - loss: 0.0434 - mae: 0.1368 - mse: 0.0434
109/109 [==============================] - 1s 5ms/step - loss: 0.0423 - mae: 0.1354 - mse: 0.0423 - val_loss: 0.0854 - val_mae: 0.2283 - val_mse: 0.0854
Epoch 25/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0530 - mae: 0.1416 - mse: 0.0530
 64/109 [================>.............] - ETA: 0s - loss: 0.0559 - mae: 0.1486 - mse: 0.0559
 96/109 [=========================>....] - ETA: 0s - loss: 0.0450 - mae: 0.1366 - mse: 0.0450
109/109 [==============================] - 1s 5ms/step - loss: 0.0434 - mae: 0.1356 - mse: 0.0434 - val_loss: 0.0519 - val_mae: 0.1632 - val_mse: 0.0519
Epoch 26/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0367 - mae: 0.1204 - mse: 0.0367
 64/109 [================>.............] - ETA: 0s - loss: 0.0305 - mae: 0.1184 - mse: 0.0305
 96/109 [=========================>....] - ETA: 0s - loss: 0.0402 - mae: 0.1290 - mse: 0.0402
109/109 [==============================] - 1s 5ms/step - loss: 0.0413 - mae: 0.1304 - mse: 0.0413 - val_loss: 0.0612 - val_mae: 0.1811 - val_mse: 0.0612
Epoch 27/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0552 - mae: 0.1443 - mse: 0.0552
 64/109 [================>.............] - ETA: 0s - loss: 0.0421 - mae: 0.1312 - mse: 0.0421
 96/109 [=========================>....] - ETA: 0s - loss: 0.0376 - mae: 0.1304 - mse: 0.0376
109/109 [==============================] - 1s 5ms/step - loss: 0.0377 - mae: 0.1339 - mse: 0.0377 - val_loss: 0.0446 - val_mae: 0.1504 - val_mse: 0.0446
Epoch 28/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0456 - mae: 0.1476 - mse: 0.0456
 64/109 [================>.............] - ETA: 0s - loss: 0.0460 - mae: 0.1469 - mse: 0.0460
 96/109 [=========================>....] - ETA: 0s - loss: 0.0500 - mae: 0.1510 - mse: 0.0500
109/109 [==============================] - 1s 5ms/step - loss: 0.0453 - mae: 0.1424 - mse: 0.0453 - val_loss: 0.0605 - val_mae: 0.2044 - val_mse: 0.0605
Epoch 29/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0634 - mae: 0.1643 - mse: 0.0634
 64/109 [================>.............] - ETA: 0s - loss: 0.0436 - mae: 0.1406 - mse: 0.0436
 96/109 [=========================>....] - ETA: 0s - loss: 0.0429 - mae: 0.1372 - mse: 0.0429
109/109 [==============================] - 1s 5ms/step - loss: 0.0404 - mae: 0.1329 - mse: 0.0404 - val_loss: 0.0469 - val_mae: 0.1754 - val_mse: 0.0469
Epoch 30/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0175 - mae: 0.0956 - mse: 0.0175
 64/109 [================>.............] - ETA: 0s - loss: 0.0337 - mae: 0.1136 - mse: 0.0337
 96/109 [=========================>....] - ETA: 0s - loss: 0.0444 - mae: 0.1356 - mse: 0.0444
109/109 [==============================] - 1s 5ms/step - loss: 0.0450 - mae: 0.1388 - mse: 0.0450 - val_loss: 0.0378 - val_mae: 0.1538 - val_mse: 0.0378
Saving trained model...
67
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         30.96807861]
average prediction= [5.0020022]
baseline= 8.790322580645162
eachuser= [0. 0. 0. 0. 0. 8.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 3.8710098266601562
['train-height-7.py', '0']
155 1
155 2
155 3
155 4
155 5
155 6
155 7
155 8
155 9
155 10
155 11
155 12
155 13
155 14
155 15
155 16
155 17
155 18
155 19
155 20
155 21
155 22
155 23
155 24
155 25
155 26
155 27
155 28
155 29
155 30
2_170_60_7_csi_a7_8.dat
170 32
170 33
170 34
170 35
170 36
170 37
2_170_60_7_csi_a7_6.dat
170 39
170 40
1_165_65_7_csi_a7_2.dat
165 42
165 43
165 44
1_165_65_7_csi_a7_5.dat
1_165_65_7_csi_a7_7.dat
165 47
165 48
165 49
1_165_65_7_csi_a7_3.dat
165 51
165 52
165 53
165 54
165 55
165 56
1_165_65_7_csi_a7_23.dat
165 58
165 59
165 60
165 61
165 62
165 63
165 64
1_165_65_7_csi_a7_1.dat
1_165_65_7_csi_a7_30.dat
165 67
165 68
165 69
1_165_65_7_csi_a7_21.dat
165 71
165 72
165 73
165 74
165 75
165 76
165 77
165 78
165 79
165 80
165 81
165 82
165 83
165 84
165 85
165 86
165 87
165 88
165 89
165 90
165 91
165 92
165 93
165 94
165 95
165 96
165 97
165 98
165 99
165 100
175 101
175 102
175 103
175 104
175 105
175 106
175 107
175 108
175 109
175 110
175 111
175 112
175 113
175 114
175 115
175 116
175 117
175 118
175 119
175 120
175 121
175 122
175 123
175 124
175 125
175 126
175 127
175 128
1_175_70_7_csi_a7_21.dat
1_175_70_7_csi_a7_13.dat
1_180_85_7_csi_a7_10.dat
180 132
180 133
180 134
180 135
180 136
180 137
1_180_85_7_csi_a7_14.dat
180 139
1_180_85_7_csi_a7_30.dat
180 141
1_180_85_7_csi_a7_1.dat
180 143
1_180_85_7_csi_a7_12.dat
180 145
180 146
1_180_85_7_csi_a7_9.dat
180 148
180 149
180 150
1_180_85_7_csi_a7_29.dat
1_180_85_7_csi_a7_24.dat
1_180_85_7_csi_a7_15.dat
180 154
180 155
180 156
180 157
180 158
180 159
180 160
1_180_75_7_csi_a7_25.dat
1_180_75_7_csi_a7_19.dat
1_180_75_7_csi_a7_9.dat
1_180_75_7_csi_a7_14.dat
1_180_75_7_csi_a7_3.dat
1_180_75_7_csi_a7_21.dat
1_180_75_7_csi_a7_22.dat
1_180_75_7_csi_a7_4.dat
1_180_75_7_csi_a7_11.dat
1_180_75_7_csi_a7_20.dat
1_180_75_7_csi_a7_28.dat
1_180_75_7_csi_a7_24.dat
1_180_75_7_csi_a7_5.dat
1_180_75_7_csi_a7_1.dat
1_180_75_7_csi_a7_15.dat
1_180_75_7_csi_a7_16.dat
1_180_75_7_csi_a7_17.dat
1_180_75_7_csi_a7_27.dat
1_180_75_7_csi_a7_26.dat
1_180_75_7_csi_a7_12.dat
1_180_75_7_csi_a7_7.dat
1_180_75_7_csi_a7_30.dat
1_180_75_7_csi_a7_23.dat
1_180_75_7_csi_a7_10.dat
1_180_75_7_csi_a7_29.dat
1_180_75_7_csi_a7_13.dat
1_180_75_7_csi_a7_2.dat
1_180_75_7_csi_a7_8.dat
1_180_75_7_csi_a7_6.dat
1_180_75_7_csi_a7_18.dat
173 191
1_173_85_7_csi_a7_9.dat
1_173_85_7_csi_a7_12.dat
1_173_85_7_csi_a7_8.dat
173 195
1_173_85_7_csi_a7_25.dat
173 197
1_173_85_7_csi_a7_20.dat
173 199
1_173_85_7_csi_a7_22.dat
1_173_85_7_csi_a7_19.dat
173 202
1_173_85_7_csi_a7_11.dat
1_173_85_7_csi_a7_7.dat
1_173_85_7_csi_a7_6.dat
173 206
1_173_85_7_csi_a7_21.dat
1_173_85_7_csi_a7_17.dat
173 209
173 210
173 211
1_173_85_7_csi_a7_23.dat
1_173_85_7_csi_a7_18.dat
173 214
173 215
173 216
173 217
1_173_85_7_csi_a7_16.dat
173 219
1_173_85_7_csi_a7_10.dat
(153, 30, 3)
(153, 443, 30, 3)
[155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155 155
 155 155 155 155 155 155 155 155 155 155 155 155 170 170 170 170 170 170
 170 170 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165 165
 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175 175
 175 175 175 175 175 175 175 175 175 175 180 180 180 180 180 180 180 180
 180 180 180 180 180 180 180 180 180 180 180 180 180 173 173 173 173 173
 173 173 173 173 173 173 173 173 173]
(153, 443, 30, 3, 1)

Loaded dataset of 153 samples, each sized (443, 30, 3, 1)


Train on 122 samples
Test on 31 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 443, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 443, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 443, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 443, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 443, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 443, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 443, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 109 samples, validate on 13 samples
Epoch 1/30

 32/109 [=======>......................] - ETA: 1s - loss: 0.3142 - mae: 0.5021 - mse: 0.3142
 64/109 [================>.............] - ETA: 0s - loss: 0.2407 - mae: 0.4228 - mse: 0.2407
 96/109 [=========================>....] - ETA: 0s - loss: 0.2040 - mae: 0.3818 - mse: 0.2040
109/109 [==============================] - 1s 9ms/step - loss: 0.2059 - mae: 0.3796 - mse: 0.2059 - val_loss: 0.1739 - val_mae: 0.3562 - val_mse: 0.1739
Epoch 2/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1352 - mae: 0.3084 - mse: 0.1352
 64/109 [================>.............] - ETA: 0s - loss: 0.1436 - mae: 0.3171 - mse: 0.1436
 96/109 [=========================>....] - ETA: 0s - loss: 0.1332 - mae: 0.3036 - mse: 0.1332
109/109 [==============================] - 1s 5ms/step - loss: 0.1337 - mae: 0.2986 - mse: 0.1337 - val_loss: 0.1313 - val_mae: 0.3056 - val_mse: 0.1313
Epoch 3/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1259 - mae: 0.3022 - mse: 0.1259
 64/109 [================>.............] - ETA: 0s - loss: 0.1092 - mae: 0.2760 - mse: 0.1092
 96/109 [=========================>....] - ETA: 0s - loss: 0.1263 - mae: 0.2951 - mse: 0.1263
109/109 [==============================] - 1s 5ms/step - loss: 0.1285 - mae: 0.2984 - mse: 0.1285 - val_loss: 0.1185 - val_mae: 0.2847 - val_mse: 0.1185
Epoch 4/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1233 - mae: 0.2798 - mse: 0.1233
 64/109 [================>.............] - ETA: 0s - loss: 0.1155 - mae: 0.2730 - mse: 0.1155
 96/109 [=========================>....] - ETA: 0s - loss: 0.1184 - mae: 0.2859 - mse: 0.1184
109/109 [==============================] - 1s 5ms/step - loss: 0.1234 - mae: 0.2927 - mse: 0.1234 - val_loss: 0.1142 - val_mae: 0.2895 - val_mse: 0.1142
Epoch 5/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1012 - mae: 0.2703 - mse: 0.1012
 64/109 [================>.............] - ETA: 0s - loss: 0.0979 - mae: 0.2547 - mse: 0.0979
 96/109 [=========================>....] - ETA: 0s - loss: 0.0998 - mae: 0.2644 - mse: 0.0998
109/109 [==============================] - 1s 5ms/step - loss: 0.1044 - mae: 0.2694 - mse: 0.1044 - val_loss: 0.1099 - val_mae: 0.2866 - val_mse: 0.1099
Epoch 6/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0850 - mae: 0.2259 - mse: 0.0850
 64/109 [================>.............] - ETA: 0s - loss: 0.1182 - mae: 0.2660 - mse: 0.1182
 96/109 [=========================>....] - ETA: 0s - loss: 0.1161 - mae: 0.2739 - mse: 0.1161
109/109 [==============================] - 1s 5ms/step - loss: 0.1167 - mae: 0.2791 - mse: 0.1167 - val_loss: 0.0977 - val_mae: 0.2679 - val_mse: 0.0977
Epoch 7/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1565 - mae: 0.3415 - mse: 0.1565
 64/109 [================>.............] - ETA: 0s - loss: 0.1143 - mae: 0.2763 - mse: 0.1143
 96/109 [=========================>....] - ETA: 0s - loss: 0.1152 - mae: 0.2805 - mse: 0.1152
109/109 [==============================] - 1s 5ms/step - loss: 0.1088 - mae: 0.2710 - mse: 0.1088 - val_loss: 0.0920 - val_mae: 0.2596 - val_mse: 0.0920
Epoch 8/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1262 - mae: 0.3006 - mse: 0.1262
 64/109 [================>.............] - ETA: 0s - loss: 0.1059 - mae: 0.2708 - mse: 0.1059
 96/109 [=========================>....] - ETA: 0s - loss: 0.1082 - mae: 0.2653 - mse: 0.1082
109/109 [==============================] - 1s 5ms/step - loss: 0.1093 - mae: 0.2692 - mse: 0.1093 - val_loss: 0.0878 - val_mae: 0.2541 - val_mse: 0.0878
Epoch 9/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0806 - mae: 0.2210 - mse: 0.0806
 64/109 [================>.............] - ETA: 0s - loss: 0.0856 - mae: 0.2361 - mse: 0.0856
 96/109 [=========================>....] - ETA: 0s - loss: 0.0833 - mae: 0.2376 - mse: 0.0833
109/109 [==============================] - 1s 5ms/step - loss: 0.0956 - mae: 0.2547 - mse: 0.0956 - val_loss: 0.0790 - val_mae: 0.2282 - val_mse: 0.0790
Epoch 10/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1085 - mae: 0.2871 - mse: 0.1085
 64/109 [================>.............] - ETA: 0s - loss: 0.1042 - mae: 0.2664 - mse: 0.1042
 96/109 [=========================>....] - ETA: 0s - loss: 0.0955 - mae: 0.2507 - mse: 0.0955
109/109 [==============================] - 1s 5ms/step - loss: 0.0984 - mae: 0.2545 - mse: 0.0984 - val_loss: 0.0744 - val_mae: 0.2217 - val_mse: 0.0744
Epoch 11/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0690 - mae: 0.2099 - mse: 0.0690
 64/109 [================>.............] - ETA: 0s - loss: 0.0844 - mae: 0.2336 - mse: 0.0844
 96/109 [=========================>....] - ETA: 0s - loss: 0.0953 - mae: 0.2502 - mse: 0.0953
109/109 [==============================] - 1s 5ms/step - loss: 0.0956 - mae: 0.2489 - mse: 0.0956 - val_loss: 0.0775 - val_mae: 0.2318 - val_mse: 0.0775
Epoch 12/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.1051 - mae: 0.2522 - mse: 0.1051
 64/109 [================>.............] - ETA: 0s - loss: 0.0915 - mae: 0.2395 - mse: 0.0915
 96/109 [=========================>....] - ETA: 0s - loss: 0.0933 - mae: 0.2420 - mse: 0.0933
109/109 [==============================] - 1s 5ms/step - loss: 0.0930 - mae: 0.2426 - mse: 0.0930 - val_loss: 0.0669 - val_mae: 0.1983 - val_mse: 0.0669
Epoch 13/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0854 - mae: 0.2326 - mse: 0.0854
 64/109 [================>.............] - ETA: 0s - loss: 0.0922 - mae: 0.2432 - mse: 0.0922
 96/109 [=========================>....] - ETA: 0s - loss: 0.0764 - mae: 0.2181 - mse: 0.0764
109/109 [==============================] - 1s 5ms/step - loss: 0.0817 - mae: 0.2228 - mse: 0.0817 - val_loss: 0.0628 - val_mae: 0.1878 - val_mse: 0.0628
Epoch 14/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0741 - mae: 0.2138 - mse: 0.0741
 64/109 [================>.............] - ETA: 0s - loss: 0.0825 - mae: 0.2292 - mse: 0.0825
 96/109 [=========================>....] - ETA: 0s - loss: 0.0856 - mae: 0.2340 - mse: 0.0856
109/109 [==============================] - 1s 5ms/step - loss: 0.0918 - mae: 0.2407 - mse: 0.0918 - val_loss: 0.0634 - val_mae: 0.1885 - val_mse: 0.0634
Epoch 15/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0963 - mae: 0.2395 - mse: 0.0963
 64/109 [================>.............] - ETA: 0s - loss: 0.0838 - mae: 0.2217 - mse: 0.0838
 96/109 [=========================>....] - ETA: 0s - loss: 0.0805 - mae: 0.2158 - mse: 0.0805
109/109 [==============================] - 1s 5ms/step - loss: 0.0804 - mae: 0.2138 - mse: 0.0804 - val_loss: 0.0604 - val_mae: 0.1897 - val_mse: 0.0604
Epoch 16/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0777 - mae: 0.2275 - mse: 0.0777
 64/109 [================>.............] - ETA: 0s - loss: 0.0808 - mae: 0.2200 - mse: 0.0808
 96/109 [=========================>....] - ETA: 0s - loss: 0.0779 - mae: 0.2126 - mse: 0.0779
109/109 [==============================] - 1s 5ms/step - loss: 0.0830 - mae: 0.2213 - mse: 0.0830 - val_loss: 0.0575 - val_mae: 0.1709 - val_mse: 0.0575
Epoch 17/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0948 - mae: 0.2416 - mse: 0.0948
 64/109 [================>.............] - ETA: 0s - loss: 0.0673 - mae: 0.1960 - mse: 0.0673
 96/109 [=========================>....] - ETA: 0s - loss: 0.0776 - mae: 0.2096 - mse: 0.0776
109/109 [==============================] - 1s 5ms/step - loss: 0.0830 - mae: 0.2177 - mse: 0.0830 - val_loss: 0.0561 - val_mae: 0.1673 - val_mse: 0.0561
Epoch 18/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0991 - mae: 0.2472 - mse: 0.0991
 64/109 [================>.............] - ETA: 0s - loss: 0.0827 - mae: 0.2164 - mse: 0.0827
 96/109 [=========================>....] - ETA: 0s - loss: 0.0850 - mae: 0.2245 - mse: 0.0850
109/109 [==============================] - 1s 5ms/step - loss: 0.0859 - mae: 0.2223 - mse: 0.0859 - val_loss: 0.0593 - val_mae: 0.1977 - val_mse: 0.0593
Epoch 19/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0708 - mae: 0.2016 - mse: 0.0708
 64/109 [================>.............] - ETA: 0s - loss: 0.0844 - mae: 0.2267 - mse: 0.0844
 96/109 [=========================>....] - ETA: 0s - loss: 0.0803 - mae: 0.2167 - mse: 0.0803
109/109 [==============================] - 1s 5ms/step - loss: 0.0786 - mae: 0.2134 - mse: 0.0786 - val_loss: 0.0502 - val_mae: 0.1623 - val_mse: 0.0502
Epoch 20/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0670 - mae: 0.2011 - mse: 0.0670
 64/109 [================>.............] - ETA: 0s - loss: 0.0892 - mae: 0.2248 - mse: 0.0892
 96/109 [=========================>....] - ETA: 0s - loss: 0.0753 - mae: 0.2037 - mse: 0.0753
109/109 [==============================] - 0s 5ms/step - loss: 0.0802 - mae: 0.2098 - mse: 0.0802 - val_loss: 0.0479 - val_mae: 0.1584 - val_mse: 0.0479
Epoch 21/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0829 - mae: 0.2118 - mse: 0.0829
 64/109 [================>.............] - ETA: 0s - loss: 0.0547 - mae: 0.1582 - mse: 0.0547
 96/109 [=========================>....] - ETA: 0s - loss: 0.0685 - mae: 0.1812 - mse: 0.0685
109/109 [==============================] - 1s 5ms/step - loss: 0.0662 - mae: 0.1801 - mse: 0.0662 - val_loss: 0.0456 - val_mae: 0.1655 - val_mse: 0.0456
Epoch 22/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0562 - mae: 0.1689 - mse: 0.0562
 64/109 [================>.............] - ETA: 0s - loss: 0.0565 - mae: 0.1668 - mse: 0.0565
 96/109 [=========================>....] - ETA: 0s - loss: 0.0653 - mae: 0.1798 - mse: 0.0653
109/109 [==============================] - 1s 5ms/step - loss: 0.0639 - mae: 0.1791 - mse: 0.0639 - val_loss: 0.0387 - val_mae: 0.1404 - val_mse: 0.0387
Epoch 23/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0601 - mae: 0.1843 - mse: 0.0601
 64/109 [================>.............] - ETA: 0s - loss: 0.0633 - mae: 0.1835 - mse: 0.0633
 96/109 [=========================>....] - ETA: 0s - loss: 0.0597 - mae: 0.1786 - mse: 0.0597
109/109 [==============================] - 1s 5ms/step - loss: 0.0590 - mae: 0.1774 - mse: 0.0590 - val_loss: 0.0366 - val_mae: 0.1471 - val_mse: 0.0366
Epoch 24/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0569 - mae: 0.1598 - mse: 0.0569
 64/109 [================>.............] - ETA: 0s - loss: 0.0664 - mae: 0.1744 - mse: 0.0664
 96/109 [=========================>....] - ETA: 0s - loss: 0.0572 - mae: 0.1623 - mse: 0.0572
109/109 [==============================] - 1s 5ms/step - loss: 0.0571 - mae: 0.1651 - mse: 0.0571 - val_loss: 0.0360 - val_mae: 0.1521 - val_mse: 0.0360
Epoch 25/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0506 - mae: 0.1513 - mse: 0.0506
 64/109 [================>.............] - ETA: 0s - loss: 0.0450 - mae: 0.1476 - mse: 0.0450
 96/109 [=========================>....] - ETA: 0s - loss: 0.0510 - mae: 0.1610 - mse: 0.0510
109/109 [==============================] - 1s 5ms/step - loss: 0.0491 - mae: 0.1599 - mse: 0.0491 - val_loss: 0.0344 - val_mae: 0.1398 - val_mse: 0.0344
Epoch 26/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0426 - mae: 0.1662 - mse: 0.0426
 64/109 [================>.............] - ETA: 0s - loss: 0.0498 - mae: 0.1638 - mse: 0.0498
 96/109 [=========================>....] - ETA: 0s - loss: 0.0490 - mae: 0.1590 - mse: 0.0490
109/109 [==============================] - 1s 5ms/step - loss: 0.0550 - mae: 0.1689 - mse: 0.0550 - val_loss: 0.0360 - val_mae: 0.1604 - val_mse: 0.0360
Epoch 27/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0385 - mae: 0.1502 - mse: 0.0385
 64/109 [================>.............] - ETA: 0s - loss: 0.0448 - mae: 0.1542 - mse: 0.0448
 96/109 [=========================>....] - ETA: 0s - loss: 0.0481 - mae: 0.1586 - mse: 0.0481
109/109 [==============================] - 0s 4ms/step - loss: 0.0522 - mae: 0.1625 - mse: 0.0522 - val_loss: 0.0304 - val_mae: 0.1289 - val_mse: 0.0304
Epoch 28/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0344 - mae: 0.1476 - mse: 0.0344
 64/109 [================>.............] - ETA: 0s - loss: 0.0517 - mae: 0.1601 - mse: 0.0517
 96/109 [=========================>....] - ETA: 0s - loss: 0.0496 - mae: 0.1555 - mse: 0.0496
109/109 [==============================] - 1s 5ms/step - loss: 0.0553 - mae: 0.1643 - mse: 0.0553 - val_loss: 0.0275 - val_mae: 0.1282 - val_mse: 0.0275
Epoch 29/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0424 - mae: 0.1393 - mse: 0.0424
 64/109 [================>.............] - ETA: 0s - loss: 0.0673 - mae: 0.1717 - mse: 0.0673
 96/109 [=========================>....] - ETA: 0s - loss: 0.0601 - mae: 0.1680 - mse: 0.0601
109/109 [==============================] - 0s 4ms/step - loss: 0.0584 - mae: 0.1657 - mse: 0.0584 - val_loss: 0.0202 - val_mae: 0.0990 - val_mse: 0.0202
Epoch 30/30

 32/109 [=======>......................] - ETA: 0s - loss: 0.0289 - mae: 0.1112 - mse: 0.0289
 64/109 [================>.............] - ETA: 0s - loss: 0.0353 - mae: 0.1202 - mse: 0.0353
 96/109 [=========================>....] - ETA: 0s - loss: 0.0447 - mae: 0.1463 - mse: 0.0447
109/109 [==============================] - 1s 5ms/step - loss: 0.0458 - mae: 0.1495 - mse: 0.0458 - val_loss: 0.0200 - val_mae: 0.1027 - val_mse: 0.0200
Saving trained model...
67
Testing...
heightdiff= [ 0.          0.          0.          0.          0.         29.43815613]
average prediction= [3.60771]
baseline= 7.080645161290323
eachuser= [0. 0. 0. 0. 0. 5.]
165 -:- nan
170 -:- nan
173 -:- nan
175 -:- nan
180 -:- nan
155 -:- 5.887631225585937
