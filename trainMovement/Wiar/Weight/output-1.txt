['train-weight-1.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
2_155_65_1_csi_a1_6.dat
65 8
2_155_65_1_csi_a1_24.dat
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_1_csi_a1_3.dat
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_1_csi_a1_11.dat
65 42
1_165_65_1_csi_a1_2.dat
1_165_65_1_csi_a1_5.dat
65 45
1_165_65_1_csi_a1_4.dat
1_165_65_1_csi_a1_13.dat
65 48
1_165_65_1_csi_a1_12.dat
65 50
65 51
1_165_65_1_csi_a1_14.dat
65 53
1_165_65_1_csi_a1_6.dat
1_165_65_1_csi_a1_1.dat
65 56
1_165_65_1_csi_a1_15.dat
1_165_65_1_csi_a1_17.dat
65 59
65 60
1_165_65_1_csi_a1_3.dat
65 62
1_165_65_1_csi_a1_9.dat
1_165_65_1_csi_a1_16.dat
1_165_65_1_csi_a1_22.dat
65 66
1_165_65_1_csi_a1_10.dat
65 68
1_165_65_1_csi_a1_7.dat
65 70
50 71
50 72
50 73
50 74
50 75
2_165_50_1_csi_a1_29.dat
50 77
2_165_50_1_csi_a1_2.dat
50 79
50 80
2_165_50_1_csi_a1_3.dat
50 82
50 83
50 84
50 85
50 86
50 87
2_165_50_1_csi_a1_28.dat
50 89
50 90
2_165_50_1_csi_a1_7.dat
50 92
50 93
50 94
50 95
50 96
2_165_50_1_csi_a1_25.dat
2_165_50_1_csi_a1_27.dat
2_165_50_1_csi_a1_11.dat
50 100
70 101
70 102
70 103
70 104
1_175_70_1_csi_a1_18.dat
1_175_70_1_csi_a1_12.dat
70 107
70 108
70 109
1_175_70_1_csi_a1_8.dat
70 111
1_175_70_1_csi_a1_3.dat
1_175_70_1_csi_a1_26.dat
70 114
1_175_70_1_csi_a1_10.dat
70 116
70 117
1_175_70_1_csi_a1_6.dat
70 119
1_175_70_1_csi_a1_9.dat
70 121
70 122
70 123
70 124
70 125
1_175_70_1_csi_a1_22.dat
70 127
70 128
1_175_70_1_csi_a1_21.dat
1_175_70_1_csi_a1_14.dat
85 131
1_180_85_1_csi_a1_6.dat
85 133
1_180_85_1_csi_a1_4.dat
85 135
85 136
85 137
1_180_85_1_csi_a1_22.dat
1_180_85_1_csi_a1_20.dat
85 140
85 141
85 142
1_180_85_1_csi_a1_25.dat
1_180_85_1_csi_a1_26.dat
1_180_85_1_csi_a1_12.dat
1_180_85_1_csi_a1_30.dat
85 147
85 148
1_180_85_1_csi_a1_27.dat
85 150
85 151
1_180_85_1_csi_a1_13.dat
1_180_85_1_csi_a1_5.dat
1_180_85_1_csi_a1_7.dat
1_180_85_1_csi_a1_9.dat
85 156
1_180_85_1_csi_a1_3.dat
85 158
85 159
1_180_85_1_csi_a1_2.dat
75 161
75 162
75 163
1_180_75_1_csi_a1_4.dat
75 165
75 166
1_180_75_1_csi_a1_27.dat
75 168
75 169
1_180_75_1_csi_a1_2.dat
1_180_75_1_csi_a1_1.dat
75 172
75 173
75 174
75 175
1_180_75_1_csi_a1_16.dat
75 177
75 178
75 179
75 180
75 181
75 182
75 183
75 184
1_180_75_1_csi_a1_15.dat
75 186
75 187
1_180_75_1_csi_a1_29.dat
75 189
75 190
1_173_85_1_csi_a1_16.dat
1_173_85_1_csi_a1_13.dat
1_173_85_1_csi_a1_22.dat
1_173_85_1_csi_a1_26.dat
1_173_85_1_csi_a1_19.dat
1_173_85_1_csi_a1_18.dat
1_173_85_1_csi_a1_5.dat
1_173_85_1_csi_a1_17.dat
1_173_85_1_csi_a1_7.dat
1_173_85_1_csi_a1_6.dat
1_173_85_1_csi_a1_9.dat
1_173_85_1_csi_a1_23.dat
85 203
85 204
1_173_85_1_csi_a1_30.dat
1_173_85_1_csi_a1_21.dat
1_173_85_1_csi_a1_20.dat
1_173_85_1_csi_a1_25.dat
1_173_85_1_csi_a1_11.dat
1_173_85_1_csi_a1_24.dat
1_173_85_1_csi_a1_28.dat
1_173_85_1_csi_a1_27.dat
1_173_85_1_csi_a1_8.dat
1_173_85_1_csi_a1_4.dat
1_173_85_1_csi_a1_14.dat
1_173_85_1_csi_a1_2.dat
1_173_85_1_csi_a1_29.dat
1_173_85_1_csi_a1_3.dat
1_173_85_1_csi_a1_1.dat
85 220
(132, 30, 3)
(132, 427, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65
 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 85 85 85]
(132, 427, 30, 3, 1)

Loaded dataset of 132 samples, each sized (427, 30, 3, 1)


Train on 105 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 427, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 427, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 427, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 427, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 427, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 427, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 427, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 94 samples, validate on 11 samples
Epoch 1/30

32/94 [=========>....................] - ETA: 0s - loss: 0.3890 - mae: 0.5418 - mse: 0.3890
64/94 [===================>..........] - ETA: 0s - loss: 0.2854 - mae: 0.4440 - mse: 0.2854
94/94 [==============================] - 1s 9ms/step - loss: 0.2512 - mae: 0.4116 - mse: 0.2512 - val_loss: 0.1740 - val_mae: 0.3616 - val_mse: 0.1740
Epoch 2/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1608 - mae: 0.3347 - mse: 0.1608
64/94 [===================>..........] - ETA: 0s - loss: 0.1510 - mae: 0.3233 - mse: 0.1510
94/94 [==============================] - 0s 5ms/step - loss: 0.1480 - mae: 0.3201 - mse: 0.1480 - val_loss: 0.1051 - val_mae: 0.2567 - val_mse: 0.1051
Epoch 3/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1242 - mae: 0.2922 - mse: 0.1242
64/94 [===================>..........] - ETA: 0s - loss: 0.1259 - mae: 0.2909 - mse: 0.1259
94/94 [==============================] - 0s 5ms/step - loss: 0.1086 - mae: 0.2637 - mse: 0.1086 - val_loss: 0.0935 - val_mae: 0.2429 - val_mse: 0.0935
Epoch 4/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0880 - mae: 0.2377 - mse: 0.0880
64/94 [===================>..........] - ETA: 0s - loss: 0.0666 - mae: 0.1993 - mse: 0.0666
94/94 [==============================] - 1s 7ms/step - loss: 0.0663 - mae: 0.2018 - mse: 0.0663 - val_loss: 0.0942 - val_mae: 0.2285 - val_mse: 0.0942
Epoch 5/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0660 - mae: 0.1914 - mse: 0.0660
64/94 [===================>..........] - ETA: 0s - loss: 0.0669 - mae: 0.1993 - mse: 0.0669
94/94 [==============================] - 1s 7ms/step - loss: 0.0636 - mae: 0.1933 - mse: 0.0636 - val_loss: 0.0567 - val_mae: 0.1913 - val_mse: 0.0567
Epoch 6/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0797 - mae: 0.2226 - mse: 0.0797
64/94 [===================>..........] - ETA: 0s - loss: 0.0593 - mae: 0.1974 - mse: 0.0593
94/94 [==============================] - 0s 5ms/step - loss: 0.0638 - mae: 0.2008 - mse: 0.0638 - val_loss: 0.0381 - val_mae: 0.1600 - val_mse: 0.0381
Epoch 7/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0677 - mae: 0.2065 - mse: 0.0677
64/94 [===================>..........] - ETA: 0s - loss: 0.0549 - mae: 0.1869 - mse: 0.0549
94/94 [==============================] - 0s 5ms/step - loss: 0.0592 - mae: 0.1941 - mse: 0.0592 - val_loss: 0.0347 - val_mae: 0.1534 - val_mse: 0.0347
Epoch 8/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0240 - mae: 0.1245 - mse: 0.0240
64/94 [===================>..........] - ETA: 0s - loss: 0.0572 - mae: 0.1788 - mse: 0.0572
94/94 [==============================] - 1s 6ms/step - loss: 0.0504 - mae: 0.1683 - mse: 0.0504 - val_loss: 0.0314 - val_mae: 0.1435 - val_mse: 0.0314
Epoch 9/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0297 - mae: 0.1459 - mse: 0.0297
64/94 [===================>..........] - ETA: 0s - loss: 0.0286 - mae: 0.1420 - mse: 0.0286
94/94 [==============================] - 0s 5ms/step - loss: 0.0357 - mae: 0.1495 - mse: 0.0357 - val_loss: 0.0137 - val_mae: 0.1113 - val_mse: 0.0137
Epoch 10/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0365 - mae: 0.1483 - mse: 0.0365
64/94 [===================>..........] - ETA: 0s - loss: 0.0336 - mae: 0.1430 - mse: 0.0336
94/94 [==============================] - 0s 4ms/step - loss: 0.0408 - mae: 0.1536 - mse: 0.0408 - val_loss: 0.0084 - val_mae: 0.0742 - val_mse: 0.0084
Epoch 11/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0295 - mae: 0.1325 - mse: 0.0295
64/94 [===================>..........] - ETA: 0s - loss: 0.0440 - mae: 0.1573 - mse: 0.0440
94/94 [==============================] - 0s 5ms/step - loss: 0.0383 - mae: 0.1458 - mse: 0.0383 - val_loss: 0.0100 - val_mae: 0.0938 - val_mse: 0.0100
Epoch 12/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0393 - mae: 0.1542 - mse: 0.0393
64/94 [===================>..........] - ETA: 0s - loss: 0.0333 - mae: 0.1357 - mse: 0.0333
94/94 [==============================] - 0s 4ms/step - loss: 0.0288 - mae: 0.1283 - mse: 0.0288 - val_loss: 0.0124 - val_mae: 0.1023 - val_mse: 0.0124
Epoch 13/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0230 - mae: 0.1049 - mse: 0.0230
64/94 [===================>..........] - ETA: 0s - loss: 0.0253 - mae: 0.1149 - mse: 0.0253
94/94 [==============================] - 0s 5ms/step - loss: 0.0284 - mae: 0.1241 - mse: 0.0284 - val_loss: 0.0050 - val_mae: 0.0634 - val_mse: 0.0050
Epoch 14/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0313 - mae: 0.1370 - mse: 0.0313
64/94 [===================>..........] - ETA: 0s - loss: 0.0262 - mae: 0.1246 - mse: 0.0262
94/94 [==============================] - 0s 5ms/step - loss: 0.0221 - mae: 0.1148 - mse: 0.0221 - val_loss: 0.0036 - val_mae: 0.0516 - val_mse: 0.0036
Epoch 15/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0228 - mae: 0.1114 - mse: 0.0228
64/94 [===================>..........] - ETA: 0s - loss: 0.0192 - mae: 0.0998 - mse: 0.0192
94/94 [==============================] - 0s 5ms/step - loss: 0.0203 - mae: 0.1043 - mse: 0.0203 - val_loss: 0.0042 - val_mae: 0.0553 - val_mse: 0.0042
Epoch 16/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0201 - mae: 0.1075 - mse: 0.0201
64/94 [===================>..........] - ETA: 0s - loss: 0.0178 - mae: 0.1020 - mse: 0.0178
94/94 [==============================] - 0s 4ms/step - loss: 0.0152 - mae: 0.0946 - mse: 0.0152 - val_loss: 0.0070 - val_mae: 0.0636 - val_mse: 0.0070
Epoch 17/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0198 - mae: 0.1018 - mse: 0.0198
64/94 [===================>..........] - ETA: 0s - loss: 0.0206 - mae: 0.1078 - mse: 0.0206
94/94 [==============================] - 0s 5ms/step - loss: 0.0200 - mae: 0.1020 - mse: 0.0200 - val_loss: 0.0059 - val_mae: 0.0585 - val_mse: 0.0059
Epoch 18/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0151 - mae: 0.0932 - mse: 0.0151
64/94 [===================>..........] - ETA: 0s - loss: 0.0140 - mae: 0.0909 - mse: 0.0140
94/94 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0903 - mse: 0.0137 - val_loss: 0.0041 - val_mae: 0.0508 - val_mse: 0.0041
Epoch 19/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0094 - mae: 0.0737 - mse: 0.0094
64/94 [===================>..........] - ETA: 0s - loss: 0.0162 - mae: 0.0914 - mse: 0.0162
94/94 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0902 - mse: 0.0148 - val_loss: 0.0038 - val_mae: 0.0536 - val_mse: 0.0038
Epoch 20/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0063 - mae: 0.0662 - mse: 0.0063
64/94 [===================>..........] - ETA: 0s - loss: 0.0094 - mae: 0.0778 - mse: 0.0094
94/94 [==============================] - 0s 5ms/step - loss: 0.0109 - mae: 0.0823 - mse: 0.0109 - val_loss: 0.0051 - val_mae: 0.0642 - val_mse: 0.0051
Epoch 21/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0070 - mae: 0.0729 - mse: 0.0070
64/94 [===================>..........] - ETA: 0s - loss: 0.0111 - mae: 0.0834 - mse: 0.0111
94/94 [==============================] - 1s 5ms/step - loss: 0.0094 - mae: 0.0731 - mse: 0.0094 - val_loss: 0.0081 - val_mae: 0.0761 - val_mse: 0.0081
Epoch 22/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0091 - mae: 0.0810 - mse: 0.0091
64/94 [===================>..........] - ETA: 0s - loss: 0.0151 - mae: 0.0942 - mse: 0.0151
94/94 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0904 - mse: 0.0138 - val_loss: 0.0056 - val_mae: 0.0636 - val_mse: 0.0056
Epoch 23/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0086 - mae: 0.0753 - mse: 0.0086
64/94 [===================>..........] - ETA: 0s - loss: 0.0103 - mae: 0.0749 - mse: 0.0103
94/94 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0857 - mse: 0.0128 - val_loss: 0.0046 - val_mae: 0.0614 - val_mse: 0.0046
Epoch 24/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0057 - mae: 0.0603 - mse: 0.0057
64/94 [===================>..........] - ETA: 0s - loss: 0.0102 - mae: 0.0767 - mse: 0.0102
94/94 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0787 - mse: 0.0114 - val_loss: 0.0071 - val_mae: 0.0728 - val_mse: 0.0071
Epoch 25/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0101 - mae: 0.0816 - mse: 0.0101
64/94 [===================>..........] - ETA: 0s - loss: 0.0104 - mae: 0.0820 - mse: 0.0104
94/94 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0851 - mse: 0.0117 - val_loss: 0.0069 - val_mae: 0.0710 - val_mse: 0.0069
Epoch 26/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0116 - mae: 0.0844 - mse: 0.0116
64/94 [===================>..........] - ETA: 0s - loss: 0.0102 - mae: 0.0767 - mse: 0.0102
94/94 [==============================] - 1s 5ms/step - loss: 0.0091 - mae: 0.0735 - mse: 0.0091 - val_loss: 0.0051 - val_mae: 0.0648 - val_mse: 0.0051
Epoch 27/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0110 - mae: 0.0800 - mse: 0.0110
64/94 [===================>..........] - ETA: 0s - loss: 0.0102 - mae: 0.0734 - mse: 0.0102
94/94 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0701 - mse: 0.0093 - val_loss: 0.0095 - val_mae: 0.0873 - val_mse: 0.0095
Epoch 28/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0084 - mae: 0.0745 - mse: 0.0084
64/94 [===================>..........] - ETA: 0s - loss: 0.0138 - mae: 0.0930 - mse: 0.0138
94/94 [==============================] - 0s 4ms/step - loss: 0.0115 - mae: 0.0836 - mse: 0.0115 - val_loss: 0.0084 - val_mae: 0.0852 - val_mse: 0.0084
Epoch 29/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0121 - mae: 0.0907 - mse: 0.0121
64/94 [===================>..........] - ETA: 0s - loss: 0.0120 - mae: 0.0866 - mse: 0.0120
94/94 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0898 - mse: 0.0133 - val_loss: 0.0065 - val_mae: 0.0740 - val_mse: 0.0065
Epoch 30/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0096 - mae: 0.0739 - mse: 0.0096
64/94 [===================>..........] - ETA: 0s - loss: 0.0091 - mae: 0.0744 - mse: 0.0091
94/94 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0708 - mse: 0.0084 - val_loss: 0.0038 - val_mae: 0.0555 - val_mse: 0.0038
Saving trained model...
88
Testing...
heightdiff= [0.         0.         0.         5.78230667 0.         0.        ]
average prediction= [1.9426826]
baseline= 7.5
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.4455766677856445
85 -:- nan
60 -:- nan
['train-weight-1.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
2_155_65_1_csi_a1_6.dat
65 8
2_155_65_1_csi_a1_24.dat
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_1_csi_a1_3.dat
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_1_csi_a1_11.dat
65 42
1_165_65_1_csi_a1_2.dat
1_165_65_1_csi_a1_5.dat
65 45
1_165_65_1_csi_a1_4.dat
1_165_65_1_csi_a1_13.dat
65 48
1_165_65_1_csi_a1_12.dat
65 50
65 51
1_165_65_1_csi_a1_14.dat
65 53
1_165_65_1_csi_a1_6.dat
1_165_65_1_csi_a1_1.dat
65 56
1_165_65_1_csi_a1_15.dat
1_165_65_1_csi_a1_17.dat
65 59
65 60
1_165_65_1_csi_a1_3.dat
65 62
1_165_65_1_csi_a1_9.dat
1_165_65_1_csi_a1_16.dat
1_165_65_1_csi_a1_22.dat
65 66
1_165_65_1_csi_a1_10.dat
65 68
1_165_65_1_csi_a1_7.dat
65 70
50 71
50 72
50 73
50 74
50 75
2_165_50_1_csi_a1_29.dat
50 77
2_165_50_1_csi_a1_2.dat
50 79
50 80
2_165_50_1_csi_a1_3.dat
50 82
50 83
50 84
50 85
50 86
50 87
2_165_50_1_csi_a1_28.dat
50 89
50 90
2_165_50_1_csi_a1_7.dat
50 92
50 93
50 94
50 95
50 96
2_165_50_1_csi_a1_25.dat
2_165_50_1_csi_a1_27.dat
2_165_50_1_csi_a1_11.dat
50 100
70 101
70 102
70 103
70 104
1_175_70_1_csi_a1_18.dat
1_175_70_1_csi_a1_12.dat
70 107
70 108
70 109
1_175_70_1_csi_a1_8.dat
70 111
1_175_70_1_csi_a1_3.dat
1_175_70_1_csi_a1_26.dat
70 114
1_175_70_1_csi_a1_10.dat
70 116
70 117
1_175_70_1_csi_a1_6.dat
70 119
1_175_70_1_csi_a1_9.dat
70 121
70 122
70 123
70 124
70 125
1_175_70_1_csi_a1_22.dat
70 127
70 128
1_175_70_1_csi_a1_21.dat
1_175_70_1_csi_a1_14.dat
85 131
1_180_85_1_csi_a1_6.dat
85 133
1_180_85_1_csi_a1_4.dat
85 135
85 136
85 137
1_180_85_1_csi_a1_22.dat
1_180_85_1_csi_a1_20.dat
85 140
85 141
85 142
1_180_85_1_csi_a1_25.dat
1_180_85_1_csi_a1_26.dat
1_180_85_1_csi_a1_12.dat
1_180_85_1_csi_a1_30.dat
85 147
85 148
1_180_85_1_csi_a1_27.dat
85 150
85 151
1_180_85_1_csi_a1_13.dat
1_180_85_1_csi_a1_5.dat
1_180_85_1_csi_a1_7.dat
1_180_85_1_csi_a1_9.dat
85 156
1_180_85_1_csi_a1_3.dat
85 158
85 159
1_180_85_1_csi_a1_2.dat
75 161
75 162
75 163
1_180_75_1_csi_a1_4.dat
75 165
75 166
1_180_75_1_csi_a1_27.dat
75 168
75 169
1_180_75_1_csi_a1_2.dat
1_180_75_1_csi_a1_1.dat
75 172
75 173
75 174
75 175
1_180_75_1_csi_a1_16.dat
75 177
75 178
75 179
75 180
75 181
75 182
75 183
75 184
1_180_75_1_csi_a1_15.dat
75 186
75 187
1_180_75_1_csi_a1_29.dat
75 189
75 190
1_173_85_1_csi_a1_16.dat
1_173_85_1_csi_a1_13.dat
1_173_85_1_csi_a1_22.dat
1_173_85_1_csi_a1_26.dat
1_173_85_1_csi_a1_19.dat
1_173_85_1_csi_a1_18.dat
1_173_85_1_csi_a1_5.dat
1_173_85_1_csi_a1_17.dat
1_173_85_1_csi_a1_7.dat
1_173_85_1_csi_a1_6.dat
1_173_85_1_csi_a1_9.dat
1_173_85_1_csi_a1_23.dat
85 203
85 204
1_173_85_1_csi_a1_30.dat
1_173_85_1_csi_a1_21.dat
1_173_85_1_csi_a1_20.dat
1_173_85_1_csi_a1_25.dat
1_173_85_1_csi_a1_11.dat
1_173_85_1_csi_a1_24.dat
1_173_85_1_csi_a1_28.dat
1_173_85_1_csi_a1_27.dat
1_173_85_1_csi_a1_8.dat
1_173_85_1_csi_a1_4.dat
1_173_85_1_csi_a1_14.dat
1_173_85_1_csi_a1_2.dat
1_173_85_1_csi_a1_29.dat
1_173_85_1_csi_a1_3.dat
1_173_85_1_csi_a1_1.dat
85 220
(132, 30, 3)
(132, 427, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65
 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 85 85 85]
(132, 427, 30, 3, 1)

Loaded dataset of 132 samples, each sized (427, 30, 3, 1)


Train on 105 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 427, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 427, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 427, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 427, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 427, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 427, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 427, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 94 samples, validate on 11 samples
Epoch 1/30

32/94 [=========>....................] - ETA: 0s - loss: 0.3584 - mae: 0.5385 - mse: 0.3584
64/94 [===================>..........] - ETA: 0s - loss: 0.2861 - mae: 0.4649 - mse: 0.2861
94/94 [==============================] - 1s 11ms/step - loss: 0.2458 - mae: 0.4284 - mse: 0.2458 - val_loss: 0.1345 - val_mae: 0.2676 - val_mse: 0.1345
Epoch 2/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1768 - mae: 0.3614 - mse: 0.1768
64/94 [===================>..........] - ETA: 0s - loss: 0.1661 - mae: 0.3464 - mse: 0.1661
94/94 [==============================] - 1s 5ms/step - loss: 0.1761 - mae: 0.3589 - mse: 0.1761 - val_loss: 0.0720 - val_mae: 0.2058 - val_mse: 0.0720
Epoch 3/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1878 - mae: 0.3854 - mse: 0.1878
64/94 [===================>..........] - ETA: 0s - loss: 0.1204 - mae: 0.2866 - mse: 0.1204
94/94 [==============================] - 1s 5ms/step - loss: 0.1213 - mae: 0.2881 - mse: 0.1213 - val_loss: 0.0805 - val_mae: 0.2187 - val_mse: 0.0805
Epoch 4/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1053 - mae: 0.2673 - mse: 0.1053
64/94 [===================>..........] - ETA: 0s - loss: 0.0807 - mae: 0.2298 - mse: 0.0807
94/94 [==============================] - 0s 5ms/step - loss: 0.0744 - mae: 0.2161 - mse: 0.0744 - val_loss: 0.0776 - val_mae: 0.2378 - val_mse: 0.0776
Epoch 5/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0629 - mae: 0.1955 - mse: 0.0629
64/94 [===================>..........] - ETA: 0s - loss: 0.0532 - mae: 0.1902 - mse: 0.0532
94/94 [==============================] - 1s 5ms/step - loss: 0.0569 - mae: 0.1958 - mse: 0.0569 - val_loss: 0.0436 - val_mae: 0.1750 - val_mse: 0.0436
Epoch 6/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0329 - mae: 0.1588 - mse: 0.0329
64/94 [===================>..........] - ETA: 0s - loss: 0.0487 - mae: 0.1773 - mse: 0.0487
94/94 [==============================] - 0s 5ms/step - loss: 0.0475 - mae: 0.1762 - mse: 0.0475 - val_loss: 0.0259 - val_mae: 0.1448 - val_mse: 0.0259
Epoch 7/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0495 - mae: 0.1813 - mse: 0.0495
64/94 [===================>..........] - ETA: 0s - loss: 0.0493 - mae: 0.1751 - mse: 0.0493
94/94 [==============================] - 1s 6ms/step - loss: 0.0452 - mae: 0.1705 - mse: 0.0452 - val_loss: 0.0288 - val_mae: 0.1536 - val_mse: 0.0288
Epoch 8/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0375 - mae: 0.1543 - mse: 0.0375
64/94 [===================>..........] - ETA: 0s - loss: 0.0380 - mae: 0.1584 - mse: 0.0380
94/94 [==============================] - 0s 5ms/step - loss: 0.0389 - mae: 0.1611 - mse: 0.0389 - val_loss: 0.0311 - val_mae: 0.1557 - val_mse: 0.0311
Epoch 9/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0395 - mae: 0.1619 - mse: 0.0395
64/94 [===================>..........] - ETA: 0s - loss: 0.0492 - mae: 0.1750 - mse: 0.0492
94/94 [==============================] - 1s 5ms/step - loss: 0.0500 - mae: 0.1773 - mse: 0.0500 - val_loss: 0.0312 - val_mae: 0.1493 - val_mse: 0.0312
Epoch 10/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0355 - mae: 0.1553 - mse: 0.0355
64/94 [===================>..........] - ETA: 0s - loss: 0.0423 - mae: 0.1633 - mse: 0.0423
94/94 [==============================] - 1s 6ms/step - loss: 0.0451 - mae: 0.1637 - mse: 0.0451 - val_loss: 0.0256 - val_mae: 0.1318 - val_mse: 0.0256
Epoch 11/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0410 - mae: 0.1562 - mse: 0.0410
64/94 [===================>..........] - ETA: 0s - loss: 0.0477 - mae: 0.1618 - mse: 0.0477
94/94 [==============================] - 1s 6ms/step - loss: 0.0436 - mae: 0.1581 - mse: 0.0436 - val_loss: 0.0170 - val_mae: 0.1026 - val_mse: 0.0170
Epoch 12/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0351 - mae: 0.1392 - mse: 0.0351
64/94 [===================>..........] - ETA: 0s - loss: 0.0336 - mae: 0.1472 - mse: 0.0336
94/94 [==============================] - 1s 5ms/step - loss: 0.0383 - mae: 0.1496 - mse: 0.0383 - val_loss: 0.0191 - val_mae: 0.1099 - val_mse: 0.0191
Epoch 13/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0213 - mae: 0.1123 - mse: 0.0213
64/94 [===================>..........] - ETA: 0s - loss: 0.0270 - mae: 0.1279 - mse: 0.0270
94/94 [==============================] - 1s 6ms/step - loss: 0.0321 - mae: 0.1402 - mse: 0.0321 - val_loss: 0.0278 - val_mae: 0.1460 - val_mse: 0.0278
Epoch 14/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0350 - mae: 0.1404 - mse: 0.0350
64/94 [===================>..........] - ETA: 0s - loss: 0.0339 - mae: 0.1469 - mse: 0.0339
94/94 [==============================] - 0s 5ms/step - loss: 0.0329 - mae: 0.1429 - mse: 0.0329 - val_loss: 0.0186 - val_mae: 0.1178 - val_mse: 0.0186
Epoch 15/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0207 - mae: 0.1007 - mse: 0.0207
64/94 [===================>..........] - ETA: 0s - loss: 0.0289 - mae: 0.1232 - mse: 0.0289
94/94 [==============================] - 1s 6ms/step - loss: 0.0277 - mae: 0.1201 - mse: 0.0277 - val_loss: 0.0087 - val_mae: 0.0764 - val_mse: 0.0087
Epoch 16/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0169 - mae: 0.1030 - mse: 0.0169
64/94 [===================>..........] - ETA: 0s - loss: 0.0182 - mae: 0.1051 - mse: 0.0182
94/94 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 0.1104 - mse: 0.0196 - val_loss: 0.0078 - val_mae: 0.0722 - val_mse: 0.0078
Epoch 17/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0199 - mae: 0.1158 - mse: 0.0199
64/94 [===================>..........] - ETA: 0s - loss: 0.0184 - mae: 0.1040 - mse: 0.0184
94/94 [==============================] - 0s 5ms/step - loss: 0.0172 - mae: 0.0988 - mse: 0.0172 - val_loss: 0.0179 - val_mae: 0.1169 - val_mse: 0.0179
Epoch 18/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0204 - mae: 0.1039 - mse: 0.0204
64/94 [===================>..........] - ETA: 0s - loss: 0.0212 - mae: 0.1044 - mse: 0.0212
94/94 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 0.0985 - mse: 0.0186 - val_loss: 0.0146 - val_mae: 0.0954 - val_mse: 0.0146
Epoch 19/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0153 - mae: 0.1010 - mse: 0.0153
64/94 [===================>..........] - ETA: 0s - loss: 0.0145 - mae: 0.0958 - mse: 0.0145
94/94 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0932 - mse: 0.0143 - val_loss: 0.0106 - val_mae: 0.0843 - val_mse: 0.0106
Epoch 20/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0118 - mae: 0.0919 - mse: 0.0118
64/94 [===================>..........] - ETA: 0s - loss: 0.0144 - mae: 0.0949 - mse: 0.0144
94/94 [==============================] - 0s 5ms/step - loss: 0.0131 - mae: 0.0902 - mse: 0.0131 - val_loss: 0.0116 - val_mae: 0.0906 - val_mse: 0.0116
Epoch 21/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0156 - mae: 0.0977 - mse: 0.0156
64/94 [===================>..........] - ETA: 0s - loss: 0.0157 - mae: 0.0953 - mse: 0.0157
94/94 [==============================] - 0s 5ms/step - loss: 0.0134 - mae: 0.0902 - mse: 0.0134 - val_loss: 0.0074 - val_mae: 0.0721 - val_mse: 0.0074
Epoch 22/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0304 - mae: 0.1098 - mse: 0.0304
64/94 [===================>..........] - ETA: 0s - loss: 0.0208 - mae: 0.0951 - mse: 0.0208
94/94 [==============================] - 0s 5ms/step - loss: 0.0162 - mae: 0.0853 - mse: 0.0162 - val_loss: 0.0078 - val_mae: 0.0764 - val_mse: 0.0078
Epoch 23/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0076 - mae: 0.0668 - mse: 0.0076
64/94 [===================>..........] - ETA: 0s - loss: 0.0094 - mae: 0.0739 - mse: 0.0094
94/94 [==============================] - 0s 5ms/step - loss: 0.0103 - mae: 0.0734 - mse: 0.0103 - val_loss: 0.0107 - val_mae: 0.0932 - val_mse: 0.0107
Epoch 24/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0116 - mae: 0.0677 - mse: 0.0116
64/94 [===================>..........] - ETA: 0s - loss: 0.0111 - mae: 0.0773 - mse: 0.0111
94/94 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0837 - mse: 0.0128 - val_loss: 0.0129 - val_mae: 0.0966 - val_mse: 0.0129
Epoch 25/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0093 - mae: 0.0800 - mse: 0.0093
64/94 [===================>..........] - ETA: 0s - loss: 0.0122 - mae: 0.0879 - mse: 0.0122
94/94 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0921 - mse: 0.0137 - val_loss: 0.0113 - val_mae: 0.0873 - val_mse: 0.0113
Epoch 26/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0090 - mae: 0.0632 - mse: 0.0090
64/94 [===================>..........] - ETA: 0s - loss: 0.0118 - mae: 0.0794 - mse: 0.0118
94/94 [==============================] - 0s 5ms/step - loss: 0.0114 - mae: 0.0804 - mse: 0.0114 - val_loss: 0.0082 - val_mae: 0.0762 - val_mse: 0.0082
Epoch 27/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0177 - mae: 0.0947 - mse: 0.0177
64/94 [===================>..........] - ETA: 0s - loss: 0.0131 - mae: 0.0822 - mse: 0.0131
94/94 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0820 - mse: 0.0135 - val_loss: 0.0146 - val_mae: 0.1121 - val_mse: 0.0146
Epoch 28/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0062 - mae: 0.0616 - mse: 0.0062
64/94 [===================>..........] - ETA: 0s - loss: 0.0108 - mae: 0.0708 - mse: 0.0108
94/94 [==============================] - 0s 5ms/step - loss: 0.0111 - mae: 0.0759 - mse: 0.0111 - val_loss: 0.0141 - val_mae: 0.1105 - val_mse: 0.0141
Epoch 29/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0072 - mae: 0.0717 - mse: 0.0072
64/94 [===================>..........] - ETA: 0s - loss: 0.0162 - mae: 0.0845 - mse: 0.0162
94/94 [==============================] - 1s 5ms/step - loss: 0.0158 - mae: 0.0858 - mse: 0.0158 - val_loss: 0.0088 - val_mae: 0.0834 - val_mse: 0.0088
Epoch 30/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0063 - mae: 0.0611 - mse: 0.0063
64/94 [===================>..........] - ETA: 0s - loss: 0.0082 - mae: 0.0692 - mse: 0.0082
94/94 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0728 - mse: 0.0090 - val_loss: 0.0145 - val_mae: 0.1044 - val_mse: 0.0145
Saving trained model...
88
Testing...
heightdiff= [0.         0.         0.         2.96939087 0.         0.        ]
average prediction= [4.0053945]
baseline= 9.166666666666666
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.593878173828125
85 -:- nan
60 -:- nan
['train-weight-1.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
2_155_65_1_csi_a1_6.dat
65 8
2_155_65_1_csi_a1_24.dat
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_1_csi_a1_3.dat
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_1_csi_a1_11.dat
65 42
1_165_65_1_csi_a1_2.dat
1_165_65_1_csi_a1_5.dat
65 45
1_165_65_1_csi_a1_4.dat
1_165_65_1_csi_a1_13.dat
65 48
1_165_65_1_csi_a1_12.dat
65 50
65 51
1_165_65_1_csi_a1_14.dat
65 53
1_165_65_1_csi_a1_6.dat
1_165_65_1_csi_a1_1.dat
65 56
1_165_65_1_csi_a1_15.dat
1_165_65_1_csi_a1_17.dat
65 59
65 60
1_165_65_1_csi_a1_3.dat
65 62
1_165_65_1_csi_a1_9.dat
1_165_65_1_csi_a1_16.dat
1_165_65_1_csi_a1_22.dat
65 66
1_165_65_1_csi_a1_10.dat
65 68
1_165_65_1_csi_a1_7.dat
65 70
50 71
50 72
50 73
50 74
50 75
2_165_50_1_csi_a1_29.dat
50 77
2_165_50_1_csi_a1_2.dat
50 79
50 80
2_165_50_1_csi_a1_3.dat
50 82
50 83
50 84
50 85
50 86
50 87
2_165_50_1_csi_a1_28.dat
50 89
50 90
2_165_50_1_csi_a1_7.dat
50 92
50 93
50 94
50 95
50 96
2_165_50_1_csi_a1_25.dat
2_165_50_1_csi_a1_27.dat
2_165_50_1_csi_a1_11.dat
50 100
70 101
70 102
70 103
70 104
1_175_70_1_csi_a1_18.dat
1_175_70_1_csi_a1_12.dat
70 107
70 108
70 109
1_175_70_1_csi_a1_8.dat
70 111
1_175_70_1_csi_a1_3.dat
1_175_70_1_csi_a1_26.dat
70 114
1_175_70_1_csi_a1_10.dat
70 116
70 117
1_175_70_1_csi_a1_6.dat
70 119
1_175_70_1_csi_a1_9.dat
70 121
70 122
70 123
70 124
70 125
1_175_70_1_csi_a1_22.dat
70 127
70 128
1_175_70_1_csi_a1_21.dat
1_175_70_1_csi_a1_14.dat
85 131
1_180_85_1_csi_a1_6.dat
85 133
1_180_85_1_csi_a1_4.dat
85 135
85 136
85 137
1_180_85_1_csi_a1_22.dat
1_180_85_1_csi_a1_20.dat
85 140
85 141
85 142
1_180_85_1_csi_a1_25.dat
1_180_85_1_csi_a1_26.dat
1_180_85_1_csi_a1_12.dat
1_180_85_1_csi_a1_30.dat
85 147
85 148
1_180_85_1_csi_a1_27.dat
85 150
85 151
1_180_85_1_csi_a1_13.dat
1_180_85_1_csi_a1_5.dat
1_180_85_1_csi_a1_7.dat
1_180_85_1_csi_a1_9.dat
85 156
1_180_85_1_csi_a1_3.dat
85 158
85 159
1_180_85_1_csi_a1_2.dat
75 161
75 162
75 163
1_180_75_1_csi_a1_4.dat
75 165
75 166
1_180_75_1_csi_a1_27.dat
75 168
75 169
1_180_75_1_csi_a1_2.dat
1_180_75_1_csi_a1_1.dat
75 172
75 173
75 174
75 175
1_180_75_1_csi_a1_16.dat
75 177
75 178
75 179
75 180
75 181
75 182
75 183
75 184
1_180_75_1_csi_a1_15.dat
75 186
75 187
1_180_75_1_csi_a1_29.dat
75 189
75 190
1_173_85_1_csi_a1_16.dat
1_173_85_1_csi_a1_13.dat
1_173_85_1_csi_a1_22.dat
1_173_85_1_csi_a1_26.dat
1_173_85_1_csi_a1_19.dat
1_173_85_1_csi_a1_18.dat
1_173_85_1_csi_a1_5.dat
1_173_85_1_csi_a1_17.dat
1_173_85_1_csi_a1_7.dat
1_173_85_1_csi_a1_6.dat
1_173_85_1_csi_a1_9.dat
1_173_85_1_csi_a1_23.dat
85 203
85 204
1_173_85_1_csi_a1_30.dat
1_173_85_1_csi_a1_21.dat
1_173_85_1_csi_a1_20.dat
1_173_85_1_csi_a1_25.dat
1_173_85_1_csi_a1_11.dat
1_173_85_1_csi_a1_24.dat
1_173_85_1_csi_a1_28.dat
1_173_85_1_csi_a1_27.dat
1_173_85_1_csi_a1_8.dat
1_173_85_1_csi_a1_4.dat
1_173_85_1_csi_a1_14.dat
1_173_85_1_csi_a1_2.dat
1_173_85_1_csi_a1_29.dat
1_173_85_1_csi_a1_3.dat
1_173_85_1_csi_a1_1.dat
85 220
(132, 30, 3)
(132, 427, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65
 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 85 85 85]
(132, 427, 30, 3, 1)

Loaded dataset of 132 samples, each sized (427, 30, 3, 1)


Train on 105 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 427, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 427, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 427, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 427, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 427, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 427, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 427, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 94 samples, validate on 11 samples
Epoch 1/30

32/94 [=========>....................] - ETA: 0s - loss: 0.2754 - mae: 0.4622 - mse: 0.2754
64/94 [===================>..........] - ETA: 0s - loss: 0.2272 - mae: 0.4127 - mse: 0.2272
94/94 [==============================] - 1s 9ms/step - loss: 0.1884 - mae: 0.3623 - mse: 0.1884 - val_loss: 0.0863 - val_mae: 0.2207 - val_mse: 0.0863
Epoch 2/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1173 - mae: 0.2873 - mse: 0.1173
64/94 [===================>..........] - ETA: 0s - loss: 0.1240 - mae: 0.3004 - mse: 0.1240
94/94 [==============================] - 1s 5ms/step - loss: 0.1290 - mae: 0.3058 - mse: 0.1290 - val_loss: 0.0715 - val_mae: 0.1917 - val_mse: 0.0715
Epoch 3/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1282 - mae: 0.2901 - mse: 0.1282
64/94 [===================>..........] - ETA: 0s - loss: 0.1109 - mae: 0.2705 - mse: 0.1109
94/94 [==============================] - 1s 5ms/step - loss: 0.0989 - mae: 0.2534 - mse: 0.0989 - val_loss: 0.0741 - val_mae: 0.1995 - val_mse: 0.0741
Epoch 4/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1114 - mae: 0.2760 - mse: 0.1114
64/94 [===================>..........] - ETA: 0s - loss: 0.0893 - mae: 0.2401 - mse: 0.0893
94/94 [==============================] - 0s 5ms/step - loss: 0.0867 - mae: 0.2283 - mse: 0.0867 - val_loss: 0.0719 - val_mae: 0.2058 - val_mse: 0.0719
Epoch 5/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0935 - mae: 0.2361 - mse: 0.0935
64/94 [===================>..........] - ETA: 0s - loss: 0.1092 - mae: 0.2587 - mse: 0.1092
94/94 [==============================] - 1s 5ms/step - loss: 0.0861 - mae: 0.2300 - mse: 0.0861 - val_loss: 0.0416 - val_mae: 0.1294 - val_mse: 0.0416
Epoch 6/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0811 - mae: 0.2179 - mse: 0.0811
64/94 [===================>..........] - ETA: 0s - loss: 0.0571 - mae: 0.1786 - mse: 0.0571
94/94 [==============================] - 1s 5ms/step - loss: 0.0569 - mae: 0.1815 - mse: 0.0569 - val_loss: 0.0329 - val_mae: 0.1426 - val_mse: 0.0329
Epoch 7/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0648 - mae: 0.2121 - mse: 0.0648
64/94 [===================>..........] - ETA: 0s - loss: 0.0622 - mae: 0.2034 - mse: 0.0622
94/94 [==============================] - 1s 5ms/step - loss: 0.0599 - mae: 0.2023 - mse: 0.0599 - val_loss: 0.0301 - val_mae: 0.1214 - val_mse: 0.0301
Epoch 8/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0486 - mae: 0.1790 - mse: 0.0486
64/94 [===================>..........] - ETA: 0s - loss: 0.0501 - mae: 0.1773 - mse: 0.0501
94/94 [==============================] - 1s 5ms/step - loss: 0.0583 - mae: 0.1906 - mse: 0.0583 - val_loss: 0.0361 - val_mae: 0.1355 - val_mse: 0.0361
Epoch 9/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0346 - mae: 0.1429 - mse: 0.0346
64/94 [===================>..........] - ETA: 0s - loss: 0.0334 - mae: 0.1442 - mse: 0.0334
94/94 [==============================] - 1s 6ms/step - loss: 0.0363 - mae: 0.1503 - mse: 0.0363 - val_loss: 0.0293 - val_mae: 0.1251 - val_mse: 0.0293
Epoch 10/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0383 - mae: 0.1637 - mse: 0.0383
64/94 [===================>..........] - ETA: 0s - loss: 0.0419 - mae: 0.1735 - mse: 0.0419
94/94 [==============================] - 0s 5ms/step - loss: 0.0361 - mae: 0.1591 - mse: 0.0361 - val_loss: 0.0165 - val_mae: 0.1022 - val_mse: 0.0165
Epoch 11/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0226 - mae: 0.1223 - mse: 0.0226
64/94 [===================>..........] - ETA: 0s - loss: 0.0308 - mae: 0.1474 - mse: 0.0308
94/94 [==============================] - 1s 5ms/step - loss: 0.0277 - mae: 0.1387 - mse: 0.0277 - val_loss: 0.0137 - val_mae: 0.0930 - val_mse: 0.0137
Epoch 12/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0437 - mae: 0.1706 - mse: 0.0437
64/94 [===================>..........] - ETA: 0s - loss: 0.0333 - mae: 0.1468 - mse: 0.0333
94/94 [==============================] - 1s 5ms/step - loss: 0.0299 - mae: 0.1373 - mse: 0.0299 - val_loss: 0.0226 - val_mae: 0.1133 - val_mse: 0.0226
Epoch 13/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0430 - mae: 0.1490 - mse: 0.0430
64/94 [===================>..........] - ETA: 0s - loss: 0.0329 - mae: 0.1373 - mse: 0.0329
94/94 [==============================] - 0s 5ms/step - loss: 0.0305 - mae: 0.1346 - mse: 0.0305 - val_loss: 0.0210 - val_mae: 0.1100 - val_mse: 0.0210
Epoch 14/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0304 - mae: 0.1266 - mse: 0.0304
64/94 [===================>..........] - ETA: 0s - loss: 0.0252 - mae: 0.1215 - mse: 0.0252
94/94 [==============================] - 0s 5ms/step - loss: 0.0255 - mae: 0.1256 - mse: 0.0255 - val_loss: 0.0106 - val_mae: 0.0763 - val_mse: 0.0106
Epoch 15/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0342 - mae: 0.1362 - mse: 0.0342
64/94 [===================>..........] - ETA: 0s - loss: 0.0307 - mae: 0.1359 - mse: 0.0307
94/94 [==============================] - 0s 5ms/step - loss: 0.0302 - mae: 0.1357 - mse: 0.0302 - val_loss: 0.0128 - val_mae: 0.0828 - val_mse: 0.0128
Epoch 16/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0283 - mae: 0.1281 - mse: 0.0283
64/94 [===================>..........] - ETA: 0s - loss: 0.0264 - mae: 0.1231 - mse: 0.0264
94/94 [==============================] - 0s 5ms/step - loss: 0.0239 - mae: 0.1219 - mse: 0.0239 - val_loss: 0.0170 - val_mae: 0.1018 - val_mse: 0.0170
Epoch 17/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0121 - mae: 0.0891 - mse: 0.0121
64/94 [===================>..........] - ETA: 0s - loss: 0.0137 - mae: 0.0929 - mse: 0.0137
94/94 [==============================] - 1s 6ms/step - loss: 0.0166 - mae: 0.0966 - mse: 0.0166 - val_loss: 0.0167 - val_mae: 0.1033 - val_mse: 0.0167
Epoch 18/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0111 - mae: 0.0847 - mse: 0.0111
64/94 [===================>..........] - ETA: 0s - loss: 0.0150 - mae: 0.0893 - mse: 0.0150
94/94 [==============================] - 0s 5ms/step - loss: 0.0144 - mae: 0.0848 - mse: 0.0144 - val_loss: 0.0113 - val_mae: 0.0838 - val_mse: 0.0113
Epoch 19/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0092 - mae: 0.0765 - mse: 0.0092
64/94 [===================>..........] - ETA: 0s - loss: 0.0176 - mae: 0.1021 - mse: 0.0176
94/94 [==============================] - 1s 5ms/step - loss: 0.0141 - mae: 0.0898 - mse: 0.0141 - val_loss: 0.0085 - val_mae: 0.0726 - val_mse: 0.0085
Epoch 20/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0094 - mae: 0.0787 - mse: 0.0094
64/94 [===================>..........] - ETA: 0s - loss: 0.0124 - mae: 0.0899 - mse: 0.0124
94/94 [==============================] - 1s 5ms/step - loss: 0.0142 - mae: 0.0914 - mse: 0.0142 - val_loss: 0.0134 - val_mae: 0.0977 - val_mse: 0.0134
Epoch 21/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0177 - mae: 0.1064 - mse: 0.0177
64/94 [===================>..........] - ETA: 0s - loss: 0.0157 - mae: 0.0933 - mse: 0.0157
94/94 [==============================] - 1s 5ms/step - loss: 0.0140 - mae: 0.0876 - mse: 0.0140 - val_loss: 0.0303 - val_mae: 0.1540 - val_mse: 0.0303
Epoch 22/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0098 - mae: 0.0767 - mse: 0.0098
64/94 [===================>..........] - ETA: 0s - loss: 0.0148 - mae: 0.0945 - mse: 0.0148
94/94 [==============================] - 1s 5ms/step - loss: 0.0144 - mae: 0.0910 - mse: 0.0144 - val_loss: 0.0149 - val_mae: 0.1063 - val_mse: 0.0149
Epoch 23/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0096 - mae: 0.0767 - mse: 0.0096
64/94 [===================>..........] - ETA: 0s - loss: 0.0119 - mae: 0.0894 - mse: 0.0119
94/94 [==============================] - 1s 5ms/step - loss: 0.0130 - mae: 0.0900 - mse: 0.0130 - val_loss: 0.0064 - val_mae: 0.0661 - val_mse: 0.0064
Epoch 24/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0096 - mae: 0.0741 - mse: 0.0096
64/94 [===================>..........] - ETA: 0s - loss: 0.0124 - mae: 0.0833 - mse: 0.0124
94/94 [==============================] - 1s 5ms/step - loss: 0.0171 - mae: 0.0922 - mse: 0.0171 - val_loss: 0.0187 - val_mae: 0.1213 - val_mse: 0.0187
Epoch 25/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0086 - mae: 0.0737 - mse: 0.0086
64/94 [===================>..........] - ETA: 0s - loss: 0.0096 - mae: 0.0784 - mse: 0.0096
94/94 [==============================] - 1s 6ms/step - loss: 0.0102 - mae: 0.0806 - mse: 0.0102 - val_loss: 0.0272 - val_mae: 0.1465 - val_mse: 0.0272
Epoch 26/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0128 - mae: 0.0904 - mse: 0.0128
64/94 [===================>..........] - ETA: 0s - loss: 0.0143 - mae: 0.0919 - mse: 0.0143
94/94 [==============================] - 1s 5ms/step - loss: 0.0141 - mae: 0.0941 - mse: 0.0141 - val_loss: 0.0153 - val_mae: 0.1064 - val_mse: 0.0153
Epoch 27/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0073 - mae: 0.0623 - mse: 0.0073
64/94 [===================>..........] - ETA: 0s - loss: 0.0093 - mae: 0.0717 - mse: 0.0093
94/94 [==============================] - 1s 5ms/step - loss: 0.0107 - mae: 0.0776 - mse: 0.0107 - val_loss: 0.0123 - val_mae: 0.0958 - val_mse: 0.0123
Epoch 28/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0053 - mae: 0.0531 - mse: 0.0053
64/94 [===================>..........] - ETA: 0s - loss: 0.0076 - mae: 0.0653 - mse: 0.0076
94/94 [==============================] - 1s 5ms/step - loss: 0.0087 - mae: 0.0663 - mse: 0.0087 - val_loss: 0.0218 - val_mae: 0.1320 - val_mse: 0.0218
Epoch 29/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0078 - mae: 0.0719 - mse: 0.0078
64/94 [===================>..........] - ETA: 0s - loss: 0.0099 - mae: 0.0750 - mse: 0.0099
94/94 [==============================] - 1s 5ms/step - loss: 0.0113 - mae: 0.0782 - mse: 0.0113 - val_loss: 0.0256 - val_mae: 0.1451 - val_mse: 0.0256
Epoch 30/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0079 - mae: 0.0738 - mse: 0.0079
64/94 [===================>..........] - ETA: 0s - loss: 0.0104 - mae: 0.0776 - mse: 0.0104
94/94 [==============================] - 1s 5ms/step - loss: 0.0102 - mae: 0.0789 - mse: 0.0102 - val_loss: 0.0112 - val_mae: 0.0919 - val_mse: 0.0112
Saving trained model...
88
Testing...
heightdiff= [0.         0.         0.         3.26929092 0.         0.        ]
average prediction= [2.9307017]
baseline= 9.907407407407407
eachuser= [0. 0. 0. 7. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.4670415605817522
85 -:- nan
60 -:- nan
['train-weight-1.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
2_155_65_1_csi_a1_6.dat
65 8
2_155_65_1_csi_a1_24.dat
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_1_csi_a1_3.dat
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_1_csi_a1_11.dat
65 42
1_165_65_1_csi_a1_2.dat
1_165_65_1_csi_a1_5.dat
65 45
1_165_65_1_csi_a1_4.dat
1_165_65_1_csi_a1_13.dat
65 48
1_165_65_1_csi_a1_12.dat
65 50
65 51
1_165_65_1_csi_a1_14.dat
65 53
1_165_65_1_csi_a1_6.dat
1_165_65_1_csi_a1_1.dat
65 56
1_165_65_1_csi_a1_15.dat
1_165_65_1_csi_a1_17.dat
65 59
65 60
1_165_65_1_csi_a1_3.dat
65 62
1_165_65_1_csi_a1_9.dat
1_165_65_1_csi_a1_16.dat
1_165_65_1_csi_a1_22.dat
65 66
1_165_65_1_csi_a1_10.dat
65 68
1_165_65_1_csi_a1_7.dat
65 70
50 71
50 72
50 73
50 74
50 75
2_165_50_1_csi_a1_29.dat
50 77
2_165_50_1_csi_a1_2.dat
50 79
50 80
2_165_50_1_csi_a1_3.dat
50 82
50 83
50 84
50 85
50 86
50 87
2_165_50_1_csi_a1_28.dat
50 89
50 90
2_165_50_1_csi_a1_7.dat
50 92
50 93
50 94
50 95
50 96
2_165_50_1_csi_a1_25.dat
2_165_50_1_csi_a1_27.dat
2_165_50_1_csi_a1_11.dat
50 100
70 101
70 102
70 103
70 104
1_175_70_1_csi_a1_18.dat
1_175_70_1_csi_a1_12.dat
70 107
70 108
70 109
1_175_70_1_csi_a1_8.dat
70 111
1_175_70_1_csi_a1_3.dat
1_175_70_1_csi_a1_26.dat
70 114
1_175_70_1_csi_a1_10.dat
70 116
70 117
1_175_70_1_csi_a1_6.dat
70 119
1_175_70_1_csi_a1_9.dat
70 121
70 122
70 123
70 124
70 125
1_175_70_1_csi_a1_22.dat
70 127
70 128
1_175_70_1_csi_a1_21.dat
1_175_70_1_csi_a1_14.dat
85 131
1_180_85_1_csi_a1_6.dat
85 133
1_180_85_1_csi_a1_4.dat
85 135
85 136
85 137
1_180_85_1_csi_a1_22.dat
1_180_85_1_csi_a1_20.dat
85 140
85 141
85 142
1_180_85_1_csi_a1_25.dat
1_180_85_1_csi_a1_26.dat
1_180_85_1_csi_a1_12.dat
1_180_85_1_csi_a1_30.dat
85 147
85 148
1_180_85_1_csi_a1_27.dat
85 150
85 151
1_180_85_1_csi_a1_13.dat
1_180_85_1_csi_a1_5.dat
1_180_85_1_csi_a1_7.dat
1_180_85_1_csi_a1_9.dat
85 156
1_180_85_1_csi_a1_3.dat
85 158
85 159
1_180_85_1_csi_a1_2.dat
75 161
75 162
75 163
1_180_75_1_csi_a1_4.dat
75 165
75 166
1_180_75_1_csi_a1_27.dat
75 168
75 169
1_180_75_1_csi_a1_2.dat
1_180_75_1_csi_a1_1.dat
75 172
75 173
75 174
75 175
1_180_75_1_csi_a1_16.dat
75 177
75 178
75 179
75 180
75 181
75 182
75 183
75 184
1_180_75_1_csi_a1_15.dat
75 186
75 187
1_180_75_1_csi_a1_29.dat
75 189
75 190
1_173_85_1_csi_a1_16.dat
1_173_85_1_csi_a1_13.dat
1_173_85_1_csi_a1_22.dat
1_173_85_1_csi_a1_26.dat
1_173_85_1_csi_a1_19.dat
1_173_85_1_csi_a1_18.dat
1_173_85_1_csi_a1_5.dat
1_173_85_1_csi_a1_17.dat
1_173_85_1_csi_a1_7.dat
1_173_85_1_csi_a1_6.dat
1_173_85_1_csi_a1_9.dat
1_173_85_1_csi_a1_23.dat
85 203
85 204
1_173_85_1_csi_a1_30.dat
1_173_85_1_csi_a1_21.dat
1_173_85_1_csi_a1_20.dat
1_173_85_1_csi_a1_25.dat
1_173_85_1_csi_a1_11.dat
1_173_85_1_csi_a1_24.dat
1_173_85_1_csi_a1_28.dat
1_173_85_1_csi_a1_27.dat
1_173_85_1_csi_a1_8.dat
1_173_85_1_csi_a1_4.dat
1_173_85_1_csi_a1_14.dat
1_173_85_1_csi_a1_2.dat
1_173_85_1_csi_a1_29.dat
1_173_85_1_csi_a1_3.dat
1_173_85_1_csi_a1_1.dat
85 220
(132, 30, 3)
(132, 427, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65
 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 85 85 85]
(132, 427, 30, 3, 1)

Loaded dataset of 132 samples, each sized (427, 30, 3, 1)


Train on 105 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 427, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 427, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 427, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 427, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 427, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 427, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 427, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 94 samples, validate on 11 samples
Epoch 1/30

32/94 [=========>....................] - ETA: 0s - loss: 0.3626 - mae: 0.5074 - mse: 0.3626
64/94 [===================>..........] - ETA: 0s - loss: 0.3042 - mae: 0.4596 - mse: 0.3042
94/94 [==============================] - 1s 9ms/step - loss: 0.2486 - mae: 0.4069 - mse: 0.2486 - val_loss: 0.1488 - val_mae: 0.3474 - val_mse: 0.1488
Epoch 2/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1368 - mae: 0.2893 - mse: 0.1368
64/94 [===================>..........] - ETA: 0s - loss: 0.1640 - mae: 0.3303 - mse: 0.1640
94/94 [==============================] - 1s 6ms/step - loss: 0.1667 - mae: 0.3335 - mse: 0.1667 - val_loss: 0.0788 - val_mae: 0.2258 - val_mse: 0.0788
Epoch 3/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1848 - mae: 0.3666 - mse: 0.1848
64/94 [===================>..........] - ETA: 0s - loss: 0.1363 - mae: 0.3023 - mse: 0.1363
94/94 [==============================] - 1s 6ms/step - loss: 0.1167 - mae: 0.2779 - mse: 0.1167 - val_loss: 0.0704 - val_mae: 0.2305 - val_mse: 0.0704
Epoch 4/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0559 - mae: 0.1780 - mse: 0.0559
64/94 [===================>..........] - ETA: 0s - loss: 0.0640 - mae: 0.1965 - mse: 0.0640
94/94 [==============================] - 1s 5ms/step - loss: 0.0618 - mae: 0.1944 - mse: 0.0618 - val_loss: 0.0709 - val_mae: 0.2364 - val_mse: 0.0709
Epoch 5/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0467 - mae: 0.1737 - mse: 0.0467
64/94 [===================>..........] - ETA: 0s - loss: 0.0726 - mae: 0.2166 - mse: 0.0726
94/94 [==============================] - 0s 5ms/step - loss: 0.0654 - mae: 0.2028 - mse: 0.0654 - val_loss: 0.0530 - val_mae: 0.2061 - val_mse: 0.0530
Epoch 6/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0547 - mae: 0.2035 - mse: 0.0547
64/94 [===================>..........] - ETA: 0s - loss: 0.0539 - mae: 0.1967 - mse: 0.0539
94/94 [==============================] - 1s 5ms/step - loss: 0.0505 - mae: 0.1869 - mse: 0.0505 - val_loss: 0.0281 - val_mae: 0.1467 - val_mse: 0.0281
Epoch 7/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0415 - mae: 0.1717 - mse: 0.0415
64/94 [===================>..........] - ETA: 0s - loss: 0.0537 - mae: 0.1872 - mse: 0.0537
94/94 [==============================] - 1s 5ms/step - loss: 0.0527 - mae: 0.1852 - mse: 0.0527 - val_loss: 0.0191 - val_mae: 0.1183 - val_mse: 0.0191
Epoch 8/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0316 - mae: 0.1318 - mse: 0.0316
64/94 [===================>..........] - ETA: 0s - loss: 0.0456 - mae: 0.1694 - mse: 0.0456
94/94 [==============================] - 0s 5ms/step - loss: 0.0427 - mae: 0.1645 - mse: 0.0427 - val_loss: 0.0176 - val_mae: 0.1108 - val_mse: 0.0176
Epoch 9/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0352 - mae: 0.1499 - mse: 0.0352
64/94 [===================>..........] - ETA: 0s - loss: 0.0406 - mae: 0.1639 - mse: 0.0406
94/94 [==============================] - 0s 5ms/step - loss: 0.0354 - mae: 0.1514 - mse: 0.0354 - val_loss: 0.0246 - val_mae: 0.1320 - val_mse: 0.0246
Epoch 10/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0382 - mae: 0.1728 - mse: 0.0382
64/94 [===================>..........] - ETA: 0s - loss: 0.0352 - mae: 0.1581 - mse: 0.0352
94/94 [==============================] - 1s 5ms/step - loss: 0.0334 - mae: 0.1498 - mse: 0.0334 - val_loss: 0.0267 - val_mae: 0.1307 - val_mse: 0.0267
Epoch 11/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0352 - mae: 0.1552 - mse: 0.0352
64/94 [===================>..........] - ETA: 0s - loss: 0.0311 - mae: 0.1481 - mse: 0.0311
94/94 [==============================] - 1s 5ms/step - loss: 0.0350 - mae: 0.1532 - mse: 0.0350 - val_loss: 0.0211 - val_mae: 0.1076 - val_mse: 0.0211
Epoch 12/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0321 - mae: 0.1362 - mse: 0.0321
64/94 [===================>..........] - ETA: 0s - loss: 0.0261 - mae: 0.1281 - mse: 0.0261
94/94 [==============================] - 1s 5ms/step - loss: 0.0299 - mae: 0.1302 - mse: 0.0299 - val_loss: 0.0185 - val_mae: 0.1057 - val_mse: 0.0185
Epoch 13/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0194 - mae: 0.1061 - mse: 0.0194
64/94 [===================>..........] - ETA: 0s - loss: 0.0201 - mae: 0.1130 - mse: 0.0201
94/94 [==============================] - 1s 5ms/step - loss: 0.0179 - mae: 0.1080 - mse: 0.0179 - val_loss: 0.0098 - val_mae: 0.0761 - val_mse: 0.0098
Epoch 14/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0189 - mae: 0.1034 - mse: 0.0189
64/94 [===================>..........] - ETA: 0s - loss: 0.0233 - mae: 0.1184 - mse: 0.0233
94/94 [==============================] - 1s 5ms/step - loss: 0.0221 - mae: 0.1156 - mse: 0.0221 - val_loss: 0.0074 - val_mae: 0.0713 - val_mse: 0.0074
Epoch 15/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0178 - mae: 0.1029 - mse: 0.0178
64/94 [===================>..........] - ETA: 0s - loss: 0.0269 - mae: 0.1229 - mse: 0.0269
94/94 [==============================] - 1s 5ms/step - loss: 0.0232 - mae: 0.1136 - mse: 0.0232 - val_loss: 0.0124 - val_mae: 0.0933 - val_mse: 0.0124
Epoch 16/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0244 - mae: 0.1109 - mse: 0.0244
64/94 [===================>..........] - ETA: 0s - loss: 0.0196 - mae: 0.1050 - mse: 0.0196
94/94 [==============================] - 0s 5ms/step - loss: 0.0214 - mae: 0.1138 - mse: 0.0214 - val_loss: 0.0126 - val_mae: 0.0907 - val_mse: 0.0126
Epoch 17/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0181 - mae: 0.1160 - mse: 0.0181
64/94 [===================>..........] - ETA: 0s - loss: 0.0138 - mae: 0.0970 - mse: 0.0138
94/94 [==============================] - 1s 5ms/step - loss: 0.0149 - mae: 0.0988 - mse: 0.0149 - val_loss: 0.0062 - val_mae: 0.0567 - val_mse: 0.0062
Epoch 18/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0178 - mae: 0.1011 - mse: 0.0178
64/94 [===================>..........] - ETA: 0s - loss: 0.0166 - mae: 0.0978 - mse: 0.0166
94/94 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 0.1006 - mse: 0.0178 - val_loss: 0.0061 - val_mae: 0.0601 - val_mse: 0.0061
Epoch 19/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0142 - mae: 0.1025 - mse: 0.0142
64/94 [===================>..........] - ETA: 0s - loss: 0.0191 - mae: 0.1120 - mse: 0.0191
94/94 [==============================] - 1s 5ms/step - loss: 0.0161 - mae: 0.1021 - mse: 0.0161 - val_loss: 0.0079 - val_mae: 0.0721 - val_mse: 0.0079
Epoch 20/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0119 - mae: 0.0876 - mse: 0.0119
64/94 [===================>..........] - ETA: 0s - loss: 0.0124 - mae: 0.0879 - mse: 0.0124
94/94 [==============================] - 1s 5ms/step - loss: 0.0118 - mae: 0.0835 - mse: 0.0118 - val_loss: 0.0082 - val_mae: 0.0733 - val_mse: 0.0082
Epoch 21/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0203 - mae: 0.1003 - mse: 0.0203
64/94 [===================>..........] - ETA: 0s - loss: 0.0218 - mae: 0.0978 - mse: 0.0218
94/94 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 0.0936 - mse: 0.0188 - val_loss: 0.0108 - val_mae: 0.0796 - val_mse: 0.0108
Epoch 22/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0127 - mae: 0.0867 - mse: 0.0127
64/94 [===================>..........] - ETA: 0s - loss: 0.0099 - mae: 0.0792 - mse: 0.0099
94/94 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0893 - mse: 0.0146 - val_loss: 0.0128 - val_mae: 0.0898 - val_mse: 0.0128
Epoch 23/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0076 - mae: 0.0687 - mse: 0.0076
64/94 [===================>..........] - ETA: 0s - loss: 0.0113 - mae: 0.0798 - mse: 0.0113
94/94 [==============================] - 0s 5ms/step - loss: 0.0110 - mae: 0.0815 - mse: 0.0110 - val_loss: 0.0072 - val_mae: 0.0655 - val_mse: 0.0072
Epoch 24/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0096 - mae: 0.0729 - mse: 0.0096
64/94 [===================>..........] - ETA: 0s - loss: 0.0122 - mae: 0.0779 - mse: 0.0122
94/94 [==============================] - 1s 5ms/step - loss: 0.0137 - mae: 0.0875 - mse: 0.0137 - val_loss: 0.0058 - val_mae: 0.0682 - val_mse: 0.0058
Epoch 25/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0082 - mae: 0.0675 - mse: 0.0082
64/94 [===================>..........] - ETA: 0s - loss: 0.0092 - mae: 0.0680 - mse: 0.0092
94/94 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0639 - mse: 0.0077 - val_loss: 0.0088 - val_mae: 0.0878 - val_mse: 0.0088
Epoch 26/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0061 - mae: 0.0607 - mse: 0.0061
64/94 [===================>..........] - ETA: 0s - loss: 0.0093 - mae: 0.0671 - mse: 0.0093
94/94 [==============================] - 0s 5ms/step - loss: 0.0105 - mae: 0.0738 - mse: 0.0105 - val_loss: 0.0129 - val_mae: 0.1034 - val_mse: 0.0129
Epoch 27/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0104 - mae: 0.0841 - mse: 0.0104
64/94 [===================>..........] - ETA: 0s - loss: 0.0075 - mae: 0.0702 - mse: 0.0075
94/94 [==============================] - 0s 5ms/step - loss: 0.0109 - mae: 0.0773 - mse: 0.0109 - val_loss: 0.0143 - val_mae: 0.1016 - val_mse: 0.0143
Epoch 28/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0087 - mae: 0.0756 - mse: 0.0087
64/94 [===================>..........] - ETA: 0s - loss: 0.0115 - mae: 0.0807 - mse: 0.0115
94/94 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0787 - mse: 0.0107 - val_loss: 0.0105 - val_mae: 0.0714 - val_mse: 0.0105
Epoch 29/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0176 - mae: 0.0974 - mse: 0.0176
64/94 [===================>..........] - ETA: 0s - loss: 0.0174 - mae: 0.0952 - mse: 0.0174
94/94 [==============================] - 1s 6ms/step - loss: 0.0164 - mae: 0.0935 - mse: 0.0164 - val_loss: 0.0152 - val_mae: 0.0924 - val_mse: 0.0152
Epoch 30/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0084 - mae: 0.0679 - mse: 0.0084
64/94 [===================>..........] - ETA: 0s - loss: 0.0103 - mae: 0.0731 - mse: 0.0103
94/94 [==============================] - 1s 5ms/step - loss: 0.0102 - mae: 0.0712 - mse: 0.0102 - val_loss: 0.0160 - val_mae: 0.1073 - val_mse: 0.0160
Saving trained model...
88
Testing...
heightdiff= [0.        0.        0.        5.0591507 0.        0.       ]
average prediction= [3.6529112]
baseline= 7.314814814814815
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.2647876739501953
85 -:- nan
60 -:- nan
['train-weight-1.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
2_155_65_1_csi_a1_6.dat
65 8
2_155_65_1_csi_a1_24.dat
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_1_csi_a1_3.dat
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_1_csi_a1_11.dat
65 42
1_165_65_1_csi_a1_2.dat
1_165_65_1_csi_a1_5.dat
65 45
1_165_65_1_csi_a1_4.dat
1_165_65_1_csi_a1_13.dat
65 48
1_165_65_1_csi_a1_12.dat
65 50
65 51
1_165_65_1_csi_a1_14.dat
65 53
1_165_65_1_csi_a1_6.dat
1_165_65_1_csi_a1_1.dat
65 56
1_165_65_1_csi_a1_15.dat
1_165_65_1_csi_a1_17.dat
65 59
65 60
1_165_65_1_csi_a1_3.dat
65 62
1_165_65_1_csi_a1_9.dat
1_165_65_1_csi_a1_16.dat
1_165_65_1_csi_a1_22.dat
65 66
1_165_65_1_csi_a1_10.dat
65 68
1_165_65_1_csi_a1_7.dat
65 70
50 71
50 72
50 73
50 74
50 75
2_165_50_1_csi_a1_29.dat
50 77
2_165_50_1_csi_a1_2.dat
50 79
50 80
2_165_50_1_csi_a1_3.dat
50 82
50 83
50 84
50 85
50 86
50 87
2_165_50_1_csi_a1_28.dat
50 89
50 90
2_165_50_1_csi_a1_7.dat
50 92
50 93
50 94
50 95
50 96
2_165_50_1_csi_a1_25.dat
2_165_50_1_csi_a1_27.dat
2_165_50_1_csi_a1_11.dat
50 100
70 101
70 102
70 103
70 104
1_175_70_1_csi_a1_18.dat
1_175_70_1_csi_a1_12.dat
70 107
70 108
70 109
1_175_70_1_csi_a1_8.dat
70 111
1_175_70_1_csi_a1_3.dat
1_175_70_1_csi_a1_26.dat
70 114
1_175_70_1_csi_a1_10.dat
70 116
70 117
1_175_70_1_csi_a1_6.dat
70 119
1_175_70_1_csi_a1_9.dat
70 121
70 122
70 123
70 124
70 125
1_175_70_1_csi_a1_22.dat
70 127
70 128
1_175_70_1_csi_a1_21.dat
1_175_70_1_csi_a1_14.dat
85 131
1_180_85_1_csi_a1_6.dat
85 133
1_180_85_1_csi_a1_4.dat
85 135
85 136
85 137
1_180_85_1_csi_a1_22.dat
1_180_85_1_csi_a1_20.dat
85 140
85 141
85 142
1_180_85_1_csi_a1_25.dat
1_180_85_1_csi_a1_26.dat
1_180_85_1_csi_a1_12.dat
1_180_85_1_csi_a1_30.dat
85 147
85 148
1_180_85_1_csi_a1_27.dat
85 150
85 151
1_180_85_1_csi_a1_13.dat
1_180_85_1_csi_a1_5.dat
1_180_85_1_csi_a1_7.dat
1_180_85_1_csi_a1_9.dat
85 156
1_180_85_1_csi_a1_3.dat
85 158
85 159
1_180_85_1_csi_a1_2.dat
75 161
75 162
75 163
1_180_75_1_csi_a1_4.dat
75 165
75 166
1_180_75_1_csi_a1_27.dat
75 168
75 169
1_180_75_1_csi_a1_2.dat
1_180_75_1_csi_a1_1.dat
75 172
75 173
75 174
75 175
1_180_75_1_csi_a1_16.dat
75 177
75 178
75 179
75 180
75 181
75 182
75 183
75 184
1_180_75_1_csi_a1_15.dat
75 186
75 187
1_180_75_1_csi_a1_29.dat
75 189
75 190
1_173_85_1_csi_a1_16.dat
1_173_85_1_csi_a1_13.dat
1_173_85_1_csi_a1_22.dat
1_173_85_1_csi_a1_26.dat
1_173_85_1_csi_a1_19.dat
1_173_85_1_csi_a1_18.dat
1_173_85_1_csi_a1_5.dat
1_173_85_1_csi_a1_17.dat
1_173_85_1_csi_a1_7.dat
1_173_85_1_csi_a1_6.dat
1_173_85_1_csi_a1_9.dat
1_173_85_1_csi_a1_23.dat
85 203
85 204
1_173_85_1_csi_a1_30.dat
1_173_85_1_csi_a1_21.dat
1_173_85_1_csi_a1_20.dat
1_173_85_1_csi_a1_25.dat
1_173_85_1_csi_a1_11.dat
1_173_85_1_csi_a1_24.dat
1_173_85_1_csi_a1_28.dat
1_173_85_1_csi_a1_27.dat
1_173_85_1_csi_a1_8.dat
1_173_85_1_csi_a1_4.dat
1_173_85_1_csi_a1_14.dat
1_173_85_1_csi_a1_2.dat
1_173_85_1_csi_a1_29.dat
1_173_85_1_csi_a1_3.dat
1_173_85_1_csi_a1_1.dat
85 220
(132, 30, 3)
(132, 427, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65
 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 85 85 85]
(132, 427, 30, 3, 1)

Loaded dataset of 132 samples, each sized (427, 30, 3, 1)


Train on 105 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 427, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 427, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 427, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 427, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 427, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 427, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 427, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 94 samples, validate on 11 samples
Epoch 1/30

32/94 [=========>....................] - ETA: 0s - loss: 0.3532 - mae: 0.5252 - mse: 0.3532
64/94 [===================>..........] - ETA: 0s - loss: 0.2726 - mae: 0.4363 - mse: 0.2726
94/94 [==============================] - 1s 9ms/step - loss: 0.2459 - mae: 0.4177 - mse: 0.2459 - val_loss: 0.2230 - val_mae: 0.4036 - val_mse: 0.2230
Epoch 2/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1442 - mae: 0.3115 - mse: 0.1442
64/94 [===================>..........] - ETA: 0s - loss: 0.1066 - mae: 0.2571 - mse: 0.1066
94/94 [==============================] - 0s 5ms/step - loss: 0.1003 - mae: 0.2461 - mse: 0.1003 - val_loss: 0.1002 - val_mae: 0.2395 - val_mse: 0.1002
Epoch 3/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0834 - mae: 0.2445 - mse: 0.0834
64/94 [===================>..........] - ETA: 0s - loss: 0.1031 - mae: 0.2732 - mse: 0.1031
94/94 [==============================] - 1s 5ms/step - loss: 0.0930 - mae: 0.2565 - mse: 0.0930 - val_loss: 0.0847 - val_mae: 0.2153 - val_mse: 0.0847
Epoch 4/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0575 - mae: 0.1937 - mse: 0.0575
64/94 [===================>..........] - ETA: 0s - loss: 0.0677 - mae: 0.2078 - mse: 0.0677
94/94 [==============================] - 1s 5ms/step - loss: 0.0539 - mae: 0.1795 - mse: 0.0539 - val_loss: 0.0815 - val_mae: 0.2092 - val_mse: 0.0815
Epoch 5/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0525 - mae: 0.1806 - mse: 0.0525
64/94 [===================>..........] - ETA: 0s - loss: 0.0370 - mae: 0.1478 - mse: 0.0370
94/94 [==============================] - 1s 6ms/step - loss: 0.0479 - mae: 0.1671 - mse: 0.0479 - val_loss: 0.0807 - val_mae: 0.2078 - val_mse: 0.0807
Epoch 6/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0249 - mae: 0.1371 - mse: 0.0249
64/94 [===================>..........] - ETA: 0s - loss: 0.0357 - mae: 0.1471 - mse: 0.0357
94/94 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 0.1549 - mse: 0.0410 - val_loss: 0.0622 - val_mae: 0.1879 - val_mse: 0.0622
Epoch 7/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0288 - mae: 0.1435 - mse: 0.0288
64/94 [===================>..........] - ETA: 0s - loss: 0.0313 - mae: 0.1438 - mse: 0.0313
94/94 [==============================] - 0s 5ms/step - loss: 0.0348 - mae: 0.1478 - mse: 0.0348 - val_loss: 0.0356 - val_mae: 0.1526 - val_mse: 0.0356
Epoch 8/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0252 - mae: 0.1370 - mse: 0.0252
64/94 [===================>..........] - ETA: 0s - loss: 0.0334 - mae: 0.1507 - mse: 0.0334
94/94 [==============================] - 1s 5ms/step - loss: 0.0324 - mae: 0.1502 - mse: 0.0324 - val_loss: 0.0225 - val_mae: 0.1337 - val_mse: 0.0225
Epoch 9/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0276 - mae: 0.1277 - mse: 0.0276
64/94 [===================>..........] - ETA: 0s - loss: 0.0263 - mae: 0.1309 - mse: 0.0263
94/94 [==============================] - 1s 5ms/step - loss: 0.0257 - mae: 0.1292 - mse: 0.0257 - val_loss: 0.0164 - val_mae: 0.1190 - val_mse: 0.0164
Epoch 10/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0308 - mae: 0.1351 - mse: 0.0308
64/94 [===================>..........] - ETA: 0s - loss: 0.0271 - mae: 0.1319 - mse: 0.0271
94/94 [==============================] - 1s 5ms/step - loss: 0.0231 - mae: 0.1235 - mse: 0.0231 - val_loss: 0.0146 - val_mae: 0.1021 - val_mse: 0.0146
Epoch 11/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0206 - mae: 0.1057 - mse: 0.0206
64/94 [===================>..........] - ETA: 0s - loss: 0.0181 - mae: 0.1087 - mse: 0.0181
94/94 [==============================] - 0s 5ms/step - loss: 0.0220 - mae: 0.1163 - mse: 0.0220 - val_loss: 0.0268 - val_mae: 0.1332 - val_mse: 0.0268
Epoch 12/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0220 - mae: 0.1063 - mse: 0.0220
64/94 [===================>..........] - ETA: 0s - loss: 0.0224 - mae: 0.1101 - mse: 0.0224
94/94 [==============================] - 0s 5ms/step - loss: 0.0218 - mae: 0.1142 - mse: 0.0218 - val_loss: 0.0279 - val_mae: 0.1365 - val_mse: 0.0279
Epoch 13/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0261 - mae: 0.1148 - mse: 0.0261
64/94 [===================>..........] - ETA: 0s - loss: 0.0260 - mae: 0.1205 - mse: 0.0260
94/94 [==============================] - 1s 5ms/step - loss: 0.0248 - mae: 0.1188 - mse: 0.0248 - val_loss: 0.0155 - val_mae: 0.0875 - val_mse: 0.0155
Epoch 14/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0148 - mae: 0.0959 - mse: 0.0148
64/94 [===================>..........] - ETA: 0s - loss: 0.0162 - mae: 0.1002 - mse: 0.0162
94/94 [==============================] - 1s 5ms/step - loss: 0.0178 - mae: 0.1036 - mse: 0.0178 - val_loss: 0.0167 - val_mae: 0.0981 - val_mse: 0.0167
Epoch 15/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0120 - mae: 0.0899 - mse: 0.0120
64/94 [===================>..........] - ETA: 0s - loss: 0.0143 - mae: 0.0913 - mse: 0.0143
94/94 [==============================] - 0s 5ms/step - loss: 0.0156 - mae: 0.0935 - mse: 0.0156 - val_loss: 0.0212 - val_mae: 0.1210 - val_mse: 0.0212
Epoch 16/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0244 - mae: 0.1004 - mse: 0.0244
64/94 [===================>..........] - ETA: 0s - loss: 0.0199 - mae: 0.0961 - mse: 0.0199
94/94 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.0899 - mse: 0.0173 - val_loss: 0.0111 - val_mae: 0.0831 - val_mse: 0.0111
Epoch 17/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0097 - mae: 0.0768 - mse: 0.0097
64/94 [===================>..........] - ETA: 0s - loss: 0.0153 - mae: 0.0885 - mse: 0.0153
94/94 [==============================] - 1s 5ms/step - loss: 0.0143 - mae: 0.0867 - mse: 0.0143 - val_loss: 0.0083 - val_mae: 0.0689 - val_mse: 0.0083
Epoch 18/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0200 - mae: 0.0960 - mse: 0.0200
64/94 [===================>..........] - ETA: 0s - loss: 0.0161 - mae: 0.0891 - mse: 0.0161
94/94 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0844 - mse: 0.0135 - val_loss: 0.0119 - val_mae: 0.0894 - val_mse: 0.0119
Epoch 19/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0099 - mae: 0.0776 - mse: 0.0099
64/94 [===================>..........] - ETA: 0s - loss: 0.0120 - mae: 0.0752 - mse: 0.0120
94/94 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0686 - mse: 0.0098 - val_loss: 0.0152 - val_mae: 0.1072 - val_mse: 0.0152
Epoch 20/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0270 - mae: 0.1081 - mse: 0.0270
64/94 [===================>..........] - ETA: 0s - loss: 0.0195 - mae: 0.0976 - mse: 0.0195
94/94 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0927 - mse: 0.0170 - val_loss: 0.0123 - val_mae: 0.0974 - val_mse: 0.0123
Epoch 21/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0166 - mae: 0.0943 - mse: 0.0166
64/94 [===================>..........] - ETA: 0s - loss: 0.0120 - mae: 0.0790 - mse: 0.0120
94/94 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0740 - mse: 0.0106 - val_loss: 0.0125 - val_mae: 0.1019 - val_mse: 0.0125
Epoch 22/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0047 - mae: 0.0547 - mse: 0.0047
64/94 [===================>..........] - ETA: 0s - loss: 0.0133 - mae: 0.0774 - mse: 0.0133
94/94 [==============================] - 0s 5ms/step - loss: 0.0116 - mae: 0.0774 - mse: 0.0116 - val_loss: 0.0152 - val_mae: 0.1122 - val_mse: 0.0152
Epoch 23/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0118 - mae: 0.0835 - mse: 0.0118
64/94 [===================>..........] - ETA: 0s - loss: 0.0151 - mae: 0.0800 - mse: 0.0151
94/94 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0772 - mse: 0.0127 - val_loss: 0.0166 - val_mae: 0.1106 - val_mse: 0.0166
Epoch 24/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0081 - mae: 0.0610 - mse: 0.0081
64/94 [===================>..........] - ETA: 0s - loss: 0.0068 - mae: 0.0587 - mse: 0.0068
94/94 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0602 - mse: 0.0068 - val_loss: 0.0211 - val_mae: 0.1203 - val_mse: 0.0211
Epoch 25/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0073 - mae: 0.0601 - mse: 0.0073
64/94 [===================>..........] - ETA: 0s - loss: 0.0123 - mae: 0.0741 - mse: 0.0123
94/94 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0714 - mse: 0.0115 - val_loss: 0.0238 - val_mae: 0.1292 - val_mse: 0.0238
Epoch 26/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0068 - mae: 0.0630 - mse: 0.0068
64/94 [===================>..........] - ETA: 0s - loss: 0.0084 - mae: 0.0634 - mse: 0.0084
94/94 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0637 - mse: 0.0079 - val_loss: 0.0139 - val_mae: 0.0895 - val_mse: 0.0139
Epoch 27/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0091 - mae: 0.0639 - mse: 0.0091
64/94 [===================>..........] - ETA: 0s - loss: 0.0102 - mae: 0.0687 - mse: 0.0102
94/94 [==============================] - 0s 5ms/step - loss: 0.0111 - mae: 0.0743 - mse: 0.0111 - val_loss: 0.0084 - val_mae: 0.0690 - val_mse: 0.0084
Epoch 28/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0127 - mae: 0.0760 - mse: 0.0127
64/94 [===================>..........] - ETA: 0s - loss: 0.0107 - mae: 0.0720 - mse: 0.0107
94/94 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0662 - mse: 0.0087 - val_loss: 0.0084 - val_mae: 0.0827 - val_mse: 0.0084
Epoch 29/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0049 - mae: 0.0545 - mse: 0.0049
64/94 [===================>..........] - ETA: 0s - loss: 0.0062 - mae: 0.0611 - mse: 0.0062
94/94 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0667 - mse: 0.0084 - val_loss: 0.0150 - val_mae: 0.1133 - val_mse: 0.0150
Epoch 30/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0211 - mae: 0.0861 - mse: 0.0211
64/94 [===================>..........] - ETA: 0s - loss: 0.0153 - mae: 0.0778 - mse: 0.0153
94/94 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0710 - mse: 0.0126 - val_loss: 0.0135 - val_mae: 0.1038 - val_mse: 0.0135
Saving trained model...
88
Testing...
heightdiff= [0.        0.        0.        0.7216301 0.        0.       ]
average prediction= [3.7519393]
baseline= 8.61111111111111
eachuser= [0. 0. 0. 1. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.7216300964355469
85 -:- nan
60 -:- nan
['train-weight-1.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
2_155_65_1_csi_a1_6.dat
65 8
2_155_65_1_csi_a1_24.dat
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_1_csi_a1_3.dat
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_1_csi_a1_11.dat
65 42
1_165_65_1_csi_a1_2.dat
1_165_65_1_csi_a1_5.dat
65 45
1_165_65_1_csi_a1_4.dat
1_165_65_1_csi_a1_13.dat
65 48
1_165_65_1_csi_a1_12.dat
65 50
65 51
1_165_65_1_csi_a1_14.dat
65 53
1_165_65_1_csi_a1_6.dat
1_165_65_1_csi_a1_1.dat
65 56
1_165_65_1_csi_a1_15.dat
1_165_65_1_csi_a1_17.dat
65 59
65 60
1_165_65_1_csi_a1_3.dat
65 62
1_165_65_1_csi_a1_9.dat
1_165_65_1_csi_a1_16.dat
1_165_65_1_csi_a1_22.dat
65 66
1_165_65_1_csi_a1_10.dat
65 68
1_165_65_1_csi_a1_7.dat
65 70
50 71
50 72
50 73
50 74
50 75
2_165_50_1_csi_a1_29.dat
50 77
2_165_50_1_csi_a1_2.dat
50 79
50 80
2_165_50_1_csi_a1_3.dat
50 82
50 83
50 84
50 85
50 86
50 87
2_165_50_1_csi_a1_28.dat
50 89
50 90
2_165_50_1_csi_a1_7.dat
50 92
50 93
50 94
50 95
50 96
2_165_50_1_csi_a1_25.dat
2_165_50_1_csi_a1_27.dat
2_165_50_1_csi_a1_11.dat
50 100
70 101
70 102
70 103
70 104
1_175_70_1_csi_a1_18.dat
1_175_70_1_csi_a1_12.dat
70 107
70 108
70 109
1_175_70_1_csi_a1_8.dat
70 111
1_175_70_1_csi_a1_3.dat
1_175_70_1_csi_a1_26.dat
70 114
1_175_70_1_csi_a1_10.dat
70 116
70 117
1_175_70_1_csi_a1_6.dat
70 119
1_175_70_1_csi_a1_9.dat
70 121
70 122
70 123
70 124
70 125
1_175_70_1_csi_a1_22.dat
70 127
70 128
1_175_70_1_csi_a1_21.dat
1_175_70_1_csi_a1_14.dat
85 131
1_180_85_1_csi_a1_6.dat
85 133
1_180_85_1_csi_a1_4.dat
85 135
85 136
85 137
1_180_85_1_csi_a1_22.dat
1_180_85_1_csi_a1_20.dat
85 140
85 141
85 142
1_180_85_1_csi_a1_25.dat
1_180_85_1_csi_a1_26.dat
1_180_85_1_csi_a1_12.dat
1_180_85_1_csi_a1_30.dat
85 147
85 148
1_180_85_1_csi_a1_27.dat
85 150
85 151
1_180_85_1_csi_a1_13.dat
1_180_85_1_csi_a1_5.dat
1_180_85_1_csi_a1_7.dat
1_180_85_1_csi_a1_9.dat
85 156
1_180_85_1_csi_a1_3.dat
85 158
85 159
1_180_85_1_csi_a1_2.dat
75 161
75 162
75 163
1_180_75_1_csi_a1_4.dat
75 165
75 166
1_180_75_1_csi_a1_27.dat
75 168
75 169
1_180_75_1_csi_a1_2.dat
1_180_75_1_csi_a1_1.dat
75 172
75 173
75 174
75 175
1_180_75_1_csi_a1_16.dat
75 177
75 178
75 179
75 180
75 181
75 182
75 183
75 184
1_180_75_1_csi_a1_15.dat
75 186
75 187
1_180_75_1_csi_a1_29.dat
75 189
75 190
1_173_85_1_csi_a1_16.dat
1_173_85_1_csi_a1_13.dat
1_173_85_1_csi_a1_22.dat
1_173_85_1_csi_a1_26.dat
1_173_85_1_csi_a1_19.dat
1_173_85_1_csi_a1_18.dat
1_173_85_1_csi_a1_5.dat
1_173_85_1_csi_a1_17.dat
1_173_85_1_csi_a1_7.dat
1_173_85_1_csi_a1_6.dat
1_173_85_1_csi_a1_9.dat
1_173_85_1_csi_a1_23.dat
85 203
85 204
1_173_85_1_csi_a1_30.dat
1_173_85_1_csi_a1_21.dat
1_173_85_1_csi_a1_20.dat
1_173_85_1_csi_a1_25.dat
1_173_85_1_csi_a1_11.dat
1_173_85_1_csi_a1_24.dat
1_173_85_1_csi_a1_28.dat
1_173_85_1_csi_a1_27.dat
1_173_85_1_csi_a1_8.dat
1_173_85_1_csi_a1_4.dat
1_173_85_1_csi_a1_14.dat
1_173_85_1_csi_a1_2.dat
1_173_85_1_csi_a1_29.dat
1_173_85_1_csi_a1_3.dat
1_173_85_1_csi_a1_1.dat
85 220
(132, 30, 3)
(132, 427, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65
 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 85 85 85]
(132, 427, 30, 3, 1)

Loaded dataset of 132 samples, each sized (427, 30, 3, 1)


Train on 105 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 427, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 427, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 427, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 427, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 427, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 427, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 427, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 94 samples, validate on 11 samples
Epoch 1/30

32/94 [=========>....................] - ETA: 0s - loss: 0.2491 - mae: 0.4297 - mse: 0.2491
64/94 [===================>..........] - ETA: 0s - loss: 0.2383 - mae: 0.4168 - mse: 0.2383
94/94 [==============================] - 1s 11ms/step - loss: 0.2074 - mae: 0.3857 - mse: 0.2074 - val_loss: 0.0839 - val_mae: 0.2444 - val_mse: 0.0839
Epoch 2/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1667 - mae: 0.3562 - mse: 0.1667
64/94 [===================>..........] - ETA: 0s - loss: 0.1877 - mae: 0.3553 - mse: 0.1877
94/94 [==============================] - 1s 11ms/step - loss: 0.1761 - mae: 0.3486 - mse: 0.1761 - val_loss: 0.0770 - val_mae: 0.2254 - val_mse: 0.0770
Epoch 3/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1019 - mae: 0.2715 - mse: 0.1019
64/94 [===================>..........] - ETA: 0s - loss: 0.1016 - mae: 0.2603 - mse: 0.1016
94/94 [==============================] - 1s 9ms/step - loss: 0.0938 - mae: 0.2517 - mse: 0.0938 - val_loss: 0.1074 - val_mae: 0.2523 - val_mse: 0.1074
Epoch 4/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1018 - mae: 0.2567 - mse: 0.1018
64/94 [===================>..........] - ETA: 0s - loss: 0.0907 - mae: 0.2413 - mse: 0.0907
94/94 [==============================] - 1s 6ms/step - loss: 0.0874 - mae: 0.2331 - mse: 0.0874 - val_loss: 0.1067 - val_mae: 0.2597 - val_mse: 0.1067
Epoch 5/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1033 - mae: 0.2508 - mse: 0.1033
64/94 [===================>..........] - ETA: 0s - loss: 0.0927 - mae: 0.2373 - mse: 0.0927
94/94 [==============================] - 0s 5ms/step - loss: 0.0838 - mae: 0.2285 - mse: 0.0838 - val_loss: 0.0783 - val_mae: 0.2229 - val_mse: 0.0783
Epoch 6/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0479 - mae: 0.1675 - mse: 0.0479
64/94 [===================>..........] - ETA: 0s - loss: 0.0581 - mae: 0.1913 - mse: 0.0581
94/94 [==============================] - 0s 5ms/step - loss: 0.0594 - mae: 0.1959 - mse: 0.0594 - val_loss: 0.0562 - val_mae: 0.1911 - val_mse: 0.0562
Epoch 7/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0478 - mae: 0.1703 - mse: 0.0478
64/94 [===================>..........] - ETA: 0s - loss: 0.0527 - mae: 0.1815 - mse: 0.0527
94/94 [==============================] - 0s 5ms/step - loss: 0.0454 - mae: 0.1703 - mse: 0.0454 - val_loss: 0.0538 - val_mae: 0.1912 - val_mse: 0.0538
Epoch 8/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0424 - mae: 0.1779 - mse: 0.0424
64/94 [===================>..........] - ETA: 0s - loss: 0.0592 - mae: 0.1984 - mse: 0.0592
94/94 [==============================] - 0s 5ms/step - loss: 0.0543 - mae: 0.1871 - mse: 0.0543 - val_loss: 0.0549 - val_mae: 0.2015 - val_mse: 0.0549
Epoch 9/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0517 - mae: 0.1945 - mse: 0.0517
64/94 [===================>..........] - ETA: 0s - loss: 0.0425 - mae: 0.1737 - mse: 0.0425
94/94 [==============================] - 0s 5ms/step - loss: 0.0414 - mae: 0.1725 - mse: 0.0414 - val_loss: 0.0583 - val_mae: 0.2052 - val_mse: 0.0583
Epoch 10/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0460 - mae: 0.1716 - mse: 0.0460
64/94 [===================>..........] - ETA: 0s - loss: 0.0511 - mae: 0.1778 - mse: 0.0511
94/94 [==============================] - 1s 5ms/step - loss: 0.0428 - mae: 0.1621 - mse: 0.0428 - val_loss: 0.0514 - val_mae: 0.1920 - val_mse: 0.0514
Epoch 11/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0271 - mae: 0.1295 - mse: 0.0271
64/94 [===================>..........] - ETA: 0s - loss: 0.0279 - mae: 0.1330 - mse: 0.0279
94/94 [==============================] - 1s 5ms/step - loss: 0.0347 - mae: 0.1469 - mse: 0.0347 - val_loss: 0.0396 - val_mae: 0.1683 - val_mse: 0.0396
Epoch 12/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0304 - mae: 0.1294 - mse: 0.0304
64/94 [===================>..........] - ETA: 0s - loss: 0.0255 - mae: 0.1210 - mse: 0.0255
94/94 [==============================] - 0s 5ms/step - loss: 0.0283 - mae: 0.1291 - mse: 0.0283 - val_loss: 0.0363 - val_mae: 0.1547 - val_mse: 0.0363
Epoch 13/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0341 - mae: 0.1401 - mse: 0.0341
64/94 [===================>..........] - ETA: 0s - loss: 0.0316 - mae: 0.1302 - mse: 0.0316
94/94 [==============================] - 0s 5ms/step - loss: 0.0325 - mae: 0.1347 - mse: 0.0325 - val_loss: 0.0449 - val_mae: 0.1633 - val_mse: 0.0449
Epoch 14/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0384 - mae: 0.1500 - mse: 0.0384
64/94 [===================>..........] - ETA: 0s - loss: 0.0374 - mae: 0.1448 - mse: 0.0374
94/94 [==============================] - 1s 5ms/step - loss: 0.0326 - mae: 0.1371 - mse: 0.0326 - val_loss: 0.0396 - val_mae: 0.1513 - val_mse: 0.0396
Epoch 15/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0275 - mae: 0.1305 - mse: 0.0275
64/94 [===================>..........] - ETA: 0s - loss: 0.0244 - mae: 0.1245 - mse: 0.0244
94/94 [==============================] - 0s 5ms/step - loss: 0.0247 - mae: 0.1283 - mse: 0.0247 - val_loss: 0.0274 - val_mae: 0.1220 - val_mse: 0.0274
Epoch 16/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0266 - mae: 0.1236 - mse: 0.0266
64/94 [===================>..........] - ETA: 0s - loss: 0.0226 - mae: 0.1107 - mse: 0.0226
94/94 [==============================] - 1s 5ms/step - loss: 0.0222 - mae: 0.1124 - mse: 0.0222 - val_loss: 0.0223 - val_mae: 0.1067 - val_mse: 0.0223
Epoch 17/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0240 - mae: 0.1291 - mse: 0.0240
64/94 [===================>..........] - ETA: 0s - loss: 0.0226 - mae: 0.1210 - mse: 0.0226
94/94 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 0.1095 - mse: 0.0197 - val_loss: 0.0253 - val_mae: 0.1116 - val_mse: 0.0253
Epoch 18/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0177 - mae: 0.0983 - mse: 0.0177
64/94 [===================>..........] - ETA: 0s - loss: 0.0170 - mae: 0.0999 - mse: 0.0170
94/94 [==============================] - 1s 5ms/step - loss: 0.0175 - mae: 0.1011 - mse: 0.0175 - val_loss: 0.0293 - val_mae: 0.1298 - val_mse: 0.0293
Epoch 19/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0111 - mae: 0.0798 - mse: 0.0111
64/94 [===================>..........] - ETA: 0s - loss: 0.0102 - mae: 0.0790 - mse: 0.0102
94/94 [==============================] - 1s 5ms/step - loss: 0.0148 - mae: 0.0878 - mse: 0.0148 - val_loss: 0.0173 - val_mae: 0.0885 - val_mse: 0.0173
Epoch 20/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0085 - mae: 0.0735 - mse: 0.0085
64/94 [===================>..........] - ETA: 0s - loss: 0.0101 - mae: 0.0709 - mse: 0.0101
94/94 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0727 - mse: 0.0101 - val_loss: 0.0111 - val_mae: 0.0608 - val_mse: 0.0111
Epoch 21/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0169 - mae: 0.0979 - mse: 0.0169
64/94 [===================>..........] - ETA: 0s - loss: 0.0167 - mae: 0.0970 - mse: 0.0167
94/94 [==============================] - 1s 5ms/step - loss: 0.0128 - mae: 0.0829 - mse: 0.0128 - val_loss: 0.0131 - val_mae: 0.0754 - val_mse: 0.0131
Epoch 22/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0104 - mae: 0.0707 - mse: 0.0104
64/94 [===================>..........] - ETA: 0s - loss: 0.0099 - mae: 0.0761 - mse: 0.0099
94/94 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0732 - mse: 0.0102 - val_loss: 0.0192 - val_mae: 0.1070 - val_mse: 0.0192
Epoch 23/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0136 - mae: 0.0915 - mse: 0.0136
64/94 [===================>..........] - ETA: 0s - loss: 0.0158 - mae: 0.0849 - mse: 0.0158
94/94 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0868 - mse: 0.0145 - val_loss: 0.0133 - val_mae: 0.0820 - val_mse: 0.0133
Epoch 24/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0183 - mae: 0.0883 - mse: 0.0183
64/94 [===================>..........] - ETA: 0s - loss: 0.0154 - mae: 0.0822 - mse: 0.0154
94/94 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0777 - mse: 0.0128 - val_loss: 0.0083 - val_mae: 0.0550 - val_mse: 0.0083
Epoch 25/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0161 - mae: 0.0998 - mse: 0.0161
64/94 [===================>..........] - ETA: 0s - loss: 0.0138 - mae: 0.0892 - mse: 0.0138
94/94 [==============================] - 0s 5ms/step - loss: 0.0152 - mae: 0.0875 - mse: 0.0152 - val_loss: 0.0251 - val_mae: 0.1335 - val_mse: 0.0251
Epoch 26/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0161 - mae: 0.0947 - mse: 0.0161
64/94 [===================>..........] - ETA: 0s - loss: 0.0147 - mae: 0.0929 - mse: 0.0147
94/94 [==============================] - 0s 5ms/step - loss: 0.0123 - mae: 0.0837 - mse: 0.0123 - val_loss: 0.0187 - val_mae: 0.1052 - val_mse: 0.0187
Epoch 27/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0204 - mae: 0.1024 - mse: 0.0204
64/94 [===================>..........] - ETA: 0s - loss: 0.0164 - mae: 0.0949 - mse: 0.0164
94/94 [==============================] - 0s 5ms/step - loss: 0.0144 - mae: 0.0878 - mse: 0.0144 - val_loss: 0.0070 - val_mae: 0.0595 - val_mse: 0.0070
Epoch 28/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0141 - mae: 0.0936 - mse: 0.0141
64/94 [===================>..........] - ETA: 0s - loss: 0.0133 - mae: 0.0886 - mse: 0.0133
94/94 [==============================] - 1s 5ms/step - loss: 0.0137 - mae: 0.0889 - mse: 0.0137 - val_loss: 0.0159 - val_mae: 0.1029 - val_mse: 0.0159
Epoch 29/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0109 - mae: 0.0787 - mse: 0.0109
64/94 [===================>..........] - ETA: 0s - loss: 0.0103 - mae: 0.0796 - mse: 0.0103
94/94 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0749 - mse: 0.0091 - val_loss: 0.0175 - val_mae: 0.1115 - val_mse: 0.0175
Epoch 30/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0116 - mae: 0.0849 - mse: 0.0116
64/94 [===================>..........] - ETA: 0s - loss: 0.0110 - mae: 0.0747 - mse: 0.0110
94/94 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0687 - mse: 0.0093 - val_loss: 0.0139 - val_mae: 0.0971 - val_mse: 0.0139
Saving trained model...
88
Testing...
heightdiff= [0.         0.         0.         5.16457748 0.         0.        ]
average prediction= [3.0542886]
baseline= 7.314814814814815
eachuser= [0. 0. 0. 3. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.7215258280436199
85 -:- nan
60 -:- nan
['train-weight-1.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
2_155_65_1_csi_a1_6.dat
65 8
2_155_65_1_csi_a1_24.dat
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_1_csi_a1_3.dat
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_1_csi_a1_11.dat
65 42
1_165_65_1_csi_a1_2.dat
1_165_65_1_csi_a1_5.dat
65 45
1_165_65_1_csi_a1_4.dat
1_165_65_1_csi_a1_13.dat
65 48
1_165_65_1_csi_a1_12.dat
65 50
65 51
1_165_65_1_csi_a1_14.dat
65 53
1_165_65_1_csi_a1_6.dat
1_165_65_1_csi_a1_1.dat
65 56
1_165_65_1_csi_a1_15.dat
1_165_65_1_csi_a1_17.dat
65 59
65 60
1_165_65_1_csi_a1_3.dat
65 62
1_165_65_1_csi_a1_9.dat
1_165_65_1_csi_a1_16.dat
1_165_65_1_csi_a1_22.dat
65 66
1_165_65_1_csi_a1_10.dat
65 68
1_165_65_1_csi_a1_7.dat
65 70
50 71
50 72
50 73
50 74
50 75
2_165_50_1_csi_a1_29.dat
50 77
2_165_50_1_csi_a1_2.dat
50 79
50 80
2_165_50_1_csi_a1_3.dat
50 82
50 83
50 84
50 85
50 86
50 87
2_165_50_1_csi_a1_28.dat
50 89
50 90
2_165_50_1_csi_a1_7.dat
50 92
50 93
50 94
50 95
50 96
2_165_50_1_csi_a1_25.dat
2_165_50_1_csi_a1_27.dat
2_165_50_1_csi_a1_11.dat
50 100
70 101
70 102
70 103
70 104
1_175_70_1_csi_a1_18.dat
1_175_70_1_csi_a1_12.dat
70 107
70 108
70 109
1_175_70_1_csi_a1_8.dat
70 111
1_175_70_1_csi_a1_3.dat
1_175_70_1_csi_a1_26.dat
70 114
1_175_70_1_csi_a1_10.dat
70 116
70 117
1_175_70_1_csi_a1_6.dat
70 119
1_175_70_1_csi_a1_9.dat
70 121
70 122
70 123
70 124
70 125
1_175_70_1_csi_a1_22.dat
70 127
70 128
1_175_70_1_csi_a1_21.dat
1_175_70_1_csi_a1_14.dat
85 131
1_180_85_1_csi_a1_6.dat
85 133
1_180_85_1_csi_a1_4.dat
85 135
85 136
85 137
1_180_85_1_csi_a1_22.dat
1_180_85_1_csi_a1_20.dat
85 140
85 141
85 142
1_180_85_1_csi_a1_25.dat
1_180_85_1_csi_a1_26.dat
1_180_85_1_csi_a1_12.dat
1_180_85_1_csi_a1_30.dat
85 147
85 148
1_180_85_1_csi_a1_27.dat
85 150
85 151
1_180_85_1_csi_a1_13.dat
1_180_85_1_csi_a1_5.dat
1_180_85_1_csi_a1_7.dat
1_180_85_1_csi_a1_9.dat
85 156
1_180_85_1_csi_a1_3.dat
85 158
85 159
1_180_85_1_csi_a1_2.dat
75 161
75 162
75 163
1_180_75_1_csi_a1_4.dat
75 165
75 166
1_180_75_1_csi_a1_27.dat
75 168
75 169
1_180_75_1_csi_a1_2.dat
1_180_75_1_csi_a1_1.dat
75 172
75 173
75 174
75 175
1_180_75_1_csi_a1_16.dat
75 177
75 178
75 179
75 180
75 181
75 182
75 183
75 184
1_180_75_1_csi_a1_15.dat
75 186
75 187
1_180_75_1_csi_a1_29.dat
75 189
75 190
1_173_85_1_csi_a1_16.dat
1_173_85_1_csi_a1_13.dat
1_173_85_1_csi_a1_22.dat
1_173_85_1_csi_a1_26.dat
1_173_85_1_csi_a1_19.dat
1_173_85_1_csi_a1_18.dat
1_173_85_1_csi_a1_5.dat
1_173_85_1_csi_a1_17.dat
1_173_85_1_csi_a1_7.dat
1_173_85_1_csi_a1_6.dat
1_173_85_1_csi_a1_9.dat
1_173_85_1_csi_a1_23.dat
85 203
85 204
1_173_85_1_csi_a1_30.dat
1_173_85_1_csi_a1_21.dat
1_173_85_1_csi_a1_20.dat
1_173_85_1_csi_a1_25.dat
1_173_85_1_csi_a1_11.dat
1_173_85_1_csi_a1_24.dat
1_173_85_1_csi_a1_28.dat
1_173_85_1_csi_a1_27.dat
1_173_85_1_csi_a1_8.dat
1_173_85_1_csi_a1_4.dat
1_173_85_1_csi_a1_14.dat
1_173_85_1_csi_a1_2.dat
1_173_85_1_csi_a1_29.dat
1_173_85_1_csi_a1_3.dat
1_173_85_1_csi_a1_1.dat
85 220
(132, 30, 3)
(132, 427, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65
 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 85 85 85]
(132, 427, 30, 3, 1)

Loaded dataset of 132 samples, each sized (427, 30, 3, 1)


Train on 105 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 427, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 427, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 427, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 427, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 427, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 427, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 427, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 94 samples, validate on 11 samples
Epoch 1/30

32/94 [=========>....................] - ETA: 0s - loss: 0.3700 - mae: 0.5218 - mse: 0.3700
64/94 [===================>..........] - ETA: 0s - loss: 0.3168 - mae: 0.4866 - mse: 0.3168
94/94 [==============================] - 1s 9ms/step - loss: 0.2670 - mae: 0.4361 - mse: 0.2670 - val_loss: 0.2199 - val_mae: 0.4152 - val_mse: 0.2199
Epoch 2/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1003 - mae: 0.2574 - mse: 0.1003
64/94 [===================>..........] - ETA: 0s - loss: 0.0930 - mae: 0.2520 - mse: 0.0930
94/94 [==============================] - 1s 5ms/step - loss: 0.0911 - mae: 0.2502 - mse: 0.0911 - val_loss: 0.0707 - val_mae: 0.2482 - val_mse: 0.0707
Epoch 3/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1203 - mae: 0.3011 - mse: 0.1203
64/94 [===================>..........] - ETA: 0s - loss: 0.1189 - mae: 0.2983 - mse: 0.1189
94/94 [==============================] - 0s 5ms/step - loss: 0.1117 - mae: 0.2841 - mse: 0.1117 - val_loss: 0.1046 - val_mae: 0.2832 - val_mse: 0.1046
Epoch 4/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0795 - mae: 0.2468 - mse: 0.0795
64/94 [===================>..........] - ETA: 0s - loss: 0.0589 - mae: 0.2026 - mse: 0.0589
94/94 [==============================] - 1s 5ms/step - loss: 0.0510 - mae: 0.1859 - mse: 0.0510 - val_loss: 0.1658 - val_mae: 0.3687 - val_mse: 0.1658
Epoch 5/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0849 - mae: 0.2394 - mse: 0.0849
64/94 [===================>..........] - ETA: 0s - loss: 0.0683 - mae: 0.2156 - mse: 0.0683
94/94 [==============================] - 1s 5ms/step - loss: 0.0643 - mae: 0.2034 - mse: 0.0643 - val_loss: 0.1493 - val_mae: 0.3518 - val_mse: 0.1493
Epoch 6/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0716 - mae: 0.2034 - mse: 0.0716
64/94 [===================>..........] - ETA: 0s - loss: 0.0623 - mae: 0.1940 - mse: 0.0623
94/94 [==============================] - 1s 5ms/step - loss: 0.0564 - mae: 0.1860 - mse: 0.0564 - val_loss: 0.0864 - val_mae: 0.2626 - val_mse: 0.0864
Epoch 7/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0147 - mae: 0.0952 - mse: 0.0147
64/94 [===================>..........] - ETA: 0s - loss: 0.0287 - mae: 0.1315 - mse: 0.0287
94/94 [==============================] - 1s 6ms/step - loss: 0.0343 - mae: 0.1474 - mse: 0.0343 - val_loss: 0.0415 - val_mae: 0.1893 - val_mse: 0.0415
Epoch 8/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0396 - mae: 0.1596 - mse: 0.0396
64/94 [===================>..........] - ETA: 0s - loss: 0.0406 - mae: 0.1610 - mse: 0.0406
94/94 [==============================] - 0s 5ms/step - loss: 0.0387 - mae: 0.1621 - mse: 0.0387 - val_loss: 0.0385 - val_mae: 0.1839 - val_mse: 0.0385
Epoch 9/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0328 - mae: 0.1493 - mse: 0.0328
64/94 [===================>..........] - ETA: 0s - loss: 0.0309 - mae: 0.1482 - mse: 0.0309
94/94 [==============================] - 0s 5ms/step - loss: 0.0379 - mae: 0.1612 - mse: 0.0379 - val_loss: 0.0684 - val_mae: 0.2369 - val_mse: 0.0684
Epoch 10/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0305 - mae: 0.1406 - mse: 0.0305
64/94 [===================>..........] - ETA: 0s - loss: 0.0304 - mae: 0.1426 - mse: 0.0304
94/94 [==============================] - 0s 5ms/step - loss: 0.0304 - mae: 0.1398 - mse: 0.0304 - val_loss: 0.0797 - val_mae: 0.2527 - val_mse: 0.0797
Epoch 11/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0268 - mae: 0.1375 - mse: 0.0268
64/94 [===================>..........] - ETA: 0s - loss: 0.0271 - mae: 0.1339 - mse: 0.0271
94/94 [==============================] - 1s 5ms/step - loss: 0.0273 - mae: 0.1332 - mse: 0.0273 - val_loss: 0.0582 - val_mae: 0.2186 - val_mse: 0.0582
Epoch 12/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0198 - mae: 0.1090 - mse: 0.0198
64/94 [===================>..........] - ETA: 0s - loss: 0.0202 - mae: 0.1107 - mse: 0.0202
94/94 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 0.1110 - mse: 0.0210 - val_loss: 0.0351 - val_mae: 0.1742 - val_mse: 0.0351
Epoch 13/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0144 - mae: 0.0957 - mse: 0.0144
64/94 [===================>..........] - ETA: 0s - loss: 0.0176 - mae: 0.1013 - mse: 0.0176
94/94 [==============================] - 1s 5ms/step - loss: 0.0188 - mae: 0.1096 - mse: 0.0188 - val_loss: 0.0249 - val_mae: 0.1428 - val_mse: 0.0249
Epoch 14/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0152 - mae: 0.1005 - mse: 0.0152
64/94 [===================>..........] - ETA: 0s - loss: 0.0173 - mae: 0.1031 - mse: 0.0173
94/94 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.1047 - mse: 0.0185 - val_loss: 0.0309 - val_mae: 0.1554 - val_mse: 0.0309
Epoch 15/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0124 - mae: 0.0794 - mse: 0.0124
64/94 [===================>..........] - ETA: 0s - loss: 0.0173 - mae: 0.0977 - mse: 0.0173
94/94 [==============================] - 0s 5ms/step - loss: 0.0152 - mae: 0.0948 - mse: 0.0152 - val_loss: 0.0400 - val_mae: 0.1762 - val_mse: 0.0400
Epoch 16/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0130 - mae: 0.0957 - mse: 0.0130
64/94 [===================>..........] - ETA: 0s - loss: 0.0190 - mae: 0.1089 - mse: 0.0190
94/94 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.1028 - mse: 0.0177 - val_loss: 0.0422 - val_mae: 0.1848 - val_mse: 0.0422
Epoch 17/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0180 - mae: 0.0896 - mse: 0.0180
64/94 [===================>..........] - ETA: 0s - loss: 0.0197 - mae: 0.0984 - mse: 0.0197
94/94 [==============================] - 1s 5ms/step - loss: 0.0203 - mae: 0.1016 - mse: 0.0203 - val_loss: 0.0376 - val_mae: 0.1681 - val_mse: 0.0376
Epoch 18/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0206 - mae: 0.1168 - mse: 0.0206
64/94 [===================>..........] - ETA: 0s - loss: 0.0180 - mae: 0.1084 - mse: 0.0180
94/94 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.1062 - mse: 0.0173 - val_loss: 0.0379 - val_mae: 0.1684 - val_mse: 0.0379
Epoch 19/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0173 - mae: 0.1028 - mse: 0.0173
64/94 [===================>..........] - ETA: 0s - loss: 0.0221 - mae: 0.1134 - mse: 0.0221
94/94 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 0.1080 - mse: 0.0189 - val_loss: 0.0416 - val_mae: 0.1853 - val_mse: 0.0416
Epoch 20/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0133 - mae: 0.0886 - mse: 0.0133
64/94 [===================>..........] - ETA: 0s - loss: 0.0113 - mae: 0.0786 - mse: 0.0113
94/94 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0858 - mse: 0.0130 - val_loss: 0.0361 - val_mae: 0.1716 - val_mse: 0.0361
Epoch 21/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0115 - mae: 0.0847 - mse: 0.0115
64/94 [===================>..........] - ETA: 0s - loss: 0.0185 - mae: 0.0956 - mse: 0.0185
94/94 [==============================] - 1s 5ms/step - loss: 0.0169 - mae: 0.0932 - mse: 0.0169 - val_loss: 0.0267 - val_mae: 0.1442 - val_mse: 0.0267
Epoch 22/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0257 - mae: 0.1095 - mse: 0.0257
64/94 [===================>..........] - ETA: 0s - loss: 0.0215 - mae: 0.1023 - mse: 0.0215
94/94 [==============================] - 0s 5ms/step - loss: 0.0208 - mae: 0.0986 - mse: 0.0208 - val_loss: 0.0256 - val_mae: 0.1452 - val_mse: 0.0256
Epoch 23/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0110 - mae: 0.0922 - mse: 0.0110
64/94 [===================>..........] - ETA: 0s - loss: 0.0114 - mae: 0.0906 - mse: 0.0114
94/94 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0947 - mse: 0.0145 - val_loss: 0.0345 - val_mae: 0.1708 - val_mse: 0.0345
Epoch 24/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0103 - mae: 0.0776 - mse: 0.0103
64/94 [===================>..........] - ETA: 0s - loss: 0.0122 - mae: 0.0781 - mse: 0.0122
94/94 [==============================] - 0s 5ms/step - loss: 0.0114 - mae: 0.0768 - mse: 0.0114 - val_loss: 0.0417 - val_mae: 0.1880 - val_mse: 0.0417
Epoch 25/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0139 - mae: 0.0936 - mse: 0.0139
64/94 [===================>..........] - ETA: 0s - loss: 0.0143 - mae: 0.0930 - mse: 0.0143
94/94 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0940 - mse: 0.0137 - val_loss: 0.0342 - val_mae: 0.1698 - val_mse: 0.0342
Epoch 26/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0127 - mae: 0.0865 - mse: 0.0127
64/94 [===================>..........] - ETA: 0s - loss: 0.0128 - mae: 0.0833 - mse: 0.0128
94/94 [==============================] - 1s 5ms/step - loss: 0.0114 - mae: 0.0795 - mse: 0.0114 - val_loss: 0.0315 - val_mae: 0.1638 - val_mse: 0.0315
Epoch 27/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0190 - mae: 0.0935 - mse: 0.0190
64/94 [===================>..........] - ETA: 0s - loss: 0.0148 - mae: 0.0856 - mse: 0.0148
94/94 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0881 - mse: 0.0142 - val_loss: 0.0279 - val_mae: 0.1531 - val_mse: 0.0279
Epoch 28/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0102 - mae: 0.0598 - mse: 0.0102
64/94 [===================>..........] - ETA: 0s - loss: 0.0118 - mae: 0.0772 - mse: 0.0118
94/94 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0774 - mse: 0.0118 - val_loss: 0.0262 - val_mae: 0.1484 - val_mse: 0.0262
Epoch 29/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0092 - mae: 0.0687 - mse: 0.0092
64/94 [===================>..........] - ETA: 0s - loss: 0.0076 - mae: 0.0642 - mse: 0.0076
94/94 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0629 - mse: 0.0075 - val_loss: 0.0239 - val_mae: 0.1418 - val_mse: 0.0239
Epoch 30/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0121 - mae: 0.0833 - mse: 0.0121
64/94 [===================>..........] - ETA: 0s - loss: 0.0133 - mae: 0.0861 - mse: 0.0133
94/94 [==============================] - 1s 5ms/step - loss: 0.0118 - mae: 0.0797 - mse: 0.0118 - val_loss: 0.0298 - val_mae: 0.1593 - val_mse: 0.0298
Saving trained model...
88
Testing...
heightdiff= [0.         0.         0.         4.89412308 0.         0.        ]
average prediction= [4.4293046]
baseline= 9.537037037037036
eachuser= [0. 0. 0. 6. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.8156871795654297
85 -:- nan
60 -:- nan
['train-weight-1.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
2_155_65_1_csi_a1_6.dat
65 8
2_155_65_1_csi_a1_24.dat
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_1_csi_a1_3.dat
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_1_csi_a1_11.dat
65 42
1_165_65_1_csi_a1_2.dat
1_165_65_1_csi_a1_5.dat
65 45
1_165_65_1_csi_a1_4.dat
1_165_65_1_csi_a1_13.dat
65 48
1_165_65_1_csi_a1_12.dat
65 50
65 51
1_165_65_1_csi_a1_14.dat
65 53
1_165_65_1_csi_a1_6.dat
1_165_65_1_csi_a1_1.dat
65 56
1_165_65_1_csi_a1_15.dat
1_165_65_1_csi_a1_17.dat
65 59
65 60
1_165_65_1_csi_a1_3.dat
65 62
1_165_65_1_csi_a1_9.dat
1_165_65_1_csi_a1_16.dat
1_165_65_1_csi_a1_22.dat
65 66
1_165_65_1_csi_a1_10.dat
65 68
1_165_65_1_csi_a1_7.dat
65 70
50 71
50 72
50 73
50 74
50 75
2_165_50_1_csi_a1_29.dat
50 77
2_165_50_1_csi_a1_2.dat
50 79
50 80
2_165_50_1_csi_a1_3.dat
50 82
50 83
50 84
50 85
50 86
50 87
2_165_50_1_csi_a1_28.dat
50 89
50 90
2_165_50_1_csi_a1_7.dat
50 92
50 93
50 94
50 95
50 96
2_165_50_1_csi_a1_25.dat
2_165_50_1_csi_a1_27.dat
2_165_50_1_csi_a1_11.dat
50 100
70 101
70 102
70 103
70 104
1_175_70_1_csi_a1_18.dat
1_175_70_1_csi_a1_12.dat
70 107
70 108
70 109
1_175_70_1_csi_a1_8.dat
70 111
1_175_70_1_csi_a1_3.dat
1_175_70_1_csi_a1_26.dat
70 114
1_175_70_1_csi_a1_10.dat
70 116
70 117
1_175_70_1_csi_a1_6.dat
70 119
1_175_70_1_csi_a1_9.dat
70 121
70 122
70 123
70 124
70 125
1_175_70_1_csi_a1_22.dat
70 127
70 128
1_175_70_1_csi_a1_21.dat
1_175_70_1_csi_a1_14.dat
85 131
1_180_85_1_csi_a1_6.dat
85 133
1_180_85_1_csi_a1_4.dat
85 135
85 136
85 137
1_180_85_1_csi_a1_22.dat
1_180_85_1_csi_a1_20.dat
85 140
85 141
85 142
1_180_85_1_csi_a1_25.dat
1_180_85_1_csi_a1_26.dat
1_180_85_1_csi_a1_12.dat
1_180_85_1_csi_a1_30.dat
85 147
85 148
1_180_85_1_csi_a1_27.dat
85 150
85 151
1_180_85_1_csi_a1_13.dat
1_180_85_1_csi_a1_5.dat
1_180_85_1_csi_a1_7.dat
1_180_85_1_csi_a1_9.dat
85 156
1_180_85_1_csi_a1_3.dat
85 158
85 159
1_180_85_1_csi_a1_2.dat
75 161
75 162
75 163
1_180_75_1_csi_a1_4.dat
75 165
75 166
1_180_75_1_csi_a1_27.dat
75 168
75 169
1_180_75_1_csi_a1_2.dat
1_180_75_1_csi_a1_1.dat
75 172
75 173
75 174
75 175
1_180_75_1_csi_a1_16.dat
75 177
75 178
75 179
75 180
75 181
75 182
75 183
75 184
1_180_75_1_csi_a1_15.dat
75 186
75 187
1_180_75_1_csi_a1_29.dat
75 189
75 190
1_173_85_1_csi_a1_16.dat
1_173_85_1_csi_a1_13.dat
1_173_85_1_csi_a1_22.dat
1_173_85_1_csi_a1_26.dat
1_173_85_1_csi_a1_19.dat
1_173_85_1_csi_a1_18.dat
1_173_85_1_csi_a1_5.dat
1_173_85_1_csi_a1_17.dat
1_173_85_1_csi_a1_7.dat
1_173_85_1_csi_a1_6.dat
1_173_85_1_csi_a1_9.dat
1_173_85_1_csi_a1_23.dat
85 203
85 204
1_173_85_1_csi_a1_30.dat
1_173_85_1_csi_a1_21.dat
1_173_85_1_csi_a1_20.dat
1_173_85_1_csi_a1_25.dat
1_173_85_1_csi_a1_11.dat
1_173_85_1_csi_a1_24.dat
1_173_85_1_csi_a1_28.dat
1_173_85_1_csi_a1_27.dat
1_173_85_1_csi_a1_8.dat
1_173_85_1_csi_a1_4.dat
1_173_85_1_csi_a1_14.dat
1_173_85_1_csi_a1_2.dat
1_173_85_1_csi_a1_29.dat
1_173_85_1_csi_a1_3.dat
1_173_85_1_csi_a1_1.dat
85 220
(132, 30, 3)
(132, 427, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65
 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 85 85 85]
(132, 427, 30, 3, 1)

Loaded dataset of 132 samples, each sized (427, 30, 3, 1)


Train on 105 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 427, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 427, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 427, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 427, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 427, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 427, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 427, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 94 samples, validate on 11 samples
Epoch 1/30

32/94 [=========>....................] - ETA: 0s - loss: 0.3101 - mae: 0.4617 - mse: 0.3101
64/94 [===================>..........] - ETA: 0s - loss: 0.2901 - mae: 0.4620 - mse: 0.2901
94/94 [==============================] - 1s 9ms/step - loss: 0.2689 - mae: 0.4482 - mse: 0.2689 - val_loss: 0.1034 - val_mae: 0.2604 - val_mse: 0.1034
Epoch 2/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1559 - mae: 0.3445 - mse: 0.1559
64/94 [===================>..........] - ETA: 0s - loss: 0.1467 - mae: 0.3226 - mse: 0.1467
94/94 [==============================] - 0s 5ms/step - loss: 0.1192 - mae: 0.2863 - mse: 0.1192 - val_loss: 0.0678 - val_mae: 0.2241 - val_mse: 0.0678
Epoch 3/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0658 - mae: 0.2119 - mse: 0.0658
64/94 [===================>..........] - ETA: 0s - loss: 0.0987 - mae: 0.2579 - mse: 0.0987
94/94 [==============================] - 1s 5ms/step - loss: 0.1127 - mae: 0.2751 - mse: 0.1127 - val_loss: 0.0512 - val_mae: 0.1907 - val_mse: 0.0512
Epoch 4/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0666 - mae: 0.2185 - mse: 0.0666
64/94 [===================>..........] - ETA: 0s - loss: 0.0713 - mae: 0.2218 - mse: 0.0713
94/94 [==============================] - 0s 5ms/step - loss: 0.0654 - mae: 0.2058 - mse: 0.0654 - val_loss: 0.0276 - val_mae: 0.1368 - val_mse: 0.0276
Epoch 5/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0513 - mae: 0.1988 - mse: 0.0513
64/94 [===================>..........] - ETA: 0s - loss: 0.0521 - mae: 0.2002 - mse: 0.0521
94/94 [==============================] - 0s 5ms/step - loss: 0.0484 - mae: 0.1899 - mse: 0.0484 - val_loss: 0.0344 - val_mae: 0.1599 - val_mse: 0.0344
Epoch 6/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0612 - mae: 0.2059 - mse: 0.0612
64/94 [===================>..........] - ETA: 0s - loss: 0.0508 - mae: 0.1852 - mse: 0.0508
94/94 [==============================] - 0s 5ms/step - loss: 0.0499 - mae: 0.1796 - mse: 0.0499 - val_loss: 0.0278 - val_mae: 0.1437 - val_mse: 0.0278
Epoch 7/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0284 - mae: 0.1438 - mse: 0.0284
64/94 [===================>..........] - ETA: 0s - loss: 0.0374 - mae: 0.1548 - mse: 0.0374
94/94 [==============================] - 0s 5ms/step - loss: 0.0333 - mae: 0.1485 - mse: 0.0333 - val_loss: 0.0154 - val_mae: 0.1111 - val_mse: 0.0154
Epoch 8/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0241 - mae: 0.1303 - mse: 0.0241
64/94 [===================>..........] - ETA: 0s - loss: 0.0296 - mae: 0.1423 - mse: 0.0296
94/94 [==============================] - 1s 5ms/step - loss: 0.0311 - mae: 0.1453 - mse: 0.0311 - val_loss: 0.0107 - val_mae: 0.0944 - val_mse: 0.0107
Epoch 9/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0289 - mae: 0.1466 - mse: 0.0289
64/94 [===================>..........] - ETA: 0s - loss: 0.0240 - mae: 0.1314 - mse: 0.0240
94/94 [==============================] - 0s 5ms/step - loss: 0.0291 - mae: 0.1395 - mse: 0.0291 - val_loss: 0.0099 - val_mae: 0.0913 - val_mse: 0.0099
Epoch 10/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0150 - mae: 0.1031 - mse: 0.0150
64/94 [===================>..........] - ETA: 0s - loss: 0.0206 - mae: 0.1137 - mse: 0.0206
94/94 [==============================] - 0s 5ms/step - loss: 0.0231 - mae: 0.1192 - mse: 0.0231 - val_loss: 0.0135 - val_mae: 0.0968 - val_mse: 0.0135
Epoch 11/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0099 - mae: 0.0739 - mse: 0.0099
64/94 [===================>..........] - ETA: 0s - loss: 0.0249 - mae: 0.1129 - mse: 0.0249
94/94 [==============================] - 0s 5ms/step - loss: 0.0245 - mae: 0.1109 - mse: 0.0245 - val_loss: 0.0123 - val_mae: 0.0934 - val_mse: 0.0123
Epoch 12/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0272 - mae: 0.1218 - mse: 0.0272
64/94 [===================>..........] - ETA: 0s - loss: 0.0251 - mae: 0.1156 - mse: 0.0251
94/94 [==============================] - 0s 5ms/step - loss: 0.0253 - mae: 0.1156 - mse: 0.0253 - val_loss: 0.0070 - val_mae: 0.0706 - val_mse: 0.0070
Epoch 13/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0364 - mae: 0.1513 - mse: 0.0364
64/94 [===================>..........] - ETA: 0s - loss: 0.0267 - mae: 0.1257 - mse: 0.0267
94/94 [==============================] - 0s 5ms/step - loss: 0.0232 - mae: 0.1179 - mse: 0.0232 - val_loss: 0.0074 - val_mae: 0.0637 - val_mse: 0.0074
Epoch 14/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0132 - mae: 0.0868 - mse: 0.0132
64/94 [===================>..........] - ETA: 0s - loss: 0.0107 - mae: 0.0817 - mse: 0.0107
94/94 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 0.0971 - mse: 0.0197 - val_loss: 0.0062 - val_mae: 0.0617 - val_mse: 0.0062
Epoch 15/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0170 - mae: 0.1046 - mse: 0.0170
64/94 [===================>..........] - ETA: 0s - loss: 0.0167 - mae: 0.1010 - mse: 0.0167
94/94 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0945 - mse: 0.0157 - val_loss: 0.0054 - val_mae: 0.0659 - val_mse: 0.0054
Epoch 16/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0215 - mae: 0.1009 - mse: 0.0215
64/94 [===================>..........] - ETA: 0s - loss: 0.0162 - mae: 0.0909 - mse: 0.0162
94/94 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0888 - mse: 0.0168 - val_loss: 0.0059 - val_mae: 0.0702 - val_mse: 0.0059
Epoch 17/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0239 - mae: 0.1056 - mse: 0.0239
64/94 [===================>..........] - ETA: 0s - loss: 0.0177 - mae: 0.0890 - mse: 0.0177
94/94 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.0906 - mse: 0.0174 - val_loss: 0.0056 - val_mae: 0.0674 - val_mse: 0.0056
Epoch 18/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0327 - mae: 0.1251 - mse: 0.0327
64/94 [===================>..........] - ETA: 0s - loss: 0.0252 - mae: 0.1138 - mse: 0.0252
94/94 [==============================] - 1s 5ms/step - loss: 0.0225 - mae: 0.1087 - mse: 0.0225 - val_loss: 0.0052 - val_mae: 0.0629 - val_mse: 0.0052
Epoch 19/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0151 - mae: 0.0856 - mse: 0.0151
64/94 [===================>..........] - ETA: 0s - loss: 0.0172 - mae: 0.0922 - mse: 0.0172
94/94 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 0.0895 - mse: 0.0164 - val_loss: 0.0054 - val_mae: 0.0651 - val_mse: 0.0054
Epoch 20/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0070 - mae: 0.0643 - mse: 0.0070
64/94 [===================>..........] - ETA: 0s - loss: 0.0099 - mae: 0.0741 - mse: 0.0099
94/94 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0835 - mse: 0.0135 - val_loss: 0.0049 - val_mae: 0.0630 - val_mse: 0.0049
Epoch 21/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0102 - mae: 0.0756 - mse: 0.0102
64/94 [===================>..........] - ETA: 0s - loss: 0.0231 - mae: 0.0977 - mse: 0.0231
94/94 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 0.0925 - mse: 0.0193 - val_loss: 0.0040 - val_mae: 0.0552 - val_mse: 0.0040
Epoch 22/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0096 - mae: 0.0707 - mse: 0.0096
64/94 [===================>..........] - ETA: 0s - loss: 0.0104 - mae: 0.0725 - mse: 0.0104
94/94 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0727 - mse: 0.0104 - val_loss: 0.0036 - val_mae: 0.0515 - val_mse: 0.0036
Epoch 23/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0118 - mae: 0.0833 - mse: 0.0118
64/94 [===================>..........] - ETA: 0s - loss: 0.0138 - mae: 0.0907 - mse: 0.0138
94/94 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0887 - mse: 0.0133 - val_loss: 0.0034 - val_mae: 0.0499 - val_mse: 0.0034
Epoch 24/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0066 - mae: 0.0692 - mse: 0.0066
64/94 [===================>..........] - ETA: 0s - loss: 0.0153 - mae: 0.0837 - mse: 0.0153
94/94 [==============================] - 0s 5ms/step - loss: 0.0124 - mae: 0.0767 - mse: 0.0124 - val_loss: 0.0037 - val_mae: 0.0513 - val_mse: 0.0037
Epoch 25/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0083 - mae: 0.0714 - mse: 0.0083
64/94 [===================>..........] - ETA: 0s - loss: 0.0109 - mae: 0.0787 - mse: 0.0109
94/94 [==============================] - 1s 5ms/step - loss: 0.0141 - mae: 0.0867 - mse: 0.0141 - val_loss: 0.0039 - val_mae: 0.0510 - val_mse: 0.0039
Epoch 26/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0159 - mae: 0.0849 - mse: 0.0159
64/94 [===================>..........] - ETA: 0s - loss: 0.0164 - mae: 0.0895 - mse: 0.0164
94/94 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0809 - mse: 0.0135 - val_loss: 0.0036 - val_mae: 0.0495 - val_mse: 0.0036
Epoch 27/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0122 - mae: 0.0829 - mse: 0.0122
64/94 [===================>..........] - ETA: 0s - loss: 0.0119 - mae: 0.0808 - mse: 0.0119
94/94 [==============================] - 1s 5ms/step - loss: 0.0108 - mae: 0.0772 - mse: 0.0108 - val_loss: 0.0028 - val_mae: 0.0415 - val_mse: 0.0028
Epoch 28/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0087 - mae: 0.0721 - mse: 0.0087
64/94 [===================>..........] - ETA: 0s - loss: 0.0100 - mae: 0.0732 - mse: 0.0100
94/94 [==============================] - 1s 5ms/step - loss: 0.0110 - mae: 0.0775 - mse: 0.0110 - val_loss: 0.0029 - val_mae: 0.0399 - val_mse: 0.0029
Epoch 29/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0169 - mae: 0.0920 - mse: 0.0169
64/94 [===================>..........] - ETA: 0s - loss: 0.0168 - mae: 0.0875 - mse: 0.0168
94/94 [==============================] - 0s 5ms/step - loss: 0.0140 - mae: 0.0780 - mse: 0.0140 - val_loss: 0.0061 - val_mae: 0.0676 - val_mse: 0.0061
Epoch 30/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0155 - mae: 0.0891 - mse: 0.0155
64/94 [===================>..........] - ETA: 0s - loss: 0.0128 - mae: 0.0809 - mse: 0.0128
94/94 [==============================] - 1s 5ms/step - loss: 0.0101 - mae: 0.0719 - mse: 0.0101 - val_loss: 0.0055 - val_mae: 0.0602 - val_mse: 0.0055
Saving trained model...
88
Testing...
heightdiff= [0.        0.        0.        2.7532196 0.        0.       ]
average prediction= [2.5913851]
baseline= 8.796296296296296
eachuser= [0. 0. 0. 3. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.9177398681640625
85 -:- nan
60 -:- nan
['train-weight-1.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
2_155_65_1_csi_a1_6.dat
65 8
2_155_65_1_csi_a1_24.dat
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_1_csi_a1_3.dat
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_1_csi_a1_11.dat
65 42
1_165_65_1_csi_a1_2.dat
1_165_65_1_csi_a1_5.dat
65 45
1_165_65_1_csi_a1_4.dat
1_165_65_1_csi_a1_13.dat
65 48
1_165_65_1_csi_a1_12.dat
65 50
65 51
1_165_65_1_csi_a1_14.dat
65 53
1_165_65_1_csi_a1_6.dat
1_165_65_1_csi_a1_1.dat
65 56
1_165_65_1_csi_a1_15.dat
1_165_65_1_csi_a1_17.dat
65 59
65 60
1_165_65_1_csi_a1_3.dat
65 62
1_165_65_1_csi_a1_9.dat
1_165_65_1_csi_a1_16.dat
1_165_65_1_csi_a1_22.dat
65 66
1_165_65_1_csi_a1_10.dat
65 68
1_165_65_1_csi_a1_7.dat
65 70
50 71
50 72
50 73
50 74
50 75
2_165_50_1_csi_a1_29.dat
50 77
2_165_50_1_csi_a1_2.dat
50 79
50 80
2_165_50_1_csi_a1_3.dat
50 82
50 83
50 84
50 85
50 86
50 87
2_165_50_1_csi_a1_28.dat
50 89
50 90
2_165_50_1_csi_a1_7.dat
50 92
50 93
50 94
50 95
50 96
2_165_50_1_csi_a1_25.dat
2_165_50_1_csi_a1_27.dat
2_165_50_1_csi_a1_11.dat
50 100
70 101
70 102
70 103
70 104
1_175_70_1_csi_a1_18.dat
1_175_70_1_csi_a1_12.dat
70 107
70 108
70 109
1_175_70_1_csi_a1_8.dat
70 111
1_175_70_1_csi_a1_3.dat
1_175_70_1_csi_a1_26.dat
70 114
1_175_70_1_csi_a1_10.dat
70 116
70 117
1_175_70_1_csi_a1_6.dat
70 119
1_175_70_1_csi_a1_9.dat
70 121
70 122
70 123
70 124
70 125
1_175_70_1_csi_a1_22.dat
70 127
70 128
1_175_70_1_csi_a1_21.dat
1_175_70_1_csi_a1_14.dat
85 131
1_180_85_1_csi_a1_6.dat
85 133
1_180_85_1_csi_a1_4.dat
85 135
85 136
85 137
1_180_85_1_csi_a1_22.dat
1_180_85_1_csi_a1_20.dat
85 140
85 141
85 142
1_180_85_1_csi_a1_25.dat
1_180_85_1_csi_a1_26.dat
1_180_85_1_csi_a1_12.dat
1_180_85_1_csi_a1_30.dat
85 147
85 148
1_180_85_1_csi_a1_27.dat
85 150
85 151
1_180_85_1_csi_a1_13.dat
1_180_85_1_csi_a1_5.dat
1_180_85_1_csi_a1_7.dat
1_180_85_1_csi_a1_9.dat
85 156
1_180_85_1_csi_a1_3.dat
85 158
85 159
1_180_85_1_csi_a1_2.dat
75 161
75 162
75 163
1_180_75_1_csi_a1_4.dat
75 165
75 166
1_180_75_1_csi_a1_27.dat
75 168
75 169
1_180_75_1_csi_a1_2.dat
1_180_75_1_csi_a1_1.dat
75 172
75 173
75 174
75 175
1_180_75_1_csi_a1_16.dat
75 177
75 178
75 179
75 180
75 181
75 182
75 183
75 184
1_180_75_1_csi_a1_15.dat
75 186
75 187
1_180_75_1_csi_a1_29.dat
75 189
75 190
1_173_85_1_csi_a1_16.dat
1_173_85_1_csi_a1_13.dat
1_173_85_1_csi_a1_22.dat
1_173_85_1_csi_a1_26.dat
1_173_85_1_csi_a1_19.dat
1_173_85_1_csi_a1_18.dat
1_173_85_1_csi_a1_5.dat
1_173_85_1_csi_a1_17.dat
1_173_85_1_csi_a1_7.dat
1_173_85_1_csi_a1_6.dat
1_173_85_1_csi_a1_9.dat
1_173_85_1_csi_a1_23.dat
85 203
85 204
1_173_85_1_csi_a1_30.dat
1_173_85_1_csi_a1_21.dat
1_173_85_1_csi_a1_20.dat
1_173_85_1_csi_a1_25.dat
1_173_85_1_csi_a1_11.dat
1_173_85_1_csi_a1_24.dat
1_173_85_1_csi_a1_28.dat
1_173_85_1_csi_a1_27.dat
1_173_85_1_csi_a1_8.dat
1_173_85_1_csi_a1_4.dat
1_173_85_1_csi_a1_14.dat
1_173_85_1_csi_a1_2.dat
1_173_85_1_csi_a1_29.dat
1_173_85_1_csi_a1_3.dat
1_173_85_1_csi_a1_1.dat
85 220
(132, 30, 3)
(132, 427, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65
 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 85 85 85]
(132, 427, 30, 3, 1)

Loaded dataset of 132 samples, each sized (427, 30, 3, 1)


Train on 105 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 427, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 427, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 427, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 427, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 427, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 427, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 427, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 94 samples, validate on 11 samples
Epoch 1/30

32/94 [=========>....................] - ETA: 0s - loss: 0.4526 - mae: 0.5740 - mse: 0.4526
64/94 [===================>..........] - ETA: 0s - loss: 0.3419 - mae: 0.5008 - mse: 0.3419
94/94 [==============================] - 1s 9ms/step - loss: 0.2791 - mae: 0.4424 - mse: 0.2791 - val_loss: 0.0623 - val_mae: 0.1725 - val_mse: 0.0623
Epoch 2/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1064 - mae: 0.2763 - mse: 0.1064
64/94 [===================>..........] - ETA: 0s - loss: 0.0946 - mae: 0.2548 - mse: 0.0946
94/94 [==============================] - 1s 5ms/step - loss: 0.1006 - mae: 0.2657 - mse: 0.1006 - val_loss: 0.1131 - val_mae: 0.3100 - val_mse: 0.1131
Epoch 3/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1407 - mae: 0.3266 - mse: 0.1407
64/94 [===================>..........] - ETA: 0s - loss: 0.1277 - mae: 0.3134 - mse: 0.1277
94/94 [==============================] - 1s 5ms/step - loss: 0.1134 - mae: 0.2970 - mse: 0.1134 - val_loss: 0.0557 - val_mae: 0.1900 - val_mse: 0.0557
Epoch 4/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0434 - mae: 0.1645 - mse: 0.0434
64/94 [===================>..........] - ETA: 0s - loss: 0.0601 - mae: 0.1930 - mse: 0.0601
94/94 [==============================] - 1s 5ms/step - loss: 0.0642 - mae: 0.1987 - mse: 0.0642 - val_loss: 0.0469 - val_mae: 0.1633 - val_mse: 0.0469
Epoch 5/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0437 - mae: 0.1660 - mse: 0.0437
64/94 [===================>..........] - ETA: 0s - loss: 0.0541 - mae: 0.1855 - mse: 0.0541
94/94 [==============================] - 1s 5ms/step - loss: 0.0696 - mae: 0.2095 - mse: 0.0696 - val_loss: 0.0477 - val_mae: 0.1612 - val_mse: 0.0477
Epoch 6/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0694 - mae: 0.2093 - mse: 0.0694
64/94 [===================>..........] - ETA: 0s - loss: 0.0629 - mae: 0.1987 - mse: 0.0629
94/94 [==============================] - 0s 5ms/step - loss: 0.0679 - mae: 0.2050 - mse: 0.0679 - val_loss: 0.0374 - val_mae: 0.1491 - val_mse: 0.0374
Epoch 7/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0480 - mae: 0.1737 - mse: 0.0480
64/94 [===================>..........] - ETA: 0s - loss: 0.0493 - mae: 0.1736 - mse: 0.0493
94/94 [==============================] - 1s 5ms/step - loss: 0.0512 - mae: 0.1801 - mse: 0.0512 - val_loss: 0.0338 - val_mae: 0.1631 - val_mse: 0.0338
Epoch 8/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0385 - mae: 0.1443 - mse: 0.0385
64/94 [===================>..........] - ETA: 0s - loss: 0.0425 - mae: 0.1605 - mse: 0.0425
94/94 [==============================] - 0s 5ms/step - loss: 0.0444 - mae: 0.1619 - mse: 0.0444 - val_loss: 0.0316 - val_mae: 0.1598 - val_mse: 0.0316
Epoch 9/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0320 - mae: 0.1470 - mse: 0.0320
64/94 [===================>..........] - ETA: 0s - loss: 0.0329 - mae: 0.1532 - mse: 0.0329
94/94 [==============================] - 1s 5ms/step - loss: 0.0374 - mae: 0.1620 - mse: 0.0374 - val_loss: 0.0250 - val_mae: 0.1431 - val_mse: 0.0250
Epoch 10/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0322 - mae: 0.1529 - mse: 0.0322
64/94 [===================>..........] - ETA: 0s - loss: 0.0301 - mae: 0.1462 - mse: 0.0301
94/94 [==============================] - 0s 5ms/step - loss: 0.0363 - mae: 0.1575 - mse: 0.0363 - val_loss: 0.0206 - val_mae: 0.1191 - val_mse: 0.0206
Epoch 11/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0250 - mae: 0.1270 - mse: 0.0250
64/94 [===================>..........] - ETA: 0s - loss: 0.0384 - mae: 0.1570 - mse: 0.0384
94/94 [==============================] - 0s 5ms/step - loss: 0.0364 - mae: 0.1475 - mse: 0.0364 - val_loss: 0.0199 - val_mae: 0.1018 - val_mse: 0.0199
Epoch 12/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0279 - mae: 0.1459 - mse: 0.0279
64/94 [===================>..........] - ETA: 0s - loss: 0.0425 - mae: 0.1562 - mse: 0.0425
94/94 [==============================] - 1s 5ms/step - loss: 0.0399 - mae: 0.1512 - mse: 0.0399 - val_loss: 0.0145 - val_mae: 0.0929 - val_mse: 0.0145
Epoch 13/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0290 - mae: 0.1346 - mse: 0.0290
64/94 [===================>..........] - ETA: 0s - loss: 0.0306 - mae: 0.1400 - mse: 0.0306
94/94 [==============================] - 0s 5ms/step - loss: 0.0293 - mae: 0.1364 - mse: 0.0293 - val_loss: 0.0103 - val_mae: 0.0907 - val_mse: 0.0103
Epoch 14/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0335 - mae: 0.1352 - mse: 0.0335
64/94 [===================>..........] - ETA: 0s - loss: 0.0276 - mae: 0.1268 - mse: 0.0276
94/94 [==============================] - 0s 5ms/step - loss: 0.0285 - mae: 0.1303 - mse: 0.0285 - val_loss: 0.0091 - val_mae: 0.0863 - val_mse: 0.0091
Epoch 15/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0307 - mae: 0.1416 - mse: 0.0307
64/94 [===================>..........] - ETA: 0s - loss: 0.0328 - mae: 0.1426 - mse: 0.0328
94/94 [==============================] - 0s 5ms/step - loss: 0.0308 - mae: 0.1346 - mse: 0.0308 - val_loss: 0.0067 - val_mae: 0.0743 - val_mse: 0.0067
Epoch 16/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0168 - mae: 0.1012 - mse: 0.0168
64/94 [===================>..........] - ETA: 0s - loss: 0.0226 - mae: 0.1184 - mse: 0.0226
94/94 [==============================] - 0s 5ms/step - loss: 0.0235 - mae: 0.1206 - mse: 0.0235 - val_loss: 0.0082 - val_mae: 0.0641 - val_mse: 0.0082
Epoch 17/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0171 - mae: 0.1004 - mse: 0.0171
64/94 [===================>..........] - ETA: 0s - loss: 0.0225 - mae: 0.1154 - mse: 0.0225
94/94 [==============================] - 1s 5ms/step - loss: 0.0227 - mae: 0.1163 - mse: 0.0227 - val_loss: 0.0070 - val_mae: 0.0608 - val_mse: 0.0070
Epoch 18/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0114 - mae: 0.0798 - mse: 0.0114
64/94 [===================>..........] - ETA: 0s - loss: 0.0166 - mae: 0.0974 - mse: 0.0166
94/94 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 0.0974 - mse: 0.0164 - val_loss: 0.0054 - val_mae: 0.0574 - val_mse: 0.0054
Epoch 19/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0211 - mae: 0.1039 - mse: 0.0211
64/94 [===================>..........] - ETA: 0s - loss: 0.0177 - mae: 0.0958 - mse: 0.0177
94/94 [==============================] - 0s 5ms/step - loss: 0.0245 - mae: 0.1073 - mse: 0.0245 - val_loss: 0.0045 - val_mae: 0.0526 - val_mse: 0.0045
Epoch 20/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0242 - mae: 0.1212 - mse: 0.0242
64/94 [===================>..........] - ETA: 0s - loss: 0.0224 - mae: 0.1172 - mse: 0.0224
94/94 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 0.1107 - mse: 0.0201 - val_loss: 0.0054 - val_mae: 0.0531 - val_mse: 0.0054
Epoch 21/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0181 - mae: 0.0963 - mse: 0.0181
64/94 [===================>..........] - ETA: 0s - loss: 0.0199 - mae: 0.0948 - mse: 0.0199
94/94 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0858 - mse: 0.0157 - val_loss: 0.0062 - val_mae: 0.0602 - val_mse: 0.0062
Epoch 22/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0189 - mae: 0.1036 - mse: 0.0189
64/94 [===================>..........] - ETA: 0s - loss: 0.0203 - mae: 0.1050 - mse: 0.0203
94/94 [==============================] - 1s 5ms/step - loss: 0.0176 - mae: 0.0979 - mse: 0.0176 - val_loss: 0.0054 - val_mae: 0.0594 - val_mse: 0.0054
Epoch 23/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0089 - mae: 0.0706 - mse: 0.0089
64/94 [===================>..........] - ETA: 0s - loss: 0.0094 - mae: 0.0743 - mse: 0.0094
94/94 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0813 - mse: 0.0132 - val_loss: 0.0031 - val_mae: 0.0455 - val_mse: 0.0031
Epoch 24/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0124 - mae: 0.0809 - mse: 0.0124
64/94 [===================>..........] - ETA: 0s - loss: 0.0110 - mae: 0.0755 - mse: 0.0110
94/94 [==============================] - 1s 5ms/step - loss: 0.0114 - mae: 0.0799 - mse: 0.0114 - val_loss: 0.0030 - val_mae: 0.0462 - val_mse: 0.0030
Epoch 25/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0186 - mae: 0.0979 - mse: 0.0186
64/94 [===================>..........] - ETA: 0s - loss: 0.0119 - mae: 0.0773 - mse: 0.0119
94/94 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0748 - mse: 0.0112 - val_loss: 0.0105 - val_mae: 0.0875 - val_mse: 0.0105
Epoch 26/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0111 - mae: 0.0773 - mse: 0.0111
64/94 [===================>..........] - ETA: 0s - loss: 0.0206 - mae: 0.1042 - mse: 0.0206
94/94 [==============================] - 1s 5ms/step - loss: 0.0160 - mae: 0.0891 - mse: 0.0160 - val_loss: 0.0093 - val_mae: 0.0791 - val_mse: 0.0093
Epoch 27/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0108 - mae: 0.0803 - mse: 0.0108
64/94 [===================>..........] - ETA: 0s - loss: 0.0095 - mae: 0.0741 - mse: 0.0095
94/94 [==============================] - 1s 6ms/step - loss: 0.0097 - mae: 0.0762 - mse: 0.0097 - val_loss: 0.0042 - val_mae: 0.0501 - val_mse: 0.0042
Epoch 28/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0190 - mae: 0.1090 - mse: 0.0190
64/94 [===================>..........] - ETA: 0s - loss: 0.0145 - mae: 0.0925 - mse: 0.0145
94/94 [==============================] - 0s 5ms/step - loss: 0.0151 - mae: 0.0954 - mse: 0.0151 - val_loss: 0.0092 - val_mae: 0.0800 - val_mse: 0.0092
Epoch 29/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0191 - mae: 0.0959 - mse: 0.0191
64/94 [===================>..........] - ETA: 0s - loss: 0.0192 - mae: 0.0984 - mse: 0.0192
94/94 [==============================] - 0s 5ms/step - loss: 0.0159 - mae: 0.0905 - mse: 0.0159 - val_loss: 0.0108 - val_mae: 0.0921 - val_mse: 0.0108
Epoch 30/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0117 - mae: 0.0869 - mse: 0.0117
64/94 [===================>..........] - ETA: 0s - loss: 0.0142 - mae: 0.0886 - mse: 0.0142
94/94 [==============================] - 0s 5ms/step - loss: 0.0117 - mae: 0.0805 - mse: 0.0117 - val_loss: 0.0075 - val_mae: 0.0762 - val_mse: 0.0075
Saving trained model...
88
Testing...
heightdiff= [0.         0.         0.         8.75426865 0.         0.        ]
average prediction= [3.0733507]
baseline= 8.055555555555555
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.7508537292480468
85 -:- nan
60 -:- nan
['train-weight-1.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
2_155_65_1_csi_a1_6.dat
65 8
2_155_65_1_csi_a1_24.dat
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_1_csi_a1_3.dat
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_1_csi_a1_11.dat
65 42
1_165_65_1_csi_a1_2.dat
1_165_65_1_csi_a1_5.dat
65 45
1_165_65_1_csi_a1_4.dat
1_165_65_1_csi_a1_13.dat
65 48
1_165_65_1_csi_a1_12.dat
65 50
65 51
1_165_65_1_csi_a1_14.dat
65 53
1_165_65_1_csi_a1_6.dat
1_165_65_1_csi_a1_1.dat
65 56
1_165_65_1_csi_a1_15.dat
1_165_65_1_csi_a1_17.dat
65 59
65 60
1_165_65_1_csi_a1_3.dat
65 62
1_165_65_1_csi_a1_9.dat
1_165_65_1_csi_a1_16.dat
1_165_65_1_csi_a1_22.dat
65 66
1_165_65_1_csi_a1_10.dat
65 68
1_165_65_1_csi_a1_7.dat
65 70
50 71
50 72
50 73
50 74
50 75
2_165_50_1_csi_a1_29.dat
50 77
2_165_50_1_csi_a1_2.dat
50 79
50 80
2_165_50_1_csi_a1_3.dat
50 82
50 83
50 84
50 85
50 86
50 87
2_165_50_1_csi_a1_28.dat
50 89
50 90
2_165_50_1_csi_a1_7.dat
50 92
50 93
50 94
50 95
50 96
2_165_50_1_csi_a1_25.dat
2_165_50_1_csi_a1_27.dat
2_165_50_1_csi_a1_11.dat
50 100
70 101
70 102
70 103
70 104
1_175_70_1_csi_a1_18.dat
1_175_70_1_csi_a1_12.dat
70 107
70 108
70 109
1_175_70_1_csi_a1_8.dat
70 111
1_175_70_1_csi_a1_3.dat
1_175_70_1_csi_a1_26.dat
70 114
1_175_70_1_csi_a1_10.dat
70 116
70 117
1_175_70_1_csi_a1_6.dat
70 119
1_175_70_1_csi_a1_9.dat
70 121
70 122
70 123
70 124
70 125
1_175_70_1_csi_a1_22.dat
70 127
70 128
1_175_70_1_csi_a1_21.dat
1_175_70_1_csi_a1_14.dat
85 131
1_180_85_1_csi_a1_6.dat
85 133
1_180_85_1_csi_a1_4.dat
85 135
85 136
85 137
1_180_85_1_csi_a1_22.dat
1_180_85_1_csi_a1_20.dat
85 140
85 141
85 142
1_180_85_1_csi_a1_25.dat
1_180_85_1_csi_a1_26.dat
1_180_85_1_csi_a1_12.dat
1_180_85_1_csi_a1_30.dat
85 147
85 148
1_180_85_1_csi_a1_27.dat
85 150
85 151
1_180_85_1_csi_a1_13.dat
1_180_85_1_csi_a1_5.dat
1_180_85_1_csi_a1_7.dat
1_180_85_1_csi_a1_9.dat
85 156
1_180_85_1_csi_a1_3.dat
85 158
85 159
1_180_85_1_csi_a1_2.dat
75 161
75 162
75 163
1_180_75_1_csi_a1_4.dat
75 165
75 166
1_180_75_1_csi_a1_27.dat
75 168
75 169
1_180_75_1_csi_a1_2.dat
1_180_75_1_csi_a1_1.dat
75 172
75 173
75 174
75 175
1_180_75_1_csi_a1_16.dat
75 177
75 178
75 179
75 180
75 181
75 182
75 183
75 184
1_180_75_1_csi_a1_15.dat
75 186
75 187
1_180_75_1_csi_a1_29.dat
75 189
75 190
1_173_85_1_csi_a1_16.dat
1_173_85_1_csi_a1_13.dat
1_173_85_1_csi_a1_22.dat
1_173_85_1_csi_a1_26.dat
1_173_85_1_csi_a1_19.dat
1_173_85_1_csi_a1_18.dat
1_173_85_1_csi_a1_5.dat
1_173_85_1_csi_a1_17.dat
1_173_85_1_csi_a1_7.dat
1_173_85_1_csi_a1_6.dat
1_173_85_1_csi_a1_9.dat
1_173_85_1_csi_a1_23.dat
85 203
85 204
1_173_85_1_csi_a1_30.dat
1_173_85_1_csi_a1_21.dat
1_173_85_1_csi_a1_20.dat
1_173_85_1_csi_a1_25.dat
1_173_85_1_csi_a1_11.dat
1_173_85_1_csi_a1_24.dat
1_173_85_1_csi_a1_28.dat
1_173_85_1_csi_a1_27.dat
1_173_85_1_csi_a1_8.dat
1_173_85_1_csi_a1_4.dat
1_173_85_1_csi_a1_14.dat
1_173_85_1_csi_a1_2.dat
1_173_85_1_csi_a1_29.dat
1_173_85_1_csi_a1_3.dat
1_173_85_1_csi_a1_1.dat
85 220
(132, 30, 3)
(132, 427, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65
 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 85 85 85]
(132, 427, 30, 3, 1)

Loaded dataset of 132 samples, each sized (427, 30, 3, 1)


Train on 105 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 427, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 427, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 427, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 427, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 427, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 427, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 427, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 94 samples, validate on 11 samples
Epoch 1/30

32/94 [=========>....................] - ETA: 0s - loss: 0.4101 - mae: 0.5519 - mse: 0.4101
64/94 [===================>..........] - ETA: 0s - loss: 0.2917 - mae: 0.4545 - mse: 0.2917
94/94 [==============================] - 1s 9ms/step - loss: 0.2564 - mae: 0.4288 - mse: 0.2564 - val_loss: 0.1057 - val_mae: 0.2218 - val_mse: 0.1057
Epoch 2/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0477 - mae: 0.1724 - mse: 0.0477
64/94 [===================>..........] - ETA: 0s - loss: 0.0942 - mae: 0.2499 - mse: 0.0942
94/94 [==============================] - 1s 5ms/step - loss: 0.1034 - mae: 0.2647 - mse: 0.1034 - val_loss: 0.1260 - val_mae: 0.3340 - val_mse: 0.1260
Epoch 3/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1630 - mae: 0.3304 - mse: 0.1630
64/94 [===================>..........] - ETA: 0s - loss: 0.1282 - mae: 0.2913 - mse: 0.1282
94/94 [==============================] - 1s 5ms/step - loss: 0.1110 - mae: 0.2665 - mse: 0.1110 - val_loss: 0.0900 - val_mae: 0.2439 - val_mse: 0.0900
Epoch 4/30

32/94 [=========>....................] - ETA: 0s - loss: 0.1033 - mae: 0.2663 - mse: 0.1033
64/94 [===================>..........] - ETA: 0s - loss: 0.0833 - mae: 0.2341 - mse: 0.0833
94/94 [==============================] - 0s 5ms/step - loss: 0.0727 - mae: 0.2198 - mse: 0.0727 - val_loss: 0.0914 - val_mae: 0.2022 - val_mse: 0.0914
Epoch 5/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0711 - mae: 0.2111 - mse: 0.0711
64/94 [===================>..........] - ETA: 0s - loss: 0.0738 - mae: 0.2104 - mse: 0.0738
94/94 [==============================] - 1s 5ms/step - loss: 0.0731 - mae: 0.2183 - mse: 0.0731 - val_loss: 0.0938 - val_mae: 0.2120 - val_mse: 0.0938
Epoch 6/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0639 - mae: 0.2145 - mse: 0.0639
64/94 [===================>..........] - ETA: 0s - loss: 0.0581 - mae: 0.1991 - mse: 0.0581
94/94 [==============================] - 0s 5ms/step - loss: 0.0576 - mae: 0.1944 - mse: 0.0576 - val_loss: 0.0796 - val_mae: 0.1936 - val_mse: 0.0796
Epoch 7/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0528 - mae: 0.1900 - mse: 0.0528
64/94 [===================>..........] - ETA: 0s - loss: 0.0528 - mae: 0.1852 - mse: 0.0528
94/94 [==============================] - 0s 5ms/step - loss: 0.0575 - mae: 0.1932 - mse: 0.0575 - val_loss: 0.0631 - val_mae: 0.2003 - val_mse: 0.0631
Epoch 8/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0414 - mae: 0.1569 - mse: 0.0414
64/94 [===================>..........] - ETA: 0s - loss: 0.0444 - mae: 0.1672 - mse: 0.0444
94/94 [==============================] - 0s 5ms/step - loss: 0.0514 - mae: 0.1815 - mse: 0.0514 - val_loss: 0.0546 - val_mae: 0.1902 - val_mse: 0.0546
Epoch 9/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0586 - mae: 0.1857 - mse: 0.0586
64/94 [===================>..........] - ETA: 0s - loss: 0.0434 - mae: 0.1615 - mse: 0.0434
94/94 [==============================] - 0s 5ms/step - loss: 0.0451 - mae: 0.1672 - mse: 0.0451 - val_loss: 0.0585 - val_mae: 0.1665 - val_mse: 0.0585
Epoch 10/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0502 - mae: 0.1807 - mse: 0.0502
64/94 [===================>..........] - ETA: 0s - loss: 0.0427 - mae: 0.1639 - mse: 0.0427
94/94 [==============================] - 0s 5ms/step - loss: 0.0382 - mae: 0.1602 - mse: 0.0382 - val_loss: 0.0629 - val_mae: 0.1679 - val_mse: 0.0629
Epoch 11/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0145 - mae: 0.0983 - mse: 0.0145
64/94 [===================>..........] - ETA: 0s - loss: 0.0235 - mae: 0.1182 - mse: 0.0235
94/94 [==============================] - 0s 5ms/step - loss: 0.0269 - mae: 0.1252 - mse: 0.0269 - val_loss: 0.0589 - val_mae: 0.1624 - val_mse: 0.0589
Epoch 12/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0311 - mae: 0.1331 - mse: 0.0311
64/94 [===================>..........] - ETA: 0s - loss: 0.0246 - mae: 0.1223 - mse: 0.0246
94/94 [==============================] - 1s 5ms/step - loss: 0.0260 - mae: 0.1239 - mse: 0.0260 - val_loss: 0.0448 - val_mae: 0.1338 - val_mse: 0.0448
Epoch 13/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0236 - mae: 0.1257 - mse: 0.0236
64/94 [===================>..........] - ETA: 0s - loss: 0.0177 - mae: 0.1084 - mse: 0.0177
94/94 [==============================] - 0s 5ms/step - loss: 0.0218 - mae: 0.1094 - mse: 0.0218 - val_loss: 0.0375 - val_mae: 0.1135 - val_mse: 0.0375
Epoch 14/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0287 - mae: 0.1391 - mse: 0.0287
64/94 [===================>..........] - ETA: 0s - loss: 0.0278 - mae: 0.1310 - mse: 0.0278
94/94 [==============================] - 1s 5ms/step - loss: 0.0315 - mae: 0.1323 - mse: 0.0315 - val_loss: 0.0403 - val_mae: 0.1157 - val_mse: 0.0403
Epoch 15/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0244 - mae: 0.1130 - mse: 0.0244
64/94 [===================>..........] - ETA: 0s - loss: 0.0170 - mae: 0.0956 - mse: 0.0170
94/94 [==============================] - 1s 5ms/step - loss: 0.0156 - mae: 0.0931 - mse: 0.0156 - val_loss: 0.0462 - val_mae: 0.1393 - val_mse: 0.0462
Epoch 16/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0446 - mae: 0.1456 - mse: 0.0446
64/94 [===================>..........] - ETA: 0s - loss: 0.0312 - mae: 0.1188 - mse: 0.0312
94/94 [==============================] - 1s 5ms/step - loss: 0.0253 - mae: 0.1071 - mse: 0.0253 - val_loss: 0.0477 - val_mae: 0.1503 - val_mse: 0.0477
Epoch 17/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0100 - mae: 0.0750 - mse: 0.0100
64/94 [===================>..........] - ETA: 0s - loss: 0.0114 - mae: 0.0849 - mse: 0.0114
94/94 [==============================] - 1s 5ms/step - loss: 0.0167 - mae: 0.0909 - mse: 0.0167 - val_loss: 0.0457 - val_mae: 0.1505 - val_mse: 0.0457
Epoch 18/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0229 - mae: 0.0958 - mse: 0.0229
64/94 [===================>..........] - ETA: 0s - loss: 0.0180 - mae: 0.0932 - mse: 0.0180
94/94 [==============================] - 0s 5ms/step - loss: 0.0203 - mae: 0.0968 - mse: 0.0203 - val_loss: 0.0419 - val_mae: 0.1402 - val_mse: 0.0419
Epoch 19/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0124 - mae: 0.0807 - mse: 0.0124
64/94 [===================>..........] - ETA: 0s - loss: 0.0107 - mae: 0.0802 - mse: 0.0107
94/94 [==============================] - 1s 5ms/step - loss: 0.0175 - mae: 0.0963 - mse: 0.0175 - val_loss: 0.0376 - val_mae: 0.1289 - val_mse: 0.0376
Epoch 20/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0136 - mae: 0.0961 - mse: 0.0136
64/94 [===================>..........] - ETA: 0s - loss: 0.0171 - mae: 0.0977 - mse: 0.0171
94/94 [==============================] - 1s 5ms/step - loss: 0.0179 - mae: 0.0943 - mse: 0.0179 - val_loss: 0.0376 - val_mae: 0.1330 - val_mse: 0.0376
Epoch 21/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0185 - mae: 0.0899 - mse: 0.0185
64/94 [===================>..........] - ETA: 0s - loss: 0.0207 - mae: 0.1004 - mse: 0.0207
94/94 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 0.0971 - mse: 0.0193 - val_loss: 0.0372 - val_mae: 0.1333 - val_mse: 0.0372
Epoch 22/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0119 - mae: 0.0759 - mse: 0.0119
64/94 [===================>..........] - ETA: 0s - loss: 0.0155 - mae: 0.0855 - mse: 0.0155
94/94 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0849 - mse: 0.0142 - val_loss: 0.0421 - val_mae: 0.1490 - val_mse: 0.0421
Epoch 23/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0200 - mae: 0.1018 - mse: 0.0200
64/94 [===================>..........] - ETA: 0s - loss: 0.0224 - mae: 0.0963 - mse: 0.0224
94/94 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 0.0966 - mse: 0.0210 - val_loss: 0.0429 - val_mae: 0.1523 - val_mse: 0.0429
Epoch 24/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0134 - mae: 0.0690 - mse: 0.0134
64/94 [===================>..........] - ETA: 0s - loss: 0.0103 - mae: 0.0685 - mse: 0.0103
94/94 [==============================] - 1s 5ms/step - loss: 0.0142 - mae: 0.0783 - mse: 0.0142 - val_loss: 0.0374 - val_mae: 0.1378 - val_mse: 0.0374
Epoch 25/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0154 - mae: 0.0980 - mse: 0.0154
64/94 [===================>..........] - ETA: 0s - loss: 0.0174 - mae: 0.0961 - mse: 0.0174
94/94 [==============================] - 0s 5ms/step - loss: 0.0167 - mae: 0.0928 - mse: 0.0167 - val_loss: 0.0410 - val_mae: 0.1469 - val_mse: 0.0410
Epoch 26/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0124 - mae: 0.0776 - mse: 0.0124
64/94 [===================>..........] - ETA: 0s - loss: 0.0190 - mae: 0.0941 - mse: 0.0190
94/94 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0884 - mse: 0.0153 - val_loss: 0.0422 - val_mae: 0.1497 - val_mse: 0.0422
Epoch 27/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0198 - mae: 0.1010 - mse: 0.0198
64/94 [===================>..........] - ETA: 0s - loss: 0.0182 - mae: 0.0953 - mse: 0.0182
94/94 [==============================] - 1s 5ms/step - loss: 0.0155 - mae: 0.0877 - mse: 0.0155 - val_loss: 0.0353 - val_mae: 0.1323 - val_mse: 0.0353
Epoch 28/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0051 - mae: 0.0539 - mse: 0.0051
64/94 [===================>..........] - ETA: 0s - loss: 0.0069 - mae: 0.0639 - mse: 0.0069
94/94 [==============================] - 0s 5ms/step - loss: 0.0124 - mae: 0.0761 - mse: 0.0124 - val_loss: 0.0358 - val_mae: 0.1340 - val_mse: 0.0358
Epoch 29/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0212 - mae: 0.1035 - mse: 0.0212
64/94 [===================>..........] - ETA: 0s - loss: 0.0156 - mae: 0.0852 - mse: 0.0156
94/94 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0780 - mse: 0.0137 - val_loss: 0.0418 - val_mae: 0.1515 - val_mse: 0.0418
Epoch 30/30

32/94 [=========>....................] - ETA: 0s - loss: 0.0110 - mae: 0.0798 - mse: 0.0110
64/94 [===================>..........] - ETA: 0s - loss: 0.0092 - mae: 0.0705 - mse: 0.0092
94/94 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0786 - mse: 0.0133 - val_loss: 0.0389 - val_mae: 0.1456 - val_mse: 0.0389
Saving trained model...
88
Testing...
heightdiff= [0.         0.         0.         6.10089874 0.         0.        ]
average prediction= [4.4000115]
baseline= 8.425925925925926
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.5252246856689453
85 -:- nan
60 -:- nan
