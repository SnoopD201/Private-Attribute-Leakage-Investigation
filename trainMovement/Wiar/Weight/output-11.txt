['train-weight-11.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
60 34
60 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
60 38
60 39
60 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
50 71
2_165_50_11_csi_a11_29.dat
50 73
50 74
50 75
50 76
50 77
50 78
2_165_50_11_csi_a11_19.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
2_165_50_11_csi_a11_6.dat
50 96
2_165_50_11_csi_a11_28.dat
50 98
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
1_175_70_11_csi_a11_29.dat
70 120
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
85 135
85 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
85 141
1_180_85_11_csi_a11_28.dat
85 143
85 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
85 150
85 151
85 152
85 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
75 161
75 162
75 163
75 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
75 167
1_180_75_11_csi_a11_21.dat
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
75 182
1_180_75_11_csi_a11_16.dat
75 184
75 185
75 186
75 187
75 188
75 189
75 190
1_173_85_11_csi_a11_22.dat
85 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
85 197
85 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
85 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
85 204
1_173_85_11_csi_a11_2.dat
85 206
1_173_85_11_csi_a11_24.dat
85 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
85 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85
 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 85 85 85 85 85 85 85 85]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.3253 - mae: 0.4892 - mse: 0.3253
64/93 [===================>..........] - ETA: 0s - loss: 0.3046 - mae: 0.4744 - mse: 0.3046
93/93 [==============================] - 1s 9ms/step - loss: 0.2948 - mae: 0.4717 - mse: 0.2948 - val_loss: 0.1563 - val_mae: 0.3470 - val_mse: 0.1563
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.2742 - mae: 0.4701 - mse: 0.2742
64/93 [===================>..........] - ETA: 0s - loss: 0.2151 - mae: 0.4112 - mse: 0.2151
93/93 [==============================] - 1s 6ms/step - loss: 0.1941 - mae: 0.3804 - mse: 0.1941 - val_loss: 0.0739 - val_mae: 0.1708 - val_mse: 0.0739
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1670 - mae: 0.3384 - mse: 0.1670
64/93 [===================>..........] - ETA: 0s - loss: 0.1626 - mae: 0.3272 - mse: 0.1626
93/93 [==============================] - 1s 6ms/step - loss: 0.1636 - mae: 0.3277 - mse: 0.1636 - val_loss: 0.0658 - val_mae: 0.1864 - val_mse: 0.0658
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1157 - mae: 0.2902 - mse: 0.1157
64/93 [===================>..........] - ETA: 0s - loss: 0.1132 - mae: 0.2853 - mse: 0.1132
93/93 [==============================] - 1s 6ms/step - loss: 0.1056 - mae: 0.2746 - mse: 0.1056 - val_loss: 0.0484 - val_mae: 0.1600 - val_mse: 0.0484
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1051 - mae: 0.2729 - mse: 0.1051
64/93 [===================>..........] - ETA: 0s - loss: 0.0981 - mae: 0.2656 - mse: 0.0981
93/93 [==============================] - 1s 6ms/step - loss: 0.0869 - mae: 0.2501 - mse: 0.0869 - val_loss: 0.0411 - val_mae: 0.1439 - val_mse: 0.0411
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0685 - mae: 0.2134 - mse: 0.0685
64/93 [===================>..........] - ETA: 0s - loss: 0.0697 - mae: 0.2164 - mse: 0.0697
93/93 [==============================] - 1s 7ms/step - loss: 0.0707 - mae: 0.2189 - mse: 0.0707 - val_loss: 0.0333 - val_mae: 0.1444 - val_mse: 0.0333
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0461 - mae: 0.1747 - mse: 0.0461
64/93 [===================>..........] - ETA: 0s - loss: 0.0489 - mae: 0.1888 - mse: 0.0489
93/93 [==============================] - 1s 6ms/step - loss: 0.0484 - mae: 0.1848 - mse: 0.0484 - val_loss: 0.0302 - val_mae: 0.1579 - val_mse: 0.0302
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0329 - mae: 0.1520 - mse: 0.0329
64/93 [===================>..........] - ETA: 0s - loss: 0.0454 - mae: 0.1743 - mse: 0.0454
93/93 [==============================] - 1s 6ms/step - loss: 0.0437 - mae: 0.1704 - mse: 0.0437 - val_loss: 0.0277 - val_mae: 0.1515 - val_mse: 0.0277
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0344 - mae: 0.1520 - mse: 0.0344
64/93 [===================>..........] - ETA: 0s - loss: 0.0383 - mae: 0.1574 - mse: 0.0383
93/93 [==============================] - 0s 5ms/step - loss: 0.0376 - mae: 0.1542 - mse: 0.0376 - val_loss: 0.0215 - val_mae: 0.1202 - val_mse: 0.0215
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0248 - mae: 0.1242 - mse: 0.0248
64/93 [===================>..........] - ETA: 0s - loss: 0.0270 - mae: 0.1257 - mse: 0.0270
93/93 [==============================] - 0s 5ms/step - loss: 0.0362 - mae: 0.1392 - mse: 0.0362 - val_loss: 0.0241 - val_mae: 0.1232 - val_mse: 0.0241
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0337 - mae: 0.1309 - mse: 0.0337
64/93 [===================>..........] - ETA: 0s - loss: 0.0297 - mae: 0.1235 - mse: 0.0297
93/93 [==============================] - 1s 6ms/step - loss: 0.0304 - mae: 0.1273 - mse: 0.0304 - val_loss: 0.0156 - val_mae: 0.1030 - val_mse: 0.0156
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0229 - mae: 0.1206 - mse: 0.0229
64/93 [===================>..........] - ETA: 0s - loss: 0.0277 - mae: 0.1270 - mse: 0.0277
93/93 [==============================] - 0s 5ms/step - loss: 0.0318 - mae: 0.1360 - mse: 0.0318 - val_loss: 0.0143 - val_mae: 0.0930 - val_mse: 0.0143
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0241 - mae: 0.1154 - mse: 0.0241
64/93 [===================>..........] - ETA: 0s - loss: 0.0259 - mae: 0.1173 - mse: 0.0259
93/93 [==============================] - 1s 6ms/step - loss: 0.0248 - mae: 0.1137 - mse: 0.0248 - val_loss: 0.0151 - val_mae: 0.0986 - val_mse: 0.0151
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0438 - mae: 0.1596 - mse: 0.0438
64/93 [===================>..........] - ETA: 0s - loss: 0.0322 - mae: 0.1318 - mse: 0.0322
93/93 [==============================] - 0s 5ms/step - loss: 0.0278 - mae: 0.1181 - mse: 0.0278 - val_loss: 0.0178 - val_mae: 0.1132 - val_mse: 0.0178
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0259 - mae: 0.1144 - mse: 0.0259
64/93 [===================>..........] - ETA: 0s - loss: 0.0223 - mae: 0.1069 - mse: 0.0223
93/93 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 0.1016 - mse: 0.0192 - val_loss: 0.0182 - val_mae: 0.1126 - val_mse: 0.0182
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0194 - mae: 0.1002 - mse: 0.0194
64/93 [===================>..........] - ETA: 0s - loss: 0.0186 - mae: 0.0989 - mse: 0.0186
93/93 [==============================] - 0s 5ms/step - loss: 0.0222 - mae: 0.1074 - mse: 0.0222 - val_loss: 0.0206 - val_mae: 0.1250 - val_mse: 0.0206
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0178 - mae: 0.0986 - mse: 0.0178
64/93 [===================>..........] - ETA: 0s - loss: 0.0170 - mae: 0.0936 - mse: 0.0170
93/93 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 0.0973 - mse: 0.0176 - val_loss: 0.0182 - val_mae: 0.1151 - val_mse: 0.0182
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0168 - mae: 0.0970 - mse: 0.0168
64/93 [===================>..........] - ETA: 0s - loss: 0.0140 - mae: 0.0851 - mse: 0.0140
93/93 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.0975 - mse: 0.0177 - val_loss: 0.0201 - val_mae: 0.1264 - val_mse: 0.0201
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0109 - mae: 0.0717 - mse: 0.0109
64/93 [===================>..........] - ETA: 0s - loss: 0.0139 - mae: 0.0923 - mse: 0.0139
93/93 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 0.0958 - mse: 0.0166 - val_loss: 0.0250 - val_mae: 0.1429 - val_mse: 0.0250
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0151 - mae: 0.0885 - mse: 0.0151
64/93 [===================>..........] - ETA: 0s - loss: 0.0221 - mae: 0.1055 - mse: 0.0221
93/93 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 0.1040 - mse: 0.0199 - val_loss: 0.0221 - val_mae: 0.1344 - val_mse: 0.0221
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0155 - mae: 0.0873 - mse: 0.0155
64/93 [===================>..........] - ETA: 0s - loss: 0.0161 - mae: 0.0937 - mse: 0.0161
93/93 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0896 - mse: 0.0143 - val_loss: 0.0213 - val_mae: 0.1303 - val_mse: 0.0213
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0221 - mae: 0.1005 - mse: 0.0221
64/93 [===================>..........] - ETA: 0s - loss: 0.0193 - mae: 0.1000 - mse: 0.0193
93/93 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 0.1044 - mse: 0.0192 - val_loss: 0.0220 - val_mae: 0.1319 - val_mse: 0.0220
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0129 - mae: 0.0967 - mse: 0.0129
64/93 [===================>..........] - ETA: 0s - loss: 0.0117 - mae: 0.0847 - mse: 0.0117
93/93 [==============================] - 0s 5ms/step - loss: 0.0124 - mae: 0.0821 - mse: 0.0124 - val_loss: 0.0216 - val_mae: 0.1312 - val_mse: 0.0216
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0099 - mae: 0.0777 - mse: 0.0099
64/93 [===================>..........] - ETA: 0s - loss: 0.0138 - mae: 0.0889 - mse: 0.0138
93/93 [==============================] - 0s 5ms/step - loss: 0.0159 - mae: 0.0963 - mse: 0.0159 - val_loss: 0.0163 - val_mae: 0.1120 - val_mse: 0.0163
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0162 - mae: 0.0924 - mse: 0.0162
64/93 [===================>..........] - ETA: 0s - loss: 0.0114 - mae: 0.0779 - mse: 0.0114
93/93 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0857 - mse: 0.0130 - val_loss: 0.0174 - val_mae: 0.1183 - val_mse: 0.0174
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0174 - mae: 0.0917 - mse: 0.0174
64/93 [===================>..........] - ETA: 0s - loss: 0.0199 - mae: 0.1032 - mse: 0.0199
93/93 [==============================] - 1s 6ms/step - loss: 0.0163 - mae: 0.0931 - mse: 0.0163 - val_loss: 0.0224 - val_mae: 0.1341 - val_mse: 0.0224
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0064 - mae: 0.0658 - mse: 0.0064
64/93 [===================>..........] - ETA: 0s - loss: 0.0174 - mae: 0.0924 - mse: 0.0174
93/93 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.1004 - mse: 0.0187 - val_loss: 0.0169 - val_mae: 0.1150 - val_mse: 0.0169
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0104 - mae: 0.0787 - mse: 0.0104
64/93 [===================>..........] - ETA: 0s - loss: 0.0144 - mae: 0.0890 - mse: 0.0144
93/93 [==============================] - 0s 4ms/step - loss: 0.0135 - mae: 0.0875 - mse: 0.0135 - val_loss: 0.0153 - val_mae: 0.1082 - val_mse: 0.0153
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0165 - mae: 0.1009 - mse: 0.0165
64/93 [===================>..........] - ETA: 0s - loss: 0.0136 - mae: 0.0915 - mse: 0.0136
93/93 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0922 - mse: 0.0138 - val_loss: 0.0224 - val_mae: 0.1342 - val_mse: 0.0224
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0176 - mae: 0.0906 - mse: 0.0176
64/93 [===================>..........] - ETA: 0s - loss: 0.0148 - mae: 0.0847 - mse: 0.0148
93/93 [==============================] - 0s 5ms/step - loss: 0.0151 - mae: 0.0915 - mse: 0.0151 - val_loss: 0.0131 - val_mae: 0.1022 - val_mse: 0.0131
Saving trained model...
89
Testing...
heightdiff= [0.         0.         0.         5.33140182 0.         0.        ]
average prediction= [2.5933604]
baseline= 8.981481481481481
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.0662803649902344
85 -:- nan
60 -:- nan
['train-weight-11.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
60 34
60 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
60 38
60 39
60 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
50 71
2_165_50_11_csi_a11_29.dat
50 73
50 74
50 75
50 76
50 77
50 78
2_165_50_11_csi_a11_19.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
2_165_50_11_csi_a11_6.dat
50 96
2_165_50_11_csi_a11_28.dat
50 98
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
1_175_70_11_csi_a11_29.dat
70 120
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
85 135
85 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
85 141
1_180_85_11_csi_a11_28.dat
85 143
85 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
85 150
85 151
85 152
85 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
75 161
75 162
75 163
75 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
75 167
1_180_75_11_csi_a11_21.dat
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
75 182
1_180_75_11_csi_a11_16.dat
75 184
75 185
75 186
75 187
75 188
75 189
75 190
1_173_85_11_csi_a11_22.dat
85 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
85 197
85 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
85 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
85 204
1_173_85_11_csi_a11_2.dat
85 206
1_173_85_11_csi_a11_24.dat
85 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
85 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85
 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 85 85 85 85 85 85 85 85]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.4384 - mae: 0.5927 - mse: 0.4384
64/93 [===================>..........] - ETA: 0s - loss: 0.3479 - mae: 0.5149 - mse: 0.3479
93/93 [==============================] - 1s 9ms/step - loss: 0.2876 - mae: 0.4601 - mse: 0.2876 - val_loss: 0.0490 - val_mae: 0.2078 - val_mse: 0.0490
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1612 - mae: 0.3223 - mse: 0.1612
64/93 [===================>..........] - ETA: 0s - loss: 0.1389 - mae: 0.2934 - mse: 0.1389
93/93 [==============================] - 1s 6ms/step - loss: 0.1509 - mae: 0.3026 - mse: 0.1509 - val_loss: 0.0261 - val_mae: 0.1112 - val_mse: 0.0261
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1694 - mae: 0.3191 - mse: 0.1694
64/93 [===================>..........] - ETA: 0s - loss: 0.1469 - mae: 0.2933 - mse: 0.1469
93/93 [==============================] - 1s 6ms/step - loss: 0.1324 - mae: 0.2810 - mse: 0.1324 - val_loss: 0.0155 - val_mae: 0.0982 - val_mse: 0.0155
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0709 - mae: 0.2049 - mse: 0.0709
64/93 [===================>..........] - ETA: 0s - loss: 0.0867 - mae: 0.2396 - mse: 0.0867
93/93 [==============================] - 1s 6ms/step - loss: 0.0941 - mae: 0.2483 - mse: 0.0941 - val_loss: 0.0319 - val_mae: 0.1606 - val_mse: 0.0319
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0907 - mae: 0.2402 - mse: 0.0907
64/93 [===================>..........] - ETA: 0s - loss: 0.0858 - mae: 0.2310 - mse: 0.0858
93/93 [==============================] - 1s 6ms/step - loss: 0.0815 - mae: 0.2256 - mse: 0.0815 - val_loss: 0.0293 - val_mae: 0.1434 - val_mse: 0.0293
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0597 - mae: 0.1969 - mse: 0.0597
64/93 [===================>..........] - ETA: 0s - loss: 0.0731 - mae: 0.2167 - mse: 0.0731
93/93 [==============================] - 1s 6ms/step - loss: 0.0699 - mae: 0.2101 - mse: 0.0699 - val_loss: 0.0104 - val_mae: 0.1004 - val_mse: 0.0104
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0537 - mae: 0.1960 - mse: 0.0537
64/93 [===================>..........] - ETA: 0s - loss: 0.0495 - mae: 0.1820 - mse: 0.0495
93/93 [==============================] - 1s 6ms/step - loss: 0.0477 - mae: 0.1741 - mse: 0.0477 - val_loss: 0.0125 - val_mae: 0.0779 - val_mse: 0.0125
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0603 - mae: 0.2111 - mse: 0.0603
64/93 [===================>..........] - ETA: 0s - loss: 0.0537 - mae: 0.1963 - mse: 0.0537
93/93 [==============================] - 1s 6ms/step - loss: 0.0537 - mae: 0.1981 - mse: 0.0537 - val_loss: 0.0115 - val_mae: 0.0879 - val_mse: 0.0115
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0376 - mae: 0.1674 - mse: 0.0376
64/93 [===================>..........] - ETA: 0s - loss: 0.0378 - mae: 0.1557 - mse: 0.0378
93/93 [==============================] - 1s 6ms/step - loss: 0.0358 - mae: 0.1495 - mse: 0.0358 - val_loss: 0.0155 - val_mae: 0.1159 - val_mse: 0.0155
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0480 - mae: 0.1791 - mse: 0.0480
64/93 [===================>..........] - ETA: 0s - loss: 0.0448 - mae: 0.1678 - mse: 0.0448
93/93 [==============================] - 1s 6ms/step - loss: 0.0415 - mae: 0.1594 - mse: 0.0415 - val_loss: 0.0130 - val_mae: 0.0964 - val_mse: 0.0130
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0378 - mae: 0.1397 - mse: 0.0378
64/93 [===================>..........] - ETA: 0s - loss: 0.0413 - mae: 0.1575 - mse: 0.0413
93/93 [==============================] - 1s 6ms/step - loss: 0.0438 - mae: 0.1617 - mse: 0.0438 - val_loss: 0.0101 - val_mae: 0.0804 - val_mse: 0.0101
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0403 - mae: 0.1574 - mse: 0.0403
64/93 [===================>..........] - ETA: 0s - loss: 0.0307 - mae: 0.1393 - mse: 0.0307
93/93 [==============================] - 1s 6ms/step - loss: 0.0308 - mae: 0.1378 - mse: 0.0308 - val_loss: 0.0089 - val_mae: 0.0854 - val_mse: 0.0089
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0405 - mae: 0.1569 - mse: 0.0405
64/93 [===================>..........] - ETA: 0s - loss: 0.0359 - mae: 0.1418 - mse: 0.0359
93/93 [==============================] - 1s 6ms/step - loss: 0.0292 - mae: 0.1282 - mse: 0.0292 - val_loss: 0.0083 - val_mae: 0.0831 - val_mse: 0.0083
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0123 - mae: 0.0802 - mse: 0.0123
64/93 [===================>..........] - ETA: 0s - loss: 0.0214 - mae: 0.1049 - mse: 0.0214
93/93 [==============================] - 1s 6ms/step - loss: 0.0233 - mae: 0.1109 - mse: 0.0233 - val_loss: 0.0071 - val_mae: 0.0706 - val_mse: 0.0071
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0176 - mae: 0.1003 - mse: 0.0176
64/93 [===================>..........] - ETA: 0s - loss: 0.0224 - mae: 0.1152 - mse: 0.0224
93/93 [==============================] - 1s 6ms/step - loss: 0.0259 - mae: 0.1197 - mse: 0.0259 - val_loss: 0.0093 - val_mae: 0.0666 - val_mse: 0.0093
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0250 - mae: 0.1239 - mse: 0.0250
64/93 [===================>..........] - ETA: 0s - loss: 0.0246 - mae: 0.1158 - mse: 0.0246
93/93 [==============================] - 1s 6ms/step - loss: 0.0224 - mae: 0.1113 - mse: 0.0224 - val_loss: 0.0097 - val_mae: 0.0781 - val_mse: 0.0097
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0137 - mae: 0.1003 - mse: 0.0137
64/93 [===================>..........] - ETA: 0s - loss: 0.0217 - mae: 0.1151 - mse: 0.0217
93/93 [==============================] - 1s 6ms/step - loss: 0.0200 - mae: 0.1107 - mse: 0.0200 - val_loss: 0.0170 - val_mae: 0.1184 - val_mse: 0.0170
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0211 - mae: 0.1087 - mse: 0.0211
64/93 [===================>..........] - ETA: 0s - loss: 0.0174 - mae: 0.0957 - mse: 0.0174
93/93 [==============================] - 1s 5ms/step - loss: 0.0220 - mae: 0.1003 - mse: 0.0220 - val_loss: 0.0177 - val_mae: 0.1145 - val_mse: 0.0177
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0241 - mae: 0.1165 - mse: 0.0241
64/93 [===================>..........] - ETA: 0s - loss: 0.0177 - mae: 0.0959 - mse: 0.0177
93/93 [==============================] - 1s 6ms/step - loss: 0.0180 - mae: 0.1010 - mse: 0.0180 - val_loss: 0.0180 - val_mae: 0.1032 - val_mse: 0.0180
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0136 - mae: 0.0968 - mse: 0.0136
64/93 [===================>..........] - ETA: 0s - loss: 0.0196 - mae: 0.1105 - mse: 0.0196
93/93 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 0.1126 - mse: 0.0211 - val_loss: 0.0160 - val_mae: 0.1019 - val_mse: 0.0160
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0151 - mae: 0.0909 - mse: 0.0151
64/93 [===================>..........] - ETA: 0s - loss: 0.0209 - mae: 0.1064 - mse: 0.0209
93/93 [==============================] - 1s 5ms/step - loss: 0.0219 - mae: 0.1067 - mse: 0.0219 - val_loss: 0.0172 - val_mae: 0.1127 - val_mse: 0.0172
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0238 - mae: 0.1071 - mse: 0.0238
64/93 [===================>..........] - ETA: 0s - loss: 0.0175 - mae: 0.0943 - mse: 0.0175
93/93 [==============================] - 1s 5ms/step - loss: 0.0220 - mae: 0.1077 - mse: 0.0220 - val_loss: 0.0159 - val_mae: 0.1105 - val_mse: 0.0159
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0249 - mae: 0.1093 - mse: 0.0249
64/93 [===================>..........] - ETA: 0s - loss: 0.0223 - mae: 0.1025 - mse: 0.0223
93/93 [==============================] - 1s 6ms/step - loss: 0.0239 - mae: 0.1105 - mse: 0.0239 - val_loss: 0.0116 - val_mae: 0.0813 - val_mse: 0.0116
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0278 - mae: 0.1207 - mse: 0.0278
64/93 [===================>..........] - ETA: 0s - loss: 0.0225 - mae: 0.1076 - mse: 0.0225
93/93 [==============================] - 1s 5ms/step - loss: 0.0189 - mae: 0.0990 - mse: 0.0189 - val_loss: 0.0122 - val_mae: 0.0889 - val_mse: 0.0122
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0114 - mae: 0.0797 - mse: 0.0114
64/93 [===================>..........] - ETA: 0s - loss: 0.0160 - mae: 0.0910 - mse: 0.0160
93/93 [==============================] - 1s 6ms/step - loss: 0.0142 - mae: 0.0882 - mse: 0.0142 - val_loss: 0.0146 - val_mae: 0.1069 - val_mse: 0.0146
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0065 - mae: 0.0628 - mse: 0.0065
64/93 [===================>..........] - ETA: 0s - loss: 0.0128 - mae: 0.0778 - mse: 0.0128
93/93 [==============================] - 1s 6ms/step - loss: 0.0137 - mae: 0.0827 - mse: 0.0137 - val_loss: 0.0135 - val_mae: 0.0991 - val_mse: 0.0135
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0174 - mae: 0.0908 - mse: 0.0174
64/93 [===================>..........] - ETA: 0s - loss: 0.0145 - mae: 0.0834 - mse: 0.0145
93/93 [==============================] - 1s 6ms/step - loss: 0.0174 - mae: 0.0909 - mse: 0.0174 - val_loss: 0.0154 - val_mae: 0.1062 - val_mse: 0.0154
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0237 - mae: 0.1110 - mse: 0.0237
64/93 [===================>..........] - ETA: 0s - loss: 0.0192 - mae: 0.1004 - mse: 0.0192
93/93 [==============================] - 1s 6ms/step - loss: 0.0161 - mae: 0.0934 - mse: 0.0161 - val_loss: 0.0172 - val_mae: 0.1104 - val_mse: 0.0172
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0126 - mae: 0.0775 - mse: 0.0126
64/93 [===================>..........] - ETA: 0s - loss: 0.0119 - mae: 0.0838 - mse: 0.0119
93/93 [==============================] - 1s 6ms/step - loss: 0.0163 - mae: 0.0951 - mse: 0.0163 - val_loss: 0.0155 - val_mae: 0.1072 - val_mse: 0.0155
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0144 - mae: 0.0858 - mse: 0.0144
64/93 [===================>..........] - ETA: 0s - loss: 0.0130 - mae: 0.0873 - mse: 0.0130
93/93 [==============================] - 1s 6ms/step - loss: 0.0144 - mae: 0.0865 - mse: 0.0144 - val_loss: 0.0094 - val_mae: 0.0799 - val_mse: 0.0094
Saving trained model...
89
Testing...
heightdiff= [0.        0.        0.        4.3087616 0.        0.       ]
average prediction= [2.6639812]
baseline= 6.7592592592592595
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.8617523193359375
85 -:- nan
60 -:- nan
['train-weight-11.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
60 34
60 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
60 38
60 39
60 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
50 71
2_165_50_11_csi_a11_29.dat
50 73
50 74
50 75
50 76
50 77
50 78
2_165_50_11_csi_a11_19.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
2_165_50_11_csi_a11_6.dat
50 96
2_165_50_11_csi_a11_28.dat
50 98
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
1_175_70_11_csi_a11_29.dat
70 120
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
85 135
85 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
85 141
1_180_85_11_csi_a11_28.dat
85 143
85 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
85 150
85 151
85 152
85 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
75 161
75 162
75 163
75 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
75 167
1_180_75_11_csi_a11_21.dat
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
75 182
1_180_75_11_csi_a11_16.dat
75 184
75 185
75 186
75 187
75 188
75 189
75 190
1_173_85_11_csi_a11_22.dat
85 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
85 197
85 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
85 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
85 204
1_173_85_11_csi_a11_2.dat
85 206
1_173_85_11_csi_a11_24.dat
85 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
85 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85
 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 85 85 85 85 85 85 85 85]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.3579 - mae: 0.5225 - mse: 0.3579
64/93 [===================>..........] - ETA: 0s - loss: 0.2741 - mae: 0.4405 - mse: 0.2741
93/93 [==============================] - 1s 9ms/step - loss: 0.2252 - mae: 0.3901 - mse: 0.2252 - val_loss: 0.0758 - val_mae: 0.2455 - val_mse: 0.0758
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0849 - mae: 0.2510 - mse: 0.0849
64/93 [===================>..........] - ETA: 0s - loss: 0.1093 - mae: 0.2909 - mse: 0.1093
93/93 [==============================] - 1s 6ms/step - loss: 0.1127 - mae: 0.2948 - mse: 0.1127 - val_loss: 0.0456 - val_mae: 0.1965 - val_mse: 0.0456
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1414 - mae: 0.3322 - mse: 0.1414
64/93 [===================>..........] - ETA: 0s - loss: 0.1239 - mae: 0.3061 - mse: 0.1239
93/93 [==============================] - 1s 5ms/step - loss: 0.1069 - mae: 0.2863 - mse: 0.1069 - val_loss: 0.0458 - val_mae: 0.2031 - val_mse: 0.0458
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0657 - mae: 0.2349 - mse: 0.0657
64/93 [===================>..........] - ETA: 0s - loss: 0.0780 - mae: 0.2447 - mse: 0.0780
93/93 [==============================] - 1s 5ms/step - loss: 0.0828 - mae: 0.2528 - mse: 0.0828 - val_loss: 0.0565 - val_mae: 0.2017 - val_mse: 0.0565
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0947 - mae: 0.2733 - mse: 0.0947
64/93 [===================>..........] - ETA: 0s - loss: 0.0775 - mae: 0.2397 - mse: 0.0775
93/93 [==============================] - 1s 6ms/step - loss: 0.0819 - mae: 0.2409 - mse: 0.0819 - val_loss: 0.0395 - val_mae: 0.1752 - val_mse: 0.0395
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0927 - mae: 0.2543 - mse: 0.0927
64/93 [===================>..........] - ETA: 0s - loss: 0.0775 - mae: 0.2303 - mse: 0.0775
93/93 [==============================] - 0s 5ms/step - loss: 0.0683 - mae: 0.2202 - mse: 0.0683 - val_loss: 0.0185 - val_mae: 0.1292 - val_mse: 0.0185
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0583 - mae: 0.2097 - mse: 0.0583
64/93 [===================>..........] - ETA: 0s - loss: 0.0616 - mae: 0.2115 - mse: 0.0616
93/93 [==============================] - 1s 6ms/step - loss: 0.0609 - mae: 0.2150 - mse: 0.0609 - val_loss: 0.0134 - val_mae: 0.1042 - val_mse: 0.0134
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0468 - mae: 0.1822 - mse: 0.0468
64/93 [===================>..........] - ETA: 0s - loss: 0.0440 - mae: 0.1760 - mse: 0.0440
93/93 [==============================] - 0s 5ms/step - loss: 0.0461 - mae: 0.1764 - mse: 0.0461 - val_loss: 0.0126 - val_mae: 0.1031 - val_mse: 0.0126
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0402 - mae: 0.1661 - mse: 0.0402
64/93 [===================>..........] - ETA: 0s - loss: 0.0576 - mae: 0.1867 - mse: 0.0576
93/93 [==============================] - 1s 5ms/step - loss: 0.0461 - mae: 0.1662 - mse: 0.0461 - val_loss: 0.0139 - val_mae: 0.1076 - val_mse: 0.0139
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0450 - mae: 0.1453 - mse: 0.0450
64/93 [===================>..........] - ETA: 0s - loss: 0.0479 - mae: 0.1500 - mse: 0.0479
93/93 [==============================] - 0s 5ms/step - loss: 0.0383 - mae: 0.1373 - mse: 0.0383 - val_loss: 0.0067 - val_mae: 0.0715 - val_mse: 0.0067
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0635 - mae: 0.1834 - mse: 0.0635
64/93 [===================>..........] - ETA: 0s - loss: 0.0476 - mae: 0.1571 - mse: 0.0476
93/93 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 0.1499 - mse: 0.0409 - val_loss: 0.0046 - val_mae: 0.0558 - val_mse: 0.0046
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0213 - mae: 0.1174 - mse: 0.0213
64/93 [===================>..........] - ETA: 0s - loss: 0.0324 - mae: 0.1372 - mse: 0.0324
93/93 [==============================] - 1s 5ms/step - loss: 0.0294 - mae: 0.1267 - mse: 0.0294 - val_loss: 0.0054 - val_mae: 0.0631 - val_mse: 0.0054
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0357 - mae: 0.1299 - mse: 0.0357
64/93 [===================>..........] - ETA: 0s - loss: 0.0328 - mae: 0.1283 - mse: 0.0328
93/93 [==============================] - 0s 5ms/step - loss: 0.0340 - mae: 0.1293 - mse: 0.0340 - val_loss: 0.0074 - val_mae: 0.0689 - val_mse: 0.0074
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0312 - mae: 0.1171 - mse: 0.0312
64/93 [===================>..........] - ETA: 0s - loss: 0.0284 - mae: 0.1194 - mse: 0.0284
93/93 [==============================] - 1s 5ms/step - loss: 0.0282 - mae: 0.1226 - mse: 0.0282 - val_loss: 0.0074 - val_mae: 0.0689 - val_mse: 0.0074
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0272 - mae: 0.1247 - mse: 0.0272
64/93 [===================>..........] - ETA: 0s - loss: 0.0246 - mae: 0.1180 - mse: 0.0246
93/93 [==============================] - 0s 5ms/step - loss: 0.0221 - mae: 0.1129 - mse: 0.0221 - val_loss: 0.0078 - val_mae: 0.0712 - val_mse: 0.0078
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0201 - mae: 0.1042 - mse: 0.0201
64/93 [===================>..........] - ETA: 0s - loss: 0.0185 - mae: 0.1062 - mse: 0.0185
93/93 [==============================] - 1s 6ms/step - loss: 0.0204 - mae: 0.1090 - mse: 0.0204 - val_loss: 0.0095 - val_mae: 0.0744 - val_mse: 0.0095
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0228 - mae: 0.1146 - mse: 0.0228
64/93 [===================>..........] - ETA: 0s - loss: 0.0186 - mae: 0.1053 - mse: 0.0186
93/93 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 0.1077 - mse: 0.0187 - val_loss: 0.0076 - val_mae: 0.0709 - val_mse: 0.0076
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0152 - mae: 0.0945 - mse: 0.0152
64/93 [===================>..........] - ETA: 0s - loss: 0.0191 - mae: 0.1016 - mse: 0.0191
93/93 [==============================] - 1s 5ms/step - loss: 0.0163 - mae: 0.0953 - mse: 0.0163 - val_loss: 0.0041 - val_mae: 0.0540 - val_mse: 0.0041
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0167 - mae: 0.1029 - mse: 0.0167
64/93 [===================>..........] - ETA: 0s - loss: 0.0180 - mae: 0.1000 - mse: 0.0180
93/93 [==============================] - 1s 5ms/step - loss: 0.0206 - mae: 0.1102 - mse: 0.0206 - val_loss: 0.0048 - val_mae: 0.0569 - val_mse: 0.0048
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0182 - mae: 0.0996 - mse: 0.0182
64/93 [===================>..........] - ETA: 0s - loss: 0.0151 - mae: 0.0893 - mse: 0.0151
93/93 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0963 - mse: 0.0182 - val_loss: 0.0098 - val_mae: 0.0806 - val_mse: 0.0098
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0108 - mae: 0.0705 - mse: 0.0108
64/93 [===================>..........] - ETA: 0s - loss: 0.0156 - mae: 0.0899 - mse: 0.0156
93/93 [==============================] - 1s 5ms/step - loss: 0.0138 - mae: 0.0881 - mse: 0.0138 - val_loss: 0.0051 - val_mae: 0.0560 - val_mse: 0.0051
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0112 - mae: 0.0762 - mse: 0.0112
64/93 [===================>..........] - ETA: 0s - loss: 0.0109 - mae: 0.0786 - mse: 0.0109
93/93 [==============================] - 0s 5ms/step - loss: 0.0152 - mae: 0.0923 - mse: 0.0152 - val_loss: 0.0040 - val_mae: 0.0525 - val_mse: 0.0040
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0134 - mae: 0.0815 - mse: 0.0134
64/93 [===================>..........] - ETA: 0s - loss: 0.0148 - mae: 0.0916 - mse: 0.0148
93/93 [==============================] - 1s 6ms/step - loss: 0.0166 - mae: 0.0930 - mse: 0.0166 - val_loss: 0.0077 - val_mae: 0.0726 - val_mse: 0.0077
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0231 - mae: 0.1110 - mse: 0.0231
64/93 [===================>..........] - ETA: 0s - loss: 0.0214 - mae: 0.1145 - mse: 0.0214
93/93 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 0.1012 - mse: 0.0176 - val_loss: 0.0094 - val_mae: 0.0812 - val_mse: 0.0094
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0070 - mae: 0.0709 - mse: 0.0070
64/93 [===================>..........] - ETA: 0s - loss: 0.0112 - mae: 0.0845 - mse: 0.0112
93/93 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0805 - mse: 0.0118 - val_loss: 0.0041 - val_mae: 0.0555 - val_mse: 0.0041
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0130 - mae: 0.0898 - mse: 0.0130
64/93 [===================>..........] - ETA: 0s - loss: 0.0134 - mae: 0.0930 - mse: 0.0134
93/93 [==============================] - 0s 5ms/step - loss: 0.0122 - mae: 0.0869 - mse: 0.0122 - val_loss: 0.0045 - val_mae: 0.0544 - val_mse: 0.0045
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0195 - mae: 0.0997 - mse: 0.0195
64/93 [===================>..........] - ETA: 0s - loss: 0.0133 - mae: 0.0821 - mse: 0.0133
93/93 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0845 - mse: 0.0132 - val_loss: 0.0178 - val_mae: 0.1233 - val_mse: 0.0178
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0162 - mae: 0.0943 - mse: 0.0162
64/93 [===================>..........] - ETA: 0s - loss: 0.0215 - mae: 0.1085 - mse: 0.0215
93/93 [==============================] - 1s 6ms/step - loss: 0.0188 - mae: 0.1020 - mse: 0.0188 - val_loss: 0.0040 - val_mae: 0.0521 - val_mse: 0.0040
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0146 - mae: 0.0897 - mse: 0.0146
64/93 [===================>..........] - ETA: 0s - loss: 0.0156 - mae: 0.0955 - mse: 0.0156
93/93 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0931 - mse: 0.0148 - val_loss: 0.0018 - val_mae: 0.0371 - val_mse: 0.0018
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0139 - mae: 0.0840 - mse: 0.0139
64/93 [===================>..........] - ETA: 0s - loss: 0.0112 - mae: 0.0780 - mse: 0.0112
93/93 [==============================] - 1s 5ms/step - loss: 0.0106 - mae: 0.0756 - mse: 0.0106 - val_loss: 0.0103 - val_mae: 0.0869 - val_mse: 0.0103
Saving trained model...
89
Testing...
heightdiff= [0.         0.         0.         2.87106705 0.         0.        ]
average prediction= [4.8707666]
baseline= 6.574074074074074
eachuser= [0. 0. 0. 2. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.4355335235595703
85 -:- nan
60 -:- nan
['train-weight-11.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
60 34
60 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
60 38
60 39
60 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
50 71
2_165_50_11_csi_a11_29.dat
50 73
50 74
50 75
50 76
50 77
50 78
2_165_50_11_csi_a11_19.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
2_165_50_11_csi_a11_6.dat
50 96
2_165_50_11_csi_a11_28.dat
50 98
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
1_175_70_11_csi_a11_29.dat
70 120
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
85 135
85 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
85 141
1_180_85_11_csi_a11_28.dat
85 143
85 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
85 150
85 151
85 152
85 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
75 161
75 162
75 163
75 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
75 167
1_180_75_11_csi_a11_21.dat
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
75 182
1_180_75_11_csi_a11_16.dat
75 184
75 185
75 186
75 187
75 188
75 189
75 190
1_173_85_11_csi_a11_22.dat
85 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
85 197
85 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
85 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
85 204
1_173_85_11_csi_a11_2.dat
85 206
1_173_85_11_csi_a11_24.dat
85 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
85 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85
 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 85 85 85 85 85 85 85 85]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.3131 - mae: 0.4979 - mse: 0.3131
64/93 [===================>..........] - ETA: 0s - loss: 0.2885 - mae: 0.4824 - mse: 0.2885
93/93 [==============================] - 1s 10ms/step - loss: 0.2583 - mae: 0.4477 - mse: 0.2583 - val_loss: 0.1891 - val_mae: 0.3949 - val_mse: 0.1891
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1261 - mae: 0.2798 - mse: 0.1261
64/93 [===================>..........] - ETA: 0s - loss: 0.1958 - mae: 0.3466 - mse: 0.1958
93/93 [==============================] - 1s 11ms/step - loss: 0.1842 - mae: 0.3282 - mse: 0.1842 - val_loss: 0.1683 - val_mae: 0.3267 - val_mse: 0.1683
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1422 - mae: 0.2897 - mse: 0.1422
64/93 [===================>..........] - ETA: 0s - loss: 0.1541 - mae: 0.3109 - mse: 0.1541
93/93 [==============================] - 1s 9ms/step - loss: 0.1505 - mae: 0.3051 - mse: 0.1505 - val_loss: 0.1198 - val_mae: 0.3143 - val_mse: 0.1198
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1008 - mae: 0.2594 - mse: 0.1008
64/93 [===================>..........] - ETA: 0s - loss: 0.1087 - mae: 0.2571 - mse: 0.1087
93/93 [==============================] - 1s 6ms/step - loss: 0.1125 - mae: 0.2717 - mse: 0.1125 - val_loss: 0.1153 - val_mae: 0.3125 - val_mse: 0.1153
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0767 - mae: 0.2238 - mse: 0.0767
64/93 [===================>..........] - ETA: 0s - loss: 0.0985 - mae: 0.2604 - mse: 0.0985
93/93 [==============================] - 0s 5ms/step - loss: 0.0950 - mae: 0.2580 - mse: 0.0950 - val_loss: 0.0872 - val_mae: 0.2606 - val_mse: 0.0872
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0895 - mae: 0.2292 - mse: 0.0895
64/93 [===================>..........] - ETA: 0s - loss: 0.0783 - mae: 0.2127 - mse: 0.0783
93/93 [==============================] - 1s 6ms/step - loss: 0.0683 - mae: 0.1977 - mse: 0.0683 - val_loss: 0.0568 - val_mae: 0.1901 - val_mse: 0.0568
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0593 - mae: 0.2012 - mse: 0.0593
64/93 [===================>..........] - ETA: 0s - loss: 0.0544 - mae: 0.1897 - mse: 0.0544
93/93 [==============================] - 0s 5ms/step - loss: 0.0609 - mae: 0.2051 - mse: 0.0609 - val_loss: 0.0496 - val_mae: 0.1603 - val_mse: 0.0496
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0477 - mae: 0.1815 - mse: 0.0477
64/93 [===================>..........] - ETA: 0s - loss: 0.0542 - mae: 0.1967 - mse: 0.0542
93/93 [==============================] - 0s 5ms/step - loss: 0.0549 - mae: 0.1917 - mse: 0.0549 - val_loss: 0.0442 - val_mae: 0.1395 - val_mse: 0.0442
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0545 - mae: 0.1925 - mse: 0.0545
64/93 [===================>..........] - ETA: 0s - loss: 0.0446 - mae: 0.1704 - mse: 0.0446
93/93 [==============================] - 0s 5ms/step - loss: 0.0487 - mae: 0.1717 - mse: 0.0487 - val_loss: 0.0468 - val_mae: 0.1286 - val_mse: 0.0468
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0499 - mae: 0.1722 - mse: 0.0499
64/93 [===================>..........] - ETA: 0s - loss: 0.0366 - mae: 0.1487 - mse: 0.0366
93/93 [==============================] - 0s 5ms/step - loss: 0.0442 - mae: 0.1543 - mse: 0.0442 - val_loss: 0.0434 - val_mae: 0.1367 - val_mse: 0.0434
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0457 - mae: 0.1407 - mse: 0.0457
64/93 [===================>..........] - ETA: 0s - loss: 0.0365 - mae: 0.1273 - mse: 0.0365
93/93 [==============================] - 0s 5ms/step - loss: 0.0378 - mae: 0.1353 - mse: 0.0378 - val_loss: 0.0429 - val_mae: 0.1471 - val_mse: 0.0429
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0430 - mae: 0.1520 - mse: 0.0430
64/93 [===================>..........] - ETA: 0s - loss: 0.0425 - mae: 0.1525 - mse: 0.0425
93/93 [==============================] - 0s 5ms/step - loss: 0.0364 - mae: 0.1390 - mse: 0.0364 - val_loss: 0.0370 - val_mae: 0.1280 - val_mse: 0.0370
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0283 - mae: 0.1208 - mse: 0.0283
64/93 [===================>..........] - ETA: 0s - loss: 0.0292 - mae: 0.1218 - mse: 0.0292
93/93 [==============================] - 1s 5ms/step - loss: 0.0340 - mae: 0.1343 - mse: 0.0340 - val_loss: 0.0409 - val_mae: 0.1329 - val_mse: 0.0409
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0466 - mae: 0.1718 - mse: 0.0466
64/93 [===================>..........] - ETA: 0s - loss: 0.0342 - mae: 0.1438 - mse: 0.0342
93/93 [==============================] - 1s 5ms/step - loss: 0.0353 - mae: 0.1423 - mse: 0.0353 - val_loss: 0.0288 - val_mae: 0.1028 - val_mse: 0.0288
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0334 - mae: 0.1432 - mse: 0.0334
64/93 [===================>..........] - ETA: 0s - loss: 0.0248 - mae: 0.1238 - mse: 0.0248
93/93 [==============================] - 0s 5ms/step - loss: 0.0275 - mae: 0.1333 - mse: 0.0275 - val_loss: 0.0237 - val_mae: 0.0963 - val_mse: 0.0237
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0435 - mae: 0.1726 - mse: 0.0435
64/93 [===================>..........] - ETA: 0s - loss: 0.0335 - mae: 0.1537 - mse: 0.0335
93/93 [==============================] - 1s 5ms/step - loss: 0.0376 - mae: 0.1576 - mse: 0.0376 - val_loss: 0.0261 - val_mae: 0.0973 - val_mse: 0.0261
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0249 - mae: 0.1147 - mse: 0.0249
64/93 [===================>..........] - ETA: 0s - loss: 0.0257 - mae: 0.1173 - mse: 0.0257
93/93 [==============================] - 0s 5ms/step - loss: 0.0278 - mae: 0.1233 - mse: 0.0278 - val_loss: 0.0271 - val_mae: 0.1025 - val_mse: 0.0271
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0306 - mae: 0.1257 - mse: 0.0306
64/93 [===================>..........] - ETA: 0s - loss: 0.0298 - mae: 0.1292 - mse: 0.0298
93/93 [==============================] - 0s 5ms/step - loss: 0.0293 - mae: 0.1269 - mse: 0.0293 - val_loss: 0.0245 - val_mae: 0.0937 - val_mse: 0.0245
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0356 - mae: 0.1390 - mse: 0.0356
64/93 [===================>..........] - ETA: 0s - loss: 0.0287 - mae: 0.1230 - mse: 0.0287
93/93 [==============================] - 1s 5ms/step - loss: 0.0286 - mae: 0.1272 - mse: 0.0286 - val_loss: 0.0230 - val_mae: 0.1025 - val_mse: 0.0230
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0238 - mae: 0.1232 - mse: 0.0238
64/93 [===================>..........] - ETA: 0s - loss: 0.0224 - mae: 0.1174 - mse: 0.0224
93/93 [==============================] - 1s 5ms/step - loss: 0.0237 - mae: 0.1163 - mse: 0.0237 - val_loss: 0.0260 - val_mae: 0.1037 - val_mse: 0.0260
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0246 - mae: 0.1125 - mse: 0.0246
64/93 [===================>..........] - ETA: 0s - loss: 0.0277 - mae: 0.1183 - mse: 0.0277
93/93 [==============================] - 1s 6ms/step - loss: 0.0238 - mae: 0.1109 - mse: 0.0238 - val_loss: 0.0295 - val_mae: 0.1140 - val_mse: 0.0295
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0358 - mae: 0.1438 - mse: 0.0358
64/93 [===================>..........] - ETA: 0s - loss: 0.0267 - mae: 0.1255 - mse: 0.0267
93/93 [==============================] - 0s 5ms/step - loss: 0.0253 - mae: 0.1193 - mse: 0.0253 - val_loss: 0.0217 - val_mae: 0.0978 - val_mse: 0.0217
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0125 - mae: 0.0886 - mse: 0.0125
64/93 [===================>..........] - ETA: 0s - loss: 0.0158 - mae: 0.0952 - mse: 0.0158
93/93 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 0.0999 - mse: 0.0171 - val_loss: 0.0155 - val_mae: 0.0839 - val_mse: 0.0155
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0172 - mae: 0.1025 - mse: 0.0172
64/93 [===================>..........] - ETA: 0s - loss: 0.0156 - mae: 0.0957 - mse: 0.0156
93/93 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0921 - mse: 0.0148 - val_loss: 0.0195 - val_mae: 0.0927 - val_mse: 0.0195
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0206 - mae: 0.1139 - mse: 0.0206
64/93 [===================>..........] - ETA: 0s - loss: 0.0195 - mae: 0.1007 - mse: 0.0195
93/93 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 0.0990 - mse: 0.0183 - val_loss: 0.0259 - val_mae: 0.1144 - val_mse: 0.0259
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0182 - mae: 0.1034 - mse: 0.0182
64/93 [===================>..........] - ETA: 0s - loss: 0.0159 - mae: 0.0959 - mse: 0.0159
93/93 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 0.0974 - mse: 0.0171 - val_loss: 0.0186 - val_mae: 0.0973 - val_mse: 0.0186
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0097 - mae: 0.0793 - mse: 0.0097
64/93 [===================>..........] - ETA: 0s - loss: 0.0141 - mae: 0.0920 - mse: 0.0141
93/93 [==============================] - 0s 5ms/step - loss: 0.0149 - mae: 0.0948 - mse: 0.0149 - val_loss: 0.0119 - val_mae: 0.0749 - val_mse: 0.0119
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0221 - mae: 0.1196 - mse: 0.0221
64/93 [===================>..........] - ETA: 0s - loss: 0.0200 - mae: 0.1131 - mse: 0.0200
93/93 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 0.1070 - mse: 0.0183 - val_loss: 0.0200 - val_mae: 0.1066 - val_mse: 0.0200
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0103 - mae: 0.0781 - mse: 0.0103
64/93 [===================>..........] - ETA: 0s - loss: 0.0174 - mae: 0.0946 - mse: 0.0174
93/93 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0927 - mse: 0.0157 - val_loss: 0.0213 - val_mae: 0.1121 - val_mse: 0.0213
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0114 - mae: 0.0793 - mse: 0.0114
64/93 [===================>..........] - ETA: 0s - loss: 0.0116 - mae: 0.0777 - mse: 0.0116
93/93 [==============================] - 0s 5ms/step - loss: 0.0117 - mae: 0.0818 - mse: 0.0117 - val_loss: 0.0128 - val_mae: 0.0787 - val_mse: 0.0128
Saving trained model...
89
Testing...
heightdiff= [ 0.          0.          0.         15.89867783  0.          0.        ]
average prediction= [2.6763124]
baseline= 9.351851851851851
eachuser= [0. 0. 0. 8. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.9873347282409668
85 -:- nan
60 -:- nan
['train-weight-11.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
60 34
60 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
60 38
60 39
60 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
50 71
2_165_50_11_csi_a11_29.dat
50 73
50 74
50 75
50 76
50 77
50 78
2_165_50_11_csi_a11_19.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
2_165_50_11_csi_a11_6.dat
50 96
2_165_50_11_csi_a11_28.dat
50 98
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
1_175_70_11_csi_a11_29.dat
70 120
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
85 135
85 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
85 141
1_180_85_11_csi_a11_28.dat
85 143
85 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
85 150
85 151
85 152
85 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
75 161
75 162
75 163
75 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
75 167
1_180_75_11_csi_a11_21.dat
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
75 182
1_180_75_11_csi_a11_16.dat
75 184
75 185
75 186
75 187
75 188
75 189
75 190
1_173_85_11_csi_a11_22.dat
85 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
85 197
85 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
85 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
85 204
1_173_85_11_csi_a11_2.dat
85 206
1_173_85_11_csi_a11_24.dat
85 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
85 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85
 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 85 85 85 85 85 85 85 85]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.4250 - mae: 0.5480 - mse: 0.4250
64/93 [===================>..........] - ETA: 0s - loss: 0.3549 - mae: 0.5136 - mse: 0.3549
93/93 [==============================] - 1s 9ms/step - loss: 0.2987 - mae: 0.4695 - mse: 0.2987 - val_loss: 0.1755 - val_mae: 0.3811 - val_mse: 0.1755
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1420 - mae: 0.3362 - mse: 0.1420
64/93 [===================>..........] - ETA: 0s - loss: 0.1269 - mae: 0.2977 - mse: 0.1269
93/93 [==============================] - 1s 5ms/step - loss: 0.1124 - mae: 0.2688 - mse: 0.1124 - val_loss: 0.1124 - val_mae: 0.2451 - val_mse: 0.1124
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1486 - mae: 0.2977 - mse: 0.1486
64/93 [===================>..........] - ETA: 0s - loss: 0.1566 - mae: 0.3063 - mse: 0.1566
93/93 [==============================] - 1s 5ms/step - loss: 0.1380 - mae: 0.2914 - mse: 0.1380 - val_loss: 0.0865 - val_mae: 0.2360 - val_mse: 0.0865
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1223 - mae: 0.2606 - mse: 0.1223
64/93 [===================>..........] - ETA: 0s - loss: 0.0968 - mae: 0.2331 - mse: 0.0968
93/93 [==============================] - 1s 5ms/step - loss: 0.0895 - mae: 0.2263 - mse: 0.0895 - val_loss: 0.0972 - val_mae: 0.2723 - val_mse: 0.0972
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0842 - mae: 0.2247 - mse: 0.0842
64/93 [===================>..........] - ETA: 0s - loss: 0.0806 - mae: 0.2288 - mse: 0.0806
93/93 [==============================] - 1s 5ms/step - loss: 0.0778 - mae: 0.2294 - mse: 0.0778 - val_loss: 0.0994 - val_mae: 0.2745 - val_mse: 0.0994
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0969 - mae: 0.2563 - mse: 0.0969
64/93 [===================>..........] - ETA: 0s - loss: 0.0753 - mae: 0.2150 - mse: 0.0753
93/93 [==============================] - 1s 5ms/step - loss: 0.0643 - mae: 0.1996 - mse: 0.0643 - val_loss: 0.0689 - val_mae: 0.2251 - val_mse: 0.0689
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0464 - mae: 0.1591 - mse: 0.0464
64/93 [===================>..........] - ETA: 0s - loss: 0.0446 - mae: 0.1647 - mse: 0.0446
93/93 [==============================] - 0s 5ms/step - loss: 0.0541 - mae: 0.1818 - mse: 0.0541 - val_loss: 0.0399 - val_mae: 0.1770 - val_mse: 0.0399
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0409 - mae: 0.1599 - mse: 0.0409
64/93 [===================>..........] - ETA: 0s - loss: 0.0405 - mae: 0.1650 - mse: 0.0405
93/93 [==============================] - 0s 5ms/step - loss: 0.0434 - mae: 0.1713 - mse: 0.0434 - val_loss: 0.0272 - val_mae: 0.1414 - val_mse: 0.0272
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0410 - mae: 0.1638 - mse: 0.0410
64/93 [===================>..........] - ETA: 0s - loss: 0.0446 - mae: 0.1743 - mse: 0.0446
93/93 [==============================] - 1s 5ms/step - loss: 0.0443 - mae: 0.1715 - mse: 0.0443 - val_loss: 0.0281 - val_mae: 0.1419 - val_mse: 0.0281
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0239 - mae: 0.1261 - mse: 0.0239
64/93 [===================>..........] - ETA: 0s - loss: 0.0295 - mae: 0.1329 - mse: 0.0295
93/93 [==============================] - 0s 5ms/step - loss: 0.0368 - mae: 0.1482 - mse: 0.0368 - val_loss: 0.0400 - val_mae: 0.1638 - val_mse: 0.0400
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0359 - mae: 0.1463 - mse: 0.0359
64/93 [===================>..........] - ETA: 0s - loss: 0.0305 - mae: 0.1361 - mse: 0.0305
93/93 [==============================] - 1s 5ms/step - loss: 0.0368 - mae: 0.1469 - mse: 0.0368 - val_loss: 0.0400 - val_mae: 0.1587 - val_mse: 0.0400
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0393 - mae: 0.1530 - mse: 0.0393
64/93 [===================>..........] - ETA: 0s - loss: 0.0434 - mae: 0.1512 - mse: 0.0434
93/93 [==============================] - 0s 5ms/step - loss: 0.0356 - mae: 0.1352 - mse: 0.0356 - val_loss: 0.0299 - val_mae: 0.1371 - val_mse: 0.0299
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0297 - mae: 0.1370 - mse: 0.0297
64/93 [===================>..........] - ETA: 0s - loss: 0.0291 - mae: 0.1367 - mse: 0.0291
93/93 [==============================] - 0s 5ms/step - loss: 0.0305 - mae: 0.1346 - mse: 0.0305 - val_loss: 0.0248 - val_mae: 0.1245 - val_mse: 0.0248
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0384 - mae: 0.1547 - mse: 0.0384
64/93 [===================>..........] - ETA: 0s - loss: 0.0277 - mae: 0.1310 - mse: 0.0277
93/93 [==============================] - 0s 5ms/step - loss: 0.0296 - mae: 0.1338 - mse: 0.0296 - val_loss: 0.0274 - val_mae: 0.1363 - val_mse: 0.0274
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0289 - mae: 0.1273 - mse: 0.0289
64/93 [===================>..........] - ETA: 0s - loss: 0.0305 - mae: 0.1280 - mse: 0.0305
93/93 [==============================] - 0s 5ms/step - loss: 0.0343 - mae: 0.1318 - mse: 0.0343 - val_loss: 0.0375 - val_mae: 0.1629 - val_mse: 0.0375
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0304 - mae: 0.1106 - mse: 0.0304
64/93 [===================>..........] - ETA: 0s - loss: 0.0210 - mae: 0.0988 - mse: 0.0210
93/93 [==============================] - 1s 5ms/step - loss: 0.0275 - mae: 0.1166 - mse: 0.0275 - val_loss: 0.0322 - val_mae: 0.1527 - val_mse: 0.0322
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0071 - mae: 0.0688 - mse: 0.0071
64/93 [===================>..........] - ETA: 0s - loss: 0.0178 - mae: 0.0998 - mse: 0.0178
93/93 [==============================] - 0s 5ms/step - loss: 0.0223 - mae: 0.1112 - mse: 0.0223 - val_loss: 0.0266 - val_mae: 0.1385 - val_mse: 0.0266
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0243 - mae: 0.1296 - mse: 0.0243
64/93 [===================>..........] - ETA: 0s - loss: 0.0184 - mae: 0.1092 - mse: 0.0184
93/93 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 0.1115 - mse: 0.0194 - val_loss: 0.0297 - val_mae: 0.1504 - val_mse: 0.0297
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0179 - mae: 0.1024 - mse: 0.0179
64/93 [===================>..........] - ETA: 0s - loss: 0.0178 - mae: 0.0981 - mse: 0.0178
93/93 [==============================] - 0s 5ms/step - loss: 0.0206 - mae: 0.1014 - mse: 0.0206 - val_loss: 0.0301 - val_mae: 0.1537 - val_mse: 0.0301
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0177 - mae: 0.1008 - mse: 0.0177
64/93 [===================>..........] - ETA: 0s - loss: 0.0178 - mae: 0.1045 - mse: 0.0178
93/93 [==============================] - 0s 5ms/step - loss: 0.0206 - mae: 0.1096 - mse: 0.0206 - val_loss: 0.0212 - val_mae: 0.1294 - val_mse: 0.0212
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0151 - mae: 0.0939 - mse: 0.0151
64/93 [===================>..........] - ETA: 0s - loss: 0.0170 - mae: 0.0981 - mse: 0.0170
93/93 [==============================] - 1s 5ms/step - loss: 0.0177 - mae: 0.1040 - mse: 0.0177 - val_loss: 0.0134 - val_mae: 0.0969 - val_mse: 0.0134
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0156 - mae: 0.0999 - mse: 0.0156
64/93 [===================>..........] - ETA: 0s - loss: 0.0162 - mae: 0.0986 - mse: 0.0162
93/93 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 0.0988 - mse: 0.0183 - val_loss: 0.0218 - val_mae: 0.1268 - val_mse: 0.0218
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0107 - mae: 0.0801 - mse: 0.0107
64/93 [===================>..........] - ETA: 0s - loss: 0.0164 - mae: 0.0914 - mse: 0.0164
93/93 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0911 - mse: 0.0165 - val_loss: 0.0252 - val_mae: 0.1390 - val_mse: 0.0252
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0235 - mae: 0.1004 - mse: 0.0235
64/93 [===================>..........] - ETA: 0s - loss: 0.0207 - mae: 0.1016 - mse: 0.0207
93/93 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 0.0977 - mse: 0.0180 - val_loss: 0.0190 - val_mae: 0.1217 - val_mse: 0.0190
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0195 - mae: 0.1157 - mse: 0.0195
64/93 [===================>..........] - ETA: 0s - loss: 0.0188 - mae: 0.1129 - mse: 0.0188
93/93 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 0.1093 - mse: 0.0196 - val_loss: 0.0219 - val_mae: 0.1333 - val_mse: 0.0219
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0119 - mae: 0.0869 - mse: 0.0119
64/93 [===================>..........] - ETA: 0s - loss: 0.0153 - mae: 0.0977 - mse: 0.0153
93/93 [==============================] - 0s 5ms/step - loss: 0.0147 - mae: 0.0941 - mse: 0.0147 - val_loss: 0.0271 - val_mae: 0.1458 - val_mse: 0.0271
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0190 - mae: 0.0957 - mse: 0.0190
64/93 [===================>..........] - ETA: 0s - loss: 0.0136 - mae: 0.0841 - mse: 0.0136
93/93 [==============================] - 0s 5ms/step - loss: 0.0120 - mae: 0.0809 - mse: 0.0120 - val_loss: 0.0206 - val_mae: 0.1269 - val_mse: 0.0206
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0102 - mae: 0.0741 - mse: 0.0102
64/93 [===================>..........] - ETA: 0s - loss: 0.0169 - mae: 0.0941 - mse: 0.0169
93/93 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0920 - mse: 0.0157 - val_loss: 0.0210 - val_mae: 0.1278 - val_mse: 0.0210
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0134 - mae: 0.0945 - mse: 0.0134
64/93 [===================>..........] - ETA: 0s - loss: 0.0162 - mae: 0.0990 - mse: 0.0162
93/93 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0936 - mse: 0.0141 - val_loss: 0.0289 - val_mae: 0.1517 - val_mse: 0.0289
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0120 - mae: 0.0884 - mse: 0.0120
64/93 [===================>..........] - ETA: 0s - loss: 0.0132 - mae: 0.0894 - mse: 0.0132
93/93 [==============================] - 0s 5ms/step - loss: 0.0144 - mae: 0.0936 - mse: 0.0144 - val_loss: 0.0279 - val_mae: 0.1483 - val_mse: 0.0279
Saving trained model...
89
Testing...
heightdiff= [ 0.          0.          0.         11.04914093  0.          0.        ]
average prediction= [3.5930705]
baseline= 8.425925925925926
eachuser= [0. 0. 0. 6. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.8415234883626301
85 -:- nan
60 -:- nan
['train-weight-11.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
60 34
60 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
60 38
60 39
60 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
50 71
2_165_50_11_csi_a11_29.dat
50 73
50 74
50 75
50 76
50 77
50 78
2_165_50_11_csi_a11_19.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
2_165_50_11_csi_a11_6.dat
50 96
2_165_50_11_csi_a11_28.dat
50 98
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
1_175_70_11_csi_a11_29.dat
70 120
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
85 135
85 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
85 141
1_180_85_11_csi_a11_28.dat
85 143
85 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
85 150
85 151
85 152
85 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
75 161
75 162
75 163
75 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
75 167
1_180_75_11_csi_a11_21.dat
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
75 182
1_180_75_11_csi_a11_16.dat
75 184
75 185
75 186
75 187
75 188
75 189
75 190
1_173_85_11_csi_a11_22.dat
85 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
85 197
85 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
85 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
85 204
1_173_85_11_csi_a11_2.dat
85 206
1_173_85_11_csi_a11_24.dat
85 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
85 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85
 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 85 85 85 85 85 85 85 85]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.2384 - mae: 0.4406 - mse: 0.2384
64/93 [===================>..........] - ETA: 0s - loss: 0.2580 - mae: 0.4559 - mse: 0.2580
93/93 [==============================] - 1s 9ms/step - loss: 0.2481 - mae: 0.4469 - mse: 0.2481 - val_loss: 0.1197 - val_mae: 0.3002 - val_mse: 0.1197
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1174 - mae: 0.2794 - mse: 0.1174
64/93 [===================>..........] - ETA: 0s - loss: 0.1116 - mae: 0.2618 - mse: 0.1116
93/93 [==============================] - 1s 5ms/step - loss: 0.1301 - mae: 0.2764 - mse: 0.1301 - val_loss: 0.1378 - val_mae: 0.2850 - val_mse: 0.1378
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1496 - mae: 0.2850 - mse: 0.1496
64/93 [===================>..........] - ETA: 0s - loss: 0.1674 - mae: 0.3144 - mse: 0.1674
93/93 [==============================] - 0s 5ms/step - loss: 0.1371 - mae: 0.2829 - mse: 0.1371 - val_loss: 0.0741 - val_mae: 0.1924 - val_mse: 0.0741
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0534 - mae: 0.1825 - mse: 0.0534
64/93 [===================>..........] - ETA: 0s - loss: 0.0716 - mae: 0.2139 - mse: 0.0716
93/93 [==============================] - 1s 5ms/step - loss: 0.0824 - mae: 0.2257 - mse: 0.0824 - val_loss: 0.0721 - val_mae: 0.2336 - val_mse: 0.0721
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0767 - mae: 0.2178 - mse: 0.0767
64/93 [===================>..........] - ETA: 0s - loss: 0.0866 - mae: 0.2422 - mse: 0.0866
93/93 [==============================] - 1s 5ms/step - loss: 0.0788 - mae: 0.2240 - mse: 0.0788 - val_loss: 0.0642 - val_mae: 0.2164 - val_mse: 0.0642
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0979 - mae: 0.2354 - mse: 0.0979
64/93 [===================>..........] - ETA: 0s - loss: 0.0838 - mae: 0.2273 - mse: 0.0838
93/93 [==============================] - 1s 5ms/step - loss: 0.0809 - mae: 0.2266 - mse: 0.0809 - val_loss: 0.0410 - val_mae: 0.1658 - val_mse: 0.0410
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0817 - mae: 0.2265 - mse: 0.0817
64/93 [===================>..........] - ETA: 0s - loss: 0.0549 - mae: 0.1844 - mse: 0.0549
93/93 [==============================] - 0s 5ms/step - loss: 0.0602 - mae: 0.1908 - mse: 0.0602 - val_loss: 0.0276 - val_mae: 0.1483 - val_mse: 0.0276
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0537 - mae: 0.1960 - mse: 0.0537
64/93 [===================>..........] - ETA: 0s - loss: 0.0526 - mae: 0.1913 - mse: 0.0526
93/93 [==============================] - 0s 5ms/step - loss: 0.0498 - mae: 0.1851 - mse: 0.0498 - val_loss: 0.0222 - val_mae: 0.1346 - val_mse: 0.0222
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0464 - mae: 0.1905 - mse: 0.0464
64/93 [===================>..........] - ETA: 0s - loss: 0.0447 - mae: 0.1763 - mse: 0.0447
93/93 [==============================] - 1s 5ms/step - loss: 0.0381 - mae: 0.1617 - mse: 0.0381 - val_loss: 0.0212 - val_mae: 0.1288 - val_mse: 0.0212
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0307 - mae: 0.1392 - mse: 0.0307
64/93 [===================>..........] - ETA: 0s - loss: 0.0394 - mae: 0.1503 - mse: 0.0394
93/93 [==============================] - 0s 5ms/step - loss: 0.0383 - mae: 0.1523 - mse: 0.0383 - val_loss: 0.0243 - val_mae: 0.1191 - val_mse: 0.0243
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0426 - mae: 0.1577 - mse: 0.0426
64/93 [===================>..........] - ETA: 0s - loss: 0.0386 - mae: 0.1463 - mse: 0.0386
93/93 [==============================] - 0s 5ms/step - loss: 0.0401 - mae: 0.1489 - mse: 0.0401 - val_loss: 0.0157 - val_mae: 0.0932 - val_mse: 0.0157
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0422 - mae: 0.1501 - mse: 0.0422
64/93 [===================>..........] - ETA: 0s - loss: 0.0351 - mae: 0.1350 - mse: 0.0351
93/93 [==============================] - 0s 5ms/step - loss: 0.0305 - mae: 0.1285 - mse: 0.0305 - val_loss: 0.0066 - val_mae: 0.0651 - val_mse: 0.0066
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0647 - mae: 0.1869 - mse: 0.0647
64/93 [===================>..........] - ETA: 0s - loss: 0.0411 - mae: 0.1441 - mse: 0.0411
93/93 [==============================] - 0s 5ms/step - loss: 0.0381 - mae: 0.1477 - mse: 0.0381 - val_loss: 0.0075 - val_mae: 0.0667 - val_mse: 0.0075
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0191 - mae: 0.1085 - mse: 0.0191
64/93 [===================>..........] - ETA: 0s - loss: 0.0254 - mae: 0.1210 - mse: 0.0254
93/93 [==============================] - 0s 5ms/step - loss: 0.0237 - mae: 0.1196 - mse: 0.0237 - val_loss: 0.0131 - val_mae: 0.0994 - val_mse: 0.0131
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0262 - mae: 0.1096 - mse: 0.0262
64/93 [===================>..........] - ETA: 0s - loss: 0.0285 - mae: 0.1172 - mse: 0.0285
93/93 [==============================] - 0s 5ms/step - loss: 0.0303 - mae: 0.1211 - mse: 0.0303 - val_loss: 0.0196 - val_mae: 0.1210 - val_mse: 0.0196
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0225 - mae: 0.1208 - mse: 0.0225
64/93 [===================>..........] - ETA: 0s - loss: 0.0263 - mae: 0.1161 - mse: 0.0263
93/93 [==============================] - 0s 5ms/step - loss: 0.0279 - mae: 0.1201 - mse: 0.0279 - val_loss: 0.0157 - val_mae: 0.1093 - val_mse: 0.0157
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0240 - mae: 0.1121 - mse: 0.0240
64/93 [===================>..........] - ETA: 0s - loss: 0.0219 - mae: 0.1105 - mse: 0.0219
93/93 [==============================] - 1s 5ms/step - loss: 0.0243 - mae: 0.1194 - mse: 0.0243 - val_loss: 0.0120 - val_mae: 0.0885 - val_mse: 0.0120
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0126 - mae: 0.0907 - mse: 0.0126
64/93 [===================>..........] - ETA: 0s - loss: 0.0192 - mae: 0.1113 - mse: 0.0192
93/93 [==============================] - 0s 5ms/step - loss: 0.0200 - mae: 0.1097 - mse: 0.0200 - val_loss: 0.0104 - val_mae: 0.0855 - val_mse: 0.0104
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0183 - mae: 0.0987 - mse: 0.0183
64/93 [===================>..........] - ETA: 0s - loss: 0.0249 - mae: 0.1151 - mse: 0.0249
93/93 [==============================] - 0s 5ms/step - loss: 0.0229 - mae: 0.1137 - mse: 0.0229 - val_loss: 0.0114 - val_mae: 0.0869 - val_mse: 0.0114
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0242 - mae: 0.1119 - mse: 0.0242
64/93 [===================>..........] - ETA: 0s - loss: 0.0310 - mae: 0.1233 - mse: 0.0310
93/93 [==============================] - 0s 5ms/step - loss: 0.0258 - mae: 0.1109 - mse: 0.0258 - val_loss: 0.0129 - val_mae: 0.0906 - val_mse: 0.0129
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0197 - mae: 0.0968 - mse: 0.0197
64/93 [===================>..........] - ETA: 0s - loss: 0.0179 - mae: 0.0970 - mse: 0.0179
93/93 [==============================] - 1s 5ms/step - loss: 0.0224 - mae: 0.1087 - mse: 0.0224 - val_loss: 0.0099 - val_mae: 0.0832 - val_mse: 0.0099
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0303 - mae: 0.1251 - mse: 0.0303
64/93 [===================>..........] - ETA: 0s - loss: 0.0288 - mae: 0.1202 - mse: 0.0288
93/93 [==============================] - 1s 5ms/step - loss: 0.0226 - mae: 0.1046 - mse: 0.0226 - val_loss: 0.0070 - val_mae: 0.0682 - val_mse: 0.0070
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0302 - mae: 0.1309 - mse: 0.0302
64/93 [===================>..........] - ETA: 0s - loss: 0.0212 - mae: 0.1052 - mse: 0.0212
93/93 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.1003 - mse: 0.0185 - val_loss: 0.0086 - val_mae: 0.0764 - val_mse: 0.0086
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0124 - mae: 0.0907 - mse: 0.0124
64/93 [===================>..........] - ETA: 0s - loss: 0.0162 - mae: 0.0973 - mse: 0.0162
93/93 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.1012 - mse: 0.0169 - val_loss: 0.0130 - val_mae: 0.0984 - val_mse: 0.0130
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0243 - mae: 0.1103 - mse: 0.0243
64/93 [===================>..........] - ETA: 0s - loss: 0.0232 - mae: 0.1143 - mse: 0.0232
93/93 [==============================] - 0s 5ms/step - loss: 0.0239 - mae: 0.1147 - mse: 0.0239 - val_loss: 0.0120 - val_mae: 0.0891 - val_mse: 0.0120
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0143 - mae: 0.0972 - mse: 0.0143
64/93 [===================>..........] - ETA: 0s - loss: 0.0134 - mae: 0.0920 - mse: 0.0134
93/93 [==============================] - 0s 5ms/step - loss: 0.0162 - mae: 0.0981 - mse: 0.0162 - val_loss: 0.0059 - val_mae: 0.0584 - val_mse: 0.0059
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0150 - mae: 0.0962 - mse: 0.0150
64/93 [===================>..........] - ETA: 0s - loss: 0.0227 - mae: 0.1070 - mse: 0.0227
93/93 [==============================] - 0s 5ms/step - loss: 0.0200 - mae: 0.1040 - mse: 0.0200 - val_loss: 0.0060 - val_mae: 0.0607 - val_mse: 0.0060
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0267 - mae: 0.1190 - mse: 0.0267
64/93 [===================>..........] - ETA: 0s - loss: 0.0232 - mae: 0.1091 - mse: 0.0232
93/93 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 0.1027 - mse: 0.0199 - val_loss: 0.0064 - val_mae: 0.0633 - val_mse: 0.0064
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0196 - mae: 0.0988 - mse: 0.0196
64/93 [===================>..........] - ETA: 0s - loss: 0.0221 - mae: 0.1065 - mse: 0.0221
93/93 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 0.1001 - mse: 0.0191 - val_loss: 0.0068 - val_mae: 0.0643 - val_mse: 0.0068
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0094 - mae: 0.0764 - mse: 0.0094
64/93 [===================>..........] - ETA: 0s - loss: 0.0151 - mae: 0.0858 - mse: 0.0151
93/93 [==============================] - 0s 5ms/step - loss: 0.0136 - mae: 0.0841 - mse: 0.0136 - val_loss: 0.0065 - val_mae: 0.0647 - val_mse: 0.0065
Saving trained model...
89
Testing...
heightdiff= [ 0.          0.          0.         20.12910843  0.          0.        ]
average prediction= [3.721635]
baseline= 10.833333333333334
eachuser= [0. 0. 0. 9. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 2.236567603217231
85 -:- nan
60 -:- nan
['train-weight-11.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
60 34
60 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
60 38
60 39
60 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
50 71
2_165_50_11_csi_a11_29.dat
50 73
50 74
50 75
50 76
50 77
50 78
2_165_50_11_csi_a11_19.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
2_165_50_11_csi_a11_6.dat
50 96
2_165_50_11_csi_a11_28.dat
50 98
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
1_175_70_11_csi_a11_29.dat
70 120
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
85 135
85 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
85 141
1_180_85_11_csi_a11_28.dat
85 143
85 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
85 150
85 151
85 152
85 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
75 161
75 162
75 163
75 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
75 167
1_180_75_11_csi_a11_21.dat
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
75 182
1_180_75_11_csi_a11_16.dat
75 184
75 185
75 186
75 187
75 188
75 189
75 190
1_173_85_11_csi_a11_22.dat
85 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
85 197
85 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
85 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
85 204
1_173_85_11_csi_a11_2.dat
85 206
1_173_85_11_csi_a11_24.dat
85 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
85 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85
 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 85 85 85 85 85 85 85 85]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.4767 - mae: 0.6359 - mse: 0.4767
64/93 [===================>..........] - ETA: 0s - loss: 0.3624 - mae: 0.5317 - mse: 0.3624
93/93 [==============================] - 1s 9ms/step - loss: 0.2888 - mae: 0.4564 - mse: 0.2888 - val_loss: 0.1207 - val_mae: 0.3013 - val_mse: 0.1207
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1836 - mae: 0.3295 - mse: 0.1836
64/93 [===================>..........] - ETA: 0s - loss: 0.1509 - mae: 0.3094 - mse: 0.1509
93/93 [==============================] - 0s 5ms/step - loss: 0.1439 - mae: 0.2999 - mse: 0.1439 - val_loss: 0.1633 - val_mae: 0.3053 - val_mse: 0.1633
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1805 - mae: 0.3236 - mse: 0.1805
64/93 [===================>..........] - ETA: 0s - loss: 0.1398 - mae: 0.2895 - mse: 0.1398
93/93 [==============================] - 1s 5ms/step - loss: 0.1366 - mae: 0.2903 - mse: 0.1366 - val_loss: 0.0912 - val_mae: 0.2801 - val_mse: 0.0912
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1643 - mae: 0.3174 - mse: 0.1643
64/93 [===================>..........] - ETA: 0s - loss: 0.1254 - mae: 0.2789 - mse: 0.1254
93/93 [==============================] - 1s 5ms/step - loss: 0.1092 - mae: 0.2619 - mse: 0.1092 - val_loss: 0.0803 - val_mae: 0.2724 - val_mse: 0.0803
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0895 - mae: 0.2314 - mse: 0.0895
64/93 [===================>..........] - ETA: 0s - loss: 0.1038 - mae: 0.2588 - mse: 0.1038
93/93 [==============================] - 1s 5ms/step - loss: 0.1095 - mae: 0.2652 - mse: 0.1095 - val_loss: 0.0726 - val_mae: 0.2566 - val_mse: 0.0726
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1243 - mae: 0.3003 - mse: 0.1243
64/93 [===================>..........] - ETA: 0s - loss: 0.1046 - mae: 0.2724 - mse: 0.1046
93/93 [==============================] - 0s 5ms/step - loss: 0.0902 - mae: 0.2483 - mse: 0.0902 - val_loss: 0.0553 - val_mae: 0.2285 - val_mse: 0.0553
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0921 - mae: 0.2520 - mse: 0.0921
64/93 [===================>..........] - ETA: 0s - loss: 0.0827 - mae: 0.2341 - mse: 0.0827
93/93 [==============================] - 1s 5ms/step - loss: 0.0781 - mae: 0.2258 - mse: 0.0781 - val_loss: 0.0426 - val_mae: 0.1922 - val_mse: 0.0426
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0853 - mae: 0.2310 - mse: 0.0853
64/93 [===================>..........] - ETA: 0s - loss: 0.0730 - mae: 0.2132 - mse: 0.0730
93/93 [==============================] - 0s 5ms/step - loss: 0.0678 - mae: 0.2063 - mse: 0.0678 - val_loss: 0.0296 - val_mae: 0.1588 - val_mse: 0.0296
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0601 - mae: 0.1928 - mse: 0.0601
64/93 [===================>..........] - ETA: 0s - loss: 0.0587 - mae: 0.1943 - mse: 0.0587
93/93 [==============================] - 0s 5ms/step - loss: 0.0523 - mae: 0.1874 - mse: 0.0523 - val_loss: 0.0211 - val_mae: 0.1366 - val_mse: 0.0211
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0696 - mae: 0.2161 - mse: 0.0696
64/93 [===================>..........] - ETA: 0s - loss: 0.0548 - mae: 0.1918 - mse: 0.0548
93/93 [==============================] - 0s 5ms/step - loss: 0.0455 - mae: 0.1707 - mse: 0.0455 - val_loss: 0.0172 - val_mae: 0.1228 - val_mse: 0.0172
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0430 - mae: 0.1595 - mse: 0.0430
64/93 [===================>..........] - ETA: 0s - loss: 0.0489 - mae: 0.1738 - mse: 0.0489
93/93 [==============================] - 0s 5ms/step - loss: 0.0437 - mae: 0.1670 - mse: 0.0437 - val_loss: 0.0106 - val_mae: 0.0927 - val_mse: 0.0106
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0433 - mae: 0.1754 - mse: 0.0433
64/93 [===================>..........] - ETA: 0s - loss: 0.0420 - mae: 0.1719 - mse: 0.0420
93/93 [==============================] - 1s 5ms/step - loss: 0.0436 - mae: 0.1770 - mse: 0.0436 - val_loss: 0.0062 - val_mae: 0.0642 - val_mse: 0.0062
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0388 - mae: 0.1449 - mse: 0.0388
64/93 [===================>..........] - ETA: 0s - loss: 0.0304 - mae: 0.1291 - mse: 0.0304
93/93 [==============================] - 1s 6ms/step - loss: 0.0370 - mae: 0.1411 - mse: 0.0370 - val_loss: 0.0065 - val_mae: 0.0675 - val_mse: 0.0065
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0272 - mae: 0.1186 - mse: 0.0272
64/93 [===================>..........] - ETA: 0s - loss: 0.0256 - mae: 0.1163 - mse: 0.0256
93/93 [==============================] - 1s 5ms/step - loss: 0.0305 - mae: 0.1283 - mse: 0.0305 - val_loss: 0.0010 - val_mae: 0.0232 - val_mse: 0.0010
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0213 - mae: 0.1165 - mse: 0.0213
64/93 [===================>..........] - ETA: 0s - loss: 0.0215 - mae: 0.1135 - mse: 0.0215
93/93 [==============================] - 1s 5ms/step - loss: 0.0209 - mae: 0.1145 - mse: 0.0209 - val_loss: 0.0019 - val_mae: 0.0385 - val_mse: 0.0019
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0352 - mae: 0.1428 - mse: 0.0352
64/93 [===================>..........] - ETA: 0s - loss: 0.0286 - mae: 0.1264 - mse: 0.0286
93/93 [==============================] - 0s 5ms/step - loss: 0.0297 - mae: 0.1311 - mse: 0.0297 - val_loss: 0.0088 - val_mae: 0.0868 - val_mse: 0.0088
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0249 - mae: 0.1224 - mse: 0.0249
64/93 [===================>..........] - ETA: 0s - loss: 0.0239 - mae: 0.1154 - mse: 0.0239
93/93 [==============================] - 0s 5ms/step - loss: 0.0220 - mae: 0.1109 - mse: 0.0220 - val_loss: 0.0086 - val_mae: 0.0812 - val_mse: 0.0086
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0379 - mae: 0.1274 - mse: 0.0379
64/93 [===================>..........] - ETA: 0s - loss: 0.0290 - mae: 0.1176 - mse: 0.0290
93/93 [==============================] - 0s 5ms/step - loss: 0.0254 - mae: 0.1139 - mse: 0.0254 - val_loss: 0.0054 - val_mae: 0.0682 - val_mse: 0.0054
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0307 - mae: 0.1363 - mse: 0.0307
64/93 [===================>..........] - ETA: 0s - loss: 0.0256 - mae: 0.1195 - mse: 0.0256
93/93 [==============================] - 0s 5ms/step - loss: 0.0247 - mae: 0.1179 - mse: 0.0247 - val_loss: 0.0076 - val_mae: 0.0719 - val_mse: 0.0076
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0174 - mae: 0.1037 - mse: 0.0174
64/93 [===================>..........] - ETA: 0s - loss: 0.0227 - mae: 0.1142 - mse: 0.0227
93/93 [==============================] - 0s 5ms/step - loss: 0.0213 - mae: 0.1095 - mse: 0.0213 - val_loss: 0.0102 - val_mae: 0.0890 - val_mse: 0.0102
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0225 - mae: 0.1193 - mse: 0.0225
64/93 [===================>..........] - ETA: 0s - loss: 0.0203 - mae: 0.1008 - mse: 0.0203
93/93 [==============================] - 0s 5ms/step - loss: 0.0236 - mae: 0.1132 - mse: 0.0236 - val_loss: 0.0043 - val_mae: 0.0534 - val_mse: 0.0043
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0154 - mae: 0.0981 - mse: 0.0154
64/93 [===================>..........] - ETA: 0s - loss: 0.0246 - mae: 0.1161 - mse: 0.0246
93/93 [==============================] - 1s 5ms/step - loss: 0.0218 - mae: 0.1104 - mse: 0.0218 - val_loss: 0.0040 - val_mae: 0.0500 - val_mse: 0.0040
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0265 - mae: 0.1280 - mse: 0.0265
64/93 [===================>..........] - ETA: 0s - loss: 0.0210 - mae: 0.1065 - mse: 0.0210
93/93 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 0.1039 - mse: 0.0199 - val_loss: 0.0068 - val_mae: 0.0669 - val_mse: 0.0068
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0215 - mae: 0.1092 - mse: 0.0215
64/93 [===================>..........] - ETA: 0s - loss: 0.0183 - mae: 0.1032 - mse: 0.0183
93/93 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0962 - mse: 0.0160 - val_loss: 0.0049 - val_mae: 0.0555 - val_mse: 0.0049
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0192 - mae: 0.0938 - mse: 0.0192
64/93 [===================>..........] - ETA: 0s - loss: 0.0154 - mae: 0.0882 - mse: 0.0154
93/93 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0909 - mse: 0.0148 - val_loss: 0.0049 - val_mae: 0.0568 - val_mse: 0.0049
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0163 - mae: 0.0918 - mse: 0.0163
64/93 [===================>..........] - ETA: 0s - loss: 0.0136 - mae: 0.0904 - mse: 0.0136
93/93 [==============================] - 0s 5ms/step - loss: 0.0172 - mae: 0.0972 - mse: 0.0172 - val_loss: 0.0124 - val_mae: 0.0991 - val_mse: 0.0124
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0146 - mae: 0.0842 - mse: 0.0146
64/93 [===================>..........] - ETA: 0s - loss: 0.0165 - mae: 0.0942 - mse: 0.0165
93/93 [==============================] - 0s 5ms/step - loss: 0.0150 - mae: 0.0911 - mse: 0.0150 - val_loss: 0.0085 - val_mae: 0.0764 - val_mse: 0.0085
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0111 - mae: 0.0787 - mse: 0.0111
64/93 [===================>..........] - ETA: 0s - loss: 0.0145 - mae: 0.0914 - mse: 0.0145
93/93 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0925 - mse: 0.0142 - val_loss: 0.0042 - val_mae: 0.0570 - val_mse: 0.0042
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0152 - mae: 0.0915 - mse: 0.0152
64/93 [===================>..........] - ETA: 0s - loss: 0.0131 - mae: 0.0875 - mse: 0.0131
93/93 [==============================] - 0s 5ms/step - loss: 0.0134 - mae: 0.0896 - mse: 0.0134 - val_loss: 0.0055 - val_mae: 0.0607 - val_mse: 0.0055
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0129 - mae: 0.0911 - mse: 0.0129
64/93 [===================>..........] - ETA: 0s - loss: 0.0127 - mae: 0.0945 - mse: 0.0127
93/93 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0926 - mse: 0.0127 - val_loss: 0.0137 - val_mae: 0.1071 - val_mse: 0.0137
Saving trained model...
89
Testing...
heightdiff= [ 0.          0.          0.         13.29055023  0.          0.        ]
average prediction= [4.9274964]
baseline= 10.277777777777779
eachuser= [0. 0. 0. 8. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.6613187789916992
85 -:- nan
60 -:- nan
['train-weight-11.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
60 34
60 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
60 38
60 39
60 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
50 71
2_165_50_11_csi_a11_29.dat
50 73
50 74
50 75
50 76
50 77
50 78
2_165_50_11_csi_a11_19.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
2_165_50_11_csi_a11_6.dat
50 96
2_165_50_11_csi_a11_28.dat
50 98
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
1_175_70_11_csi_a11_29.dat
70 120
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
85 135
85 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
85 141
1_180_85_11_csi_a11_28.dat
85 143
85 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
85 150
85 151
85 152
85 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
75 161
75 162
75 163
75 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
75 167
1_180_75_11_csi_a11_21.dat
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
75 182
1_180_75_11_csi_a11_16.dat
75 184
75 185
75 186
75 187
75 188
75 189
75 190
1_173_85_11_csi_a11_22.dat
85 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
85 197
85 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
85 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
85 204
1_173_85_11_csi_a11_2.dat
85 206
1_173_85_11_csi_a11_24.dat
85 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
85 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85
 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 85 85 85 85 85 85 85 85]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.3109 - mae: 0.4632 - mse: 0.3109
64/93 [===================>..........] - ETA: 0s - loss: 0.2546 - mae: 0.4207 - mse: 0.2546
93/93 [==============================] - 1s 9ms/step - loss: 0.2196 - mae: 0.3871 - mse: 0.2196 - val_loss: 0.1102 - val_mae: 0.3002 - val_mse: 0.1102
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1361 - mae: 0.3054 - mse: 0.1361
64/93 [===================>..........] - ETA: 0s - loss: 0.1241 - mae: 0.2865 - mse: 0.1241
93/93 [==============================] - 0s 5ms/step - loss: 0.1126 - mae: 0.2708 - mse: 0.1126 - val_loss: 0.0847 - val_mae: 0.2729 - val_mse: 0.0847
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1022 - mae: 0.2608 - mse: 0.1022
64/93 [===================>..........] - ETA: 0s - loss: 0.1030 - mae: 0.2803 - mse: 0.1030
93/93 [==============================] - 1s 5ms/step - loss: 0.1004 - mae: 0.2718 - mse: 0.1004 - val_loss: 0.0854 - val_mae: 0.2766 - val_mse: 0.0854
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0760 - mae: 0.2330 - mse: 0.0760
64/93 [===================>..........] - ETA: 0s - loss: 0.0713 - mae: 0.2236 - mse: 0.0713
93/93 [==============================] - 1s 5ms/step - loss: 0.0718 - mae: 0.2278 - mse: 0.0718 - val_loss: 0.0868 - val_mae: 0.2670 - val_mse: 0.0868
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0545 - mae: 0.2000 - mse: 0.0545
64/93 [===================>..........] - ETA: 0s - loss: 0.0610 - mae: 0.2144 - mse: 0.0610
93/93 [==============================] - 1s 6ms/step - loss: 0.0630 - mae: 0.2144 - mse: 0.0630 - val_loss: 0.0655 - val_mae: 0.2343 - val_mse: 0.0655
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0482 - mae: 0.1989 - mse: 0.0482
64/93 [===================>..........] - ETA: 0s - loss: 0.0528 - mae: 0.1965 - mse: 0.0528
93/93 [==============================] - 0s 5ms/step - loss: 0.0485 - mae: 0.1874 - mse: 0.0485 - val_loss: 0.0454 - val_mae: 0.1920 - val_mse: 0.0454
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0679 - mae: 0.2113 - mse: 0.0679
64/93 [===================>..........] - ETA: 0s - loss: 0.0615 - mae: 0.2010 - mse: 0.0615
93/93 [==============================] - 1s 5ms/step - loss: 0.0569 - mae: 0.1929 - mse: 0.0569 - val_loss: 0.0393 - val_mae: 0.1729 - val_mse: 0.0393
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0575 - mae: 0.1886 - mse: 0.0575
64/93 [===================>..........] - ETA: 0s - loss: 0.0460 - mae: 0.1755 - mse: 0.0460
93/93 [==============================] - 0s 5ms/step - loss: 0.0472 - mae: 0.1719 - mse: 0.0472 - val_loss: 0.0370 - val_mae: 0.1585 - val_mse: 0.0370
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0316 - mae: 0.1346 - mse: 0.0316
64/93 [===================>..........] - ETA: 0s - loss: 0.0293 - mae: 0.1215 - mse: 0.0293
93/93 [==============================] - 0s 5ms/step - loss: 0.0385 - mae: 0.1350 - mse: 0.0385 - val_loss: 0.0216 - val_mae: 0.1179 - val_mse: 0.0216
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0378 - mae: 0.1506 - mse: 0.0378
64/93 [===================>..........] - ETA: 0s - loss: 0.0335 - mae: 0.1454 - mse: 0.0335
93/93 [==============================] - 0s 5ms/step - loss: 0.0375 - mae: 0.1497 - mse: 0.0375 - val_loss: 0.0143 - val_mae: 0.1015 - val_mse: 0.0143
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0249 - mae: 0.1134 - mse: 0.0249
64/93 [===================>..........] - ETA: 0s - loss: 0.0347 - mae: 0.1435 - mse: 0.0347
93/93 [==============================] - 0s 5ms/step - loss: 0.0317 - mae: 0.1357 - mse: 0.0317 - val_loss: 0.0168 - val_mae: 0.0972 - val_mse: 0.0168
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0399 - mae: 0.1525 - mse: 0.0399
64/93 [===================>..........] - ETA: 0s - loss: 0.0456 - mae: 0.1553 - mse: 0.0456
93/93 [==============================] - 0s 5ms/step - loss: 0.0387 - mae: 0.1433 - mse: 0.0387 - val_loss: 0.0125 - val_mae: 0.0782 - val_mse: 0.0125
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0227 - mae: 0.1088 - mse: 0.0227
64/93 [===================>..........] - ETA: 0s - loss: 0.0280 - mae: 0.1195 - mse: 0.0280
93/93 [==============================] - 0s 5ms/step - loss: 0.0292 - mae: 0.1216 - mse: 0.0292 - val_loss: 0.0103 - val_mae: 0.0706 - val_mse: 0.0103
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0439 - mae: 0.1592 - mse: 0.0439
64/93 [===================>..........] - ETA: 0s - loss: 0.0315 - mae: 0.1344 - mse: 0.0315
93/93 [==============================] - 0s 5ms/step - loss: 0.0288 - mae: 0.1306 - mse: 0.0288 - val_loss: 0.0115 - val_mae: 0.0723 - val_mse: 0.0115
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0228 - mae: 0.1072 - mse: 0.0228
64/93 [===================>..........] - ETA: 0s - loss: 0.0298 - mae: 0.1275 - mse: 0.0298
93/93 [==============================] - 1s 5ms/step - loss: 0.0265 - mae: 0.1182 - mse: 0.0265 - val_loss: 0.0093 - val_mae: 0.0648 - val_mse: 0.0093
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0251 - mae: 0.1134 - mse: 0.0251
64/93 [===================>..........] - ETA: 0s - loss: 0.0285 - mae: 0.1257 - mse: 0.0285
93/93 [==============================] - 0s 5ms/step - loss: 0.0245 - mae: 0.1155 - mse: 0.0245 - val_loss: 0.0124 - val_mae: 0.0753 - val_mse: 0.0124
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0212 - mae: 0.0992 - mse: 0.0212
64/93 [===================>..........] - ETA: 0s - loss: 0.0240 - mae: 0.1149 - mse: 0.0240
93/93 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 0.1059 - mse: 0.0205 - val_loss: 0.0075 - val_mae: 0.0587 - val_mse: 0.0075
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0186 - mae: 0.1042 - mse: 0.0186
64/93 [===================>..........] - ETA: 0s - loss: 0.0192 - mae: 0.1091 - mse: 0.0192
93/93 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 0.1037 - mse: 0.0180 - val_loss: 0.0105 - val_mae: 0.0760 - val_mse: 0.0105
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0200 - mae: 0.1056 - mse: 0.0200
64/93 [===================>..........] - ETA: 0s - loss: 0.0124 - mae: 0.0803 - mse: 0.0124
93/93 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0878 - mse: 0.0160 - val_loss: 0.0104 - val_mae: 0.0795 - val_mse: 0.0104
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0153 - mae: 0.0958 - mse: 0.0153
64/93 [===================>..........] - ETA: 0s - loss: 0.0142 - mae: 0.0940 - mse: 0.0142
93/93 [==============================] - 1s 5ms/step - loss: 0.0160 - mae: 0.0998 - mse: 0.0160 - val_loss: 0.0082 - val_mae: 0.0709 - val_mse: 0.0082
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0267 - mae: 0.1289 - mse: 0.0267
64/93 [===================>..........] - ETA: 0s - loss: 0.0211 - mae: 0.1123 - mse: 0.0211
93/93 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 0.1027 - mse: 0.0188 - val_loss: 0.0308 - val_mae: 0.1451 - val_mse: 0.0308
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0254 - mae: 0.1130 - mse: 0.0254
64/93 [===================>..........] - ETA: 0s - loss: 0.0212 - mae: 0.1014 - mse: 0.0212
93/93 [==============================] - 0s 5ms/step - loss: 0.0220 - mae: 0.1005 - mse: 0.0220 - val_loss: 0.0082 - val_mae: 0.0598 - val_mse: 0.0082
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0134 - mae: 0.0919 - mse: 0.0134
64/93 [===================>..........] - ETA: 0s - loss: 0.0154 - mae: 0.0977 - mse: 0.0154
93/93 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 0.1034 - mse: 0.0166 - val_loss: 0.0069 - val_mae: 0.0562 - val_mse: 0.0069
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0127 - mae: 0.0832 - mse: 0.0127
64/93 [===================>..........] - ETA: 0s - loss: 0.0141 - mae: 0.0869 - mse: 0.0141
93/93 [==============================] - 0s 5ms/step - loss: 0.0144 - mae: 0.0885 - mse: 0.0144 - val_loss: 0.0188 - val_mae: 0.1004 - val_mse: 0.0188
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0175 - mae: 0.0970 - mse: 0.0175
64/93 [===================>..........] - ETA: 0s - loss: 0.0143 - mae: 0.0885 - mse: 0.0143
93/93 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0877 - mse: 0.0137 - val_loss: 0.0090 - val_mae: 0.0625 - val_mse: 0.0090
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0105 - mae: 0.0835 - mse: 0.0105
64/93 [===================>..........] - ETA: 0s - loss: 0.0092 - mae: 0.0750 - mse: 0.0092
93/93 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0778 - mse: 0.0098 - val_loss: 0.0056 - val_mae: 0.0566 - val_mse: 0.0056
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0103 - mae: 0.0795 - mse: 0.0103
64/93 [===================>..........] - ETA: 0s - loss: 0.0096 - mae: 0.0757 - mse: 0.0096
93/93 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0835 - mse: 0.0143 - val_loss: 0.0097 - val_mae: 0.0674 - val_mse: 0.0097
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0123 - mae: 0.0856 - mse: 0.0123
64/93 [===================>..........] - ETA: 0s - loss: 0.0174 - mae: 0.0921 - mse: 0.0174
93/93 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0856 - mse: 0.0145 - val_loss: 0.0064 - val_mae: 0.0588 - val_mse: 0.0064
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0141 - mae: 0.0891 - mse: 0.0141
64/93 [===================>..........] - ETA: 0s - loss: 0.0132 - mae: 0.0775 - mse: 0.0132
93/93 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0789 - mse: 0.0129 - val_loss: 0.0052 - val_mae: 0.0520 - val_mse: 0.0052
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0107 - mae: 0.0766 - mse: 0.0107
64/93 [===================>..........] - ETA: 0s - loss: 0.0102 - mae: 0.0735 - mse: 0.0102
93/93 [==============================] - 0s 5ms/step - loss: 0.0110 - mae: 0.0776 - mse: 0.0110 - val_loss: 0.0085 - val_mae: 0.0630 - val_mse: 0.0085
Saving trained model...
89
Testing...
heightdiff= [0.         0.         0.         6.13075638 0.         0.        ]
average prediction= [3.3149939]
baseline= 8.796296296296296
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.532689094543457
85 -:- nan
60 -:- nan
['train-weight-11.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
60 34
60 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
60 38
60 39
60 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
50 71
2_165_50_11_csi_a11_29.dat
50 73
50 74
50 75
50 76
50 77
50 78
2_165_50_11_csi_a11_19.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
2_165_50_11_csi_a11_6.dat
50 96
2_165_50_11_csi_a11_28.dat
50 98
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
1_175_70_11_csi_a11_29.dat
70 120
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
85 135
85 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
85 141
1_180_85_11_csi_a11_28.dat
85 143
85 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
85 150
85 151
85 152
85 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
75 161
75 162
75 163
75 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
75 167
1_180_75_11_csi_a11_21.dat
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
75 182
1_180_75_11_csi_a11_16.dat
75 184
75 185
75 186
75 187
75 188
75 189
75 190
1_173_85_11_csi_a11_22.dat
85 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
85 197
85 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
85 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
85 204
1_173_85_11_csi_a11_2.dat
85 206
1_173_85_11_csi_a11_24.dat
85 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
85 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85
 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 85 85 85 85 85 85 85 85]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.2477 - mae: 0.4291 - mse: 0.2477
64/93 [===================>..........] - ETA: 0s - loss: 0.2258 - mae: 0.4107 - mse: 0.2258
93/93 [==============================] - 1s 9ms/step - loss: 0.1936 - mae: 0.3720 - mse: 0.1936 - val_loss: 0.0914 - val_mae: 0.2689 - val_mse: 0.0914
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0879 - mae: 0.2475 - mse: 0.0879
64/93 [===================>..........] - ETA: 0s - loss: 0.0910 - mae: 0.2495 - mse: 0.0910
93/93 [==============================] - 1s 5ms/step - loss: 0.1107 - mae: 0.2718 - mse: 0.1107 - val_loss: 0.1079 - val_mae: 0.2886 - val_mse: 0.1079
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1267 - mae: 0.3052 - mse: 0.1267
64/93 [===================>..........] - ETA: 0s - loss: 0.1095 - mae: 0.2686 - mse: 0.1095
93/93 [==============================] - 1s 5ms/step - loss: 0.0871 - mae: 0.2300 - mse: 0.0871 - val_loss: 0.0664 - val_mae: 0.2244 - val_mse: 0.0664
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0679 - mae: 0.2024 - mse: 0.0679
64/93 [===================>..........] - ETA: 0s - loss: 0.0629 - mae: 0.2041 - mse: 0.0629
93/93 [==============================] - 1s 5ms/step - loss: 0.0655 - mae: 0.2109 - mse: 0.0655 - val_loss: 0.0626 - val_mae: 0.2049 - val_mse: 0.0626
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0944 - mae: 0.2418 - mse: 0.0944
64/93 [===================>..........] - ETA: 0s - loss: 0.0863 - mae: 0.2398 - mse: 0.0863
93/93 [==============================] - 0s 5ms/step - loss: 0.0783 - mae: 0.2316 - mse: 0.0783 - val_loss: 0.0504 - val_mae: 0.1836 - val_mse: 0.0504
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0462 - mae: 0.1750 - mse: 0.0462
64/93 [===================>..........] - ETA: 0s - loss: 0.0598 - mae: 0.1953 - mse: 0.0598
93/93 [==============================] - 0s 5ms/step - loss: 0.0543 - mae: 0.1824 - mse: 0.0543 - val_loss: 0.0352 - val_mae: 0.1625 - val_mse: 0.0352
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0326 - mae: 0.1407 - mse: 0.0326
64/93 [===================>..........] - ETA: 0s - loss: 0.0448 - mae: 0.1668 - mse: 0.0448
93/93 [==============================] - 1s 6ms/step - loss: 0.0448 - mae: 0.1726 - mse: 0.0448 - val_loss: 0.0290 - val_mae: 0.1483 - val_mse: 0.0290
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0188 - mae: 0.1109 - mse: 0.0188
64/93 [===================>..........] - ETA: 0s - loss: 0.0325 - mae: 0.1469 - mse: 0.0325
93/93 [==============================] - 0s 5ms/step - loss: 0.0421 - mae: 0.1678 - mse: 0.0421 - val_loss: 0.0230 - val_mae: 0.1293 - val_mse: 0.0230
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0360 - mae: 0.1520 - mse: 0.0360
64/93 [===================>..........] - ETA: 0s - loss: 0.0313 - mae: 0.1460 - mse: 0.0313
93/93 [==============================] - 1s 6ms/step - loss: 0.0313 - mae: 0.1450 - mse: 0.0313 - val_loss: 0.0239 - val_mae: 0.1259 - val_mse: 0.0239
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0382 - mae: 0.1527 - mse: 0.0382
64/93 [===================>..........] - ETA: 0s - loss: 0.0282 - mae: 0.1295 - mse: 0.0282
93/93 [==============================] - 1s 5ms/step - loss: 0.0315 - mae: 0.1371 - mse: 0.0315 - val_loss: 0.0221 - val_mae: 0.1191 - val_mse: 0.0221
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0309 - mae: 0.1320 - mse: 0.0309
64/93 [===================>..........] - ETA: 0s - loss: 0.0314 - mae: 0.1318 - mse: 0.0314
93/93 [==============================] - 1s 5ms/step - loss: 0.0321 - mae: 0.1319 - mse: 0.0321 - val_loss: 0.0152 - val_mae: 0.1020 - val_mse: 0.0152
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0355 - mae: 0.1322 - mse: 0.0355
64/93 [===================>..........] - ETA: 0s - loss: 0.0357 - mae: 0.1374 - mse: 0.0357
93/93 [==============================] - 1s 5ms/step - loss: 0.0317 - mae: 0.1335 - mse: 0.0317 - val_loss: 0.0124 - val_mae: 0.0920 - val_mse: 0.0124
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0307 - mae: 0.1284 - mse: 0.0307
64/93 [===================>..........] - ETA: 0s - loss: 0.0294 - mae: 0.1322 - mse: 0.0294
93/93 [==============================] - 1s 5ms/step - loss: 0.0374 - mae: 0.1472 - mse: 0.0374 - val_loss: 0.0130 - val_mae: 0.0927 - val_mse: 0.0130
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0216 - mae: 0.1086 - mse: 0.0216
64/93 [===================>..........] - ETA: 0s - loss: 0.0222 - mae: 0.1078 - mse: 0.0222
93/93 [==============================] - 0s 5ms/step - loss: 0.0226 - mae: 0.1117 - mse: 0.0226 - val_loss: 0.0211 - val_mae: 0.1059 - val_mse: 0.0211
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0307 - mae: 0.1328 - mse: 0.0307
64/93 [===================>..........] - ETA: 0s - loss: 0.0318 - mae: 0.1314 - mse: 0.0318
93/93 [==============================] - 0s 5ms/step - loss: 0.0299 - mae: 0.1281 - mse: 0.0299 - val_loss: 0.0154 - val_mae: 0.0960 - val_mse: 0.0154
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0150 - mae: 0.0881 - mse: 0.0150
64/93 [===================>..........] - ETA: 0s - loss: 0.0167 - mae: 0.0985 - mse: 0.0167
93/93 [==============================] - 1s 5ms/step - loss: 0.0174 - mae: 0.0993 - mse: 0.0174 - val_loss: 0.0125 - val_mae: 0.0881 - val_mse: 0.0125
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0159 - mae: 0.1010 - mse: 0.0159
64/93 [===================>..........] - ETA: 0s - loss: 0.0238 - mae: 0.1126 - mse: 0.0238
93/93 [==============================] - 0s 5ms/step - loss: 0.0236 - mae: 0.1171 - mse: 0.0236 - val_loss: 0.0163 - val_mae: 0.0927 - val_mse: 0.0163
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0160 - mae: 0.1022 - mse: 0.0160
64/93 [===================>..........] - ETA: 0s - loss: 0.0248 - mae: 0.1105 - mse: 0.0248
93/93 [==============================] - 1s 6ms/step - loss: 0.0242 - mae: 0.1096 - mse: 0.0242 - val_loss: 0.0145 - val_mae: 0.0855 - val_mse: 0.0145
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0306 - mae: 0.1382 - mse: 0.0306
64/93 [===================>..........] - ETA: 0s - loss: 0.0204 - mae: 0.1086 - mse: 0.0204
93/93 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 0.1105 - mse: 0.0211 - val_loss: 0.0132 - val_mae: 0.0791 - val_mse: 0.0132
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0163 - mae: 0.0986 - mse: 0.0163
64/93 [===================>..........] - ETA: 0s - loss: 0.0161 - mae: 0.0965 - mse: 0.0161
93/93 [==============================] - 1s 5ms/step - loss: 0.0151 - mae: 0.0961 - mse: 0.0151 - val_loss: 0.0182 - val_mae: 0.0945 - val_mse: 0.0182
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0157 - mae: 0.1062 - mse: 0.0157
64/93 [===================>..........] - ETA: 0s - loss: 0.0134 - mae: 0.0959 - mse: 0.0134
93/93 [==============================] - 0s 5ms/step - loss: 0.0117 - mae: 0.0903 - mse: 0.0117 - val_loss: 0.0195 - val_mae: 0.0976 - val_mse: 0.0195
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0145 - mae: 0.0926 - mse: 0.0145
64/93 [===================>..........] - ETA: 0s - loss: 0.0188 - mae: 0.1091 - mse: 0.0188
93/93 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.1028 - mse: 0.0174 - val_loss: 0.0137 - val_mae: 0.0804 - val_mse: 0.0137
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0122 - mae: 0.0840 - mse: 0.0122
64/93 [===================>..........] - ETA: 0s - loss: 0.0154 - mae: 0.0927 - mse: 0.0154
93/93 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0854 - mse: 0.0130 - val_loss: 0.0204 - val_mae: 0.0976 - val_mse: 0.0204
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0106 - mae: 0.0770 - mse: 0.0106
64/93 [===================>..........] - ETA: 0s - loss: 0.0164 - mae: 0.0896 - mse: 0.0164
93/93 [==============================] - 0s 5ms/step - loss: 0.0149 - mae: 0.0889 - mse: 0.0149 - val_loss: 0.0263 - val_mae: 0.1137 - val_mse: 0.0263
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0136 - mae: 0.0896 - mse: 0.0136
64/93 [===================>..........] - ETA: 0s - loss: 0.0159 - mae: 0.0981 - mse: 0.0159
93/93 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0923 - mse: 0.0146 - val_loss: 0.0095 - val_mae: 0.0651 - val_mse: 0.0095
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0072 - mae: 0.0679 - mse: 0.0072
64/93 [===================>..........] - ETA: 0s - loss: 0.0129 - mae: 0.0850 - mse: 0.0129
93/93 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0947 - mse: 0.0165 - val_loss: 0.0168 - val_mae: 0.0927 - val_mse: 0.0168
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0158 - mae: 0.0978 - mse: 0.0158
64/93 [===================>..........] - ETA: 0s - loss: 0.0159 - mae: 0.0939 - mse: 0.0159
93/93 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0979 - mse: 0.0165 - val_loss: 0.0244 - val_mae: 0.1189 - val_mse: 0.0244
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0094 - mae: 0.0645 - mse: 0.0094
64/93 [===================>..........] - ETA: 0s - loss: 0.0114 - mae: 0.0762 - mse: 0.0114
93/93 [==============================] - 1s 5ms/step - loss: 0.0122 - mae: 0.0786 - mse: 0.0122 - val_loss: 0.0073 - val_mae: 0.0623 - val_mse: 0.0073
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0084 - mae: 0.0764 - mse: 0.0084
64/93 [===================>..........] - ETA: 0s - loss: 0.0116 - mae: 0.0885 - mse: 0.0116
93/93 [==============================] - 0s 5ms/step - loss: 0.0140 - mae: 0.0918 - mse: 0.0140 - val_loss: 0.0106 - val_mae: 0.0733 - val_mse: 0.0106
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0111 - mae: 0.0704 - mse: 0.0111
64/93 [===================>..........] - ETA: 0s - loss: 0.0096 - mae: 0.0706 - mse: 0.0096
93/93 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0823 - mse: 0.0137 - val_loss: 0.0196 - val_mae: 0.0999 - val_mse: 0.0196
Saving trained model...
89
Testing...
heightdiff= [0.         0.         0.         2.12427521 0.         0.        ]
average prediction= [6.9624047]
baseline= 9.537037037037036
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.42485504150390624
85 -:- nan
60 -:- nan
['train-weight-11.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
2_170_60_11_csi_a11_6.dat
2_170_60_11_csi_a11_3.dat
2_170_60_11_csi_a11_4.dat
60 34
60 35
2_170_60_11_csi_a11_5.dat
2_170_60_11_csi_a11_7.dat
60 38
60 39
60 40
1_165_65_11_csi_a11_4.dat
1_165_65_11_csi_a11_20.dat
1_165_65_11_csi_a11_11.dat
1_165_65_11_csi_a11_23.dat
1_165_65_11_csi_a11_16.dat
1_165_65_11_csi_a11_10.dat
1_165_65_11_csi_a11_28.dat
1_165_65_11_csi_a11_19.dat
1_165_65_11_csi_a11_27.dat
1_165_65_11_csi_a11_14.dat
1_165_65_11_csi_a11_26.dat
1_165_65_11_csi_a11_15.dat
1_165_65_11_csi_a11_5.dat
1_165_65_11_csi_a11_13.dat
1_165_65_11_csi_a11_8.dat
1_165_65_11_csi_a11_30.dat
1_165_65_11_csi_a11_6.dat
1_165_65_11_csi_a11_18.dat
1_165_65_11_csi_a11_9.dat
1_165_65_11_csi_a11_24.dat
1_165_65_11_csi_a11_25.dat
1_165_65_11_csi_a11_22.dat
1_165_65_11_csi_a11_12.dat
1_165_65_11_csi_a11_3.dat
1_165_65_11_csi_a11_2.dat
1_165_65_11_csi_a11_29.dat
1_165_65_11_csi_a11_21.dat
1_165_65_11_csi_a11_17.dat
1_165_65_11_csi_a11_7.dat
1_165_65_11_csi_a11_1.dat
50 71
2_165_50_11_csi_a11_29.dat
50 73
50 74
50 75
50 76
50 77
50 78
2_165_50_11_csi_a11_19.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
2_165_50_11_csi_a11_6.dat
50 96
2_165_50_11_csi_a11_28.dat
50 98
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
1_175_70_11_csi_a11_29.dat
70 120
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
1_180_85_11_csi_a11_20.dat
1_180_85_11_csi_a11_4.dat
1_180_85_11_csi_a11_13.dat
1_180_85_11_csi_a11_17.dat
85 135
85 136
1_180_85_11_csi_a11_21.dat
1_180_85_11_csi_a11_18.dat
1_180_85_11_csi_a11_9.dat
1_180_85_11_csi_a11_3.dat
85 141
1_180_85_11_csi_a11_28.dat
85 143
85 144
1_180_85_11_csi_a11_1.dat
1_180_85_11_csi_a11_10.dat
1_180_85_11_csi_a11_14.dat
1_180_85_11_csi_a11_7.dat
1_180_85_11_csi_a11_25.dat
85 150
85 151
85 152
85 153
1_180_85_11_csi_a11_12.dat
1_180_85_11_csi_a11_8.dat
1_180_85_11_csi_a11_5.dat
1_180_85_11_csi_a11_27.dat
1_180_85_11_csi_a11_29.dat
1_180_85_11_csi_a11_2.dat
1_180_85_11_csi_a11_24.dat
75 161
75 162
75 163
75 164
1_180_75_11_csi_a11_25.dat
1_180_75_11_csi_a11_17.dat
75 167
1_180_75_11_csi_a11_21.dat
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
1_180_75_11_csi_a11_15.dat
1_180_75_11_csi_a11_12.dat
75 182
1_180_75_11_csi_a11_16.dat
75 184
75 185
75 186
75 187
75 188
75 189
75 190
1_173_85_11_csi_a11_22.dat
85 192
1_173_85_11_csi_a11_19.dat
1_173_85_11_csi_a11_9.dat
1_173_85_11_csi_a11_18.dat
1_173_85_11_csi_a11_28.dat
85 197
85 198
1_173_85_11_csi_a11_21.dat
1_173_85_11_csi_a11_27.dat
85 201
1_173_85_11_csi_a11_8.dat
1_173_85_11_csi_a11_29.dat
85 204
1_173_85_11_csi_a11_2.dat
85 206
1_173_85_11_csi_a11_24.dat
85 208
1_173_85_11_csi_a11_1.dat
1_173_85_11_csi_a11_6.dat
1_173_85_11_csi_a11_3.dat
1_173_85_11_csi_a11_15.dat
1_173_85_11_csi_a11_30.dat
1_173_85_11_csi_a11_16.dat
85 215
1_173_85_11_csi_a11_25.dat
1_173_85_11_csi_a11_4.dat
1_173_85_11_csi_a11_14.dat
1_173_85_11_csi_a11_12.dat
1_173_85_11_csi_a11_17.dat
(131, 30, 3)
(131, 425, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85
 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 85 85 85 85 85 85 85 85]
(131, 425, 30, 3, 1)

Loaded dataset of 131 samples, each sized (425, 30, 3, 1)


Train on 104 samples
Test on 27 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 425, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 425, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 425, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 425, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 425, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 425, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 425, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 93 samples, validate on 11 samples
Epoch 1/30

32/93 [=========>....................] - ETA: 0s - loss: 0.3592 - mae: 0.5039 - mse: 0.3592
64/93 [===================>..........] - ETA: 0s - loss: 0.2937 - mae: 0.4570 - mse: 0.2937
93/93 [==============================] - 1s 9ms/step - loss: 0.2554 - mae: 0.4220 - mse: 0.2554 - val_loss: 0.0946 - val_mae: 0.2564 - val_mse: 0.0946
Epoch 2/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0911 - mae: 0.2607 - mse: 0.0911
64/93 [===================>..........] - ETA: 0s - loss: 0.0949 - mae: 0.2470 - mse: 0.0949
93/93 [==============================] - 1s 5ms/step - loss: 0.1041 - mae: 0.2522 - mse: 0.1041 - val_loss: 0.0297 - val_mae: 0.1199 - val_mse: 0.0297
Epoch 3/30

32/93 [=========>....................] - ETA: 0s - loss: 0.1126 - mae: 0.2784 - mse: 0.1126
64/93 [===================>..........] - ETA: 0s - loss: 0.1024 - mae: 0.2629 - mse: 0.1024
93/93 [==============================] - 1s 5ms/step - loss: 0.0970 - mae: 0.2548 - mse: 0.0970 - val_loss: 0.0502 - val_mae: 0.1481 - val_mse: 0.0502
Epoch 4/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0573 - mae: 0.1944 - mse: 0.0573
64/93 [===================>..........] - ETA: 0s - loss: 0.0585 - mae: 0.1946 - mse: 0.0585
93/93 [==============================] - 0s 5ms/step - loss: 0.0742 - mae: 0.2137 - mse: 0.0742 - val_loss: 0.1020 - val_mae: 0.2716 - val_mse: 0.1020
Epoch 5/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0577 - mae: 0.1942 - mse: 0.0577
64/93 [===================>..........] - ETA: 0s - loss: 0.0843 - mae: 0.2384 - mse: 0.0843
93/93 [==============================] - 0s 5ms/step - loss: 0.0798 - mae: 0.2264 - mse: 0.0798 - val_loss: 0.0851 - val_mae: 0.2374 - val_mse: 0.0851
Epoch 6/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0933 - mae: 0.2213 - mse: 0.0933
64/93 [===================>..........] - ETA: 0s - loss: 0.0657 - mae: 0.1925 - mse: 0.0657
93/93 [==============================] - 0s 5ms/step - loss: 0.0559 - mae: 0.1781 - mse: 0.0559 - val_loss: 0.0417 - val_mae: 0.1290 - val_mse: 0.0417
Epoch 7/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0323 - mae: 0.1393 - mse: 0.0323
64/93 [===================>..........] - ETA: 0s - loss: 0.0450 - mae: 0.1625 - mse: 0.0450
93/93 [==============================] - 0s 5ms/step - loss: 0.0461 - mae: 0.1696 - mse: 0.0461 - val_loss: 0.0317 - val_mae: 0.1173 - val_mse: 0.0317
Epoch 8/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0556 - mae: 0.2080 - mse: 0.0556
64/93 [===================>..........] - ETA: 0s - loss: 0.0441 - mae: 0.1793 - mse: 0.0441
93/93 [==============================] - 0s 5ms/step - loss: 0.0518 - mae: 0.1903 - mse: 0.0518 - val_loss: 0.0362 - val_mae: 0.1157 - val_mse: 0.0362
Epoch 9/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0255 - mae: 0.1310 - mse: 0.0255
64/93 [===================>..........] - ETA: 0s - loss: 0.0367 - mae: 0.1483 - mse: 0.0367
93/93 [==============================] - 0s 5ms/step - loss: 0.0375 - mae: 0.1472 - mse: 0.0375 - val_loss: 0.0427 - val_mae: 0.1330 - val_mse: 0.0427
Epoch 10/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0313 - mae: 0.1250 - mse: 0.0313
64/93 [===================>..........] - ETA: 0s - loss: 0.0287 - mae: 0.1221 - mse: 0.0287
93/93 [==============================] - 0s 5ms/step - loss: 0.0314 - mae: 0.1266 - mse: 0.0314 - val_loss: 0.0366 - val_mae: 0.1187 - val_mse: 0.0366
Epoch 11/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0246 - mae: 0.1227 - mse: 0.0246
64/93 [===================>..........] - ETA: 0s - loss: 0.0183 - mae: 0.1059 - mse: 0.0183
93/93 [==============================] - 0s 5ms/step - loss: 0.0306 - mae: 0.1246 - mse: 0.0306 - val_loss: 0.0298 - val_mae: 0.0970 - val_mse: 0.0298
Epoch 12/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0543 - mae: 0.1481 - mse: 0.0543
64/93 [===================>..........] - ETA: 0s - loss: 0.0388 - mae: 0.1349 - mse: 0.0388
93/93 [==============================] - 0s 5ms/step - loss: 0.0334 - mae: 0.1252 - mse: 0.0334 - val_loss: 0.0223 - val_mae: 0.0732 - val_mse: 0.0223
Epoch 13/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0242 - mae: 0.1102 - mse: 0.0242
64/93 [===================>..........] - ETA: 0s - loss: 0.0273 - mae: 0.1228 - mse: 0.0273
93/93 [==============================] - 0s 5ms/step - loss: 0.0307 - mae: 0.1295 - mse: 0.0307 - val_loss: 0.0258 - val_mae: 0.0889 - val_mse: 0.0258
Epoch 14/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0179 - mae: 0.1016 - mse: 0.0179
64/93 [===================>..........] - ETA: 0s - loss: 0.0230 - mae: 0.1072 - mse: 0.0230
93/93 [==============================] - 0s 5ms/step - loss: 0.0301 - mae: 0.1212 - mse: 0.0301 - val_loss: 0.0365 - val_mae: 0.1343 - val_mse: 0.0365
Epoch 15/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0418 - mae: 0.1221 - mse: 0.0418
64/93 [===================>..........] - ETA: 0s - loss: 0.0345 - mae: 0.1199 - mse: 0.0345
93/93 [==============================] - 0s 5ms/step - loss: 0.0314 - mae: 0.1125 - mse: 0.0314 - val_loss: 0.0228 - val_mae: 0.0720 - val_mse: 0.0228
Epoch 16/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0193 - mae: 0.1088 - mse: 0.0193
64/93 [===================>..........] - ETA: 0s - loss: 0.0213 - mae: 0.1121 - mse: 0.0213
93/93 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 0.1094 - mse: 0.0219 - val_loss: 0.0204 - val_mae: 0.0748 - val_mse: 0.0204
Epoch 17/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0180 - mae: 0.0843 - mse: 0.0180
64/93 [===================>..........] - ETA: 0s - loss: 0.0252 - mae: 0.1067 - mse: 0.0252
93/93 [==============================] - 0s 5ms/step - loss: 0.0253 - mae: 0.1074 - mse: 0.0253 - val_loss: 0.0312 - val_mae: 0.1278 - val_mse: 0.0312
Epoch 18/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0382 - mae: 0.1379 - mse: 0.0382
64/93 [===================>..........] - ETA: 0s - loss: 0.0296 - mae: 0.1174 - mse: 0.0296
93/93 [==============================] - 0s 5ms/step - loss: 0.0267 - mae: 0.1122 - mse: 0.0267 - val_loss: 0.0326 - val_mae: 0.1402 - val_mse: 0.0326
Epoch 19/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0160 - mae: 0.0911 - mse: 0.0160
64/93 [===================>..........] - ETA: 0s - loss: 0.0199 - mae: 0.0953 - mse: 0.0199
93/93 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.0910 - mse: 0.0185 - val_loss: 0.0203 - val_mae: 0.0985 - val_mse: 0.0203
Epoch 20/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0145 - mae: 0.0916 - mse: 0.0145
64/93 [===================>..........] - ETA: 0s - loss: 0.0156 - mae: 0.0909 - mse: 0.0156
93/93 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 0.0907 - mse: 0.0163 - val_loss: 0.0142 - val_mae: 0.0833 - val_mse: 0.0142
Epoch 21/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0262 - mae: 0.1088 - mse: 0.0262
64/93 [===================>..........] - ETA: 0s - loss: 0.0226 - mae: 0.1046 - mse: 0.0226
93/93 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 0.0980 - mse: 0.0194 - val_loss: 0.0137 - val_mae: 0.0867 - val_mse: 0.0137
Epoch 22/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0096 - mae: 0.0746 - mse: 0.0096
64/93 [===================>..........] - ETA: 0s - loss: 0.0136 - mae: 0.0776 - mse: 0.0136
93/93 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 0.0879 - mse: 0.0180 - val_loss: 0.0248 - val_mae: 0.1266 - val_mse: 0.0248
Epoch 23/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0157 - mae: 0.0743 - mse: 0.0157
64/93 [===================>..........] - ETA: 0s - loss: 0.0128 - mae: 0.0760 - mse: 0.0128
93/93 [==============================] - 0s 5ms/step - loss: 0.0135 - mae: 0.0806 - mse: 0.0135 - val_loss: 0.0157 - val_mae: 0.0950 - val_mse: 0.0157
Epoch 24/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0163 - mae: 0.0922 - mse: 0.0163
64/93 [===================>..........] - ETA: 0s - loss: 0.0143 - mae: 0.0890 - mse: 0.0143
93/93 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0928 - mse: 0.0169 - val_loss: 0.0159 - val_mae: 0.1041 - val_mse: 0.0159
Epoch 25/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0095 - mae: 0.0826 - mse: 0.0095
64/93 [===================>..........] - ETA: 0s - loss: 0.0103 - mae: 0.0830 - mse: 0.0103
93/93 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0875 - mse: 0.0133 - val_loss: 0.0120 - val_mae: 0.0960 - val_mse: 0.0120
Epoch 26/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0150 - mae: 0.0843 - mse: 0.0150
64/93 [===================>..........] - ETA: 0s - loss: 0.0155 - mae: 0.0824 - mse: 0.0155
93/93 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0843 - mse: 0.0148 - val_loss: 0.0136 - val_mae: 0.0964 - val_mse: 0.0136
Epoch 27/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0111 - mae: 0.0835 - mse: 0.0111
64/93 [===================>..........] - ETA: 0s - loss: 0.0144 - mae: 0.0888 - mse: 0.0144
93/93 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0847 - mse: 0.0132 - val_loss: 0.0235 - val_mae: 0.1355 - val_mse: 0.0235
Epoch 28/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0123 - mae: 0.0749 - mse: 0.0123
64/93 [===================>..........] - ETA: 0s - loss: 0.0144 - mae: 0.0800 - mse: 0.0144
93/93 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0743 - mse: 0.0118 - val_loss: 0.0259 - val_mae: 0.1460 - val_mse: 0.0259
Epoch 29/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0102 - mae: 0.0757 - mse: 0.0102
64/93 [===================>..........] - ETA: 0s - loss: 0.0091 - mae: 0.0721 - mse: 0.0091
93/93 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0766 - mse: 0.0107 - val_loss: 0.0161 - val_mae: 0.1088 - val_mse: 0.0161
Epoch 30/30

32/93 [=========>....................] - ETA: 0s - loss: 0.0137 - mae: 0.0925 - mse: 0.0137
64/93 [===================>..........] - ETA: 0s - loss: 0.0099 - mae: 0.0775 - mse: 0.0099
93/93 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0832 - mse: 0.0138 - val_loss: 0.0240 - val_mae: 0.1415 - val_mse: 0.0240
Saving trained model...
89
Testing...
heightdiff= [0.         0.         0.         5.76024246 0.         0.        ]
average prediction= [6.696978]
baseline= 10.092592592592593
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.4400606155395508
85 -:- nan
60 -:- nan
