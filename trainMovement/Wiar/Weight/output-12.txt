['train-weight-12.py', '1']
65 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
65 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
65 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
65 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
60 31
60 32
60 33
60 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
60 37
60 38
2_170_60_12_csi_a12_4.dat
60 40
65 41
65 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
65 48
65 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
65 56
65 57
1_165_65_12_csi_a12_7.dat
65 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
65 70
2_165_50_12_csi_a12_13.dat
50 72
50 73
50 74
50 75
50 76
50 77
50 78
50 79
50 80
50 81
50 82
50 83
50 84
50 85
2_165_50_12_csi_a12_7.dat
50 87
2_165_50_12_csi_a12_23.dat
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
70 119
70 120
70 121
70 122
70 123
70 124
70 125
1_175_70_12_csi_a12_26.dat
70 127
70 128
70 129
70 130
85 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
85 134
85 135
1_180_85_12_csi_a12_19.dat
85 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
85 140
1_180_85_12_csi_a12_12.dat
85 142
85 143
85 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
85 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
75 161
75 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
75 165
75 166
75 167
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
1_180_75_12_csi_a12_12.dat
75 178
1_180_75_12_csi_a12_13.dat
75 180
75 181
75 182
1_180_75_12_csi_a12_14.dat
75 184
75 185
75 186
75 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
75 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[65 65 65 65 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.4132 - mae: 0.5794 - mse: 0.4132
64/75 [========================>.....] - ETA: 0s - loss: 0.2945 - mae: 0.4693 - mse: 0.2945
75/75 [==============================] - 1s 12ms/step - loss: 0.2684 - mae: 0.4417 - mse: 0.2684 - val_loss: 0.2460 - val_mae: 0.4741 - val_mse: 0.2460
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1601 - mae: 0.3246 - mse: 0.1601
64/75 [========================>.....] - ETA: 0s - loss: 0.1501 - mae: 0.3155 - mse: 0.1501
75/75 [==============================] - 0s 6ms/step - loss: 0.1466 - mae: 0.3110 - mse: 0.1466 - val_loss: 0.2333 - val_mae: 0.4543 - val_mse: 0.2333
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1109 - mae: 0.2363 - mse: 0.1109
64/75 [========================>.....] - ETA: 0s - loss: 0.1007 - mae: 0.2406 - mse: 0.1007
75/75 [==============================] - 0s 6ms/step - loss: 0.0983 - mae: 0.2392 - mse: 0.0983 - val_loss: 0.0882 - val_mae: 0.2812 - val_mse: 0.0882
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0920 - mae: 0.2538 - mse: 0.0920
64/75 [========================>.....] - ETA: 0s - loss: 0.0903 - mae: 0.2545 - mse: 0.0903
75/75 [==============================] - 0s 5ms/step - loss: 0.0809 - mae: 0.2371 - mse: 0.0809 - val_loss: 0.0419 - val_mae: 0.1879 - val_mse: 0.0419
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0829 - mae: 0.2515 - mse: 0.0829
64/75 [========================>.....] - ETA: 0s - loss: 0.0789 - mae: 0.2317 - mse: 0.0789
75/75 [==============================] - 0s 6ms/step - loss: 0.0835 - mae: 0.2369 - mse: 0.0835 - val_loss: 0.0341 - val_mae: 0.1658 - val_mse: 0.0341
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0810 - mae: 0.2305 - mse: 0.0810
64/75 [========================>.....] - ETA: 0s - loss: 0.0716 - mae: 0.2192 - mse: 0.0716
75/75 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.2118 - mse: 0.0668 - val_loss: 0.0404 - val_mae: 0.1756 - val_mse: 0.0404
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0552 - mae: 0.1933 - mse: 0.0552
64/75 [========================>.....] - ETA: 0s - loss: 0.0548 - mae: 0.1875 - mse: 0.0548
75/75 [==============================] - 0s 5ms/step - loss: 0.0523 - mae: 0.1854 - mse: 0.0523 - val_loss: 0.0293 - val_mae: 0.1414 - val_mse: 0.0293
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0693 - mae: 0.1972 - mse: 0.0693
64/75 [========================>.....] - ETA: 0s - loss: 0.0559 - mae: 0.1848 - mse: 0.0559
75/75 [==============================] - 0s 6ms/step - loss: 0.0540 - mae: 0.1845 - mse: 0.0540 - val_loss: 0.0146 - val_mae: 0.0980 - val_mse: 0.0146
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0657 - mae: 0.1853 - mse: 0.0657
64/75 [========================>.....] - ETA: 0s - loss: 0.0505 - mae: 0.1700 - mse: 0.0505
75/75 [==============================] - 0s 5ms/step - loss: 0.0519 - mae: 0.1694 - mse: 0.0519 - val_loss: 0.0077 - val_mae: 0.0742 - val_mse: 0.0077
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0406 - mae: 0.1634 - mse: 0.0406
64/75 [========================>.....] - ETA: 0s - loss: 0.0418 - mae: 0.1486 - mse: 0.0418
75/75 [==============================] - 0s 5ms/step - loss: 0.0395 - mae: 0.1487 - mse: 0.0395 - val_loss: 0.0055 - val_mae: 0.0589 - val_mse: 0.0055
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0297 - mae: 0.1375 - mse: 0.0297
64/75 [========================>.....] - ETA: 0s - loss: 0.0314 - mae: 0.1411 - mse: 0.0314
75/75 [==============================] - 0s 5ms/step - loss: 0.0361 - mae: 0.1517 - mse: 0.0361 - val_loss: 0.0047 - val_mae: 0.0487 - val_mse: 0.0047
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0180 - mae: 0.1116 - mse: 0.0180
64/75 [========================>.....] - ETA: 0s - loss: 0.0298 - mae: 0.1342 - mse: 0.0298
75/75 [==============================] - 0s 5ms/step - loss: 0.0316 - mae: 0.1408 - mse: 0.0316 - val_loss: 0.0047 - val_mae: 0.0418 - val_mse: 0.0047
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0181 - mae: 0.1121 - mse: 0.0181
64/75 [========================>.....] - ETA: 0s - loss: 0.0274 - mae: 0.1319 - mse: 0.0274
75/75 [==============================] - 0s 5ms/step - loss: 0.0271 - mae: 0.1302 - mse: 0.0271 - val_loss: 0.0043 - val_mae: 0.0399 - val_mse: 0.0043
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0261 - mae: 0.1315 - mse: 0.0261
64/75 [========================>.....] - ETA: 0s - loss: 0.0241 - mae: 0.1194 - mse: 0.0241
75/75 [==============================] - 0s 5ms/step - loss: 0.0226 - mae: 0.1172 - mse: 0.0226 - val_loss: 0.0039 - val_mae: 0.0386 - val_mse: 0.0039
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0203 - mae: 0.1073 - mse: 0.0203
64/75 [========================>.....] - ETA: 0s - loss: 0.0233 - mae: 0.1136 - mse: 0.0233
75/75 [==============================] - 0s 6ms/step - loss: 0.0217 - mae: 0.1101 - mse: 0.0217 - val_loss: 0.0035 - val_mae: 0.0394 - val_mse: 0.0035
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0337 - mae: 0.1481 - mse: 0.0337
64/75 [========================>.....] - ETA: 0s - loss: 0.0329 - mae: 0.1374 - mse: 0.0329
75/75 [==============================] - 0s 6ms/step - loss: 0.0313 - mae: 0.1322 - mse: 0.0313 - val_loss: 0.0032 - val_mae: 0.0391 - val_mse: 0.0032
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0236 - mae: 0.1274 - mse: 0.0236
64/75 [========================>.....] - ETA: 0s - loss: 0.0182 - mae: 0.1102 - mse: 0.0182
75/75 [==============================] - 0s 6ms/step - loss: 0.0182 - mae: 0.1082 - mse: 0.0182 - val_loss: 0.0029 - val_mae: 0.0375 - val_mse: 0.0029
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0174 - mae: 0.1100 - mse: 0.0174
64/75 [========================>.....] - ETA: 0s - loss: 0.0216 - mae: 0.1131 - mse: 0.0216
75/75 [==============================] - 0s 6ms/step - loss: 0.0218 - mae: 0.1164 - mse: 0.0218 - val_loss: 0.0030 - val_mae: 0.0406 - val_mse: 0.0030
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0211 - mae: 0.1007 - mse: 0.0211
64/75 [========================>.....] - ETA: 0s - loss: 0.0192 - mae: 0.0979 - mse: 0.0192
75/75 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 0.1002 - mse: 0.0193 - val_loss: 0.0038 - val_mae: 0.0457 - val_mse: 0.0038
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0217 - mae: 0.1137 - mse: 0.0217
64/75 [========================>.....] - ETA: 0s - loss: 0.0193 - mae: 0.1024 - mse: 0.0193
75/75 [==============================] - 0s 6ms/step - loss: 0.0206 - mae: 0.1080 - mse: 0.0206 - val_loss: 0.0035 - val_mae: 0.0431 - val_mse: 0.0035
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0203 - mae: 0.1081 - mse: 0.0203
64/75 [========================>.....] - ETA: 0s - loss: 0.0190 - mae: 0.1027 - mse: 0.0190
75/75 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 0.1031 - mse: 0.0191 - val_loss: 0.0033 - val_mae: 0.0412 - val_mse: 0.0033
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0234 - mae: 0.1219 - mse: 0.0234
64/75 [========================>.....] - ETA: 0s - loss: 0.0209 - mae: 0.1166 - mse: 0.0209
75/75 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 0.1117 - mse: 0.0193 - val_loss: 0.0048 - val_mae: 0.0513 - val_mse: 0.0048
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0141 - mae: 0.0985 - mse: 0.0141
64/75 [========================>.....] - ETA: 0s - loss: 0.0158 - mae: 0.0983 - mse: 0.0158
75/75 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0982 - mse: 0.0153 - val_loss: 0.0050 - val_mae: 0.0531 - val_mse: 0.0050
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0193 - mae: 0.0977 - mse: 0.0193
64/75 [========================>.....] - ETA: 0s - loss: 0.0176 - mae: 0.0996 - mse: 0.0176
75/75 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 0.1058 - mse: 0.0191 - val_loss: 0.0028 - val_mae: 0.0394 - val_mse: 0.0028
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0316 - mae: 0.1369 - mse: 0.0316
64/75 [========================>.....] - ETA: 0s - loss: 0.0281 - mae: 0.1317 - mse: 0.0281
75/75 [==============================] - 0s 5ms/step - loss: 0.0263 - mae: 0.1265 - mse: 0.0263 - val_loss: 0.0030 - val_mae: 0.0430 - val_mse: 0.0030
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0268 - mae: 0.1328 - mse: 0.0268
64/75 [========================>.....] - ETA: 0s - loss: 0.0250 - mae: 0.1246 - mse: 0.0250
75/75 [==============================] - 0s 6ms/step - loss: 0.0253 - mae: 0.1220 - mse: 0.0253 - val_loss: 0.0050 - val_mae: 0.0536 - val_mse: 0.0050
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0288 - mae: 0.1304 - mse: 0.0288
64/75 [========================>.....] - ETA: 0s - loss: 0.0221 - mae: 0.1134 - mse: 0.0221
75/75 [==============================] - 0s 5ms/step - loss: 0.0207 - mae: 0.1103 - mse: 0.0207 - val_loss: 0.0027 - val_mae: 0.0426 - val_mse: 0.0027
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0150 - mae: 0.0985 - mse: 0.0150
64/75 [========================>.....] - ETA: 0s - loss: 0.0140 - mae: 0.0958 - mse: 0.0140
75/75 [==============================] - 0s 5ms/step - loss: 0.0136 - mae: 0.0945 - mse: 0.0136 - val_loss: 0.0025 - val_mae: 0.0430 - val_mse: 0.0025
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0209 - mae: 0.1225 - mse: 0.0209
64/75 [========================>.....] - ETA: 0s - loss: 0.0220 - mae: 0.1206 - mse: 0.0220
75/75 [==============================] - 0s 6ms/step - loss: 0.0231 - mae: 0.1254 - mse: 0.0231 - val_loss: 0.0041 - val_mae: 0.0515 - val_mse: 0.0041
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0112 - mae: 0.0917 - mse: 0.0112
64/75 [========================>.....] - ETA: 0s - loss: 0.0126 - mae: 0.0918 - mse: 0.0126
75/75 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0905 - mse: 0.0122 - val_loss: 0.0041 - val_mae: 0.0504 - val_mse: 0.0041
Saving trained model...
115
Testing...
heightdiff= [0.         0.         0.         4.97039795 0.         0.        ]
average prediction= [2.7428212]
baseline= 7.738095238095238
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.2425994873046875
85 -:- nan
60 -:- nan
['train-weight-12.py', '1']
65 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
65 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
65 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
65 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
60 31
60 32
60 33
60 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
60 37
60 38
2_170_60_12_csi_a12_4.dat
60 40
65 41
65 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
65 48
65 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
65 56
65 57
1_165_65_12_csi_a12_7.dat
65 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
65 70
2_165_50_12_csi_a12_13.dat
50 72
50 73
50 74
50 75
50 76
50 77
50 78
50 79
50 80
50 81
50 82
50 83
50 84
50 85
2_165_50_12_csi_a12_7.dat
50 87
2_165_50_12_csi_a12_23.dat
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
70 119
70 120
70 121
70 122
70 123
70 124
70 125
1_175_70_12_csi_a12_26.dat
70 127
70 128
70 129
70 130
85 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
85 134
85 135
1_180_85_12_csi_a12_19.dat
85 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
85 140
1_180_85_12_csi_a12_12.dat
85 142
85 143
85 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
85 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
75 161
75 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
75 165
75 166
75 167
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
1_180_75_12_csi_a12_12.dat
75 178
1_180_75_12_csi_a12_13.dat
75 180
75 181
75 182
1_180_75_12_csi_a12_14.dat
75 184
75 185
75 186
75 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
75 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[65 65 65 65 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.3359 - mae: 0.5126 - mse: 0.3359
64/75 [========================>.....] - ETA: 0s - loss: 0.2612 - mae: 0.4541 - mse: 0.2612
75/75 [==============================] - 1s 12ms/step - loss: 0.2477 - mae: 0.4390 - mse: 0.2477 - val_loss: 0.1777 - val_mae: 0.3645 - val_mse: 0.1777
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1599 - mae: 0.3228 - mse: 0.1599
64/75 [========================>.....] - ETA: 0s - loss: 0.1620 - mae: 0.3150 - mse: 0.1620
75/75 [==============================] - 1s 7ms/step - loss: 0.1676 - mae: 0.3206 - mse: 0.1676 - val_loss: 0.1756 - val_mae: 0.3597 - val_mse: 0.1756
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1237 - mae: 0.2904 - mse: 0.1237
64/75 [========================>.....] - ETA: 0s - loss: 0.1200 - mae: 0.2741 - mse: 0.1200
75/75 [==============================] - 1s 7ms/step - loss: 0.1113 - mae: 0.2622 - mse: 0.1113 - val_loss: 0.1081 - val_mae: 0.2910 - val_mse: 0.1081
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0769 - mae: 0.2366 - mse: 0.0769
64/75 [========================>.....] - ETA: 0s - loss: 0.0874 - mae: 0.2537 - mse: 0.0874
75/75 [==============================] - 1s 7ms/step - loss: 0.0947 - mae: 0.2619 - mse: 0.0947 - val_loss: 0.0876 - val_mae: 0.2644 - val_mse: 0.0876
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0976 - mae: 0.2775 - mse: 0.0976
64/75 [========================>.....] - ETA: 0s - loss: 0.0931 - mae: 0.2644 - mse: 0.0931
75/75 [==============================] - 1s 7ms/step - loss: 0.0921 - mae: 0.2632 - mse: 0.0921 - val_loss: 0.0738 - val_mae: 0.2531 - val_mse: 0.0738
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0622 - mae: 0.2067 - mse: 0.0622
64/75 [========================>.....] - ETA: 0s - loss: 0.0579 - mae: 0.2012 - mse: 0.0579
75/75 [==============================] - 1s 7ms/step - loss: 0.0598 - mae: 0.2054 - mse: 0.0598 - val_loss: 0.0634 - val_mae: 0.2404 - val_mse: 0.0634
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0473 - mae: 0.1771 - mse: 0.0473
64/75 [========================>.....] - ETA: 0s - loss: 0.0528 - mae: 0.1845 - mse: 0.0528
75/75 [==============================] - 1s 7ms/step - loss: 0.0514 - mae: 0.1843 - mse: 0.0514 - val_loss: 0.0544 - val_mae: 0.2213 - val_mse: 0.0544
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0505 - mae: 0.1925 - mse: 0.0505
64/75 [========================>.....] - ETA: 0s - loss: 0.0614 - mae: 0.2033 - mse: 0.0614
75/75 [==============================] - 1s 7ms/step - loss: 0.0593 - mae: 0.2001 - mse: 0.0593 - val_loss: 0.0404 - val_mae: 0.1891 - val_mse: 0.0404
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0310 - mae: 0.1465 - mse: 0.0310
64/75 [========================>.....] - ETA: 0s - loss: 0.0389 - mae: 0.1634 - mse: 0.0389
75/75 [==============================] - 1s 7ms/step - loss: 0.0378 - mae: 0.1623 - mse: 0.0378 - val_loss: 0.0336 - val_mae: 0.1613 - val_mse: 0.0336
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0405 - mae: 0.1682 - mse: 0.0405
64/75 [========================>.....] - ETA: 0s - loss: 0.0339 - mae: 0.1528 - mse: 0.0339
75/75 [==============================] - 1s 7ms/step - loss: 0.0339 - mae: 0.1547 - mse: 0.0339 - val_loss: 0.0289 - val_mae: 0.1419 - val_mse: 0.0289
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0340 - mae: 0.1476 - mse: 0.0340
64/75 [========================>.....] - ETA: 0s - loss: 0.0276 - mae: 0.1341 - mse: 0.0276
75/75 [==============================] - 1s 7ms/step - loss: 0.0268 - mae: 0.1344 - mse: 0.0268 - val_loss: 0.0241 - val_mae: 0.1186 - val_mse: 0.0241
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0303 - mae: 0.1439 - mse: 0.0303
64/75 [========================>.....] - ETA: 0s - loss: 0.0277 - mae: 0.1352 - mse: 0.0277
75/75 [==============================] - 1s 7ms/step - loss: 0.0312 - mae: 0.1435 - mse: 0.0312 - val_loss: 0.0198 - val_mae: 0.1019 - val_mse: 0.0198
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0263 - mae: 0.1260 - mse: 0.0263
64/75 [========================>.....] - ETA: 0s - loss: 0.0264 - mae: 0.1251 - mse: 0.0264
75/75 [==============================] - 1s 7ms/step - loss: 0.0255 - mae: 0.1230 - mse: 0.0255 - val_loss: 0.0172 - val_mae: 0.1023 - val_mse: 0.0172
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0324 - mae: 0.1344 - mse: 0.0324
64/75 [========================>.....] - ETA: 0s - loss: 0.0241 - mae: 0.1139 - mse: 0.0241
75/75 [==============================] - 1s 7ms/step - loss: 0.0243 - mae: 0.1173 - mse: 0.0243 - val_loss: 0.0144 - val_mae: 0.0887 - val_mse: 0.0144
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0187 - mae: 0.1113 - mse: 0.0187
64/75 [========================>.....] - ETA: 0s - loss: 0.0185 - mae: 0.1077 - mse: 0.0185
75/75 [==============================] - 1s 7ms/step - loss: 0.0207 - mae: 0.1143 - mse: 0.0207 - val_loss: 0.0132 - val_mae: 0.0849 - val_mse: 0.0132
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0132 - mae: 0.0970 - mse: 0.0132
64/75 [========================>.....] - ETA: 0s - loss: 0.0192 - mae: 0.1055 - mse: 0.0192
75/75 [==============================] - 1s 7ms/step - loss: 0.0184 - mae: 0.1044 - mse: 0.0184 - val_loss: 0.0167 - val_mae: 0.0985 - val_mse: 0.0167
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0151 - mae: 0.0928 - mse: 0.0151
64/75 [========================>.....] - ETA: 0s - loss: 0.0165 - mae: 0.0926 - mse: 0.0165
75/75 [==============================] - 1s 7ms/step - loss: 0.0166 - mae: 0.0951 - mse: 0.0166 - val_loss: 0.0181 - val_mae: 0.1074 - val_mse: 0.0181
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0148 - mae: 0.0965 - mse: 0.0148
64/75 [========================>.....] - ETA: 0s - loss: 0.0162 - mae: 0.0983 - mse: 0.0162
75/75 [==============================] - 1s 7ms/step - loss: 0.0159 - mae: 0.0975 - mse: 0.0159 - val_loss: 0.0181 - val_mae: 0.1109 - val_mse: 0.0181
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0127 - mae: 0.0979 - mse: 0.0127
64/75 [========================>.....] - ETA: 0s - loss: 0.0111 - mae: 0.0891 - mse: 0.0111
75/75 [==============================] - 1s 7ms/step - loss: 0.0107 - mae: 0.0866 - mse: 0.0107 - val_loss: 0.0143 - val_mae: 0.0995 - val_mse: 0.0143
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0153 - mae: 0.0919 - mse: 0.0153
64/75 [========================>.....] - ETA: 0s - loss: 0.0141 - mae: 0.0917 - mse: 0.0141
75/75 [==============================] - 1s 7ms/step - loss: 0.0146 - mae: 0.0913 - mse: 0.0146 - val_loss: 0.0113 - val_mae: 0.0854 - val_mse: 0.0113
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0159 - mae: 0.0908 - mse: 0.0159
64/75 [========================>.....] - ETA: 0s - loss: 0.0171 - mae: 0.0934 - mse: 0.0171
75/75 [==============================] - 1s 7ms/step - loss: 0.0158 - mae: 0.0911 - mse: 0.0158 - val_loss: 0.0175 - val_mae: 0.1046 - val_mse: 0.0175
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0187 - mae: 0.1066 - mse: 0.0187
64/75 [========================>.....] - ETA: 0s - loss: 0.0142 - mae: 0.0887 - mse: 0.0142
75/75 [==============================] - 1s 7ms/step - loss: 0.0135 - mae: 0.0871 - mse: 0.0135 - val_loss: 0.0193 - val_mae: 0.1016 - val_mse: 0.0193
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0124 - mae: 0.0850 - mse: 0.0124
64/75 [========================>.....] - ETA: 0s - loss: 0.0108 - mae: 0.0774 - mse: 0.0108
75/75 [==============================] - 1s 7ms/step - loss: 0.0115 - mae: 0.0816 - mse: 0.0115 - val_loss: 0.0124 - val_mae: 0.0775 - val_mse: 0.0124
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0124 - mae: 0.0835 - mse: 0.0124
64/75 [========================>.....] - ETA: 0s - loss: 0.0149 - mae: 0.0908 - mse: 0.0149
75/75 [==============================] - 1s 7ms/step - loss: 0.0166 - mae: 0.0963 - mse: 0.0166 - val_loss: 0.0106 - val_mae: 0.0742 - val_mse: 0.0106
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0100 - mae: 0.0834 - mse: 0.0100
64/75 [========================>.....] - ETA: 0s - loss: 0.0112 - mae: 0.0847 - mse: 0.0112
75/75 [==============================] - 1s 7ms/step - loss: 0.0120 - mae: 0.0876 - mse: 0.0120 - val_loss: 0.0159 - val_mae: 0.0931 - val_mse: 0.0159
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0109 - mae: 0.0866 - mse: 0.0109
64/75 [========================>.....] - ETA: 0s - loss: 0.0109 - mae: 0.0852 - mse: 0.0109
75/75 [==============================] - 1s 7ms/step - loss: 0.0109 - mae: 0.0829 - mse: 0.0109 - val_loss: 0.0143 - val_mae: 0.0933 - val_mse: 0.0143
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0133 - mae: 0.0927 - mse: 0.0133
64/75 [========================>.....] - ETA: 0s - loss: 0.0108 - mae: 0.0805 - mse: 0.0108
75/75 [==============================] - 1s 7ms/step - loss: 0.0100 - mae: 0.0771 - mse: 0.0100 - val_loss: 0.0110 - val_mae: 0.0851 - val_mse: 0.0110
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0214 - mae: 0.0987 - mse: 0.0214
64/75 [========================>.....] - ETA: 0s - loss: 0.0155 - mae: 0.0879 - mse: 0.0155
75/75 [==============================] - 0s 7ms/step - loss: 0.0158 - mae: 0.0906 - mse: 0.0158 - val_loss: 0.0151 - val_mae: 0.0953 - val_mse: 0.0151
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0072 - mae: 0.0682 - mse: 0.0072
64/75 [========================>.....] - ETA: 0s - loss: 0.0105 - mae: 0.0780 - mse: 0.0105
75/75 [==============================] - 1s 7ms/step - loss: 0.0107 - mae: 0.0773 - mse: 0.0107 - val_loss: 0.0162 - val_mae: 0.0910 - val_mse: 0.0162
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0126 - mae: 0.0888 - mse: 0.0126
64/75 [========================>.....] - ETA: 0s - loss: 0.0114 - mae: 0.0817 - mse: 0.0114
75/75 [==============================] - 1s 7ms/step - loss: 0.0117 - mae: 0.0847 - mse: 0.0117 - val_loss: 0.0116 - val_mae: 0.0714 - val_mse: 0.0116
Saving trained model...
115
Testing...
heightdiff= [0.         0.         0.         7.43894958 0.         0.        ]
average prediction= [4.062458]
baseline= 7.5
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.8597373962402344
85 -:- nan
60 -:- nan
['train-weight-12.py', '1']
65 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
65 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
65 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
65 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
60 31
60 32
60 33
60 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
60 37
60 38
2_170_60_12_csi_a12_4.dat
60 40
65 41
65 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
65 48
65 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
65 56
65 57
1_165_65_12_csi_a12_7.dat
65 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
65 70
2_165_50_12_csi_a12_13.dat
50 72
50 73
50 74
50 75
50 76
50 77
50 78
50 79
50 80
50 81
50 82
50 83
50 84
50 85
2_165_50_12_csi_a12_7.dat
50 87
2_165_50_12_csi_a12_23.dat
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
70 119
70 120
70 121
70 122
70 123
70 124
70 125
1_175_70_12_csi_a12_26.dat
70 127
70 128
70 129
70 130
85 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
85 134
85 135
1_180_85_12_csi_a12_19.dat
85 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
85 140
1_180_85_12_csi_a12_12.dat
85 142
85 143
85 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
85 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
75 161
75 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
75 165
75 166
75 167
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
1_180_75_12_csi_a12_12.dat
75 178
1_180_75_12_csi_a12_13.dat
75 180
75 181
75 182
1_180_75_12_csi_a12_14.dat
75 184
75 185
75 186
75 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
75 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[65 65 65 65 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.2199 - mae: 0.3826 - mse: 0.2199
64/75 [========================>.....] - ETA: 0s - loss: 0.2079 - mae: 0.3854 - mse: 0.2079
75/75 [==============================] - 1s 11ms/step - loss: 0.2122 - mae: 0.3886 - mse: 0.2122 - val_loss: 0.1473 - val_mae: 0.3453 - val_mse: 0.1473
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1505 - mae: 0.3104 - mse: 0.1505
64/75 [========================>.....] - ETA: 0s - loss: 0.1498 - mae: 0.3082 - mse: 0.1498
75/75 [==============================] - 0s 7ms/step - loss: 0.1362 - mae: 0.2907 - mse: 0.1362 - val_loss: 0.1241 - val_mae: 0.3014 - val_mse: 0.1241
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1699 - mae: 0.3120 - mse: 0.1699
64/75 [========================>.....] - ETA: 0s - loss: 0.1260 - mae: 0.2715 - mse: 0.1260
75/75 [==============================] - 0s 7ms/step - loss: 0.1177 - mae: 0.2624 - mse: 0.1177 - val_loss: 0.1241 - val_mae: 0.3092 - val_mse: 0.1241
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0714 - mae: 0.2328 - mse: 0.0714
64/75 [========================>.....] - ETA: 0s - loss: 0.0716 - mae: 0.2266 - mse: 0.0716
75/75 [==============================] - 0s 6ms/step - loss: 0.0751 - mae: 0.2323 - mse: 0.0751 - val_loss: 0.1246 - val_mae: 0.3010 - val_mse: 0.1246
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0685 - mae: 0.2196 - mse: 0.0685
64/75 [========================>.....] - ETA: 0s - loss: 0.0842 - mae: 0.2455 - mse: 0.0842
75/75 [==============================] - 1s 7ms/step - loss: 0.0839 - mae: 0.2484 - mse: 0.0839 - val_loss: 0.1009 - val_mae: 0.2650 - val_mse: 0.1009
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0492 - mae: 0.1849 - mse: 0.0492
64/75 [========================>.....] - ETA: 0s - loss: 0.0653 - mae: 0.2096 - mse: 0.0653
75/75 [==============================] - 1s 7ms/step - loss: 0.0624 - mae: 0.2050 - mse: 0.0624 - val_loss: 0.0712 - val_mae: 0.2134 - val_mse: 0.0712
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0455 - mae: 0.1698 - mse: 0.0455
64/75 [========================>.....] - ETA: 0s - loss: 0.0429 - mae: 0.1665 - mse: 0.0429
75/75 [==============================] - 1s 7ms/step - loss: 0.0478 - mae: 0.1739 - mse: 0.0478 - val_loss: 0.0476 - val_mae: 0.1575 - val_mse: 0.0476
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0555 - mae: 0.1953 - mse: 0.0555
64/75 [========================>.....] - ETA: 0s - loss: 0.0402 - mae: 0.1666 - mse: 0.0402
75/75 [==============================] - 1s 7ms/step - loss: 0.0409 - mae: 0.1670 - mse: 0.0409 - val_loss: 0.0334 - val_mae: 0.1295 - val_mse: 0.0334
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0313 - mae: 0.1542 - mse: 0.0313
64/75 [========================>.....] - ETA: 0s - loss: 0.0449 - mae: 0.1668 - mse: 0.0449
75/75 [==============================] - 1s 7ms/step - loss: 0.0437 - mae: 0.1660 - mse: 0.0437 - val_loss: 0.0307 - val_mae: 0.1280 - val_mse: 0.0307
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0340 - mae: 0.1548 - mse: 0.0340
64/75 [========================>.....] - ETA: 0s - loss: 0.0379 - mae: 0.1628 - mse: 0.0379
75/75 [==============================] - 0s 6ms/step - loss: 0.0399 - mae: 0.1622 - mse: 0.0399 - val_loss: 0.0235 - val_mae: 0.1122 - val_mse: 0.0235
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0243 - mae: 0.1234 - mse: 0.0243
64/75 [========================>.....] - ETA: 0s - loss: 0.0207 - mae: 0.1132 - mse: 0.0207
75/75 [==============================] - 1s 7ms/step - loss: 0.0193 - mae: 0.1091 - mse: 0.0193 - val_loss: 0.0137 - val_mae: 0.0931 - val_mse: 0.0137
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0365 - mae: 0.1467 - mse: 0.0365
64/75 [========================>.....] - ETA: 0s - loss: 0.0433 - mae: 0.1566 - mse: 0.0433
75/75 [==============================] - 1s 7ms/step - loss: 0.0399 - mae: 0.1514 - mse: 0.0399 - val_loss: 0.0224 - val_mae: 0.1103 - val_mse: 0.0224
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0198 - mae: 0.1122 - mse: 0.0198
64/75 [========================>.....] - ETA: 0s - loss: 0.0196 - mae: 0.1124 - mse: 0.0196
75/75 [==============================] - 0s 7ms/step - loss: 0.0228 - mae: 0.1210 - mse: 0.0228 - val_loss: 0.0213 - val_mae: 0.1082 - val_mse: 0.0213
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0233 - mae: 0.1131 - mse: 0.0233
64/75 [========================>.....] - ETA: 0s - loss: 0.0208 - mae: 0.1103 - mse: 0.0208
75/75 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1137 - mse: 0.0221 - val_loss: 0.0216 - val_mae: 0.1054 - val_mse: 0.0216
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0224 - mae: 0.1065 - mse: 0.0224
64/75 [========================>.....] - ETA: 0s - loss: 0.0191 - mae: 0.0980 - mse: 0.0191
75/75 [==============================] - 1s 7ms/step - loss: 0.0196 - mae: 0.0994 - mse: 0.0196 - val_loss: 0.0314 - val_mae: 0.1202 - val_mse: 0.0314
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0162 - mae: 0.1061 - mse: 0.0162
64/75 [========================>.....] - ETA: 0s - loss: 0.0161 - mae: 0.1043 - mse: 0.0161
75/75 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.1012 - mse: 0.0153 - val_loss: 0.0341 - val_mae: 0.1296 - val_mse: 0.0341
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0110 - mae: 0.0804 - mse: 0.0110
64/75 [========================>.....] - ETA: 0s - loss: 0.0139 - mae: 0.0899 - mse: 0.0139
75/75 [==============================] - 0s 7ms/step - loss: 0.0195 - mae: 0.1040 - mse: 0.0195 - val_loss: 0.0230 - val_mae: 0.0971 - val_mse: 0.0230
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0107 - mae: 0.0816 - mse: 0.0107
64/75 [========================>.....] - ETA: 0s - loss: 0.0157 - mae: 0.0994 - mse: 0.0157
75/75 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.0991 - mse: 0.0156 - val_loss: 0.0186 - val_mae: 0.0894 - val_mse: 0.0186
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0211 - mae: 0.1236 - mse: 0.0211
64/75 [========================>.....] - ETA: 0s - loss: 0.0160 - mae: 0.1077 - mse: 0.0160
75/75 [==============================] - 0s 6ms/step - loss: 0.0185 - mae: 0.1091 - mse: 0.0185 - val_loss: 0.0245 - val_mae: 0.1084 - val_mse: 0.0245
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0189 - mae: 0.1073 - mse: 0.0189
64/75 [========================>.....] - ETA: 0s - loss: 0.0190 - mae: 0.1097 - mse: 0.0190
75/75 [==============================] - 1s 7ms/step - loss: 0.0187 - mae: 0.1091 - mse: 0.0187 - val_loss: 0.0276 - val_mae: 0.1162 - val_mse: 0.0276
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0158 - mae: 0.1012 - mse: 0.0158
64/75 [========================>.....] - ETA: 0s - loss: 0.0180 - mae: 0.1075 - mse: 0.0180
75/75 [==============================] - 0s 6ms/step - loss: 0.0184 - mae: 0.1057 - mse: 0.0184 - val_loss: 0.0349 - val_mae: 0.1355 - val_mse: 0.0349
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0135 - mae: 0.0932 - mse: 0.0135
64/75 [========================>.....] - ETA: 0s - loss: 0.0142 - mae: 0.0927 - mse: 0.0142
75/75 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.0907 - mse: 0.0136 - val_loss: 0.0318 - val_mae: 0.1249 - val_mse: 0.0318
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0088 - mae: 0.0709 - mse: 0.0088
64/75 [========================>.....] - ETA: 0s - loss: 0.0096 - mae: 0.0786 - mse: 0.0096
75/75 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.0793 - mse: 0.0105 - val_loss: 0.0195 - val_mae: 0.0818 - val_mse: 0.0195
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0146 - mae: 0.0932 - mse: 0.0146
64/75 [========================>.....] - ETA: 0s - loss: 0.0147 - mae: 0.0949 - mse: 0.0147
75/75 [==============================] - 0s 7ms/step - loss: 0.0145 - mae: 0.0960 - mse: 0.0145 - val_loss: 0.0183 - val_mae: 0.0785 - val_mse: 0.0183
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0161 - mae: 0.0976 - mse: 0.0161
64/75 [========================>.....] - ETA: 0s - loss: 0.0149 - mae: 0.0974 - mse: 0.0149
75/75 [==============================] - 1s 7ms/step - loss: 0.0137 - mae: 0.0927 - mse: 0.0137 - val_loss: 0.0492 - val_mae: 0.1648 - val_mse: 0.0492
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0105 - mae: 0.0821 - mse: 0.0105
64/75 [========================>.....] - ETA: 0s - loss: 0.0175 - mae: 0.0990 - mse: 0.0175
75/75 [==============================] - 0s 7ms/step - loss: 0.0171 - mae: 0.0971 - mse: 0.0171 - val_loss: 0.0405 - val_mae: 0.1440 - val_mse: 0.0405
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0131 - mae: 0.0819 - mse: 0.0131
64/75 [========================>.....] - ETA: 0s - loss: 0.0127 - mae: 0.0804 - mse: 0.0127
75/75 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0762 - mse: 0.0117 - val_loss: 0.0166 - val_mae: 0.0726 - val_mse: 0.0166
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0237 - mae: 0.1173 - mse: 0.0237
64/75 [========================>.....] - ETA: 0s - loss: 0.0162 - mae: 0.0948 - mse: 0.0162
75/75 [==============================] - 1s 7ms/step - loss: 0.0173 - mae: 0.0977 - mse: 0.0173 - val_loss: 0.0284 - val_mae: 0.1191 - val_mse: 0.0284
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0120 - mae: 0.0731 - mse: 0.0120
64/75 [========================>.....] - ETA: 0s - loss: 0.0112 - mae: 0.0771 - mse: 0.0112
75/75 [==============================] - 0s 7ms/step - loss: 0.0129 - mae: 0.0828 - mse: 0.0129 - val_loss: 0.0417 - val_mae: 0.1598 - val_mse: 0.0417
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0169 - mae: 0.1048 - mse: 0.0169
64/75 [========================>.....] - ETA: 0s - loss: 0.0136 - mae: 0.0928 - mse: 0.0136
75/75 [==============================] - 0s 7ms/step - loss: 0.0131 - mae: 0.0905 - mse: 0.0131 - val_loss: 0.0238 - val_mae: 0.1109 - val_mse: 0.0238
Saving trained model...
115
Testing...
heightdiff= [0.         0.         0.         3.98100281 0.         0.        ]
average prediction= [2.7149456]
baseline= 9.880952380952381
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.9952507019042969
85 -:- nan
60 -:- nan
['train-weight-12.py', '1']
65 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
65 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
65 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
65 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
60 31
60 32
60 33
60 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
60 37
60 38
2_170_60_12_csi_a12_4.dat
60 40
65 41
65 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
65 48
65 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
65 56
65 57
1_165_65_12_csi_a12_7.dat
65 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
65 70
2_165_50_12_csi_a12_13.dat
50 72
50 73
50 74
50 75
50 76
50 77
50 78
50 79
50 80
50 81
50 82
50 83
50 84
50 85
2_165_50_12_csi_a12_7.dat
50 87
2_165_50_12_csi_a12_23.dat
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
70 119
70 120
70 121
70 122
70 123
70 124
70 125
1_175_70_12_csi_a12_26.dat
70 127
70 128
70 129
70 130
85 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
85 134
85 135
1_180_85_12_csi_a12_19.dat
85 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
85 140
1_180_85_12_csi_a12_12.dat
85 142
85 143
85 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
85 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
75 161
75 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
75 165
75 166
75 167
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
1_180_75_12_csi_a12_12.dat
75 178
1_180_75_12_csi_a12_13.dat
75 180
75 181
75 182
1_180_75_12_csi_a12_14.dat
75 184
75 185
75 186
75 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
75 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[65 65 65 65 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.3630 - mae: 0.5284 - mse: 0.3630
64/75 [========================>.....] - ETA: 0s - loss: 0.2822 - mae: 0.4608 - mse: 0.2822
75/75 [==============================] - 1s 11ms/step - loss: 0.2685 - mae: 0.4513 - mse: 0.2685 - val_loss: 0.1451 - val_mae: 0.3328 - val_mse: 0.1451
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1223 - mae: 0.3126 - mse: 0.1223
64/75 [========================>.....] - ETA: 0s - loss: 0.1223 - mae: 0.3149 - mse: 0.1223
75/75 [==============================] - 0s 7ms/step - loss: 0.1190 - mae: 0.3068 - mse: 0.1190 - val_loss: 0.0829 - val_mae: 0.2308 - val_mse: 0.0829
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1266 - mae: 0.2975 - mse: 0.1266
64/75 [========================>.....] - ETA: 0s - loss: 0.1285 - mae: 0.2930 - mse: 0.1285
75/75 [==============================] - 0s 7ms/step - loss: 0.1206 - mae: 0.2840 - mse: 0.1206 - val_loss: 0.0466 - val_mae: 0.1665 - val_mse: 0.0466
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0784 - mae: 0.2246 - mse: 0.0784
64/75 [========================>.....] - ETA: 0s - loss: 0.0691 - mae: 0.2010 - mse: 0.0691
75/75 [==============================] - 1s 7ms/step - loss: 0.0673 - mae: 0.2034 - mse: 0.0673 - val_loss: 0.0332 - val_mae: 0.1553 - val_mse: 0.0332
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0379 - mae: 0.1549 - mse: 0.0379
64/75 [========================>.....] - ETA: 0s - loss: 0.0392 - mae: 0.1601 - mse: 0.0392
75/75 [==============================] - 0s 7ms/step - loss: 0.0411 - mae: 0.1660 - mse: 0.0411 - val_loss: 0.0406 - val_mae: 0.1820 - val_mse: 0.0406
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0563 - mae: 0.1919 - mse: 0.0563
64/75 [========================>.....] - ETA: 0s - loss: 0.0503 - mae: 0.1825 - mse: 0.0503
75/75 [==============================] - 1s 7ms/step - loss: 0.0483 - mae: 0.1771 - mse: 0.0483 - val_loss: 0.0360 - val_mae: 0.1678 - val_mse: 0.0360
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0354 - mae: 0.1447 - mse: 0.0354
64/75 [========================>.....] - ETA: 0s - loss: 0.0348 - mae: 0.1479 - mse: 0.0348
75/75 [==============================] - 1s 7ms/step - loss: 0.0332 - mae: 0.1434 - mse: 0.0332 - val_loss: 0.0334 - val_mae: 0.1561 - val_mse: 0.0334
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0275 - mae: 0.1313 - mse: 0.0275
64/75 [========================>.....] - ETA: 0s - loss: 0.0276 - mae: 0.1327 - mse: 0.0276
75/75 [==============================] - 0s 6ms/step - loss: 0.0304 - mae: 0.1358 - mse: 0.0304 - val_loss: 0.0256 - val_mae: 0.1302 - val_mse: 0.0256
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0154 - mae: 0.1005 - mse: 0.0154
64/75 [========================>.....] - ETA: 0s - loss: 0.0166 - mae: 0.1008 - mse: 0.0166
75/75 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.1041 - mse: 0.0172 - val_loss: 0.0190 - val_mae: 0.1084 - val_mse: 0.0190
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0286 - mae: 0.1222 - mse: 0.0286
64/75 [========================>.....] - ETA: 0s - loss: 0.0270 - mae: 0.1169 - mse: 0.0270
75/75 [==============================] - 0s 6ms/step - loss: 0.0263 - mae: 0.1171 - mse: 0.0263 - val_loss: 0.0235 - val_mae: 0.1236 - val_mse: 0.0235
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0240 - mae: 0.1075 - mse: 0.0240
64/75 [========================>.....] - ETA: 0s - loss: 0.0206 - mae: 0.1068 - mse: 0.0206
75/75 [==============================] - 0s 7ms/step - loss: 0.0224 - mae: 0.1117 - mse: 0.0224 - val_loss: 0.0200 - val_mae: 0.1109 - val_mse: 0.0200
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0173 - mae: 0.0929 - mse: 0.0173
64/75 [========================>.....] - ETA: 0s - loss: 0.0203 - mae: 0.1032 - mse: 0.0203
75/75 [==============================] - 0s 6ms/step - loss: 0.0220 - mae: 0.1067 - mse: 0.0220 - val_loss: 0.0100 - val_mae: 0.0762 - val_mse: 0.0100
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0390 - mae: 0.1458 - mse: 0.0390
64/75 [========================>.....] - ETA: 0s - loss: 0.0311 - mae: 0.1325 - mse: 0.0311
75/75 [==============================] - 0s 6ms/step - loss: 0.0288 - mae: 0.1295 - mse: 0.0288 - val_loss: 0.0124 - val_mae: 0.0835 - val_mse: 0.0124
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0110 - mae: 0.0787 - mse: 0.0110
64/75 [========================>.....] - ETA: 0s - loss: 0.0133 - mae: 0.0873 - mse: 0.0133
75/75 [==============================] - 1s 7ms/step - loss: 0.0181 - mae: 0.0951 - mse: 0.0181 - val_loss: 0.0238 - val_mae: 0.1286 - val_mse: 0.0238
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0237 - mae: 0.1198 - mse: 0.0237
64/75 [========================>.....] - ETA: 0s - loss: 0.0248 - mae: 0.1140 - mse: 0.0248
75/75 [==============================] - 0s 7ms/step - loss: 0.0263 - mae: 0.1187 - mse: 0.0263 - val_loss: 0.0149 - val_mae: 0.0963 - val_mse: 0.0149
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0154 - mae: 0.0941 - mse: 0.0154
64/75 [========================>.....] - ETA: 0s - loss: 0.0158 - mae: 0.0992 - mse: 0.0158
75/75 [==============================] - 0s 6ms/step - loss: 0.0150 - mae: 0.0975 - mse: 0.0150 - val_loss: 0.0061 - val_mae: 0.0674 - val_mse: 0.0061
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0116 - mae: 0.0813 - mse: 0.0116
64/75 [========================>.....] - ETA: 0s - loss: 0.0209 - mae: 0.1111 - mse: 0.0209
75/75 [==============================] - 0s 7ms/step - loss: 0.0208 - mae: 0.1120 - mse: 0.0208 - val_loss: 0.0102 - val_mae: 0.0819 - val_mse: 0.0102
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0147 - mae: 0.0952 - mse: 0.0147
64/75 [========================>.....] - ETA: 0s - loss: 0.0168 - mae: 0.1009 - mse: 0.0168
75/75 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.1029 - mse: 0.0173 - val_loss: 0.0322 - val_mae: 0.1553 - val_mse: 0.0322
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0269 - mae: 0.1353 - mse: 0.0269
64/75 [========================>.....] - ETA: 0s - loss: 0.0250 - mae: 0.1246 - mse: 0.0250
75/75 [==============================] - 1s 7ms/step - loss: 0.0236 - mae: 0.1218 - mse: 0.0236 - val_loss: 0.0219 - val_mae: 0.1223 - val_mse: 0.0219
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0267 - mae: 0.1231 - mse: 0.0267
64/75 [========================>.....] - ETA: 0s - loss: 0.0215 - mae: 0.1152 - mse: 0.0215
75/75 [==============================] - 0s 7ms/step - loss: 0.0201 - mae: 0.1114 - mse: 0.0201 - val_loss: 0.0077 - val_mae: 0.0757 - val_mse: 0.0077
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0138 - mae: 0.0987 - mse: 0.0138
64/75 [========================>.....] - ETA: 0s - loss: 0.0180 - mae: 0.1069 - mse: 0.0180
75/75 [==============================] - 1s 7ms/step - loss: 0.0185 - mae: 0.1064 - mse: 0.0185 - val_loss: 0.0116 - val_mae: 0.0880 - val_mse: 0.0116
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0247 - mae: 0.1202 - mse: 0.0247
64/75 [========================>.....] - ETA: 0s - loss: 0.0224 - mae: 0.1152 - mse: 0.0224
75/75 [==============================] - 0s 7ms/step - loss: 0.0252 - mae: 0.1191 - mse: 0.0252 - val_loss: 0.0228 - val_mae: 0.1255 - val_mse: 0.0228
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0183 - mae: 0.0968 - mse: 0.0183
64/75 [========================>.....] - ETA: 0s - loss: 0.0203 - mae: 0.1011 - mse: 0.0203
75/75 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 0.0980 - mse: 0.0187 - val_loss: 0.0155 - val_mae: 0.1003 - val_mse: 0.0155
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0193 - mae: 0.0971 - mse: 0.0193
64/75 [========================>.....] - ETA: 0s - loss: 0.0153 - mae: 0.0903 - mse: 0.0153
75/75 [==============================] - 1s 7ms/step - loss: 0.0143 - mae: 0.0887 - mse: 0.0143 - val_loss: 0.0091 - val_mae: 0.0731 - val_mse: 0.0091
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0082 - mae: 0.0728 - mse: 0.0082
64/75 [========================>.....] - ETA: 0s - loss: 0.0124 - mae: 0.0910 - mse: 0.0124
75/75 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.0969 - mse: 0.0142 - val_loss: 0.0106 - val_mae: 0.0768 - val_mse: 0.0106
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0097 - mae: 0.0794 - mse: 0.0097
64/75 [========================>.....] - ETA: 0s - loss: 0.0122 - mae: 0.0792 - mse: 0.0122
75/75 [==============================] - 0s 7ms/step - loss: 0.0109 - mae: 0.0752 - mse: 0.0109 - val_loss: 0.0199 - val_mae: 0.1127 - val_mse: 0.0199
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0087 - mae: 0.0726 - mse: 0.0087
64/75 [========================>.....] - ETA: 0s - loss: 0.0136 - mae: 0.0879 - mse: 0.0136
75/75 [==============================] - 0s 7ms/step - loss: 0.0136 - mae: 0.0891 - mse: 0.0136 - val_loss: 0.0189 - val_mae: 0.1076 - val_mse: 0.0189
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0159 - mae: 0.0949 - mse: 0.0159
64/75 [========================>.....] - ETA: 0s - loss: 0.0155 - mae: 0.0946 - mse: 0.0155
75/75 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.0901 - mse: 0.0142 - val_loss: 0.0108 - val_mae: 0.0775 - val_mse: 0.0108
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0131 - mae: 0.0914 - mse: 0.0131
64/75 [========================>.....] - ETA: 0s - loss: 0.0143 - mae: 0.0946 - mse: 0.0143
75/75 [==============================] - 1s 7ms/step - loss: 0.0142 - mae: 0.0963 - mse: 0.0142 - val_loss: 0.0202 - val_mae: 0.1149 - val_mse: 0.0202
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0089 - mae: 0.0757 - mse: 0.0089
64/75 [========================>.....] - ETA: 0s - loss: 0.0142 - mae: 0.0812 - mse: 0.0142
75/75 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.0872 - mse: 0.0148 - val_loss: 0.0245 - val_mae: 0.1307 - val_mse: 0.0245
Saving trained model...
115
Testing...
heightdiff= [0.         0.         0.         8.40975571 0.         0.        ]
average prediction= [5.2153726]
baseline= 8.214285714285714
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 2.1024389266967773
85 -:- nan
60 -:- nan
['train-weight-12.py', '1']
65 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
65 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
65 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
65 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
60 31
60 32
60 33
60 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
60 37
60 38
2_170_60_12_csi_a12_4.dat
60 40
65 41
65 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
65 48
65 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
65 56
65 57
1_165_65_12_csi_a12_7.dat
65 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
65 70
2_165_50_12_csi_a12_13.dat
50 72
50 73
50 74
50 75
50 76
50 77
50 78
50 79
50 80
50 81
50 82
50 83
50 84
50 85
2_165_50_12_csi_a12_7.dat
50 87
2_165_50_12_csi_a12_23.dat
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
70 119
70 120
70 121
70 122
70 123
70 124
70 125
1_175_70_12_csi_a12_26.dat
70 127
70 128
70 129
70 130
85 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
85 134
85 135
1_180_85_12_csi_a12_19.dat
85 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
85 140
1_180_85_12_csi_a12_12.dat
85 142
85 143
85 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
85 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
75 161
75 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
75 165
75 166
75 167
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
1_180_75_12_csi_a12_12.dat
75 178
1_180_75_12_csi_a12_13.dat
75 180
75 181
75 182
1_180_75_12_csi_a12_14.dat
75 184
75 185
75 186
75 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
75 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[65 65 65 65 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.3285 - mae: 0.5258 - mse: 0.3285
64/75 [========================>.....] - ETA: 0s - loss: 0.2322 - mae: 0.4235 - mse: 0.2322
75/75 [==============================] - 1s 11ms/step - loss: 0.2104 - mae: 0.3964 - mse: 0.2104 - val_loss: 0.1489 - val_mae: 0.3046 - val_mse: 0.1489
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0815 - mae: 0.2300 - mse: 0.0815
64/75 [========================>.....] - ETA: 0s - loss: 0.1429 - mae: 0.3039 - mse: 0.1429
75/75 [==============================] - 1s 7ms/step - loss: 0.1437 - mae: 0.3065 - mse: 0.1437 - val_loss: 0.1085 - val_mae: 0.2846 - val_mse: 0.1085
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0697 - mae: 0.2027 - mse: 0.0697
64/75 [========================>.....] - ETA: 0s - loss: 0.0785 - mae: 0.2241 - mse: 0.0785
75/75 [==============================] - 0s 6ms/step - loss: 0.0829 - mae: 0.2348 - mse: 0.0829 - val_loss: 0.0958 - val_mae: 0.2976 - val_mse: 0.0958
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0713 - mae: 0.2372 - mse: 0.0713
64/75 [========================>.....] - ETA: 0s - loss: 0.0840 - mae: 0.2528 - mse: 0.0840
75/75 [==============================] - 0s 7ms/step - loss: 0.0852 - mae: 0.2542 - mse: 0.0852 - val_loss: 0.0941 - val_mae: 0.2806 - val_mse: 0.0941
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0879 - mae: 0.2543 - mse: 0.0879
64/75 [========================>.....] - ETA: 0s - loss: 0.0748 - mae: 0.2369 - mse: 0.0748
75/75 [==============================] - 0s 6ms/step - loss: 0.0709 - mae: 0.2317 - mse: 0.0709 - val_loss: 0.0599 - val_mae: 0.2346 - val_mse: 0.0599
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0529 - mae: 0.1950 - mse: 0.0529
64/75 [========================>.....] - ETA: 0s - loss: 0.0540 - mae: 0.1966 - mse: 0.0540
75/75 [==============================] - 0s 6ms/step - loss: 0.0520 - mae: 0.1961 - mse: 0.0520 - val_loss: 0.0337 - val_mae: 0.1741 - val_mse: 0.0337
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0461 - mae: 0.1720 - mse: 0.0461
64/75 [========================>.....] - ETA: 0s - loss: 0.0631 - mae: 0.1951 - mse: 0.0631
75/75 [==============================] - 1s 7ms/step - loss: 0.0579 - mae: 0.1867 - mse: 0.0579 - val_loss: 0.0220 - val_mae: 0.1306 - val_mse: 0.0220
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0509 - mae: 0.1676 - mse: 0.0509
64/75 [========================>.....] - ETA: 0s - loss: 0.0452 - mae: 0.1659 - mse: 0.0452
75/75 [==============================] - 0s 7ms/step - loss: 0.0513 - mae: 0.1708 - mse: 0.0513 - val_loss: 0.0173 - val_mae: 0.1196 - val_mse: 0.0173
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0362 - mae: 0.1577 - mse: 0.0362
64/75 [========================>.....] - ETA: 0s - loss: 0.0310 - mae: 0.1446 - mse: 0.0310
75/75 [==============================] - 0s 6ms/step - loss: 0.0303 - mae: 0.1402 - mse: 0.0303 - val_loss: 0.0263 - val_mae: 0.1295 - val_mse: 0.0263
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0294 - mae: 0.1386 - mse: 0.0294
64/75 [========================>.....] - ETA: 0s - loss: 0.0302 - mae: 0.1392 - mse: 0.0302
75/75 [==============================] - 0s 6ms/step - loss: 0.0303 - mae: 0.1422 - mse: 0.0303 - val_loss: 0.0231 - val_mae: 0.1260 - val_mse: 0.0231
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0388 - mae: 0.1494 - mse: 0.0388
64/75 [========================>.....] - ETA: 0s - loss: 0.0400 - mae: 0.1538 - mse: 0.0400
75/75 [==============================] - 0s 6ms/step - loss: 0.0367 - mae: 0.1458 - mse: 0.0367 - val_loss: 0.0121 - val_mae: 0.0906 - val_mse: 0.0121
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0340 - mae: 0.1539 - mse: 0.0340
64/75 [========================>.....] - ETA: 0s - loss: 0.0338 - mae: 0.1478 - mse: 0.0338
75/75 [==============================] - 0s 7ms/step - loss: 0.0329 - mae: 0.1463 - mse: 0.0329 - val_loss: 0.0102 - val_mae: 0.0829 - val_mse: 0.0102
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0218 - mae: 0.1124 - mse: 0.0218
64/75 [========================>.....] - ETA: 0s - loss: 0.0341 - mae: 0.1385 - mse: 0.0341
75/75 [==============================] - 0s 6ms/step - loss: 0.0325 - mae: 0.1347 - mse: 0.0325 - val_loss: 0.0142 - val_mae: 0.0956 - val_mse: 0.0142
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0175 - mae: 0.1032 - mse: 0.0175
64/75 [========================>.....] - ETA: 0s - loss: 0.0187 - mae: 0.1096 - mse: 0.0187
75/75 [==============================] - 0s 6ms/step - loss: 0.0229 - mae: 0.1191 - mse: 0.0229 - val_loss: 0.0155 - val_mae: 0.0995 - val_mse: 0.0155
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0428 - mae: 0.1604 - mse: 0.0428
64/75 [========================>.....] - ETA: 0s - loss: 0.0283 - mae: 0.1291 - mse: 0.0283
75/75 [==============================] - 1s 7ms/step - loss: 0.0256 - mae: 0.1224 - mse: 0.0256 - val_loss: 0.0101 - val_mae: 0.0810 - val_mse: 0.0101
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0282 - mae: 0.1362 - mse: 0.0282
64/75 [========================>.....] - ETA: 0s - loss: 0.0251 - mae: 0.1221 - mse: 0.0251
75/75 [==============================] - 0s 6ms/step - loss: 0.0230 - mae: 0.1167 - mse: 0.0230 - val_loss: 0.0093 - val_mae: 0.0785 - val_mse: 0.0093
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0185 - mae: 0.1088 - mse: 0.0185
64/75 [========================>.....] - ETA: 0s - loss: 0.0184 - mae: 0.1064 - mse: 0.0184
75/75 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1148 - mse: 0.0221 - val_loss: 0.0089 - val_mae: 0.0805 - val_mse: 0.0089
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0241 - mae: 0.1090 - mse: 0.0241
64/75 [========================>.....] - ETA: 0s - loss: 0.0218 - mae: 0.1090 - mse: 0.0218
75/75 [==============================] - 0s 7ms/step - loss: 0.0207 - mae: 0.1052 - mse: 0.0207 - val_loss: 0.0152 - val_mae: 0.1050 - val_mse: 0.0152
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0262 - mae: 0.1193 - mse: 0.0262
64/75 [========================>.....] - ETA: 0s - loss: 0.0207 - mae: 0.1096 - mse: 0.0207
75/75 [==============================] - 1s 7ms/step - loss: 0.0198 - mae: 0.1074 - mse: 0.0198 - val_loss: 0.0219 - val_mae: 0.1258 - val_mse: 0.0219
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0309 - mae: 0.1312 - mse: 0.0309
64/75 [========================>.....] - ETA: 0s - loss: 0.0233 - mae: 0.1118 - mse: 0.0233
75/75 [==============================] - 1s 7ms/step - loss: 0.0231 - mae: 0.1083 - mse: 0.0231 - val_loss: 0.0165 - val_mae: 0.1075 - val_mse: 0.0165
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0143 - mae: 0.0951 - mse: 0.0143
64/75 [========================>.....] - ETA: 0s - loss: 0.0205 - mae: 0.1087 - mse: 0.0205
75/75 [==============================] - 0s 7ms/step - loss: 0.0223 - mae: 0.1157 - mse: 0.0223 - val_loss: 0.0089 - val_mae: 0.0771 - val_mse: 0.0089
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0286 - mae: 0.1316 - mse: 0.0286
64/75 [========================>.....] - ETA: 0s - loss: 0.0206 - mae: 0.1096 - mse: 0.0206
75/75 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 0.1041 - mse: 0.0186 - val_loss: 0.0173 - val_mae: 0.1081 - val_mse: 0.0173
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0161 - mae: 0.0986 - mse: 0.0161
64/75 [========================>.....] - ETA: 0s - loss: 0.0193 - mae: 0.1046 - mse: 0.0193
75/75 [==============================] - 1s 7ms/step - loss: 0.0189 - mae: 0.1042 - mse: 0.0189 - val_loss: 0.0258 - val_mae: 0.1305 - val_mse: 0.0258
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0166 - mae: 0.0984 - mse: 0.0166
64/75 [========================>.....] - ETA: 0s - loss: 0.0160 - mae: 0.0964 - mse: 0.0160
75/75 [==============================] - 0s 6ms/step - loss: 0.0163 - mae: 0.0989 - mse: 0.0163 - val_loss: 0.0163 - val_mae: 0.1031 - val_mse: 0.0163
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0220 - mae: 0.1203 - mse: 0.0220
64/75 [========================>.....] - ETA: 0s - loss: 0.0175 - mae: 0.1052 - mse: 0.0175
75/75 [==============================] - 0s 6ms/step - loss: 0.0189 - mae: 0.1100 - mse: 0.0189 - val_loss: 0.0100 - val_mae: 0.0795 - val_mse: 0.0100
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0217 - mae: 0.1139 - mse: 0.0217
64/75 [========================>.....] - ETA: 0s - loss: 0.0167 - mae: 0.1024 - mse: 0.0167
75/75 [==============================] - 0s 7ms/step - loss: 0.0164 - mae: 0.1018 - mse: 0.0164 - val_loss: 0.0146 - val_mae: 0.0977 - val_mse: 0.0146
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0204 - mae: 0.1104 - mse: 0.0204
64/75 [========================>.....] - ETA: 0s - loss: 0.0157 - mae: 0.0962 - mse: 0.0157
75/75 [==============================] - 0s 7ms/step - loss: 0.0138 - mae: 0.0885 - mse: 0.0138 - val_loss: 0.0185 - val_mae: 0.1141 - val_mse: 0.0185
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0131 - mae: 0.0868 - mse: 0.0131
64/75 [========================>.....] - ETA: 0s - loss: 0.0172 - mae: 0.1015 - mse: 0.0172
75/75 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.1002 - mse: 0.0169 - val_loss: 0.0139 - val_mae: 0.1031 - val_mse: 0.0139
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0130 - mae: 0.0858 - mse: 0.0130
64/75 [========================>.....] - ETA: 0s - loss: 0.0098 - mae: 0.0713 - mse: 0.0098
75/75 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.0785 - mse: 0.0113 - val_loss: 0.0085 - val_mae: 0.0792 - val_mse: 0.0085
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0116 - mae: 0.0687 - mse: 0.0116
64/75 [========================>.....] - ETA: 0s - loss: 0.0137 - mae: 0.0858 - mse: 0.0137
75/75 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.0831 - mse: 0.0127 - val_loss: 0.0086 - val_mae: 0.0769 - val_mse: 0.0086
Saving trained model...
115
Testing...
heightdiff= [0.         0.         0.         5.78464127 0.         0.        ]
average prediction= [1.933942]
baseline= 7.738095238095238
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.156928253173828
85 -:- nan
60 -:- nan
['train-weight-12.py', '1']
65 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
65 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
65 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
65 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
60 31
60 32
60 33
60 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
60 37
60 38
2_170_60_12_csi_a12_4.dat
60 40
65 41
65 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
65 48
65 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
65 56
65 57
1_165_65_12_csi_a12_7.dat
65 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
65 70
2_165_50_12_csi_a12_13.dat
50 72
50 73
50 74
50 75
50 76
50 77
50 78
50 79
50 80
50 81
50 82
50 83
50 84
50 85
2_165_50_12_csi_a12_7.dat
50 87
2_165_50_12_csi_a12_23.dat
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
70 119
70 120
70 121
70 122
70 123
70 124
70 125
1_175_70_12_csi_a12_26.dat
70 127
70 128
70 129
70 130
85 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
85 134
85 135
1_180_85_12_csi_a12_19.dat
85 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
85 140
1_180_85_12_csi_a12_12.dat
85 142
85 143
85 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
85 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
75 161
75 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
75 165
75 166
75 167
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
1_180_75_12_csi_a12_12.dat
75 178
1_180_75_12_csi_a12_13.dat
75 180
75 181
75 182
1_180_75_12_csi_a12_14.dat
75 184
75 185
75 186
75 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
75 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[65 65 65 65 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.3253 - mae: 0.4936 - mse: 0.3253
64/75 [========================>.....] - ETA: 0s - loss: 0.2449 - mae: 0.4299 - mse: 0.2449
75/75 [==============================] - 1s 11ms/step - loss: 0.2323 - mae: 0.4199 - mse: 0.2323 - val_loss: 0.0885 - val_mae: 0.2601 - val_mse: 0.0885
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.2186 - mae: 0.3664 - mse: 0.2186
64/75 [========================>.....] - ETA: 0s - loss: 0.1874 - mae: 0.3523 - mse: 0.1874
75/75 [==============================] - 0s 6ms/step - loss: 0.1804 - mae: 0.3479 - mse: 0.1804 - val_loss: 0.1151 - val_mae: 0.3134 - val_mse: 0.1151
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1170 - mae: 0.3046 - mse: 0.1170
64/75 [========================>.....] - ETA: 0s - loss: 0.1149 - mae: 0.2965 - mse: 0.1149
75/75 [==============================] - 0s 7ms/step - loss: 0.1189 - mae: 0.2979 - mse: 0.1189 - val_loss: 0.1468 - val_mae: 0.3635 - val_mse: 0.1468
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0886 - mae: 0.2577 - mse: 0.0886
64/75 [========================>.....] - ETA: 0s - loss: 0.0898 - mae: 0.2586 - mse: 0.0898
75/75 [==============================] - 0s 7ms/step - loss: 0.0935 - mae: 0.2605 - mse: 0.0935 - val_loss: 0.1123 - val_mae: 0.3140 - val_mse: 0.1123
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0769 - mae: 0.2379 - mse: 0.0769
64/75 [========================>.....] - ETA: 0s - loss: 0.0711 - mae: 0.2247 - mse: 0.0711
75/75 [==============================] - 0s 7ms/step - loss: 0.0704 - mae: 0.2266 - mse: 0.0704 - val_loss: 0.0387 - val_mae: 0.1644 - val_mse: 0.0387
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0594 - mae: 0.2000 - mse: 0.0594
64/75 [========================>.....] - ETA: 0s - loss: 0.0587 - mae: 0.2017 - mse: 0.0587
75/75 [==============================] - 0s 7ms/step - loss: 0.0565 - mae: 0.1967 - mse: 0.0565 - val_loss: 0.0146 - val_mae: 0.0824 - val_mse: 0.0146
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0385 - mae: 0.1554 - mse: 0.0385
64/75 [========================>.....] - ETA: 0s - loss: 0.0421 - mae: 0.1632 - mse: 0.0421
75/75 [==============================] - 0s 6ms/step - loss: 0.0389 - mae: 0.1553 - mse: 0.0389 - val_loss: 0.0201 - val_mae: 0.1151 - val_mse: 0.0201
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0561 - mae: 0.1916 - mse: 0.0561
64/75 [========================>.....] - ETA: 0s - loss: 0.0506 - mae: 0.1720 - mse: 0.0506
75/75 [==============================] - 0s 6ms/step - loss: 0.0510 - mae: 0.1740 - mse: 0.0510 - val_loss: 0.0191 - val_mae: 0.1236 - val_mse: 0.0191
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0373 - mae: 0.1472 - mse: 0.0373
64/75 [========================>.....] - ETA: 0s - loss: 0.0337 - mae: 0.1429 - mse: 0.0337
75/75 [==============================] - 0s 6ms/step - loss: 0.0360 - mae: 0.1397 - mse: 0.0360 - val_loss: 0.0194 - val_mae: 0.1276 - val_mse: 0.0194
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0263 - mae: 0.1087 - mse: 0.0263
64/75 [========================>.....] - ETA: 0s - loss: 0.0271 - mae: 0.1128 - mse: 0.0271
75/75 [==============================] - 0s 7ms/step - loss: 0.0294 - mae: 0.1201 - mse: 0.0294 - val_loss: 0.0186 - val_mae: 0.1244 - val_mse: 0.0186
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0196 - mae: 0.1107 - mse: 0.0196
64/75 [========================>.....] - ETA: 0s - loss: 0.0208 - mae: 0.1158 - mse: 0.0208
75/75 [==============================] - 0s 7ms/step - loss: 0.0198 - mae: 0.1126 - mse: 0.0198 - val_loss: 0.0129 - val_mae: 0.0958 - val_mse: 0.0129
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0246 - mae: 0.1251 - mse: 0.0246
64/75 [========================>.....] - ETA: 0s - loss: 0.0175 - mae: 0.0986 - mse: 0.0175
75/75 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.0983 - mse: 0.0172 - val_loss: 0.0102 - val_mae: 0.0812 - val_mse: 0.0102
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0256 - mae: 0.1293 - mse: 0.0256
64/75 [========================>.....] - ETA: 0s - loss: 0.0250 - mae: 0.1237 - mse: 0.0250
75/75 [==============================] - 0s 6ms/step - loss: 0.0252 - mae: 0.1245 - mse: 0.0252 - val_loss: 0.0109 - val_mae: 0.0982 - val_mse: 0.0109
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0243 - mae: 0.1262 - mse: 0.0243
64/75 [========================>.....] - ETA: 0s - loss: 0.0279 - mae: 0.1301 - mse: 0.0279
75/75 [==============================] - 0s 7ms/step - loss: 0.0264 - mae: 0.1248 - mse: 0.0264 - val_loss: 0.0110 - val_mae: 0.0977 - val_mse: 0.0110
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0187 - mae: 0.1055 - mse: 0.0187
64/75 [========================>.....] - ETA: 0s - loss: 0.0181 - mae: 0.1026 - mse: 0.0181
75/75 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.1032 - mse: 0.0181 - val_loss: 0.0075 - val_mae: 0.0722 - val_mse: 0.0075
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0196 - mae: 0.0969 - mse: 0.0196
64/75 [========================>.....] - ETA: 0s - loss: 0.0184 - mae: 0.1037 - mse: 0.0184
75/75 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.1085 - mse: 0.0197 - val_loss: 0.0113 - val_mae: 0.0958 - val_mse: 0.0113
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0143 - mae: 0.0939 - mse: 0.0143
64/75 [========================>.....] - ETA: 0s - loss: 0.0195 - mae: 0.1126 - mse: 0.0195
75/75 [==============================] - 0s 6ms/step - loss: 0.0189 - mae: 0.1064 - mse: 0.0189 - val_loss: 0.0102 - val_mae: 0.0923 - val_mse: 0.0102
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0144 - mae: 0.0969 - mse: 0.0144
64/75 [========================>.....] - ETA: 0s - loss: 0.0154 - mae: 0.0985 - mse: 0.0154
75/75 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.0950 - mse: 0.0145 - val_loss: 0.0075 - val_mae: 0.0730 - val_mse: 0.0075
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0209 - mae: 0.1116 - mse: 0.0209
64/75 [========================>.....] - ETA: 0s - loss: 0.0239 - mae: 0.1153 - mse: 0.0239
75/75 [==============================] - 1s 7ms/step - loss: 0.0241 - mae: 0.1165 - mse: 0.0241 - val_loss: 0.0081 - val_mae: 0.0789 - val_mse: 0.0081
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0098 - mae: 0.0779 - mse: 0.0098
64/75 [========================>.....] - ETA: 0s - loss: 0.0130 - mae: 0.0872 - mse: 0.0130
75/75 [==============================] - 0s 7ms/step - loss: 0.0139 - mae: 0.0919 - mse: 0.0139 - val_loss: 0.0164 - val_mae: 0.1141 - val_mse: 0.0164
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0335 - mae: 0.1354 - mse: 0.0335
64/75 [========================>.....] - ETA: 0s - loss: 0.0278 - mae: 0.1250 - mse: 0.0278
75/75 [==============================] - 0s 6ms/step - loss: 0.0256 - mae: 0.1193 - mse: 0.0256 - val_loss: 0.0162 - val_mae: 0.1093 - val_mse: 0.0162
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0137 - mae: 0.0935 - mse: 0.0137
64/75 [========================>.....] - ETA: 0s - loss: 0.0147 - mae: 0.0914 - mse: 0.0147
75/75 [==============================] - 0s 5ms/step - loss: 0.0152 - mae: 0.0913 - mse: 0.0152 - val_loss: 0.0111 - val_mae: 0.0895 - val_mse: 0.0111
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0232 - mae: 0.1061 - mse: 0.0232
64/75 [========================>.....] - ETA: 0s - loss: 0.0193 - mae: 0.0978 - mse: 0.0193
75/75 [==============================] - 0s 5ms/step - loss: 0.0207 - mae: 0.1032 - mse: 0.0207 - val_loss: 0.0060 - val_mae: 0.0644 - val_mse: 0.0060
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0182 - mae: 0.0949 - mse: 0.0182
64/75 [========================>.....] - ETA: 0s - loss: 0.0171 - mae: 0.0931 - mse: 0.0171
75/75 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 0.0975 - mse: 0.0181 - val_loss: 0.0093 - val_mae: 0.0820 - val_mse: 0.0093
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0181 - mae: 0.1036 - mse: 0.0181
64/75 [========================>.....] - ETA: 0s - loss: 0.0132 - mae: 0.0896 - mse: 0.0132
75/75 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 0.0991 - mse: 0.0192 - val_loss: 0.0159 - val_mae: 0.1065 - val_mse: 0.0159
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0158 - mae: 0.0854 - mse: 0.0158
64/75 [========================>.....] - ETA: 0s - loss: 0.0172 - mae: 0.0950 - mse: 0.0172
75/75 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 0.0943 - mse: 0.0166 - val_loss: 0.0062 - val_mae: 0.0682 - val_mse: 0.0062
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0195 - mae: 0.0991 - mse: 0.0195
64/75 [========================>.....] - ETA: 0s - loss: 0.0207 - mae: 0.1035 - mse: 0.0207
75/75 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 0.1013 - mse: 0.0198 - val_loss: 0.0068 - val_mae: 0.0708 - val_mse: 0.0068
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0182 - mae: 0.1010 - mse: 0.0182
64/75 [========================>.....] - ETA: 0s - loss: 0.0137 - mae: 0.0895 - mse: 0.0137
75/75 [==============================] - 0s 5ms/step - loss: 0.0147 - mae: 0.0923 - mse: 0.0147 - val_loss: 0.0157 - val_mae: 0.1028 - val_mse: 0.0157
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0159 - mae: 0.0967 - mse: 0.0159
64/75 [========================>.....] - ETA: 0s - loss: 0.0115 - mae: 0.0772 - mse: 0.0115
75/75 [==============================] - 0s 5ms/step - loss: 0.0120 - mae: 0.0797 - mse: 0.0120 - val_loss: 0.0102 - val_mae: 0.0818 - val_mse: 0.0102
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0133 - mae: 0.0802 - mse: 0.0133
64/75 [========================>.....] - ETA: 0s - loss: 0.0139 - mae: 0.0843 - mse: 0.0139
75/75 [==============================] - 0s 5ms/step - loss: 0.0139 - mae: 0.0828 - mse: 0.0139 - val_loss: 0.0072 - val_mae: 0.0674 - val_mse: 0.0072
Saving trained model...
115
Testing...
heightdiff= [0.        0.        0.        4.5867691 0.        0.       ]
average prediction= [2.5264068]
baseline= 8.69047619047619
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.1466922760009766
85 -:- nan
60 -:- nan
['train-weight-12.py', '1']
65 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
65 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
65 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
65 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
60 31
60 32
60 33
60 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
60 37
60 38
2_170_60_12_csi_a12_4.dat
60 40
65 41
65 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
65 48
65 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
65 56
65 57
1_165_65_12_csi_a12_7.dat
65 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
65 70
2_165_50_12_csi_a12_13.dat
50 72
50 73
50 74
50 75
50 76
50 77
50 78
50 79
50 80
50 81
50 82
50 83
50 84
50 85
2_165_50_12_csi_a12_7.dat
50 87
2_165_50_12_csi_a12_23.dat
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
70 119
70 120
70 121
70 122
70 123
70 124
70 125
1_175_70_12_csi_a12_26.dat
70 127
70 128
70 129
70 130
85 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
85 134
85 135
1_180_85_12_csi_a12_19.dat
85 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
85 140
1_180_85_12_csi_a12_12.dat
85 142
85 143
85 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
85 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
75 161
75 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
75 165
75 166
75 167
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
1_180_75_12_csi_a12_12.dat
75 178
1_180_75_12_csi_a12_13.dat
75 180
75 181
75 182
1_180_75_12_csi_a12_14.dat
75 184
75 185
75 186
75 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
75 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[65 65 65 65 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.2327 - mae: 0.3896 - mse: 0.2327
64/75 [========================>.....] - ETA: 0s - loss: 0.2117 - mae: 0.3890 - mse: 0.2117
75/75 [==============================] - 1s 11ms/step - loss: 0.1948 - mae: 0.3724 - mse: 0.1948 - val_loss: 0.0582 - val_mae: 0.2207 - val_mse: 0.0582
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1020 - mae: 0.2787 - mse: 0.1020
64/75 [========================>.....] - ETA: 0s - loss: 0.1061 - mae: 0.2767 - mse: 0.1061
75/75 [==============================] - 1s 7ms/step - loss: 0.0964 - mae: 0.2619 - mse: 0.0964 - val_loss: 0.0504 - val_mae: 0.1947 - val_mse: 0.0504
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1045 - mae: 0.2679 - mse: 0.1045
64/75 [========================>.....] - ETA: 0s - loss: 0.0803 - mae: 0.2303 - mse: 0.0803
75/75 [==============================] - 1s 7ms/step - loss: 0.0729 - mae: 0.2160 - mse: 0.0729 - val_loss: 0.0439 - val_mae: 0.1950 - val_mse: 0.0439
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0705 - mae: 0.2221 - mse: 0.0705
64/75 [========================>.....] - ETA: 0s - loss: 0.0519 - mae: 0.1771 - mse: 0.0519
75/75 [==============================] - 0s 6ms/step - loss: 0.0540 - mae: 0.1816 - mse: 0.0540 - val_loss: 0.0474 - val_mae: 0.1987 - val_mse: 0.0474
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0418 - mae: 0.1755 - mse: 0.0418
64/75 [========================>.....] - ETA: 0s - loss: 0.0466 - mae: 0.1826 - mse: 0.0466
75/75 [==============================] - 0s 7ms/step - loss: 0.0472 - mae: 0.1785 - mse: 0.0472 - val_loss: 0.0433 - val_mae: 0.1901 - val_mse: 0.0433
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0385 - mae: 0.1666 - mse: 0.0385
64/75 [========================>.....] - ETA: 0s - loss: 0.0360 - mae: 0.1546 - mse: 0.0360
75/75 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1514 - mse: 0.0341 - val_loss: 0.0336 - val_mae: 0.1425 - val_mse: 0.0336
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0340 - mae: 0.1464 - mse: 0.0340
64/75 [========================>.....] - ETA: 0s - loss: 0.0497 - mae: 0.1639 - mse: 0.0497
75/75 [==============================] - 0s 7ms/step - loss: 0.0495 - mae: 0.1657 - mse: 0.0495 - val_loss: 0.0344 - val_mae: 0.1461 - val_mse: 0.0344
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0321 - mae: 0.1414 - mse: 0.0321
64/75 [========================>.....] - ETA: 0s - loss: 0.0311 - mae: 0.1331 - mse: 0.0311
75/75 [==============================] - 0s 6ms/step - loss: 0.0336 - mae: 0.1395 - mse: 0.0336 - val_loss: 0.0411 - val_mae: 0.1862 - val_mse: 0.0411
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0558 - mae: 0.1824 - mse: 0.0558
64/75 [========================>.....] - ETA: 0s - loss: 0.0426 - mae: 0.1524 - mse: 0.0426
75/75 [==============================] - 0s 7ms/step - loss: 0.0456 - mae: 0.1624 - mse: 0.0456 - val_loss: 0.0304 - val_mae: 0.1527 - val_mse: 0.0304
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0290 - mae: 0.1239 - mse: 0.0290
64/75 [========================>.....] - ETA: 0s - loss: 0.0241 - mae: 0.1135 - mse: 0.0241
75/75 [==============================] - 0s 7ms/step - loss: 0.0235 - mae: 0.1138 - mse: 0.0235 - val_loss: 0.0226 - val_mae: 0.1222 - val_mse: 0.0226
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0180 - mae: 0.1063 - mse: 0.0180
64/75 [========================>.....] - ETA: 0s - loss: 0.0411 - mae: 0.1411 - mse: 0.0411
75/75 [==============================] - 0s 7ms/step - loss: 0.0370 - mae: 0.1351 - mse: 0.0370 - val_loss: 0.0227 - val_mae: 0.1215 - val_mse: 0.0227
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0281 - mae: 0.1200 - mse: 0.0281
64/75 [========================>.....] - ETA: 0s - loss: 0.0287 - mae: 0.1260 - mse: 0.0287
75/75 [==============================] - 1s 7ms/step - loss: 0.0299 - mae: 0.1314 - mse: 0.0299 - val_loss: 0.0217 - val_mae: 0.1324 - val_mse: 0.0217
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0201 - mae: 0.1081 - mse: 0.0201
64/75 [========================>.....] - ETA: 0s - loss: 0.0271 - mae: 0.1209 - mse: 0.0271
75/75 [==============================] - 1s 7ms/step - loss: 0.0278 - mae: 0.1229 - mse: 0.0278 - val_loss: 0.0255 - val_mae: 0.1429 - val_mse: 0.0255
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0216 - mae: 0.1110 - mse: 0.0216
64/75 [========================>.....] - ETA: 0s - loss: 0.0274 - mae: 0.1231 - mse: 0.0274
75/75 [==============================] - 0s 7ms/step - loss: 0.0262 - mae: 0.1220 - mse: 0.0262 - val_loss: 0.0202 - val_mae: 0.1244 - val_mse: 0.0202
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0186 - mae: 0.0991 - mse: 0.0186
64/75 [========================>.....] - ETA: 0s - loss: 0.0166 - mae: 0.0984 - mse: 0.0166
75/75 [==============================] - 0s 6ms/step - loss: 0.0205 - mae: 0.1082 - mse: 0.0205 - val_loss: 0.0196 - val_mae: 0.1143 - val_mse: 0.0196
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0196 - mae: 0.1033 - mse: 0.0196
64/75 [========================>.....] - ETA: 0s - loss: 0.0191 - mae: 0.1073 - mse: 0.0191
75/75 [==============================] - 0s 7ms/step - loss: 0.0197 - mae: 0.1092 - mse: 0.0197 - val_loss: 0.0181 - val_mae: 0.1119 - val_mse: 0.0181
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0200 - mae: 0.1016 - mse: 0.0200
64/75 [========================>.....] - ETA: 0s - loss: 0.0214 - mae: 0.1134 - mse: 0.0214
75/75 [==============================] - 0s 6ms/step - loss: 0.0207 - mae: 0.1107 - mse: 0.0207 - val_loss: 0.0198 - val_mae: 0.1220 - val_mse: 0.0198
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0182 - mae: 0.1028 - mse: 0.0182
64/75 [========================>.....] - ETA: 0s - loss: 0.0192 - mae: 0.1062 - mse: 0.0192
75/75 [==============================] - 0s 7ms/step - loss: 0.0237 - mae: 0.1127 - mse: 0.0237 - val_loss: 0.0201 - val_mae: 0.1249 - val_mse: 0.0201
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0179 - mae: 0.1008 - mse: 0.0179
64/75 [========================>.....] - ETA: 0s - loss: 0.0200 - mae: 0.1088 - mse: 0.0200
75/75 [==============================] - 0s 7ms/step - loss: 0.0211 - mae: 0.1113 - mse: 0.0211 - val_loss: 0.0144 - val_mae: 0.1045 - val_mse: 0.0144
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0154 - mae: 0.0975 - mse: 0.0154
64/75 [========================>.....] - ETA: 0s - loss: 0.0208 - mae: 0.1065 - mse: 0.0208
75/75 [==============================] - 0s 7ms/step - loss: 0.0214 - mae: 0.1089 - mse: 0.0214 - val_loss: 0.0131 - val_mae: 0.0962 - val_mse: 0.0131
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0197 - mae: 0.1051 - mse: 0.0197
64/75 [========================>.....] - ETA: 0s - loss: 0.0187 - mae: 0.1055 - mse: 0.0187
75/75 [==============================] - 0s 6ms/step - loss: 0.0185 - mae: 0.1039 - mse: 0.0185 - val_loss: 0.0127 - val_mae: 0.0975 - val_mse: 0.0127
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0248 - mae: 0.1131 - mse: 0.0248
64/75 [========================>.....] - ETA: 0s - loss: 0.0220 - mae: 0.1094 - mse: 0.0220
75/75 [==============================] - 0s 6ms/step - loss: 0.0201 - mae: 0.1036 - mse: 0.0201 - val_loss: 0.0171 - val_mae: 0.1152 - val_mse: 0.0171
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0144 - mae: 0.0981 - mse: 0.0144
64/75 [========================>.....] - ETA: 0s - loss: 0.0181 - mae: 0.1085 - mse: 0.0181
75/75 [==============================] - 1s 7ms/step - loss: 0.0201 - mae: 0.1101 - mse: 0.0201 - val_loss: 0.0132 - val_mae: 0.1021 - val_mse: 0.0132
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0217 - mae: 0.1121 - mse: 0.0217
64/75 [========================>.....] - ETA: 0s - loss: 0.0218 - mae: 0.1152 - mse: 0.0218
75/75 [==============================] - 0s 7ms/step - loss: 0.0209 - mae: 0.1117 - mse: 0.0209 - val_loss: 0.0137 - val_mae: 0.1025 - val_mse: 0.0137
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0165 - mae: 0.0945 - mse: 0.0165
64/75 [========================>.....] - ETA: 0s - loss: 0.0190 - mae: 0.1064 - mse: 0.0190
75/75 [==============================] - 0s 7ms/step - loss: 0.0171 - mae: 0.1001 - mse: 0.0171 - val_loss: 0.0148 - val_mae: 0.1052 - val_mse: 0.0148
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0174 - mae: 0.1095 - mse: 0.0174
64/75 [========================>.....] - ETA: 0s - loss: 0.0179 - mae: 0.1024 - mse: 0.0179
75/75 [==============================] - 1s 7ms/step - loss: 0.0178 - mae: 0.0990 - mse: 0.0178 - val_loss: 0.0169 - val_mae: 0.1130 - val_mse: 0.0169
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0217 - mae: 0.1065 - mse: 0.0217
64/75 [========================>.....] - ETA: 0s - loss: 0.0196 - mae: 0.1018 - mse: 0.0196
75/75 [==============================] - 0s 7ms/step - loss: 0.0205 - mae: 0.1069 - mse: 0.0205 - val_loss: 0.0170 - val_mae: 0.1139 - val_mse: 0.0170
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0219 - mae: 0.1159 - mse: 0.0219
64/75 [========================>.....] - ETA: 0s - loss: 0.0210 - mae: 0.1136 - mse: 0.0210
75/75 [==============================] - 0s 6ms/step - loss: 0.0191 - mae: 0.1061 - mse: 0.0191 - val_loss: 0.0139 - val_mae: 0.1049 - val_mse: 0.0139
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0169 - mae: 0.0977 - mse: 0.0169
64/75 [========================>.....] - ETA: 0s - loss: 0.0208 - mae: 0.1120 - mse: 0.0208
75/75 [==============================] - 0s 7ms/step - loss: 0.0209 - mae: 0.1129 - mse: 0.0209 - val_loss: 0.0121 - val_mae: 0.0971 - val_mse: 0.0121
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0197 - mae: 0.1036 - mse: 0.0197
64/75 [========================>.....] - ETA: 0s - loss: 0.0175 - mae: 0.0979 - mse: 0.0175
75/75 [==============================] - 0s 7ms/step - loss: 0.0186 - mae: 0.1032 - mse: 0.0186 - val_loss: 0.0150 - val_mae: 0.1055 - val_mse: 0.0150
Saving trained model...
115
Testing...
heightdiff= [0.         0.         0.         2.86251831 0.         0.        ]
average prediction= [3.3266087]
baseline= 7.738095238095238
eachuser= [0. 0. 0. 3. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.9541727701822916
85 -:- nan
60 -:- nan
['train-weight-12.py', '1']
65 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
65 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
65 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
65 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
60 31
60 32
60 33
60 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
60 37
60 38
2_170_60_12_csi_a12_4.dat
60 40
65 41
65 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
65 48
65 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
65 56
65 57
1_165_65_12_csi_a12_7.dat
65 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
65 70
2_165_50_12_csi_a12_13.dat
50 72
50 73
50 74
50 75
50 76
50 77
50 78
50 79
50 80
50 81
50 82
50 83
50 84
50 85
2_165_50_12_csi_a12_7.dat
50 87
2_165_50_12_csi_a12_23.dat
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
70 119
70 120
70 121
70 122
70 123
70 124
70 125
1_175_70_12_csi_a12_26.dat
70 127
70 128
70 129
70 130
85 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
85 134
85 135
1_180_85_12_csi_a12_19.dat
85 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
85 140
1_180_85_12_csi_a12_12.dat
85 142
85 143
85 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
85 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
75 161
75 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
75 165
75 166
75 167
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
1_180_75_12_csi_a12_12.dat
75 178
1_180_75_12_csi_a12_13.dat
75 180
75 181
75 182
1_180_75_12_csi_a12_14.dat
75 184
75 185
75 186
75 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
75 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[65 65 65 65 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.3671 - mae: 0.5384 - mse: 0.3671
64/75 [========================>.....] - ETA: 0s - loss: 0.2934 - mae: 0.4762 - mse: 0.2934
75/75 [==============================] - 1s 11ms/step - loss: 0.2592 - mae: 0.4389 - mse: 0.2592 - val_loss: 0.1536 - val_mae: 0.3721 - val_mse: 0.1536
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0975 - mae: 0.2626 - mse: 0.0975
64/75 [========================>.....] - ETA: 0s - loss: 0.1152 - mae: 0.2881 - mse: 0.1152
75/75 [==============================] - 0s 6ms/step - loss: 0.1296 - mae: 0.2998 - mse: 0.1296 - val_loss: 0.1068 - val_mae: 0.2920 - val_mse: 0.1068
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1549 - mae: 0.3123 - mse: 0.1549
64/75 [========================>.....] - ETA: 0s - loss: 0.1205 - mae: 0.2745 - mse: 0.1205
75/75 [==============================] - 1s 7ms/step - loss: 0.1121 - mae: 0.2647 - mse: 0.1121 - val_loss: 0.0938 - val_mae: 0.2844 - val_mse: 0.0938
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0699 - mae: 0.2360 - mse: 0.0699
64/75 [========================>.....] - ETA: 0s - loss: 0.0791 - mae: 0.2477 - mse: 0.0791
75/75 [==============================] - 1s 7ms/step - loss: 0.0725 - mae: 0.2339 - mse: 0.0725 - val_loss: 0.0868 - val_mae: 0.2632 - val_mse: 0.0868
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0741 - mae: 0.2216 - mse: 0.0741
64/75 [========================>.....] - ETA: 0s - loss: 0.0690 - mae: 0.2138 - mse: 0.0690
75/75 [==============================] - 1s 7ms/step - loss: 0.0639 - mae: 0.2072 - mse: 0.0639 - val_loss: 0.0608 - val_mae: 0.2112 - val_mse: 0.0608
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0481 - mae: 0.1749 - mse: 0.0481
64/75 [========================>.....] - ETA: 0s - loss: 0.0406 - mae: 0.1600 - mse: 0.0406
75/75 [==============================] - 0s 7ms/step - loss: 0.0420 - mae: 0.1638 - mse: 0.0420 - val_loss: 0.0380 - val_mae: 0.1490 - val_mse: 0.0380
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0380 - mae: 0.1468 - mse: 0.0380
64/75 [========================>.....] - ETA: 0s - loss: 0.0449 - mae: 0.1694 - mse: 0.0449
75/75 [==============================] - 0s 6ms/step - loss: 0.0431 - mae: 0.1660 - mse: 0.0431 - val_loss: 0.0270 - val_mae: 0.1116 - val_mse: 0.0270
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0290 - mae: 0.1358 - mse: 0.0290
64/75 [========================>.....] - ETA: 0s - loss: 0.0262 - mae: 0.1256 - mse: 0.0262
75/75 [==============================] - 1s 7ms/step - loss: 0.0263 - mae: 0.1213 - mse: 0.0263 - val_loss: 0.0238 - val_mae: 0.1251 - val_mse: 0.0238
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0297 - mae: 0.1350 - mse: 0.0297
64/75 [========================>.....] - ETA: 0s - loss: 0.0277 - mae: 0.1319 - mse: 0.0277
75/75 [==============================] - 0s 6ms/step - loss: 0.0267 - mae: 0.1290 - mse: 0.0267 - val_loss: 0.0200 - val_mae: 0.1121 - val_mse: 0.0200
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0503 - mae: 0.1758 - mse: 0.0503
64/75 [========================>.....] - ETA: 0s - loss: 0.0400 - mae: 0.1563 - mse: 0.0400
75/75 [==============================] - 0s 7ms/step - loss: 0.0357 - mae: 0.1461 - mse: 0.0357 - val_loss: 0.0163 - val_mae: 0.0916 - val_mse: 0.0163
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0219 - mae: 0.1304 - mse: 0.0219
64/75 [========================>.....] - ETA: 0s - loss: 0.0204 - mae: 0.1154 - mse: 0.0204
75/75 [==============================] - 0s 7ms/step - loss: 0.0191 - mae: 0.1086 - mse: 0.0191 - val_loss: 0.0173 - val_mae: 0.0900 - val_mse: 0.0173
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0236 - mae: 0.1122 - mse: 0.0236
64/75 [========================>.....] - ETA: 0s - loss: 0.0239 - mae: 0.1152 - mse: 0.0239
75/75 [==============================] - 0s 6ms/step - loss: 0.0238 - mae: 0.1139 - mse: 0.0238 - val_loss: 0.0225 - val_mae: 0.1138 - val_mse: 0.0225
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0278 - mae: 0.1189 - mse: 0.0278
64/75 [========================>.....] - ETA: 0s - loss: 0.0212 - mae: 0.1087 - mse: 0.0212
75/75 [==============================] - 0s 6ms/step - loss: 0.0196 - mae: 0.1050 - mse: 0.0196 - val_loss: 0.0357 - val_mae: 0.1556 - val_mse: 0.0357
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0377 - mae: 0.1444 - mse: 0.0377
64/75 [========================>.....] - ETA: 0s - loss: 0.0322 - mae: 0.1310 - mse: 0.0322
75/75 [==============================] - 0s 7ms/step - loss: 0.0325 - mae: 0.1305 - mse: 0.0325 - val_loss: 0.0313 - val_mae: 0.1344 - val_mse: 0.0313
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0307 - mae: 0.1362 - mse: 0.0307
64/75 [========================>.....] - ETA: 0s - loss: 0.0246 - mae: 0.1170 - mse: 0.0246
75/75 [==============================] - 0s 6ms/step - loss: 0.0267 - mae: 0.1198 - mse: 0.0267 - val_loss: 0.0227 - val_mae: 0.0902 - val_mse: 0.0227
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0266 - mae: 0.1302 - mse: 0.0266
64/75 [========================>.....] - ETA: 0s - loss: 0.0219 - mae: 0.1165 - mse: 0.0219
75/75 [==============================] - 0s 7ms/step - loss: 0.0216 - mae: 0.1161 - mse: 0.0216 - val_loss: 0.0213 - val_mae: 0.0895 - val_mse: 0.0213
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0152 - mae: 0.1040 - mse: 0.0152
64/75 [========================>.....] - ETA: 0s - loss: 0.0220 - mae: 0.1187 - mse: 0.0220
75/75 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.1138 - mse: 0.0215 - val_loss: 0.0251 - val_mae: 0.1149 - val_mse: 0.0251
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0203 - mae: 0.1110 - mse: 0.0203
64/75 [========================>.....] - ETA: 0s - loss: 0.0180 - mae: 0.0999 - mse: 0.0180
75/75 [==============================] - 0s 7ms/step - loss: 0.0188 - mae: 0.1047 - mse: 0.0188 - val_loss: 0.0217 - val_mae: 0.1075 - val_mse: 0.0217
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0313 - mae: 0.1340 - mse: 0.0313
64/75 [========================>.....] - ETA: 0s - loss: 0.0212 - mae: 0.1070 - mse: 0.0212
75/75 [==============================] - 0s 6ms/step - loss: 0.0196 - mae: 0.1044 - mse: 0.0196 - val_loss: 0.0186 - val_mae: 0.1022 - val_mse: 0.0186
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0115 - mae: 0.0790 - mse: 0.0115
64/75 [========================>.....] - ETA: 0s - loss: 0.0147 - mae: 0.0878 - mse: 0.0147
75/75 [==============================] - 0s 6ms/step - loss: 0.0165 - mae: 0.0932 - mse: 0.0165 - val_loss: 0.0213 - val_mae: 0.1108 - val_mse: 0.0213
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0111 - mae: 0.0841 - mse: 0.0111
64/75 [========================>.....] - ETA: 0s - loss: 0.0178 - mae: 0.0973 - mse: 0.0178
75/75 [==============================] - 0s 7ms/step - loss: 0.0159 - mae: 0.0906 - mse: 0.0159 - val_loss: 0.0254 - val_mae: 0.1278 - val_mse: 0.0254
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0237 - mae: 0.0963 - mse: 0.0237
64/75 [========================>.....] - ETA: 0s - loss: 0.0193 - mae: 0.0904 - mse: 0.0193
75/75 [==============================] - 1s 7ms/step - loss: 0.0196 - mae: 0.0945 - mse: 0.0196 - val_loss: 0.0215 - val_mae: 0.1121 - val_mse: 0.0215
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0174 - mae: 0.0912 - mse: 0.0174
64/75 [========================>.....] - ETA: 0s - loss: 0.0196 - mae: 0.1008 - mse: 0.0196
75/75 [==============================] - 0s 7ms/step - loss: 0.0173 - mae: 0.0928 - mse: 0.0173 - val_loss: 0.0167 - val_mae: 0.0893 - val_mse: 0.0167
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0301 - mae: 0.1208 - mse: 0.0301
64/75 [========================>.....] - ETA: 0s - loss: 0.0235 - mae: 0.1072 - mse: 0.0235
75/75 [==============================] - 0s 7ms/step - loss: 0.0210 - mae: 0.1002 - mse: 0.0210 - val_loss: 0.0205 - val_mae: 0.1105 - val_mse: 0.0205
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0148 - mae: 0.1000 - mse: 0.0148
64/75 [========================>.....] - ETA: 0s - loss: 0.0139 - mae: 0.0904 - mse: 0.0139
75/75 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.0878 - mse: 0.0132 - val_loss: 0.0260 - val_mae: 0.1347 - val_mse: 0.0260
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0194 - mae: 0.1113 - mse: 0.0194
64/75 [========================>.....] - ETA: 0s - loss: 0.0160 - mae: 0.0909 - mse: 0.0160
75/75 [==============================] - 0s 6ms/step - loss: 0.0163 - mae: 0.0929 - mse: 0.0163 - val_loss: 0.0188 - val_mae: 0.1060 - val_mse: 0.0188
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0118 - mae: 0.0832 - mse: 0.0118
64/75 [========================>.....] - ETA: 0s - loss: 0.0121 - mae: 0.0821 - mse: 0.0121
75/75 [==============================] - 0s 7ms/step - loss: 0.0129 - mae: 0.0833 - mse: 0.0129 - val_loss: 0.0166 - val_mae: 0.0898 - val_mse: 0.0166
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0144 - mae: 0.0979 - mse: 0.0144
64/75 [========================>.....] - ETA: 0s - loss: 0.0146 - mae: 0.0952 - mse: 0.0146
75/75 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.0922 - mse: 0.0136 - val_loss: 0.0191 - val_mae: 0.1089 - val_mse: 0.0191
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0140 - mae: 0.0750 - mse: 0.0140
64/75 [========================>.....] - ETA: 0s - loss: 0.0187 - mae: 0.0893 - mse: 0.0187
75/75 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.0865 - mse: 0.0172 - val_loss: 0.0196 - val_mae: 0.1142 - val_mse: 0.0196
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0176 - mae: 0.0881 - mse: 0.0176
64/75 [========================>.....] - ETA: 0s - loss: 0.0135 - mae: 0.0790 - mse: 0.0135
75/75 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.0794 - mse: 0.0135 - val_loss: 0.0149 - val_mae: 0.0915 - val_mse: 0.0149
Saving trained model...
115
Testing...
heightdiff= [ 0.          0.          0.         10.20873642  0.          0.        ]
average prediction= [4.059715]
baseline= 10.357142857142858
eachuser= [0. 0. 0. 6. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.701456069946289
85 -:- nan
60 -:- nan
['train-weight-12.py', '1']
65 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
65 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
65 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
65 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
60 31
60 32
60 33
60 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
60 37
60 38
2_170_60_12_csi_a12_4.dat
60 40
65 41
65 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
65 48
65 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
65 56
65 57
1_165_65_12_csi_a12_7.dat
65 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
65 70
2_165_50_12_csi_a12_13.dat
50 72
50 73
50 74
50 75
50 76
50 77
50 78
50 79
50 80
50 81
50 82
50 83
50 84
50 85
2_165_50_12_csi_a12_7.dat
50 87
2_165_50_12_csi_a12_23.dat
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
70 119
70 120
70 121
70 122
70 123
70 124
70 125
1_175_70_12_csi_a12_26.dat
70 127
70 128
70 129
70 130
85 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
85 134
85 135
1_180_85_12_csi_a12_19.dat
85 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
85 140
1_180_85_12_csi_a12_12.dat
85 142
85 143
85 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
85 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
75 161
75 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
75 165
75 166
75 167
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
1_180_75_12_csi_a12_12.dat
75 178
1_180_75_12_csi_a12_13.dat
75 180
75 181
75 182
1_180_75_12_csi_a12_14.dat
75 184
75 185
75 186
75 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
75 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[65 65 65 65 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.3592 - mae: 0.5216 - mse: 0.3592
64/75 [========================>.....] - ETA: 0s - loss: 0.2680 - mae: 0.4517 - mse: 0.2680
75/75 [==============================] - 1s 11ms/step - loss: 0.2470 - mae: 0.4345 - mse: 0.2470 - val_loss: 0.1470 - val_mae: 0.3566 - val_mse: 0.1470
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1359 - mae: 0.3050 - mse: 0.1359
64/75 [========================>.....] - ETA: 0s - loss: 0.1372 - mae: 0.2965 - mse: 0.1372
75/75 [==============================] - 1s 7ms/step - loss: 0.1461 - mae: 0.3080 - mse: 0.1461 - val_loss: 0.0927 - val_mae: 0.2676 - val_mse: 0.0927
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1696 - mae: 0.3251 - mse: 0.1696
64/75 [========================>.....] - ETA: 0s - loss: 0.1367 - mae: 0.2984 - mse: 0.1367
75/75 [==============================] - 1s 7ms/step - loss: 0.1266 - mae: 0.2832 - mse: 0.1266 - val_loss: 0.1133 - val_mae: 0.3153 - val_mse: 0.1133
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1094 - mae: 0.2924 - mse: 0.1094
64/75 [========================>.....] - ETA: 0s - loss: 0.1029 - mae: 0.2769 - mse: 0.1029
75/75 [==============================] - 0s 7ms/step - loss: 0.0971 - mae: 0.2696 - mse: 0.0971 - val_loss: 0.1086 - val_mae: 0.3087 - val_mse: 0.1086
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0959 - mae: 0.2751 - mse: 0.0959
64/75 [========================>.....] - ETA: 0s - loss: 0.0752 - mae: 0.2410 - mse: 0.0752
75/75 [==============================] - 0s 6ms/step - loss: 0.0743 - mae: 0.2428 - mse: 0.0743 - val_loss: 0.0617 - val_mae: 0.2333 - val_mse: 0.0617
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0620 - mae: 0.2035 - mse: 0.0620
64/75 [========================>.....] - ETA: 0s - loss: 0.0538 - mae: 0.1928 - mse: 0.0538
75/75 [==============================] - 1s 7ms/step - loss: 0.0523 - mae: 0.1909 - mse: 0.0523 - val_loss: 0.0288 - val_mae: 0.1486 - val_mse: 0.0288
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0569 - mae: 0.1887 - mse: 0.0569
64/75 [========================>.....] - ETA: 0s - loss: 0.0480 - mae: 0.1779 - mse: 0.0480
75/75 [==============================] - 0s 6ms/step - loss: 0.0511 - mae: 0.1834 - mse: 0.0511 - val_loss: 0.0285 - val_mae: 0.1450 - val_mse: 0.0285
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0398 - mae: 0.1536 - mse: 0.0398
64/75 [========================>.....] - ETA: 0s - loss: 0.0431 - mae: 0.1640 - mse: 0.0431
75/75 [==============================] - 0s 6ms/step - loss: 0.0422 - mae: 0.1655 - mse: 0.0422 - val_loss: 0.0363 - val_mae: 0.1626 - val_mse: 0.0363
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0358 - mae: 0.1614 - mse: 0.0358
64/75 [========================>.....] - ETA: 0s - loss: 0.0423 - mae: 0.1644 - mse: 0.0423
75/75 [==============================] - 0s 6ms/step - loss: 0.0410 - mae: 0.1633 - mse: 0.0410 - val_loss: 0.0292 - val_mae: 0.1357 - val_mse: 0.0292
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0309 - mae: 0.1508 - mse: 0.0309
64/75 [========================>.....] - ETA: 0s - loss: 0.0352 - mae: 0.1484 - mse: 0.0352
75/75 [==============================] - 0s 6ms/step - loss: 0.0355 - mae: 0.1511 - mse: 0.0355 - val_loss: 0.0223 - val_mae: 0.1100 - val_mse: 0.0223
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0245 - mae: 0.1266 - mse: 0.0245
64/75 [========================>.....] - ETA: 0s - loss: 0.0286 - mae: 0.1325 - mse: 0.0286
75/75 [==============================] - 0s 7ms/step - loss: 0.0294 - mae: 0.1354 - mse: 0.0294 - val_loss: 0.0279 - val_mae: 0.1210 - val_mse: 0.0279
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0202 - mae: 0.1148 - mse: 0.0202
64/75 [========================>.....] - ETA: 0s - loss: 0.0318 - mae: 0.1348 - mse: 0.0318
75/75 [==============================] - 0s 6ms/step - loss: 0.0301 - mae: 0.1330 - mse: 0.0301 - val_loss: 0.0253 - val_mae: 0.1143 - val_mse: 0.0253
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0304 - mae: 0.1254 - mse: 0.0304
64/75 [========================>.....] - ETA: 0s - loss: 0.0296 - mae: 0.1277 - mse: 0.0296
75/75 [==============================] - 0s 7ms/step - loss: 0.0265 - mae: 0.1183 - mse: 0.0265 - val_loss: 0.0249 - val_mae: 0.1148 - val_mse: 0.0249
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0147 - mae: 0.0893 - mse: 0.0147
64/75 [========================>.....] - ETA: 0s - loss: 0.0178 - mae: 0.0973 - mse: 0.0178
75/75 [==============================] - 0s 7ms/step - loss: 0.0171 - mae: 0.0969 - mse: 0.0171 - val_loss: 0.0216 - val_mae: 0.1044 - val_mse: 0.0216
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0308 - mae: 0.1307 - mse: 0.0308
64/75 [========================>.....] - ETA: 0s - loss: 0.0219 - mae: 0.1108 - mse: 0.0219
75/75 [==============================] - 0s 6ms/step - loss: 0.0222 - mae: 0.1127 - mse: 0.0222 - val_loss: 0.0277 - val_mae: 0.1292 - val_mse: 0.0277
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0103 - mae: 0.0811 - mse: 0.0103
64/75 [========================>.....] - ETA: 0s - loss: 0.0208 - mae: 0.0989 - mse: 0.0208
75/75 [==============================] - 0s 7ms/step - loss: 0.0201 - mae: 0.0985 - mse: 0.0201 - val_loss: 0.0348 - val_mae: 0.1512 - val_mse: 0.0348
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0196 - mae: 0.1049 - mse: 0.0196
64/75 [========================>.....] - ETA: 0s - loss: 0.0217 - mae: 0.1063 - mse: 0.0217
75/75 [==============================] - 0s 6ms/step - loss: 0.0211 - mae: 0.1053 - mse: 0.0211 - val_loss: 0.0225 - val_mae: 0.1111 - val_mse: 0.0225
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0180 - mae: 0.1008 - mse: 0.0180
64/75 [========================>.....] - ETA: 0s - loss: 0.0178 - mae: 0.1023 - mse: 0.0178
75/75 [==============================] - 0s 7ms/step - loss: 0.0185 - mae: 0.1073 - mse: 0.0185 - val_loss: 0.0140 - val_mae: 0.0849 - val_mse: 0.0140
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0220 - mae: 0.1212 - mse: 0.0220
64/75 [========================>.....] - ETA: 0s - loss: 0.0178 - mae: 0.1024 - mse: 0.0178
75/75 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0995 - mse: 0.0170 - val_loss: 0.0166 - val_mae: 0.0930 - val_mse: 0.0166
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0175 - mae: 0.1084 - mse: 0.0175
64/75 [========================>.....] - ETA: 0s - loss: 0.0146 - mae: 0.0948 - mse: 0.0146
75/75 [==============================] - 0s 6ms/step - loss: 0.0165 - mae: 0.0996 - mse: 0.0165 - val_loss: 0.0241 - val_mae: 0.1148 - val_mse: 0.0241
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0112 - mae: 0.0775 - mse: 0.0112
64/75 [========================>.....] - ETA: 0s - loss: 0.0155 - mae: 0.0923 - mse: 0.0155
75/75 [==============================] - 0s 6ms/step - loss: 0.0154 - mae: 0.0942 - mse: 0.0154 - val_loss: 0.0375 - val_mae: 0.1539 - val_mse: 0.0375
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0252 - mae: 0.1228 - mse: 0.0252
64/75 [========================>.....] - ETA: 0s - loss: 0.0188 - mae: 0.1014 - mse: 0.0188
75/75 [==============================] - 0s 7ms/step - loss: 0.0178 - mae: 0.0995 - mse: 0.0178 - val_loss: 0.0288 - val_mae: 0.1266 - val_mse: 0.0288
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0249 - mae: 0.1163 - mse: 0.0249
64/75 [========================>.....] - ETA: 0s - loss: 0.0195 - mae: 0.1017 - mse: 0.0195
75/75 [==============================] - 0s 6ms/step - loss: 0.0182 - mae: 0.0984 - mse: 0.0182 - val_loss: 0.0242 - val_mae: 0.1099 - val_mse: 0.0242
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0100 - mae: 0.0686 - mse: 0.0100
64/75 [========================>.....] - ETA: 0s - loss: 0.0127 - mae: 0.0775 - mse: 0.0127
75/75 [==============================] - 0s 7ms/step - loss: 0.0110 - mae: 0.0710 - mse: 0.0110 - val_loss: 0.0288 - val_mae: 0.1271 - val_mse: 0.0288
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0088 - mae: 0.0758 - mse: 0.0088
64/75 [========================>.....] - ETA: 0s - loss: 0.0118 - mae: 0.0815 - mse: 0.0118
75/75 [==============================] - 1s 7ms/step - loss: 0.0134 - mae: 0.0863 - mse: 0.0134 - val_loss: 0.0263 - val_mae: 0.1185 - val_mse: 0.0263
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0156 - mae: 0.0914 - mse: 0.0156
64/75 [========================>.....] - ETA: 0s - loss: 0.0179 - mae: 0.0884 - mse: 0.0179
75/75 [==============================] - 0s 6ms/step - loss: 0.0190 - mae: 0.0965 - mse: 0.0190 - val_loss: 0.0191 - val_mae: 0.0955 - val_mse: 0.0191
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0083 - mae: 0.0718 - mse: 0.0083
64/75 [========================>.....] - ETA: 0s - loss: 0.0121 - mae: 0.0854 - mse: 0.0121
75/75 [==============================] - 1s 7ms/step - loss: 0.0110 - mae: 0.0813 - mse: 0.0110 - val_loss: 0.0213 - val_mae: 0.1023 - val_mse: 0.0213
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0133 - mae: 0.0933 - mse: 0.0133
64/75 [========================>.....] - ETA: 0s - loss: 0.0158 - mae: 0.0949 - mse: 0.0158
75/75 [==============================] - 0s 6ms/step - loss: 0.0159 - mae: 0.0965 - mse: 0.0159 - val_loss: 0.0271 - val_mae: 0.1226 - val_mse: 0.0271
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0081 - mae: 0.0665 - mse: 0.0081
64/75 [========================>.....] - ETA: 0s - loss: 0.0105 - mae: 0.0772 - mse: 0.0105
75/75 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0784 - mse: 0.0111 - val_loss: 0.0335 - val_mae: 0.1438 - val_mse: 0.0335
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0195 - mae: 0.1054 - mse: 0.0195
64/75 [========================>.....] - ETA: 0s - loss: 0.0152 - mae: 0.0935 - mse: 0.0152
75/75 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.0910 - mse: 0.0142 - val_loss: 0.0234 - val_mae: 0.1118 - val_mse: 0.0234
Saving trained model...
115
Testing...
heightdiff= [0.         0.         0.         1.96669769 0.         0.        ]
average prediction= [3.3198237]
baseline= 9.404761904761905
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.49167442321777344
85 -:- nan
60 -:- nan
['train-weight-12.py', '1']
65 1
2_155_65_12_csi_a12_1.dat
2_155_65_12_csi_a12_5.dat
2_155_65_12_csi_a12_4.dat
2_155_65_12_csi_a12_2.dat
2_155_65_12_csi_a12_17.dat
2_155_65_12_csi_a12_30.dat
2_155_65_12_csi_a12_14.dat
65 9
2_155_65_12_csi_a12_21.dat
2_155_65_12_csi_a12_9.dat
2_155_65_12_csi_a12_29.dat
65 13
2_155_65_12_csi_a12_16.dat
2_155_65_12_csi_a12_23.dat
2_155_65_12_csi_a12_22.dat
2_155_65_12_csi_a12_7.dat
2_155_65_12_csi_a12_28.dat
65 19
2_155_65_12_csi_a12_15.dat
2_155_65_12_csi_a12_11.dat
2_155_65_12_csi_a12_27.dat
2_155_65_12_csi_a12_19.dat
2_155_65_12_csi_a12_6.dat
2_155_65_12_csi_a12_18.dat
2_155_65_12_csi_a12_12.dat
2_155_65_12_csi_a12_26.dat
2_155_65_12_csi_a12_3.dat
2_155_65_12_csi_a12_8.dat
2_155_65_12_csi_a12_20.dat
60 31
60 32
60 33
60 34
2_170_60_12_csi_a12_6.dat
2_170_60_12_csi_a12_7.dat
60 37
60 38
2_170_60_12_csi_a12_4.dat
60 40
65 41
65 42
1_165_65_12_csi_a12_26.dat
1_165_65_12_csi_a12_22.dat
1_165_65_12_csi_a12_23.dat
1_165_65_12_csi_a12_29.dat
1_165_65_12_csi_a12_8.dat
65 48
65 49
1_165_65_12_csi_a12_14.dat
1_165_65_12_csi_a12_28.dat
1_165_65_12_csi_a12_24.dat
1_165_65_12_csi_a12_15.dat
1_165_65_12_csi_a12_3.dat
1_165_65_12_csi_a12_2.dat
65 56
65 57
1_165_65_12_csi_a12_7.dat
65 59
1_165_65_12_csi_a12_6.dat
1_165_65_12_csi_a12_9.dat
1_165_65_12_csi_a12_5.dat
1_165_65_12_csi_a12_17.dat
1_165_65_12_csi_a12_25.dat
1_165_65_12_csi_a12_20.dat
1_165_65_12_csi_a12_12.dat
1_165_65_12_csi_a12_19.dat
1_165_65_12_csi_a12_10.dat
1_165_65_12_csi_a12_30.dat
65 70
2_165_50_12_csi_a12_13.dat
50 72
50 73
50 74
50 75
50 76
50 77
50 78
50 79
50 80
50 81
50 82
50 83
50 84
50 85
2_165_50_12_csi_a12_7.dat
50 87
2_165_50_12_csi_a12_23.dat
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
2_165_50_12_csi_a12_19.dat
2_165_50_12_csi_a12_20.dat
50 99
50 100
70 101
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
70 111
70 112
70 113
70 114
70 115
70 116
70 117
70 118
70 119
70 120
70 121
70 122
70 123
70 124
70 125
1_175_70_12_csi_a12_26.dat
70 127
70 128
70 129
70 130
85 131
1_180_85_12_csi_a12_2.dat
1_180_85_12_csi_a12_7.dat
85 134
85 135
1_180_85_12_csi_a12_19.dat
85 137
1_180_85_12_csi_a12_20.dat
1_180_85_12_csi_a12_4.dat
85 140
1_180_85_12_csi_a12_12.dat
85 142
85 143
85 144
1_180_85_12_csi_a12_15.dat
1_180_85_12_csi_a12_27.dat
1_180_85_12_csi_a12_26.dat
1_180_85_12_csi_a12_21.dat
1_180_85_12_csi_a12_22.dat
1_180_85_12_csi_a12_13.dat
1_180_85_12_csi_a12_17.dat
1_180_85_12_csi_a12_10.dat
85 153
1_180_85_12_csi_a12_11.dat
1_180_85_12_csi_a12_28.dat
1_180_85_12_csi_a12_9.dat
1_180_85_12_csi_a12_5.dat
1_180_85_12_csi_a12_29.dat
1_180_85_12_csi_a12_16.dat
1_180_85_12_csi_a12_18.dat
75 161
75 162
1_180_75_12_csi_a12_4.dat
1_180_75_12_csi_a12_7.dat
75 165
75 166
75 167
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
1_180_75_12_csi_a12_12.dat
75 178
1_180_75_12_csi_a12_13.dat
75 180
75 181
75 182
1_180_75_12_csi_a12_14.dat
75 184
75 185
75 186
75 187
1_180_75_12_csi_a12_1.dat
1_180_75_12_csi_a12_19.dat
75 190
1_173_85_12_csi_a12_16.dat
1_173_85_12_csi_a12_12.dat
1_173_85_12_csi_a12_5.dat
1_173_85_12_csi_a12_2.dat
1_173_85_12_csi_a12_17.dat
1_173_85_12_csi_a12_19.dat
1_173_85_12_csi_a12_10.dat
1_173_85_12_csi_a12_29.dat
1_173_85_12_csi_a12_6.dat
1_173_85_12_csi_a12_21.dat
1_173_85_12_csi_a12_11.dat
1_173_85_12_csi_a12_15.dat
1_173_85_12_csi_a12_23.dat
1_173_85_12_csi_a12_18.dat
1_173_85_12_csi_a12_26.dat
1_173_85_12_csi_a12_8.dat
1_173_85_12_csi_a12_24.dat
1_173_85_12_csi_a12_3.dat
1_173_85_12_csi_a12_14.dat
1_173_85_12_csi_a12_1.dat
1_173_85_12_csi_a12_22.dat
1_173_85_12_csi_a12_25.dat
1_173_85_12_csi_a12_13.dat
1_173_85_12_csi_a12_4.dat
1_173_85_12_csi_a12_27.dat
1_173_85_12_csi_a12_9.dat
1_173_85_12_csi_a12_28.dat
1_173_85_12_csi_a12_7.dat
1_173_85_12_csi_a12_20.dat
1_173_85_12_csi_a12_30.dat
(105, 30, 3)
(105, 464, 30, 3)
[65 65 65 65 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70
 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 85 85 85 85 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75]
(105, 464, 30, 3, 1)

Loaded dataset of 105 samples, each sized (464, 30, 3, 1)


Train on 84 samples
Test on 21 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 464, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 464, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 464, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 464, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 464, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 464, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 464, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 75 samples, validate on 9 samples
Epoch 1/30

32/75 [===========>..................] - ETA: 0s - loss: 0.2357 - mae: 0.3925 - mse: 0.2357
64/75 [========================>.....] - ETA: 0s - loss: 0.2137 - mae: 0.3926 - mse: 0.2137
75/75 [==============================] - 1s 11ms/step - loss: 0.1943 - mae: 0.3756 - mse: 0.1943 - val_loss: 0.1431 - val_mae: 0.3339 - val_mse: 0.1431
Epoch 2/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1505 - mae: 0.3060 - mse: 0.1505
64/75 [========================>.....] - ETA: 0s - loss: 0.1646 - mae: 0.3199 - mse: 0.1646
75/75 [==============================] - 0s 7ms/step - loss: 0.1481 - mae: 0.2992 - mse: 0.1481 - val_loss: 0.1280 - val_mae: 0.3120 - val_mse: 0.1280
Epoch 3/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1055 - mae: 0.2445 - mse: 0.1055
64/75 [========================>.....] - ETA: 0s - loss: 0.1130 - mae: 0.2557 - mse: 0.1130
75/75 [==============================] - 0s 6ms/step - loss: 0.1145 - mae: 0.2634 - mse: 0.1145 - val_loss: 0.1354 - val_mae: 0.3177 - val_mse: 0.1354
Epoch 4/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0878 - mae: 0.2573 - mse: 0.0878
64/75 [========================>.....] - ETA: 0s - loss: 0.1046 - mae: 0.2820 - mse: 0.1046
75/75 [==============================] - 0s 6ms/step - loss: 0.1076 - mae: 0.2896 - mse: 0.1076 - val_loss: 0.1420 - val_mae: 0.3253 - val_mse: 0.1420
Epoch 5/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0906 - mae: 0.2429 - mse: 0.0906
64/75 [========================>.....] - ETA: 0s - loss: 0.0929 - mae: 0.2622 - mse: 0.0929
75/75 [==============================] - 0s 6ms/step - loss: 0.0900 - mae: 0.2586 - mse: 0.0900 - val_loss: 0.1217 - val_mae: 0.2998 - val_mse: 0.1217
Epoch 6/30

32/75 [===========>..................] - ETA: 0s - loss: 0.1054 - mae: 0.2848 - mse: 0.1054
64/75 [========================>.....] - ETA: 0s - loss: 0.0879 - mae: 0.2548 - mse: 0.0879
75/75 [==============================] - 0s 7ms/step - loss: 0.0814 - mae: 0.2413 - mse: 0.0814 - val_loss: 0.0878 - val_mae: 0.2521 - val_mse: 0.0878
Epoch 7/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0497 - mae: 0.1835 - mse: 0.0497
64/75 [========================>.....] - ETA: 0s - loss: 0.0643 - mae: 0.2169 - mse: 0.0643
75/75 [==============================] - 0s 7ms/step - loss: 0.0603 - mae: 0.2066 - mse: 0.0603 - val_loss: 0.0691 - val_mae: 0.2195 - val_mse: 0.0691
Epoch 8/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0595 - mae: 0.2168 - mse: 0.0595
64/75 [========================>.....] - ETA: 0s - loss: 0.0603 - mae: 0.2162 - mse: 0.0603
75/75 [==============================] - 0s 6ms/step - loss: 0.0559 - mae: 0.2041 - mse: 0.0559 - val_loss: 0.0626 - val_mae: 0.2082 - val_mse: 0.0626
Epoch 9/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0583 - mae: 0.2023 - mse: 0.0583
64/75 [========================>.....] - ETA: 0s - loss: 0.0455 - mae: 0.1744 - mse: 0.0455
75/75 [==============================] - 0s 7ms/step - loss: 0.0455 - mae: 0.1759 - mse: 0.0455 - val_loss: 0.0578 - val_mae: 0.1992 - val_mse: 0.0578
Epoch 10/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0359 - mae: 0.1579 - mse: 0.0359
64/75 [========================>.....] - ETA: 0s - loss: 0.0356 - mae: 0.1535 - mse: 0.0356
75/75 [==============================] - 0s 7ms/step - loss: 0.0338 - mae: 0.1499 - mse: 0.0338 - val_loss: 0.0287 - val_mae: 0.1356 - val_mse: 0.0287
Epoch 11/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0422 - mae: 0.1678 - mse: 0.0422
64/75 [========================>.....] - ETA: 0s - loss: 0.0313 - mae: 0.1410 - mse: 0.0313
75/75 [==============================] - 1s 7ms/step - loss: 0.0315 - mae: 0.1417 - mse: 0.0315 - val_loss: 0.0253 - val_mae: 0.1193 - val_mse: 0.0253
Epoch 12/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0259 - mae: 0.1203 - mse: 0.0259
64/75 [========================>.....] - ETA: 0s - loss: 0.0205 - mae: 0.1097 - mse: 0.0205
75/75 [==============================] - 0s 7ms/step - loss: 0.0191 - mae: 0.1050 - mse: 0.0191 - val_loss: 0.0425 - val_mae: 0.1643 - val_mse: 0.0425
Epoch 13/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0397 - mae: 0.1511 - mse: 0.0397
64/75 [========================>.....] - ETA: 0s - loss: 0.0284 - mae: 0.1233 - mse: 0.0284
75/75 [==============================] - 0s 7ms/step - loss: 0.0260 - mae: 0.1191 - mse: 0.0260 - val_loss: 0.0208 - val_mae: 0.0943 - val_mse: 0.0208
Epoch 14/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0253 - mae: 0.1267 - mse: 0.0253
64/75 [========================>.....] - ETA: 0s - loss: 0.0245 - mae: 0.1171 - mse: 0.0245
75/75 [==============================] - 1s 7ms/step - loss: 0.0242 - mae: 0.1178 - mse: 0.0242 - val_loss: 0.0205 - val_mae: 0.0919 - val_mse: 0.0205
Epoch 15/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0309 - mae: 0.1288 - mse: 0.0309
64/75 [========================>.....] - ETA: 0s - loss: 0.0255 - mae: 0.1168 - mse: 0.0255
75/75 [==============================] - 0s 6ms/step - loss: 0.0237 - mae: 0.1104 - mse: 0.0237 - val_loss: 0.0311 - val_mae: 0.1289 - val_mse: 0.0311
Epoch 16/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0208 - mae: 0.1052 - mse: 0.0208
64/75 [========================>.....] - ETA: 0s - loss: 0.0233 - mae: 0.1109 - mse: 0.0233
75/75 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1085 - mse: 0.0221 - val_loss: 0.0294 - val_mae: 0.1225 - val_mse: 0.0294
Epoch 17/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0146 - mae: 0.0843 - mse: 0.0146
64/75 [========================>.....] - ETA: 0s - loss: 0.0145 - mae: 0.0882 - mse: 0.0145
75/75 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0845 - mse: 0.0133 - val_loss: 0.0238 - val_mae: 0.1029 - val_mse: 0.0238
Epoch 18/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0146 - mae: 0.0976 - mse: 0.0146
64/75 [========================>.....] - ETA: 0s - loss: 0.0147 - mae: 0.0952 - mse: 0.0147
75/75 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.0902 - mse: 0.0135 - val_loss: 0.0191 - val_mae: 0.0834 - val_mse: 0.0191
Epoch 19/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0137 - mae: 0.0971 - mse: 0.0137
64/75 [========================>.....] - ETA: 0s - loss: 0.0133 - mae: 0.0934 - mse: 0.0133
75/75 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0876 - mse: 0.0122 - val_loss: 0.0262 - val_mae: 0.1043 - val_mse: 0.0262
Epoch 20/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0109 - mae: 0.0743 - mse: 0.0109
64/75 [========================>.....] - ETA: 0s - loss: 0.0099 - mae: 0.0752 - mse: 0.0099
75/75 [==============================] - 0s 7ms/step - loss: 0.0115 - mae: 0.0780 - mse: 0.0115 - val_loss: 0.0240 - val_mae: 0.0932 - val_mse: 0.0240
Epoch 21/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0148 - mae: 0.0991 - mse: 0.0148
64/75 [========================>.....] - ETA: 0s - loss: 0.0144 - mae: 0.0956 - mse: 0.0144
75/75 [==============================] - 0s 7ms/step - loss: 0.0133 - mae: 0.0898 - mse: 0.0133 - val_loss: 0.0215 - val_mae: 0.0872 - val_mse: 0.0215
Epoch 22/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0152 - mae: 0.0962 - mse: 0.0152
64/75 [========================>.....] - ETA: 0s - loss: 0.0114 - mae: 0.0823 - mse: 0.0114
75/75 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0782 - mse: 0.0105 - val_loss: 0.0286 - val_mae: 0.1200 - val_mse: 0.0286
Epoch 23/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0139 - mae: 0.0875 - mse: 0.0139
64/75 [========================>.....] - ETA: 0s - loss: 0.0166 - mae: 0.0928 - mse: 0.0166
75/75 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 0.0914 - mse: 0.0166 - val_loss: 0.0229 - val_mae: 0.0962 - val_mse: 0.0229
Epoch 24/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0179 - mae: 0.0831 - mse: 0.0179
64/75 [========================>.....] - ETA: 0s - loss: 0.0163 - mae: 0.0830 - mse: 0.0163
75/75 [==============================] - 0s 6ms/step - loss: 0.0183 - mae: 0.0916 - mse: 0.0183 - val_loss: 0.0213 - val_mae: 0.0853 - val_mse: 0.0213
Epoch 25/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0141 - mae: 0.0929 - mse: 0.0141
64/75 [========================>.....] - ETA: 0s - loss: 0.0115 - mae: 0.0815 - mse: 0.0115
75/75 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0833 - mse: 0.0118 - val_loss: 0.0419 - val_mae: 0.1501 - val_mse: 0.0419
Epoch 26/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0074 - mae: 0.0645 - mse: 0.0074
64/75 [========================>.....] - ETA: 0s - loss: 0.0140 - mae: 0.0911 - mse: 0.0140
75/75 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0970 - mse: 0.0181 - val_loss: 0.0241 - val_mae: 0.0964 - val_mse: 0.0241
Epoch 27/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0127 - mae: 0.0860 - mse: 0.0127
64/75 [========================>.....] - ETA: 0s - loss: 0.0109 - mae: 0.0812 - mse: 0.0109
75/75 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0808 - mse: 0.0108 - val_loss: 0.0118 - val_mae: 0.0541 - val_mse: 0.0118
Epoch 28/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0111 - mae: 0.0844 - mse: 0.0111
64/75 [========================>.....] - ETA: 0s - loss: 0.0126 - mae: 0.0890 - mse: 0.0126
75/75 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.0899 - mse: 0.0140 - val_loss: 0.0191 - val_mae: 0.0947 - val_mse: 0.0191
Epoch 29/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0113 - mae: 0.0856 - mse: 0.0113
64/75 [========================>.....] - ETA: 0s - loss: 0.0115 - mae: 0.0894 - mse: 0.0115
75/75 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.0922 - mse: 0.0127 - val_loss: 0.0214 - val_mae: 0.1049 - val_mse: 0.0214
Epoch 30/30

32/75 [===========>..................] - ETA: 0s - loss: 0.0143 - mae: 0.0925 - mse: 0.0143
64/75 [========================>.....] - ETA: 0s - loss: 0.0126 - mae: 0.0861 - mse: 0.0126
75/75 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.0874 - mse: 0.0130 - val_loss: 0.0116 - val_mae: 0.0554 - val_mse: 0.0116
Saving trained model...
115
Testing...
heightdiff= [0.         0.         0.         2.36741257 0.         0.        ]
average prediction= [2.488315]
baseline= 8.928571428571429
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.591853141784668
85 -:- nan
60 -:- nan
