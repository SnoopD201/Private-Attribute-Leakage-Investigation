['train-weight-15.py', '1']
65 13
65 2
65 3
2_155_65_15_csi_a15_22.dat
65 5
65 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
2_155_65_15_csi_a15_1.dat
65 18
2_155_65_15_csi_a15_4.dat
65 20
65 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
65 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
65 41
1_165_65_15_csi_a15_12.dat
65 43
65 44
65 45
65 46
65 47
1_165_65_15_csi_a15_14.dat
65 49
65 50
1_165_65_15_csi_a15_18.dat
65 52
65 53
65 54
65 55
65 56
65 57
65 58
65 59
65 60
65 61
65 62
65 63
65 64
65 65
1_165_65_15_csi_a15_15.dat
65 67
65 68
65 69
65 70
50 71
2_165_50_15_csi_a15_10.dat
50 73
50 74
50 75
50 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
2_165_50_15_csi_a15_22.dat
50 91
50 92
50 93
2_165_50_15_csi_a15_14.dat
50 95
50 96
50 97
2_165_50_15_csi_a15_20.dat
50 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
1_175_70_15_csi_a15_28.dat
70 112
70 113
70 114
70 115
1_175_70_15_csi_a15_27.dat
70 117
70 118
70 119
1_175_70_15_csi_a15_29.dat
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
85 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
85 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
85 139
85 140
85 141
85 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
85 145
1_180_85_15_csi_a15_24.dat
85 147
85 148
85 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
85 152
85 153
85 154
1_180_85_15_csi_a15_27.dat
85 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
85 159
85 160
1_180_75_15_csi_a15_23.dat
75 162
1_180_75_15_csi_a15_17.dat
75 164
75 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
75 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
75 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
75 174
1_180_75_15_csi_a15_18.dat
75 176
1_180_75_15_csi_a15_15.dat
75 178
1_180_75_15_csi_a15_13.dat
75 180
1_180_75_15_csi_a15_3.dat
75 182
1_180_75_15_csi_a15_25.dat
75 184
75 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
75 190
85 191
1_173_85_15_csi_a15_7.dat
85 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
85 198
85 199
85 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
85 203
85 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
85 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
85 211
85 212
85 213
85 214
85 215
1_173_85_15_csi_a15_29.dat
85 217
85 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60
 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 85]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.4607 - mae: 0.6230 - mse: 0.4607
 64/106 [=================>............] - ETA: 0s - loss: 0.3895 - mae: 0.5499 - mse: 0.3895
 96/106 [==========================>...] - ETA: 0s - loss: 0.3140 - mae: 0.4751 - mse: 0.3140
106/106 [==============================] - 1s 10ms/step - loss: 0.2923 - mae: 0.4510 - mse: 0.2923 - val_loss: 0.0592 - val_mae: 0.1927 - val_mse: 0.0592
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0918 - mae: 0.2728 - mse: 0.0918
 64/106 [=================>............] - ETA: 0s - loss: 0.0866 - mae: 0.2672 - mse: 0.0866
 96/106 [==========================>...] - ETA: 0s - loss: 0.1137 - mae: 0.2863 - mse: 0.1137
106/106 [==============================] - 1s 7ms/step - loss: 0.1093 - mae: 0.2778 - mse: 0.1093 - val_loss: 0.0944 - val_mae: 0.2896 - val_mse: 0.0944
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1924 - mae: 0.3596 - mse: 0.1924
 64/106 [=================>............] - ETA: 0s - loss: 0.1306 - mae: 0.2888 - mse: 0.1306
 96/106 [==========================>...] - ETA: 0s - loss: 0.1101 - mae: 0.2711 - mse: 0.1101
106/106 [==============================] - 1s 6ms/step - loss: 0.1077 - mae: 0.2657 - mse: 0.1077 - val_loss: 0.0527 - val_mae: 0.1679 - val_mse: 0.0527
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0807 - mae: 0.2394 - mse: 0.0807
 64/106 [=================>............] - ETA: 0s - loss: 0.0809 - mae: 0.2307 - mse: 0.0809
 96/106 [==========================>...] - ETA: 0s - loss: 0.0684 - mae: 0.2092 - mse: 0.0684
106/106 [==============================] - 1s 6ms/step - loss: 0.0708 - mae: 0.2147 - mse: 0.0708 - val_loss: 0.0568 - val_mae: 0.1756 - val_mse: 0.0568
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0546 - mae: 0.1615 - mse: 0.0546
 64/106 [=================>............] - ETA: 0s - loss: 0.0693 - mae: 0.1982 - mse: 0.0693
 96/106 [==========================>...] - ETA: 0s - loss: 0.0648 - mae: 0.1965 - mse: 0.0648
106/106 [==============================] - 1s 6ms/step - loss: 0.0612 - mae: 0.1908 - mse: 0.0612 - val_loss: 0.0490 - val_mae: 0.1749 - val_mse: 0.0490
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0691 - mae: 0.2145 - mse: 0.0691
 64/106 [=================>............] - ETA: 0s - loss: 0.0512 - mae: 0.1822 - mse: 0.0512
 96/106 [==========================>...] - ETA: 0s - loss: 0.0530 - mae: 0.1921 - mse: 0.0530
106/106 [==============================] - 1s 6ms/step - loss: 0.0499 - mae: 0.1852 - mse: 0.0499 - val_loss: 0.0506 - val_mae: 0.1796 - val_mse: 0.0506
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0551 - mae: 0.1811 - mse: 0.0551
 64/106 [=================>............] - ETA: 0s - loss: 0.0556 - mae: 0.1920 - mse: 0.0556
 96/106 [==========================>...] - ETA: 0s - loss: 0.0488 - mae: 0.1799 - mse: 0.0488
106/106 [==============================] - 1s 6ms/step - loss: 0.0466 - mae: 0.1766 - mse: 0.0466 - val_loss: 0.0445 - val_mae: 0.1762 - val_mse: 0.0445
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0422 - mae: 0.1491 - mse: 0.0422
 64/106 [=================>............] - ETA: 0s - loss: 0.0370 - mae: 0.1494 - mse: 0.0370
 96/106 [==========================>...] - ETA: 0s - loss: 0.0369 - mae: 0.1537 - mse: 0.0369
106/106 [==============================] - 1s 6ms/step - loss: 0.0371 - mae: 0.1547 - mse: 0.0371 - val_loss: 0.0407 - val_mae: 0.1752 - val_mse: 0.0407
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0373 - mae: 0.1526 - mse: 0.0373
 64/106 [=================>............] - ETA: 0s - loss: 0.0340 - mae: 0.1511 - mse: 0.0340
 96/106 [==========================>...] - ETA: 0s - loss: 0.0321 - mae: 0.1463 - mse: 0.0321
106/106 [==============================] - 1s 7ms/step - loss: 0.0318 - mae: 0.1453 - mse: 0.0318 - val_loss: 0.0393 - val_mae: 0.1710 - val_mse: 0.0393
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0428 - mae: 0.1708 - mse: 0.0428
 64/106 [=================>............] - ETA: 0s - loss: 0.0380 - mae: 0.1618 - mse: 0.0380
 96/106 [==========================>...] - ETA: 0s - loss: 0.0378 - mae: 0.1596 - mse: 0.0378
106/106 [==============================] - 1s 6ms/step - loss: 0.0370 - mae: 0.1582 - mse: 0.0370 - val_loss: 0.0403 - val_mae: 0.1694 - val_mse: 0.0403
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0331 - mae: 0.1457 - mse: 0.0331
 64/106 [=================>............] - ETA: 0s - loss: 0.0276 - mae: 0.1274 - mse: 0.0276
 96/106 [==========================>...] - ETA: 0s - loss: 0.0239 - mae: 0.1209 - mse: 0.0239
106/106 [==============================] - 1s 6ms/step - loss: 0.0277 - mae: 0.1308 - mse: 0.0277 - val_loss: 0.0446 - val_mae: 0.1770 - val_mse: 0.0446
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0231 - mae: 0.0997 - mse: 0.0231
 64/106 [=================>............] - ETA: 0s - loss: 0.0301 - mae: 0.1241 - mse: 0.0301
 96/106 [==========================>...] - ETA: 0s - loss: 0.0287 - mae: 0.1237 - mse: 0.0287
106/106 [==============================] - 1s 6ms/step - loss: 0.0276 - mae: 0.1227 - mse: 0.0276 - val_loss: 0.0491 - val_mae: 0.1983 - val_mse: 0.0491
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0178 - mae: 0.1109 - mse: 0.0178
 64/106 [=================>............] - ETA: 0s - loss: 0.0262 - mae: 0.1188 - mse: 0.0262
 96/106 [==========================>...] - ETA: 0s - loss: 0.0286 - mae: 0.1289 - mse: 0.0286
106/106 [==============================] - 1s 6ms/step - loss: 0.0288 - mae: 0.1290 - mse: 0.0288 - val_loss: 0.0458 - val_mae: 0.1895 - val_mse: 0.0458
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0483 - mae: 0.1658 - mse: 0.0483
 64/106 [=================>............] - ETA: 0s - loss: 0.0362 - mae: 0.1485 - mse: 0.0362
 96/106 [==========================>...] - ETA: 0s - loss: 0.0297 - mae: 0.1325 - mse: 0.0297
106/106 [==============================] - 1s 6ms/step - loss: 0.0281 - mae: 0.1297 - mse: 0.0281 - val_loss: 0.0422 - val_mae: 0.1596 - val_mse: 0.0422
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0201 - mae: 0.1167 - mse: 0.0201
 64/106 [=================>............] - ETA: 0s - loss: 0.0237 - mae: 0.1212 - mse: 0.0237
 96/106 [==========================>...] - ETA: 0s - loss: 0.0192 - mae: 0.1098 - mse: 0.0192
106/106 [==============================] - 1s 6ms/step - loss: 0.0196 - mae: 0.1109 - mse: 0.0196 - val_loss: 0.0399 - val_mae: 0.1643 - val_mse: 0.0399
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0256 - mae: 0.1176 - mse: 0.0256
 64/106 [=================>............] - ETA: 0s - loss: 0.0263 - mae: 0.1191 - mse: 0.0263
 96/106 [==========================>...] - ETA: 0s - loss: 0.0225 - mae: 0.1106 - mse: 0.0225
106/106 [==============================] - 1s 6ms/step - loss: 0.0235 - mae: 0.1129 - mse: 0.0235 - val_loss: 0.0435 - val_mae: 0.1798 - val_mse: 0.0435
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0271 - mae: 0.1169 - mse: 0.0271
 64/106 [=================>............] - ETA: 0s - loss: 0.0249 - mae: 0.1124 - mse: 0.0249
 96/106 [==========================>...] - ETA: 0s - loss: 0.0268 - mae: 0.1144 - mse: 0.0268
106/106 [==============================] - 1s 7ms/step - loss: 0.0286 - mae: 0.1183 - mse: 0.0286 - val_loss: 0.0338 - val_mae: 0.1479 - val_mse: 0.0338
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0308 - mae: 0.1370 - mse: 0.0308
 64/106 [=================>............] - ETA: 0s - loss: 0.0260 - mae: 0.1244 - mse: 0.0260
 96/106 [==========================>...] - ETA: 0s - loss: 0.0273 - mae: 0.1283 - mse: 0.0273
106/106 [==============================] - 1s 6ms/step - loss: 0.0275 - mae: 0.1304 - mse: 0.0275 - val_loss: 0.0322 - val_mae: 0.1446 - val_mse: 0.0322
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0206 - mae: 0.1113 - mse: 0.0206
 64/106 [=================>............] - ETA: 0s - loss: 0.0237 - mae: 0.1198 - mse: 0.0237
 96/106 [==========================>...] - ETA: 0s - loss: 0.0224 - mae: 0.1104 - mse: 0.0224
106/106 [==============================] - 1s 6ms/step - loss: 0.0229 - mae: 0.1121 - mse: 0.0229 - val_loss: 0.0357 - val_mae: 0.1576 - val_mse: 0.0357
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0354 - mae: 0.1342 - mse: 0.0354
 64/106 [=================>............] - ETA: 0s - loss: 0.0291 - mae: 0.1234 - mse: 0.0291
 96/106 [==========================>...] - ETA: 0s - loss: 0.0232 - mae: 0.1103 - mse: 0.0232
106/106 [==============================] - 1s 6ms/step - loss: 0.0239 - mae: 0.1128 - mse: 0.0239 - val_loss: 0.0354 - val_mae: 0.1566 - val_mse: 0.0354
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0221 - mae: 0.1039 - mse: 0.0221
 64/106 [=================>............] - ETA: 0s - loss: 0.0220 - mae: 0.1060 - mse: 0.0220
 96/106 [==========================>...] - ETA: 0s - loss: 0.0237 - mae: 0.1110 - mse: 0.0237
106/106 [==============================] - 1s 6ms/step - loss: 0.0232 - mae: 0.1096 - mse: 0.0232 - val_loss: 0.0351 - val_mae: 0.1533 - val_mse: 0.0351
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0296 - mae: 0.1231 - mse: 0.0296
 64/106 [=================>............] - ETA: 0s - loss: 0.0259 - mae: 0.1228 - mse: 0.0259
 96/106 [==========================>...] - ETA: 0s - loss: 0.0249 - mae: 0.1207 - mse: 0.0249
106/106 [==============================] - 1s 6ms/step - loss: 0.0237 - mae: 0.1181 - mse: 0.0237 - val_loss: 0.0323 - val_mae: 0.1378 - val_mse: 0.0323
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0204 - mae: 0.1113 - mse: 0.0204
 64/106 [=================>............] - ETA: 0s - loss: 0.0196 - mae: 0.1055 - mse: 0.0196
 96/106 [==========================>...] - ETA: 0s - loss: 0.0198 - mae: 0.1033 - mse: 0.0198
106/106 [==============================] - 1s 6ms/step - loss: 0.0219 - mae: 0.1082 - mse: 0.0219 - val_loss: 0.0326 - val_mae: 0.1478 - val_mse: 0.0326
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0168 - mae: 0.0948 - mse: 0.0168
 64/106 [=================>............] - ETA: 0s - loss: 0.0219 - mae: 0.1037 - mse: 0.0219
 96/106 [==========================>...] - ETA: 0s - loss: 0.0228 - mae: 0.1083 - mse: 0.0228
106/106 [==============================] - 1s 6ms/step - loss: 0.0240 - mae: 0.1111 - mse: 0.0240 - val_loss: 0.0409 - val_mae: 0.1750 - val_mse: 0.0409
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0305 - mae: 0.1285 - mse: 0.0305
 64/106 [=================>............] - ETA: 0s - loss: 0.0240 - mae: 0.1146 - mse: 0.0240
 96/106 [==========================>...] - ETA: 0s - loss: 0.0243 - mae: 0.1151 - mse: 0.0243
106/106 [==============================] - 1s 6ms/step - loss: 0.0244 - mae: 0.1155 - mse: 0.0244 - val_loss: 0.0318 - val_mae: 0.1392 - val_mse: 0.0318
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0157 - mae: 0.0920 - mse: 0.0157
 64/106 [=================>............] - ETA: 0s - loss: 0.0249 - mae: 0.1158 - mse: 0.0249
 96/106 [==========================>...] - ETA: 0s - loss: 0.0258 - mae: 0.1180 - mse: 0.0258
106/106 [==============================] - 1s 6ms/step - loss: 0.0248 - mae: 0.1165 - mse: 0.0248 - val_loss: 0.0333 - val_mae: 0.1518 - val_mse: 0.0333
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0253 - mae: 0.1203 - mse: 0.0253
 64/106 [=================>............] - ETA: 0s - loss: 0.0161 - mae: 0.0936 - mse: 0.0161
 96/106 [==========================>...] - ETA: 0s - loss: 0.0205 - mae: 0.1052 - mse: 0.0205
106/106 [==============================] - 1s 6ms/step - loss: 0.0197 - mae: 0.1044 - mse: 0.0197 - val_loss: 0.0377 - val_mae: 0.1679 - val_mse: 0.0377
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0232 - mae: 0.1140 - mse: 0.0232
 64/106 [=================>............] - ETA: 0s - loss: 0.0228 - mae: 0.1097 - mse: 0.0228
 96/106 [==========================>...] - ETA: 0s - loss: 0.0179 - mae: 0.0980 - mse: 0.0179
106/106 [==============================] - 1s 6ms/step - loss: 0.0189 - mae: 0.0993 - mse: 0.0189 - val_loss: 0.0345 - val_mae: 0.1534 - val_mse: 0.0345
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0120 - mae: 0.0784 - mse: 0.0120
 64/106 [=================>............] - ETA: 0s - loss: 0.0172 - mae: 0.0952 - mse: 0.0172
 96/106 [==========================>...] - ETA: 0s - loss: 0.0164 - mae: 0.0932 - mse: 0.0164
106/106 [==============================] - 1s 6ms/step - loss: 0.0175 - mae: 0.0959 - mse: 0.0175 - val_loss: 0.0351 - val_mae: 0.1404 - val_mse: 0.0351
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0112 - mae: 0.0824 - mse: 0.0112
 64/106 [=================>............] - ETA: 0s - loss: 0.0110 - mae: 0.0824 - mse: 0.0110
 96/106 [==========================>...] - ETA: 0s - loss: 0.0147 - mae: 0.0877 - mse: 0.0147
106/106 [==============================] - 1s 6ms/step - loss: 0.0188 - mae: 0.0965 - mse: 0.0188 - val_loss: 0.0351 - val_mae: 0.1585 - val_mse: 0.0351
Saving trained model...
72
Testing...
heightdiff= [ 0.          0.          0.         15.35720825  0.          0.        ]
average prediction= [3.8693004]
baseline= 10.5
eachuser= [0. 0. 0. 9. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.7063564724392362
85 -:- nan
60 -:- nan
['train-weight-15.py', '1']
65 1
65 2
65 3
2_155_65_15_csi_a15_22.dat
65 5
65 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
2_155_65_15_csi_a15_1.dat
65 18
2_155_65_15_csi_a15_4.dat
65 20
65 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
65 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
65 41
1_165_65_15_csi_a15_12.dat
65 43
65 44
65 45
65 46
65 47
1_165_65_15_csi_a15_14.dat
65 49
65 50
1_165_65_15_csi_a15_18.dat
65 52
65 53
65 54
65 55
65 56
65 57
65 58
65 59
65 60
65 61
65 62
65 63
65 64
65 65
1_165_65_15_csi_a15_15.dat
65 67
65 68
65 69
65 70
50 71
2_165_50_15_csi_a15_10.dat
50 73
50 74
50 75
50 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
2_165_50_15_csi_a15_22.dat
50 91
50 92
50 93
2_165_50_15_csi_a15_14.dat
50 95
50 96
50 97
2_165_50_15_csi_a15_20.dat
50 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
1_175_70_15_csi_a15_28.dat
70 112
70 113
70 114
70 115
1_175_70_15_csi_a15_27.dat
70 117
70 118
70 119
1_175_70_15_csi_a15_29.dat
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
85 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
85 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
85 139
85 140
85 141
85 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
85 145
1_180_85_15_csi_a15_24.dat
85 147
85 148
85 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
85 152
85 153
85 154
1_180_85_15_csi_a15_27.dat
85 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
85 159
85 160
1_180_75_15_csi_a15_23.dat
75 162
1_180_75_15_csi_a15_17.dat
75 164
75 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
75 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
75 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
75 174
1_180_75_15_csi_a15_18.dat
75 176
1_180_75_15_csi_a15_15.dat
75 178
1_180_75_15_csi_a15_13.dat
75 180
1_180_75_15_csi_a15_3.dat
75 182
1_180_75_15_csi_a15_25.dat
75 184
75 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
75 190
85 191
1_173_85_15_csi_a15_7.dat
85 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
85 198
85 199
85 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
85 203
85 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
85 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
85 211
85 212
85 213
85 214
85 215
1_173_85_15_csi_a15_29.dat
85 217
85 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60
 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 85]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.2066 - mae: 0.3941 - mse: 0.2066
 64/106 [=================>............] - ETA: 0s - loss: 0.1642 - mae: 0.3423 - mse: 0.1642
 96/106 [==========================>...] - ETA: 0s - loss: 0.1468 - mae: 0.3217 - mse: 0.1468
106/106 [==============================] - 1s 9ms/step - loss: 0.1371 - mae: 0.3097 - mse: 0.1371 - val_loss: 0.1180 - val_mae: 0.3242 - val_mse: 0.1180
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1299 - mae: 0.3020 - mse: 0.1299
 64/106 [=================>............] - ETA: 0s - loss: 0.1262 - mae: 0.2817 - mse: 0.1262
 96/106 [==========================>...] - ETA: 0s - loss: 0.1151 - mae: 0.2696 - mse: 0.1151
106/106 [==============================] - 1s 7ms/step - loss: 0.1163 - mae: 0.2753 - mse: 0.1163 - val_loss: 0.0726 - val_mae: 0.2142 - val_mse: 0.0726
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0582 - mae: 0.2101 - mse: 0.0582
 64/106 [=================>............] - ETA: 0s - loss: 0.0617 - mae: 0.2110 - mse: 0.0617
 96/106 [==========================>...] - ETA: 0s - loss: 0.0687 - mae: 0.2228 - mse: 0.0687
106/106 [==============================] - 1s 12ms/step - loss: 0.0708 - mae: 0.2256 - mse: 0.0708 - val_loss: 0.0700 - val_mae: 0.1895 - val_mse: 0.0700
Epoch 4/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.0521 - mae: 0.1915 - mse: 0.0521
 64/106 [=================>............] - ETA: 0s - loss: 0.0570 - mae: 0.2043 - mse: 0.0570
 96/106 [==========================>...] - ETA: 0s - loss: 0.0597 - mae: 0.2091 - mse: 0.0597
106/106 [==============================] - 1s 13ms/step - loss: 0.0571 - mae: 0.2032 - mse: 0.0571 - val_loss: 0.0409 - val_mae: 0.1782 - val_mse: 0.0409
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0432 - mae: 0.1774 - mse: 0.0432
 64/106 [=================>............] - ETA: 0s - loss: 0.0485 - mae: 0.1848 - mse: 0.0485
 96/106 [==========================>...] - ETA: 0s - loss: 0.0532 - mae: 0.1897 - mse: 0.0532
106/106 [==============================] - 1s 7ms/step - loss: 0.0582 - mae: 0.1960 - mse: 0.0582 - val_loss: 0.0372 - val_mae: 0.1650 - val_mse: 0.0372
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0486 - mae: 0.1893 - mse: 0.0486
 64/106 [=================>............] - ETA: 0s - loss: 0.0405 - mae: 0.1684 - mse: 0.0405
 96/106 [==========================>...] - ETA: 0s - loss: 0.0403 - mae: 0.1648 - mse: 0.0403
106/106 [==============================] - 1s 7ms/step - loss: 0.0475 - mae: 0.1775 - mse: 0.0475 - val_loss: 0.0423 - val_mae: 0.1597 - val_mse: 0.0423
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0246 - mae: 0.1307 - mse: 0.0246
 64/106 [=================>............] - ETA: 0s - loss: 0.0381 - mae: 0.1507 - mse: 0.0381
 96/106 [==========================>...] - ETA: 0s - loss: 0.0407 - mae: 0.1605 - mse: 0.0407
106/106 [==============================] - 1s 7ms/step - loss: 0.0409 - mae: 0.1616 - mse: 0.0409 - val_loss: 0.0322 - val_mae: 0.1482 - val_mse: 0.0322
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0306 - mae: 0.1543 - mse: 0.0306
 64/106 [=================>............] - ETA: 0s - loss: 0.0331 - mae: 0.1560 - mse: 0.0331
 96/106 [==========================>...] - ETA: 0s - loss: 0.0365 - mae: 0.1642 - mse: 0.0365
106/106 [==============================] - 1s 7ms/step - loss: 0.0367 - mae: 0.1646 - mse: 0.0367 - val_loss: 0.0350 - val_mae: 0.1481 - val_mse: 0.0350
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0360 - mae: 0.1433 - mse: 0.0360
 64/106 [=================>............] - ETA: 0s - loss: 0.0352 - mae: 0.1468 - mse: 0.0352
 96/106 [==========================>...] - ETA: 0s - loss: 0.0335 - mae: 0.1482 - mse: 0.0335
106/106 [==============================] - 1s 7ms/step - loss: 0.0315 - mae: 0.1420 - mse: 0.0315 - val_loss: 0.0280 - val_mae: 0.1310 - val_mse: 0.0280
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0312 - mae: 0.1489 - mse: 0.0312
 64/106 [=================>............] - ETA: 0s - loss: 0.0269 - mae: 0.1351 - mse: 0.0269
 96/106 [==========================>...] - ETA: 0s - loss: 0.0301 - mae: 0.1430 - mse: 0.0301
106/106 [==============================] - 1s 7ms/step - loss: 0.0309 - mae: 0.1435 - mse: 0.0309 - val_loss: 0.0364 - val_mae: 0.1433 - val_mse: 0.0364
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0432 - mae: 0.1610 - mse: 0.0432
 64/106 [=================>............] - ETA: 0s - loss: 0.0299 - mae: 0.1326 - mse: 0.0299
 96/106 [==========================>...] - ETA: 0s - loss: 0.0279 - mae: 0.1282 - mse: 0.0279
106/106 [==============================] - 1s 7ms/step - loss: 0.0280 - mae: 0.1255 - mse: 0.0280 - val_loss: 0.0266 - val_mae: 0.1204 - val_mse: 0.0266
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0379 - mae: 0.1596 - mse: 0.0379
 64/106 [=================>............] - ETA: 0s - loss: 0.0319 - mae: 0.1465 - mse: 0.0319
 96/106 [==========================>...] - ETA: 0s - loss: 0.0301 - mae: 0.1390 - mse: 0.0301
106/106 [==============================] - 1s 7ms/step - loss: 0.0311 - mae: 0.1413 - mse: 0.0311 - val_loss: 0.0270 - val_mae: 0.1185 - val_mse: 0.0270
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0292 - mae: 0.1295 - mse: 0.0292
 64/106 [=================>............] - ETA: 0s - loss: 0.0237 - mae: 0.1196 - mse: 0.0237
 96/106 [==========================>...] - ETA: 0s - loss: 0.0216 - mae: 0.1145 - mse: 0.0216
106/106 [==============================] - 1s 7ms/step - loss: 0.0202 - mae: 0.1101 - mse: 0.0202 - val_loss: 0.0352 - val_mae: 0.1377 - val_mse: 0.0352
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0363 - mae: 0.1474 - mse: 0.0363
 64/106 [=================>............] - ETA: 0s - loss: 0.0291 - mae: 0.1368 - mse: 0.0291
 96/106 [==========================>...] - ETA: 0s - loss: 0.0219 - mae: 0.1129 - mse: 0.0219
106/106 [==============================] - 1s 7ms/step - loss: 0.0222 - mae: 0.1129 - mse: 0.0222 - val_loss: 0.0252 - val_mae: 0.1108 - val_mse: 0.0252
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0337 - mae: 0.1292 - mse: 0.0337
 64/106 [=================>............] - ETA: 0s - loss: 0.0268 - mae: 0.1169 - mse: 0.0268
 96/106 [==========================>...] - ETA: 0s - loss: 0.0316 - mae: 0.1339 - mse: 0.0316
106/106 [==============================] - 1s 7ms/step - loss: 0.0299 - mae: 0.1292 - mse: 0.0299 - val_loss: 0.0225 - val_mae: 0.0983 - val_mse: 0.0225
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0247 - mae: 0.1332 - mse: 0.0247
 64/106 [=================>............] - ETA: 0s - loss: 0.0221 - mae: 0.1210 - mse: 0.0221
 96/106 [==========================>...] - ETA: 0s - loss: 0.0231 - mae: 0.1210 - mse: 0.0231
106/106 [==============================] - 1s 7ms/step - loss: 0.0233 - mae: 0.1209 - mse: 0.0233 - val_loss: 0.0212 - val_mae: 0.1022 - val_mse: 0.0212
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0176 - mae: 0.0949 - mse: 0.0176
 64/106 [=================>............] - ETA: 0s - loss: 0.0206 - mae: 0.1070 - mse: 0.0206
 96/106 [==========================>...] - ETA: 0s - loss: 0.0227 - mae: 0.1100 - mse: 0.0227
106/106 [==============================] - 1s 7ms/step - loss: 0.0214 - mae: 0.1058 - mse: 0.0214 - val_loss: 0.0235 - val_mae: 0.1156 - val_mse: 0.0235
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0162 - mae: 0.0968 - mse: 0.0162
 64/106 [=================>............] - ETA: 0s - loss: 0.0181 - mae: 0.1048 - mse: 0.0181
 96/106 [==========================>...] - ETA: 0s - loss: 0.0176 - mae: 0.1013 - mse: 0.0176
106/106 [==============================] - 1s 7ms/step - loss: 0.0178 - mae: 0.1023 - mse: 0.0178 - val_loss: 0.0188 - val_mae: 0.0888 - val_mse: 0.0188
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0263 - mae: 0.1277 - mse: 0.0263
 64/106 [=================>............] - ETA: 0s - loss: 0.0221 - mae: 0.1167 - mse: 0.0221
 96/106 [==========================>...] - ETA: 0s - loss: 0.0217 - mae: 0.1147 - mse: 0.0217
106/106 [==============================] - 1s 7ms/step - loss: 0.0208 - mae: 0.1125 - mse: 0.0208 - val_loss: 0.0213 - val_mae: 0.1034 - val_mse: 0.0213
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0212 - mae: 0.1167 - mse: 0.0212
 64/106 [=================>............] - ETA: 0s - loss: 0.0190 - mae: 0.1073 - mse: 0.0190
 96/106 [==========================>...] - ETA: 0s - loss: 0.0249 - mae: 0.1206 - mse: 0.0249
106/106 [==============================] - 1s 7ms/step - loss: 0.0233 - mae: 0.1164 - mse: 0.0233 - val_loss: 0.0228 - val_mae: 0.1127 - val_mse: 0.0228
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0227 - mae: 0.1170 - mse: 0.0227
 64/106 [=================>............] - ETA: 0s - loss: 0.0185 - mae: 0.1097 - mse: 0.0185
 96/106 [==========================>...] - ETA: 0s - loss: 0.0224 - mae: 0.1163 - mse: 0.0224
106/106 [==============================] - 1s 7ms/step - loss: 0.0219 - mae: 0.1147 - mse: 0.0219 - val_loss: 0.0194 - val_mae: 0.1017 - val_mse: 0.0194
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0153 - mae: 0.0932 - mse: 0.0153
 64/106 [=================>............] - ETA: 0s - loss: 0.0153 - mae: 0.0945 - mse: 0.0153
 96/106 [==========================>...] - ETA: 0s - loss: 0.0174 - mae: 0.1012 - mse: 0.0174
106/106 [==============================] - 1s 7ms/step - loss: 0.0187 - mae: 0.1071 - mse: 0.0187 - val_loss: 0.0173 - val_mae: 0.0877 - val_mse: 0.0173
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0171 - mae: 0.1053 - mse: 0.0171
 64/106 [=================>............] - ETA: 0s - loss: 0.0197 - mae: 0.1094 - mse: 0.0197
 96/106 [==========================>...] - ETA: 0s - loss: 0.0196 - mae: 0.1067 - mse: 0.0196
106/106 [==============================] - 1s 7ms/step - loss: 0.0206 - mae: 0.1093 - mse: 0.0206 - val_loss: 0.0237 - val_mae: 0.1207 - val_mse: 0.0237
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0170 - mae: 0.0843 - mse: 0.0170
 64/106 [=================>............] - ETA: 0s - loss: 0.0152 - mae: 0.0852 - mse: 0.0152
 96/106 [==========================>...] - ETA: 0s - loss: 0.0205 - mae: 0.0975 - mse: 0.0205
106/106 [==============================] - 1s 7ms/step - loss: 0.0202 - mae: 0.0995 - mse: 0.0202 - val_loss: 0.0287 - val_mae: 0.1354 - val_mse: 0.0287
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0240 - mae: 0.1126 - mse: 0.0240
 64/106 [=================>............] - ETA: 0s - loss: 0.0228 - mae: 0.1157 - mse: 0.0228
 96/106 [==========================>...] - ETA: 0s - loss: 0.0210 - mae: 0.1108 - mse: 0.0210
106/106 [==============================] - 1s 7ms/step - loss: 0.0210 - mae: 0.1124 - mse: 0.0210 - val_loss: 0.0188 - val_mae: 0.0967 - val_mse: 0.0188
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0190 - mae: 0.1020 - mse: 0.0190
 64/106 [=================>............] - ETA: 0s - loss: 0.0211 - mae: 0.1105 - mse: 0.0211
 96/106 [==========================>...] - ETA: 0s - loss: 0.0209 - mae: 0.1082 - mse: 0.0209
106/106 [==============================] - 1s 7ms/step - loss: 0.0210 - mae: 0.1066 - mse: 0.0210 - val_loss: 0.0259 - val_mae: 0.1343 - val_mse: 0.0259
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0160 - mae: 0.0933 - mse: 0.0160
 64/106 [=================>............] - ETA: 0s - loss: 0.0164 - mae: 0.0963 - mse: 0.0164
 96/106 [==========================>...] - ETA: 0s - loss: 0.0176 - mae: 0.0974 - mse: 0.0176
106/106 [==============================] - 1s 7ms/step - loss: 0.0189 - mae: 0.1017 - mse: 0.0189 - val_loss: 0.0158 - val_mae: 0.0989 - val_mse: 0.0158
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0181 - mae: 0.1013 - mse: 0.0181
 64/106 [=================>............] - ETA: 0s - loss: 0.0174 - mae: 0.0962 - mse: 0.0174
 96/106 [==========================>...] - ETA: 0s - loss: 0.0204 - mae: 0.1041 - mse: 0.0204
106/106 [==============================] - 1s 7ms/step - loss: 0.0194 - mae: 0.1019 - mse: 0.0194 - val_loss: 0.0152 - val_mae: 0.0963 - val_mse: 0.0152
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0101 - mae: 0.0821 - mse: 0.0101
 64/106 [=================>............] - ETA: 0s - loss: 0.0117 - mae: 0.0845 - mse: 0.0117
 96/106 [==========================>...] - ETA: 0s - loss: 0.0120 - mae: 0.0830 - mse: 0.0120
106/106 [==============================] - 1s 7ms/step - loss: 0.0130 - mae: 0.0849 - mse: 0.0130 - val_loss: 0.0201 - val_mae: 0.1164 - val_mse: 0.0201
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0226 - mae: 0.1088 - mse: 0.0226
 64/106 [=================>............] - ETA: 0s - loss: 0.0200 - mae: 0.1011 - mse: 0.0200
 96/106 [==========================>...] - ETA: 0s - loss: 0.0181 - mae: 0.0953 - mse: 0.0181
106/106 [==============================] - 1s 7ms/step - loss: 0.0180 - mae: 0.0958 - mse: 0.0180 - val_loss: 0.0182 - val_mae: 0.1068 - val_mse: 0.0182
Saving trained model...
72
Testing...
heightdiff= [0.         0.         0.         3.26282501 0.         0.        ]
average prediction= [3.7683547]
baseline= 9.333333333333334
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.8157062530517578
85 -:- nan
60 -:- nan
['train-weight-15.py', '1']
65 1
65 2
65 3
2_155_65_15_csi_a15_22.dat
65 5
65 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
2_155_65_15_csi_a15_1.dat
65 18
2_155_65_15_csi_a15_4.dat
65 20
65 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
65 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
65 41
1_165_65_15_csi_a15_12.dat
65 43
65 44
65 45
65 46
65 47
1_165_65_15_csi_a15_14.dat
65 49
65 50
1_165_65_15_csi_a15_18.dat
65 52
65 53
65 54
65 55
65 56
65 57
65 58
65 59
65 60
65 61
65 62
65 63
65 64
65 65
1_165_65_15_csi_a15_15.dat
65 67
65 68
65 69
65 70
50 71
2_165_50_15_csi_a15_10.dat
50 73
50 74
50 75
50 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
2_165_50_15_csi_a15_22.dat
50 91
50 92
50 93
2_165_50_15_csi_a15_14.dat
50 95
50 96
50 97
2_165_50_15_csi_a15_20.dat
50 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
1_175_70_15_csi_a15_28.dat
70 112
70 113
70 114
70 115
1_175_70_15_csi_a15_27.dat
70 117
70 118
70 119
1_175_70_15_csi_a15_29.dat
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
85 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
85 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
85 139
85 140
85 141
85 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
85 145
1_180_85_15_csi_a15_24.dat
85 147
85 148
85 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
85 152
85 153
85 154
1_180_85_15_csi_a15_27.dat
85 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
85 159
85 160
1_180_75_15_csi_a15_23.dat
75 162
1_180_75_15_csi_a15_17.dat
75 164
75 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
75 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
75 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
75 174
1_180_75_15_csi_a15_18.dat
75 176
1_180_75_15_csi_a15_15.dat
75 178
1_180_75_15_csi_a15_13.dat
75 180
1_180_75_15_csi_a15_3.dat
75 182
1_180_75_15_csi_a15_25.dat
75 184
75 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
75 190
85 191
1_173_85_15_csi_a15_7.dat
85 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
85 198
85 199
85 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
85 203
85 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
85 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
85 211
85 212
85 213
85 214
85 215
1_173_85_15_csi_a15_29.dat
85 217
85 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60
 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 85]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.4243 - mae: 0.5614 - mse: 0.4243
 64/106 [=================>............] - ETA: 0s - loss: 0.3356 - mae: 0.4936 - mse: 0.3356
 96/106 [==========================>...] - ETA: 0s - loss: 0.2756 - mae: 0.4362 - mse: 0.2756
106/106 [==============================] - 1s 10ms/step - loss: 0.2545 - mae: 0.4116 - mse: 0.2545 - val_loss: 0.1706 - val_mae: 0.3869 - val_mse: 0.1706
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1131 - mae: 0.2910 - mse: 0.1131
 64/106 [=================>............] - ETA: 0s - loss: 0.1199 - mae: 0.2990 - mse: 0.1199
 96/106 [==========================>...] - ETA: 0s - loss: 0.1179 - mae: 0.2932 - mse: 0.1179
106/106 [==============================] - 1s 8ms/step - loss: 0.1187 - mae: 0.2948 - mse: 0.1187 - val_loss: 0.1294 - val_mae: 0.3438 - val_mse: 0.1294
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0728 - mae: 0.2287 - mse: 0.0728
 64/106 [=================>............] - ETA: 0s - loss: 0.0775 - mae: 0.2279 - mse: 0.0775
 96/106 [==========================>...] - ETA: 0s - loss: 0.0850 - mae: 0.2427 - mse: 0.0850
106/106 [==============================] - 1s 7ms/step - loss: 0.0875 - mae: 0.2455 - mse: 0.0875 - val_loss: 0.1445 - val_mae: 0.3249 - val_mse: 0.1445
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0569 - mae: 0.1925 - mse: 0.0569
 64/106 [=================>............] - ETA: 0s - loss: 0.0655 - mae: 0.2004 - mse: 0.0655
 96/106 [==========================>...] - ETA: 0s - loss: 0.0632 - mae: 0.1962 - mse: 0.0632
106/106 [==============================] - 1s 7ms/step - loss: 0.0720 - mae: 0.2096 - mse: 0.0720 - val_loss: 0.1147 - val_mae: 0.2793 - val_mse: 0.1147
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0697 - mae: 0.2078 - mse: 0.0697
 64/106 [=================>............] - ETA: 0s - loss: 0.0651 - mae: 0.1989 - mse: 0.0651
 96/106 [==========================>...] - ETA: 0s - loss: 0.0567 - mae: 0.1827 - mse: 0.0567
106/106 [==============================] - 1s 7ms/step - loss: 0.0545 - mae: 0.1811 - mse: 0.0545 - val_loss: 0.0446 - val_mae: 0.2015 - val_mse: 0.0446
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0379 - mae: 0.1611 - mse: 0.0379
 64/106 [=================>............] - ETA: 0s - loss: 0.0443 - mae: 0.1731 - mse: 0.0443
 96/106 [==========================>...] - ETA: 0s - loss: 0.0439 - mae: 0.1737 - mse: 0.0439
106/106 [==============================] - 1s 7ms/step - loss: 0.0439 - mae: 0.1738 - mse: 0.0439 - val_loss: 0.0310 - val_mae: 0.1699 - val_mse: 0.0310
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0518 - mae: 0.1893 - mse: 0.0518
 64/106 [=================>............] - ETA: 0s - loss: 0.0380 - mae: 0.1597 - mse: 0.0380
 96/106 [==========================>...] - ETA: 0s - loss: 0.0422 - mae: 0.1701 - mse: 0.0422
106/106 [==============================] - 1s 7ms/step - loss: 0.0402 - mae: 0.1654 - mse: 0.0402 - val_loss: 0.0497 - val_mae: 0.1893 - val_mse: 0.0497
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0311 - mae: 0.1462 - mse: 0.0311
 64/106 [=================>............] - ETA: 0s - loss: 0.0328 - mae: 0.1468 - mse: 0.0328
 96/106 [==========================>...] - ETA: 0s - loss: 0.0373 - mae: 0.1575 - mse: 0.0373
106/106 [==============================] - 1s 7ms/step - loss: 0.0390 - mae: 0.1611 - mse: 0.0390 - val_loss: 0.0614 - val_mae: 0.1995 - val_mse: 0.0614
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0314 - mae: 0.1416 - mse: 0.0314
 64/106 [=================>............] - ETA: 0s - loss: 0.0360 - mae: 0.1552 - mse: 0.0360
 96/106 [==========================>...] - ETA: 0s - loss: 0.0365 - mae: 0.1542 - mse: 0.0365
106/106 [==============================] - 1s 7ms/step - loss: 0.0353 - mae: 0.1511 - mse: 0.0353 - val_loss: 0.0343 - val_mae: 0.1536 - val_mse: 0.0343
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0373 - mae: 0.1502 - mse: 0.0373
 64/106 [=================>............] - ETA: 0s - loss: 0.0348 - mae: 0.1456 - mse: 0.0348
 96/106 [==========================>...] - ETA: 0s - loss: 0.0373 - mae: 0.1490 - mse: 0.0373
106/106 [==============================] - 1s 7ms/step - loss: 0.0385 - mae: 0.1516 - mse: 0.0385 - val_loss: 0.0285 - val_mae: 0.1372 - val_mse: 0.0285
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0239 - mae: 0.1152 - mse: 0.0239
 64/106 [=================>............] - ETA: 0s - loss: 0.0322 - mae: 0.1401 - mse: 0.0322
 96/106 [==========================>...] - ETA: 0s - loss: 0.0337 - mae: 0.1468 - mse: 0.0337
106/106 [==============================] - 1s 7ms/step - loss: 0.0337 - mae: 0.1454 - mse: 0.0337 - val_loss: 0.0523 - val_mae: 0.1742 - val_mse: 0.0523
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0314 - mae: 0.1357 - mse: 0.0314
 64/106 [=================>............] - ETA: 0s - loss: 0.0321 - mae: 0.1350 - mse: 0.0321
 96/106 [==========================>...] - ETA: 0s - loss: 0.0334 - mae: 0.1355 - mse: 0.0334
106/106 [==============================] - 1s 7ms/step - loss: 0.0400 - mae: 0.1447 - mse: 0.0400 - val_loss: 0.0517 - val_mae: 0.1707 - val_mse: 0.0517
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0322 - mae: 0.1432 - mse: 0.0322
 64/106 [=================>............] - ETA: 0s - loss: 0.0261 - mae: 0.1308 - mse: 0.0261
 96/106 [==========================>...] - ETA: 0s - loss: 0.0284 - mae: 0.1351 - mse: 0.0284
106/106 [==============================] - 1s 7ms/step - loss: 0.0288 - mae: 0.1353 - mse: 0.0288 - val_loss: 0.0188 - val_mae: 0.1071 - val_mse: 0.0188
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0550 - mae: 0.1836 - mse: 0.0550
 64/106 [=================>............] - ETA: 0s - loss: 0.0422 - mae: 0.1558 - mse: 0.0422
 96/106 [==========================>...] - ETA: 0s - loss: 0.0379 - mae: 0.1499 - mse: 0.0379
106/106 [==============================] - 1s 6ms/step - loss: 0.0387 - mae: 0.1528 - mse: 0.0387 - val_loss: 0.0207 - val_mae: 0.1062 - val_mse: 0.0207
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0239 - mae: 0.1209 - mse: 0.0239
 64/106 [=================>............] - ETA: 0s - loss: 0.0222 - mae: 0.1149 - mse: 0.0222
 96/106 [==========================>...] - ETA: 0s - loss: 0.0217 - mae: 0.1144 - mse: 0.0217
106/106 [==============================] - 1s 6ms/step - loss: 0.0238 - mae: 0.1198 - mse: 0.0238 - val_loss: 0.0508 - val_mae: 0.1580 - val_mse: 0.0508
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0258 - mae: 0.1343 - mse: 0.0258
 64/106 [=================>............] - ETA: 0s - loss: 0.0370 - mae: 0.1517 - mse: 0.0370
 96/106 [==========================>...] - ETA: 0s - loss: 0.0324 - mae: 0.1418 - mse: 0.0324
106/106 [==============================] - 1s 6ms/step - loss: 0.0313 - mae: 0.1405 - mse: 0.0313 - val_loss: 0.0474 - val_mae: 0.1516 - val_mse: 0.0474
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0340 - mae: 0.1384 - mse: 0.0340
 64/106 [=================>............] - ETA: 0s - loss: 0.0276 - mae: 0.1272 - mse: 0.0276
 96/106 [==========================>...] - ETA: 0s - loss: 0.0253 - mae: 0.1238 - mse: 0.0253
106/106 [==============================] - 1s 6ms/step - loss: 0.0249 - mae: 0.1240 - mse: 0.0249 - val_loss: 0.0300 - val_mae: 0.1205 - val_mse: 0.0300
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0340 - mae: 0.1487 - mse: 0.0340
 64/106 [=================>............] - ETA: 0s - loss: 0.0283 - mae: 0.1362 - mse: 0.0283
 96/106 [==========================>...] - ETA: 0s - loss: 0.0262 - mae: 0.1281 - mse: 0.0262
106/106 [==============================] - 1s 6ms/step - loss: 0.0252 - mae: 0.1248 - mse: 0.0252 - val_loss: 0.0358 - val_mae: 0.1290 - val_mse: 0.0358
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0330 - mae: 0.1266 - mse: 0.0330
 64/106 [=================>............] - ETA: 0s - loss: 0.0275 - mae: 0.1225 - mse: 0.0275
 96/106 [==========================>...] - ETA: 0s - loss: 0.0280 - mae: 0.1236 - mse: 0.0280
106/106 [==============================] - 1s 6ms/step - loss: 0.0262 - mae: 0.1188 - mse: 0.0262 - val_loss: 0.0429 - val_mae: 0.1366 - val_mse: 0.0429
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0235 - mae: 0.1139 - mse: 0.0235
 64/106 [=================>............] - ETA: 0s - loss: 0.0285 - mae: 0.1208 - mse: 0.0285
 96/106 [==========================>...] - ETA: 0s - loss: 0.0257 - mae: 0.1188 - mse: 0.0257
106/106 [==============================] - 1s 6ms/step - loss: 0.0257 - mae: 0.1186 - mse: 0.0257 - val_loss: 0.0384 - val_mae: 0.1224 - val_mse: 0.0384
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0247 - mae: 0.1212 - mse: 0.0247
 64/106 [=================>............] - ETA: 0s - loss: 0.0172 - mae: 0.1042 - mse: 0.0172
 96/106 [==========================>...] - ETA: 0s - loss: 0.0205 - mae: 0.1111 - mse: 0.0205
106/106 [==============================] - 1s 6ms/step - loss: 0.0196 - mae: 0.1092 - mse: 0.0196 - val_loss: 0.0290 - val_mae: 0.0974 - val_mse: 0.0290
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0145 - mae: 0.0945 - mse: 0.0145
 64/106 [=================>............] - ETA: 0s - loss: 0.0298 - mae: 0.1227 - mse: 0.0298
 96/106 [==========================>...] - ETA: 0s - loss: 0.0248 - mae: 0.1162 - mse: 0.0248
106/106 [==============================] - 1s 6ms/step - loss: 0.0256 - mae: 0.1174 - mse: 0.0256 - val_loss: 0.0409 - val_mae: 0.1250 - val_mse: 0.0409
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0332 - mae: 0.1332 - mse: 0.0332
 64/106 [=================>............] - ETA: 0s - loss: 0.0299 - mae: 0.1293 - mse: 0.0299
 96/106 [==========================>...] - ETA: 0s - loss: 0.0270 - mae: 0.1240 - mse: 0.0270
106/106 [==============================] - 1s 9ms/step - loss: 0.0294 - mae: 0.1293 - mse: 0.0294 - val_loss: 0.0346 - val_mae: 0.1132 - val_mse: 0.0346
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0283 - mae: 0.1342 - mse: 0.0283
 64/106 [=================>............] - ETA: 0s - loss: 0.0249 - mae: 0.1218 - mse: 0.0249
 96/106 [==========================>...] - ETA: 0s - loss: 0.0265 - mae: 0.1263 - mse: 0.0265
106/106 [==============================] - 2s 14ms/step - loss: 0.0248 - mae: 0.1220 - mse: 0.0248 - val_loss: 0.0255 - val_mae: 0.0923 - val_mse: 0.0255
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0164 - mae: 0.0942 - mse: 0.0164
 64/106 [=================>............] - ETA: 0s - loss: 0.0221 - mae: 0.1077 - mse: 0.0221
 96/106 [==========================>...] - ETA: 0s - loss: 0.0208 - mae: 0.1070 - mse: 0.0208
106/106 [==============================] - 1s 8ms/step - loss: 0.0200 - mae: 0.1070 - mse: 0.0200 - val_loss: 0.0243 - val_mae: 0.0911 - val_mse: 0.0243
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0277 - mae: 0.1223 - mse: 0.0277
 64/106 [=================>............] - ETA: 0s - loss: 0.0227 - mae: 0.1129 - mse: 0.0227
 96/106 [==========================>...] - ETA: 0s - loss: 0.0280 - mae: 0.1263 - mse: 0.0280
106/106 [==============================] - 1s 7ms/step - loss: 0.0265 - mae: 0.1232 - mse: 0.0265 - val_loss: 0.0297 - val_mae: 0.1114 - val_mse: 0.0297
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0241 - mae: 0.1220 - mse: 0.0241
 64/106 [=================>............] - ETA: 0s - loss: 0.0178 - mae: 0.1029 - mse: 0.0178
 96/106 [==========================>...] - ETA: 0s - loss: 0.0244 - mae: 0.1167 - mse: 0.0244
106/106 [==============================] - 1s 7ms/step - loss: 0.0233 - mae: 0.1143 - mse: 0.0233 - val_loss: 0.0383 - val_mae: 0.1321 - val_mse: 0.0383
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0256 - mae: 0.1076 - mse: 0.0256
 64/106 [=================>............] - ETA: 0s - loss: 0.0307 - mae: 0.1266 - mse: 0.0307
 96/106 [==========================>...] - ETA: 0s - loss: 0.0228 - mae: 0.1072 - mse: 0.0228
106/106 [==============================] - 1s 7ms/step - loss: 0.0213 - mae: 0.1039 - mse: 0.0213 - val_loss: 0.0374 - val_mae: 0.1276 - val_mse: 0.0374
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0115 - mae: 0.0825 - mse: 0.0115
 64/106 [=================>............] - ETA: 0s - loss: 0.0149 - mae: 0.0924 - mse: 0.0149
 96/106 [==========================>...] - ETA: 0s - loss: 0.0202 - mae: 0.1018 - mse: 0.0202
106/106 [==============================] - 1s 7ms/step - loss: 0.0187 - mae: 0.0969 - mse: 0.0187 - val_loss: 0.0263 - val_mae: 0.0919 - val_mse: 0.0263
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0239 - mae: 0.1172 - mse: 0.0239
 64/106 [=================>............] - ETA: 0s - loss: 0.0287 - mae: 0.1252 - mse: 0.0287
 96/106 [==========================>...] - ETA: 0s - loss: 0.0256 - mae: 0.1180 - mse: 0.0256
106/106 [==============================] - 1s 7ms/step - loss: 0.0259 - mae: 0.1186 - mse: 0.0259 - val_loss: 0.0308 - val_mae: 0.1029 - val_mse: 0.0308
Saving trained model...
72
Testing...
heightdiff= [0.         0.         0.         2.24905014 0.         0.        ]
average prediction= [4.801952]
baseline= 8.166666666666666
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.5622625350952148
85 -:- nan
60 -:- nan
['train-weight-15.py', '1']
65 1
65 2
65 3
2_155_65_15_csi_a15_22.dat
65 5
65 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
2_155_65_15_csi_a15_1.dat
65 18
2_155_65_15_csi_a15_4.dat
65 20
65 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
65 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
65 41
1_165_65_15_csi_a15_12.dat
65 43
65 44
65 45
65 46
65 47
1_165_65_15_csi_a15_14.dat
65 49
65 50
1_165_65_15_csi_a15_18.dat
65 52
65 53
65 54
65 55
65 56
65 57
65 58
65 59
65 60
65 61
65 62
65 63
65 64
65 65
1_165_65_15_csi_a15_15.dat
65 67
65 68
65 69
65 70
50 71
2_165_50_15_csi_a15_10.dat
50 73
50 74
50 75
50 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
2_165_50_15_csi_a15_22.dat
50 91
50 92
50 93
2_165_50_15_csi_a15_14.dat
50 95
50 96
50 97
2_165_50_15_csi_a15_20.dat
50 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
1_175_70_15_csi_a15_28.dat
70 112
70 113
70 114
70 115
1_175_70_15_csi_a15_27.dat
70 117
70 118
70 119
1_175_70_15_csi_a15_29.dat
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
85 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
85 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
85 139
85 140
85 141
85 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
85 145
1_180_85_15_csi_a15_24.dat
85 147
85 148
85 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
85 152
85 153
85 154
1_180_85_15_csi_a15_27.dat
85 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
85 159
85 160
1_180_75_15_csi_a15_23.dat
75 162
1_180_75_15_csi_a15_17.dat
75 164
75 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
75 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
75 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
75 174
1_180_75_15_csi_a15_18.dat
75 176
1_180_75_15_csi_a15_15.dat
75 178
1_180_75_15_csi_a15_13.dat
75 180
1_180_75_15_csi_a15_3.dat
75 182
1_180_75_15_csi_a15_25.dat
75 184
75 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
75 190
85 191
1_173_85_15_csi_a15_7.dat
85 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
85 198
85 199
85 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
85 203
85 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
85 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
85 211
85 212
85 213
85 214
85 215
1_173_85_15_csi_a15_29.dat
85 217
85 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60
 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 85]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.3568 - mae: 0.5193 - mse: 0.3568
 64/106 [=================>............] - ETA: 0s - loss: 0.3046 - mae: 0.4688 - mse: 0.3046
 96/106 [==========================>...] - ETA: 0s - loss: 0.2760 - mae: 0.4454 - mse: 0.2760
106/106 [==============================] - 1s 10ms/step - loss: 0.2721 - mae: 0.4426 - mse: 0.2721 - val_loss: 0.1235 - val_mae: 0.2596 - val_mse: 0.1235
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1753 - mae: 0.3256 - mse: 0.1753
 64/106 [=================>............] - ETA: 0s - loss: 0.1585 - mae: 0.3096 - mse: 0.1585
 96/106 [==========================>...] - ETA: 0s - loss: 0.1501 - mae: 0.3056 - mse: 0.1501
106/106 [==============================] - 1s 7ms/step - loss: 0.1433 - mae: 0.2998 - mse: 0.1433 - val_loss: 0.0629 - val_mae: 0.2174 - val_mse: 0.0629
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1484 - mae: 0.3277 - mse: 0.1484
 64/106 [=================>............] - ETA: 0s - loss: 0.1193 - mae: 0.2801 - mse: 0.1193
 96/106 [==========================>...] - ETA: 0s - loss: 0.1114 - mae: 0.2753 - mse: 0.1114
106/106 [==============================] - 1s 7ms/step - loss: 0.1061 - mae: 0.2685 - mse: 0.1061 - val_loss: 0.0864 - val_mae: 0.2255 - val_mse: 0.0864
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0536 - mae: 0.2014 - mse: 0.0536
 64/106 [=================>............] - ETA: 0s - loss: 0.0652 - mae: 0.2195 - mse: 0.0652
 96/106 [==========================>...] - ETA: 0s - loss: 0.0625 - mae: 0.2107 - mse: 0.0625
106/106 [==============================] - 1s 7ms/step - loss: 0.0664 - mae: 0.2198 - mse: 0.0664 - val_loss: 0.0786 - val_mae: 0.2370 - val_mse: 0.0786
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0637 - mae: 0.2191 - mse: 0.0637
 64/106 [=================>............] - ETA: 0s - loss: 0.0702 - mae: 0.2304 - mse: 0.0702
 96/106 [==========================>...] - ETA: 0s - loss: 0.0660 - mae: 0.2276 - mse: 0.0660
106/106 [==============================] - 1s 7ms/step - loss: 0.0631 - mae: 0.2221 - mse: 0.0631 - val_loss: 0.0658 - val_mae: 0.2498 - val_mse: 0.0658
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0516 - mae: 0.1953 - mse: 0.0516
 64/106 [=================>............] - ETA: 0s - loss: 0.0537 - mae: 0.2067 - mse: 0.0537
 96/106 [==========================>...] - ETA: 0s - loss: 0.0546 - mae: 0.2034 - mse: 0.0546
106/106 [==============================] - 1s 7ms/step - loss: 0.0529 - mae: 0.1989 - mse: 0.0529 - val_loss: 0.0459 - val_mae: 0.2048 - val_mse: 0.0459
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0325 - mae: 0.1523 - mse: 0.0325
 64/106 [=================>............] - ETA: 0s - loss: 0.0342 - mae: 0.1590 - mse: 0.0342
 96/106 [==========================>...] - ETA: 0s - loss: 0.0333 - mae: 0.1541 - mse: 0.0333
106/106 [==============================] - 1s 7ms/step - loss: 0.0355 - mae: 0.1600 - mse: 0.0355 - val_loss: 0.0337 - val_mae: 0.1570 - val_mse: 0.0337
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0343 - mae: 0.1493 - mse: 0.0343
 64/106 [=================>............] - ETA: 0s - loss: 0.0322 - mae: 0.1480 - mse: 0.0322
 96/106 [==========================>...] - ETA: 0s - loss: 0.0350 - mae: 0.1515 - mse: 0.0350
106/106 [==============================] - 1s 7ms/step - loss: 0.0345 - mae: 0.1513 - mse: 0.0345 - val_loss: 0.0272 - val_mae: 0.1388 - val_mse: 0.0272
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0356 - mae: 0.1455 - mse: 0.0356
 64/106 [=================>............] - ETA: 0s - loss: 0.0347 - mae: 0.1497 - mse: 0.0347
 96/106 [==========================>...] - ETA: 0s - loss: 0.0288 - mae: 0.1363 - mse: 0.0288
106/106 [==============================] - 1s 7ms/step - loss: 0.0272 - mae: 0.1321 - mse: 0.0272 - val_loss: 0.0269 - val_mae: 0.1459 - val_mse: 0.0269
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0247 - mae: 0.1355 - mse: 0.0247
 64/106 [=================>............] - ETA: 0s - loss: 0.0252 - mae: 0.1337 - mse: 0.0252
 96/106 [==========================>...] - ETA: 0s - loss: 0.0277 - mae: 0.1384 - mse: 0.0277
106/106 [==============================] - 1s 7ms/step - loss: 0.0282 - mae: 0.1401 - mse: 0.0282 - val_loss: 0.0213 - val_mae: 0.1316 - val_mse: 0.0213
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0265 - mae: 0.1206 - mse: 0.0265
 64/106 [=================>............] - ETA: 0s - loss: 0.0258 - mae: 0.1174 - mse: 0.0258
 96/106 [==========================>...] - ETA: 0s - loss: 0.0254 - mae: 0.1211 - mse: 0.0254
106/106 [==============================] - 1s 7ms/step - loss: 0.0286 - mae: 0.1273 - mse: 0.0286 - val_loss: 0.0186 - val_mae: 0.1153 - val_mse: 0.0186
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0349 - mae: 0.1244 - mse: 0.0349
 64/106 [=================>............] - ETA: 0s - loss: 0.0281 - mae: 0.1198 - mse: 0.0281
 96/106 [==========================>...] - ETA: 0s - loss: 0.0293 - mae: 0.1310 - mse: 0.0293
106/106 [==============================] - 1s 7ms/step - loss: 0.0275 - mae: 0.1269 - mse: 0.0275 - val_loss: 0.0187 - val_mae: 0.1220 - val_mse: 0.0187
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0432 - mae: 0.1685 - mse: 0.0432
 64/106 [=================>............] - ETA: 0s - loss: 0.0306 - mae: 0.1352 - mse: 0.0306
 96/106 [==========================>...] - ETA: 0s - loss: 0.0266 - mae: 0.1270 - mse: 0.0266
106/106 [==============================] - 1s 7ms/step - loss: 0.0279 - mae: 0.1306 - mse: 0.0279 - val_loss: 0.0069 - val_mae: 0.0705 - val_mse: 0.0069
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0200 - mae: 0.1164 - mse: 0.0200
 64/106 [=================>............] - ETA: 0s - loss: 0.0273 - mae: 0.1295 - mse: 0.0273
 96/106 [==========================>...] - ETA: 0s - loss: 0.0261 - mae: 0.1292 - mse: 0.0261
106/106 [==============================] - 1s 7ms/step - loss: 0.0265 - mae: 0.1301 - mse: 0.0265 - val_loss: 0.0105 - val_mae: 0.0906 - val_mse: 0.0105
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0285 - mae: 0.1285 - mse: 0.0285
 64/106 [=================>............] - ETA: 0s - loss: 0.0300 - mae: 0.1284 - mse: 0.0300
 96/106 [==========================>...] - ETA: 0s - loss: 0.0255 - mae: 0.1209 - mse: 0.0255
106/106 [==============================] - 1s 7ms/step - loss: 0.0263 - mae: 0.1253 - mse: 0.0263 - val_loss: 0.0185 - val_mae: 0.1166 - val_mse: 0.0185
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0267 - mae: 0.1225 - mse: 0.0267
 64/106 [=================>............] - ETA: 0s - loss: 0.0268 - mae: 0.1274 - mse: 0.0268
 96/106 [==========================>...] - ETA: 0s - loss: 0.0222 - mae: 0.1170 - mse: 0.0222
106/106 [==============================] - 1s 7ms/step - loss: 0.0232 - mae: 0.1186 - mse: 0.0232 - val_loss: 0.0134 - val_mae: 0.0963 - val_mse: 0.0134
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0273 - mae: 0.1332 - mse: 0.0273
 64/106 [=================>............] - ETA: 0s - loss: 0.0254 - mae: 0.1212 - mse: 0.0254
 96/106 [==========================>...] - ETA: 0s - loss: 0.0233 - mae: 0.1147 - mse: 0.0233
106/106 [==============================] - 1s 7ms/step - loss: 0.0231 - mae: 0.1139 - mse: 0.0231 - val_loss: 0.0192 - val_mae: 0.1119 - val_mse: 0.0192
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0222 - mae: 0.1008 - mse: 0.0222
 64/106 [=================>............] - ETA: 0s - loss: 0.0207 - mae: 0.1035 - mse: 0.0207
 96/106 [==========================>...] - ETA: 0s - loss: 0.0247 - mae: 0.1157 - mse: 0.0247
106/106 [==============================] - 1s 7ms/step - loss: 0.0240 - mae: 0.1144 - mse: 0.0240 - val_loss: 0.0129 - val_mae: 0.0912 - val_mse: 0.0129
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0260 - mae: 0.1232 - mse: 0.0260
 64/106 [=================>............] - ETA: 0s - loss: 0.0276 - mae: 0.1268 - mse: 0.0276
 96/106 [==========================>...] - ETA: 0s - loss: 0.0256 - mae: 0.1204 - mse: 0.0256
106/106 [==============================] - 1s 7ms/step - loss: 0.0273 - mae: 0.1243 - mse: 0.0273 - val_loss: 0.0140 - val_mae: 0.0962 - val_mse: 0.0140
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0220 - mae: 0.1109 - mse: 0.0220
 64/106 [=================>............] - ETA: 0s - loss: 0.0221 - mae: 0.1050 - mse: 0.0221
 96/106 [==========================>...] - ETA: 0s - loss: 0.0210 - mae: 0.1066 - mse: 0.0210
106/106 [==============================] - 1s 7ms/step - loss: 0.0209 - mae: 0.1061 - mse: 0.0209 - val_loss: 0.0124 - val_mae: 0.0949 - val_mse: 0.0124
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0306 - mae: 0.1253 - mse: 0.0306
 64/106 [=================>............] - ETA: 0s - loss: 0.0263 - mae: 0.1222 - mse: 0.0263
 96/106 [==========================>...] - ETA: 0s - loss: 0.0230 - mae: 0.1138 - mse: 0.0230
106/106 [==============================] - 1s 7ms/step - loss: 0.0225 - mae: 0.1130 - mse: 0.0225 - val_loss: 0.0142 - val_mae: 0.1032 - val_mse: 0.0142
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0195 - mae: 0.1046 - mse: 0.0195
 64/106 [=================>............] - ETA: 0s - loss: 0.0204 - mae: 0.1049 - mse: 0.0204
 96/106 [==========================>...] - ETA: 0s - loss: 0.0196 - mae: 0.1016 - mse: 0.0196
106/106 [==============================] - 1s 7ms/step - loss: 0.0186 - mae: 0.0997 - mse: 0.0186 - val_loss: 0.0070 - val_mae: 0.0729 - val_mse: 0.0070
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0169 - mae: 0.0913 - mse: 0.0169
 64/106 [=================>............] - ETA: 0s - loss: 0.0181 - mae: 0.0920 - mse: 0.0181
 96/106 [==========================>...] - ETA: 0s - loss: 0.0199 - mae: 0.0962 - mse: 0.0199
106/106 [==============================] - 1s 7ms/step - loss: 0.0211 - mae: 0.1018 - mse: 0.0211 - val_loss: 0.0116 - val_mae: 0.0985 - val_mse: 0.0116
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0192 - mae: 0.1032 - mse: 0.0192
 64/106 [=================>............] - ETA: 0s - loss: 0.0182 - mae: 0.0967 - mse: 0.0182
 96/106 [==========================>...] - ETA: 0s - loss: 0.0142 - mae: 0.0852 - mse: 0.0142
106/106 [==============================] - 1s 7ms/step - loss: 0.0169 - mae: 0.0926 - mse: 0.0169 - val_loss: 0.0085 - val_mae: 0.0637 - val_mse: 0.0085
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0199 - mae: 0.1097 - mse: 0.0199
 64/106 [=================>............] - ETA: 0s - loss: 0.0228 - mae: 0.1136 - mse: 0.0228
 96/106 [==========================>...] - ETA: 0s - loss: 0.0265 - mae: 0.1232 - mse: 0.0265
106/106 [==============================] - 1s 7ms/step - loss: 0.0251 - mae: 0.1191 - mse: 0.0251 - val_loss: 0.0102 - val_mae: 0.0835 - val_mse: 0.0102
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0290 - mae: 0.1101 - mse: 0.0290
 64/106 [=================>............] - ETA: 0s - loss: 0.0317 - mae: 0.1258 - mse: 0.0317
 96/106 [==========================>...] - ETA: 0s - loss: 0.0281 - mae: 0.1199 - mse: 0.0281
106/106 [==============================] - 1s 7ms/step - loss: 0.0260 - mae: 0.1144 - mse: 0.0260 - val_loss: 0.0249 - val_mae: 0.1399 - val_mse: 0.0249
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0141 - mae: 0.0953 - mse: 0.0141
 64/106 [=================>............] - ETA: 0s - loss: 0.0211 - mae: 0.1017 - mse: 0.0211
 96/106 [==========================>...] - ETA: 0s - loss: 0.0200 - mae: 0.1009 - mse: 0.0200
106/106 [==============================] - 1s 7ms/step - loss: 0.0200 - mae: 0.1021 - mse: 0.0200 - val_loss: 0.0118 - val_mae: 0.0966 - val_mse: 0.0118
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0141 - mae: 0.0914 - mse: 0.0141
 64/106 [=================>............] - ETA: 0s - loss: 0.0127 - mae: 0.0881 - mse: 0.0127
 96/106 [==========================>...] - ETA: 0s - loss: 0.0163 - mae: 0.0968 - mse: 0.0163
106/106 [==============================] - 1s 7ms/step - loss: 0.0168 - mae: 0.0992 - mse: 0.0168 - val_loss: 0.0073 - val_mae: 0.0663 - val_mse: 0.0073
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0278 - mae: 0.1241 - mse: 0.0278
 64/106 [=================>............] - ETA: 0s - loss: 0.0208 - mae: 0.1036 - mse: 0.0208
 96/106 [==========================>...] - ETA: 0s - loss: 0.0220 - mae: 0.1063 - mse: 0.0220
106/106 [==============================] - 1s 7ms/step - loss: 0.0220 - mae: 0.1047 - mse: 0.0220 - val_loss: 0.0144 - val_mae: 0.1078 - val_mse: 0.0144
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0151 - mae: 0.0864 - mse: 0.0151
 64/106 [=================>............] - ETA: 0s - loss: 0.0145 - mae: 0.0882 - mse: 0.0145
 96/106 [==========================>...] - ETA: 0s - loss: 0.0201 - mae: 0.1077 - mse: 0.0201
106/106 [==============================] - 1s 7ms/step - loss: 0.0200 - mae: 0.1085 - mse: 0.0200 - val_loss: 0.0127 - val_mae: 0.1013 - val_mse: 0.0127
Saving trained model...
72
Testing...
heightdiff= [0.         0.         0.         2.64758682 0.         0.        ]
average prediction= [4.9525156]
baseline= 8.666666666666666
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.5295173645019531
85 -:- nan
60 -:- nan
['train-weight-15.py', '1']
65 1
65 2
65 3
2_155_65_15_csi_a15_22.dat
65 5
65 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
2_155_65_15_csi_a15_1.dat
65 18
2_155_65_15_csi_a15_4.dat
65 20
65 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
65 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
65 41
1_165_65_15_csi_a15_12.dat
65 43
65 44
65 45
65 46
65 47
1_165_65_15_csi_a15_14.dat
65 49
65 50
1_165_65_15_csi_a15_18.dat
65 52
65 53
65 54
65 55
65 56
65 57
65 58
65 59
65 60
65 61
65 62
65 63
65 64
65 65
1_165_65_15_csi_a15_15.dat
65 67
65 68
65 69
65 70
50 71
2_165_50_15_csi_a15_10.dat
50 73
50 74
50 75
50 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
2_165_50_15_csi_a15_22.dat
50 91
50 92
50 93
2_165_50_15_csi_a15_14.dat
50 95
50 96
50 97
2_165_50_15_csi_a15_20.dat
50 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
1_175_70_15_csi_a15_28.dat
70 112
70 113
70 114
70 115
1_175_70_15_csi_a15_27.dat
70 117
70 118
70 119
1_175_70_15_csi_a15_29.dat
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
85 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
85 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
85 139
85 140
85 141
85 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
85 145
1_180_85_15_csi_a15_24.dat
85 147
85 148
85 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
85 152
85 153
85 154
1_180_85_15_csi_a15_27.dat
85 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
85 159
85 160
1_180_75_15_csi_a15_23.dat
75 162
1_180_75_15_csi_a15_17.dat
75 164
75 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
75 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
75 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
75 174
1_180_75_15_csi_a15_18.dat
75 176
1_180_75_15_csi_a15_15.dat
75 178
1_180_75_15_csi_a15_13.dat
75 180
1_180_75_15_csi_a15_3.dat
75 182
1_180_75_15_csi_a15_25.dat
75 184
75 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
75 190
85 191
1_173_85_15_csi_a15_7.dat
85 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
85 198
85 199
85 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
85 203
85 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
85 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
85 211
85 212
85 213
85 214
85 215
1_173_85_15_csi_a15_29.dat
85 217
85 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60
 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 85]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.2344 - mae: 0.3819 - mse: 0.2344
 64/106 [=================>............] - ETA: 0s - loss: 0.1851 - mae: 0.3300 - mse: 0.1851
 96/106 [==========================>...] - ETA: 0s - loss: 0.1464 - mae: 0.2982 - mse: 0.1464
106/106 [==============================] - 1s 10ms/step - loss: 0.1390 - mae: 0.2900 - mse: 0.1390 - val_loss: 0.0584 - val_mae: 0.2052 - val_mse: 0.0584
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1179 - mae: 0.2853 - mse: 0.1179
 64/106 [=================>............] - ETA: 0s - loss: 0.1492 - mae: 0.3233 - mse: 0.1492
 96/106 [==========================>...] - ETA: 0s - loss: 0.1258 - mae: 0.2927 - mse: 0.1258
106/106 [==============================] - 1s 7ms/step - loss: 0.1217 - mae: 0.2885 - mse: 0.1217 - val_loss: 0.0861 - val_mae: 0.2346 - val_mse: 0.0861
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0899 - mae: 0.2557 - mse: 0.0899
 64/106 [=================>............] - ETA: 0s - loss: 0.0787 - mae: 0.2211 - mse: 0.0787
 96/106 [==========================>...] - ETA: 0s - loss: 0.0872 - mae: 0.2427 - mse: 0.0872
106/106 [==============================] - 1s 7ms/step - loss: 0.0901 - mae: 0.2484 - mse: 0.0901 - val_loss: 0.1108 - val_mae: 0.2742 - val_mse: 0.1108
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0783 - mae: 0.2345 - mse: 0.0783
 64/106 [=================>............] - ETA: 0s - loss: 0.0736 - mae: 0.2230 - mse: 0.0736
 96/106 [==========================>...] - ETA: 0s - loss: 0.0718 - mae: 0.2220 - mse: 0.0718
106/106 [==============================] - 1s 7ms/step - loss: 0.0734 - mae: 0.2255 - mse: 0.0734 - val_loss: 0.0534 - val_mae: 0.1970 - val_mse: 0.0534
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0639 - mae: 0.2073 - mse: 0.0639
 64/106 [=================>............] - ETA: 0s - loss: 0.0718 - mae: 0.2171 - mse: 0.0718
 96/106 [==========================>...] - ETA: 0s - loss: 0.0698 - mae: 0.2188 - mse: 0.0698
106/106 [==============================] - 1s 7ms/step - loss: 0.0664 - mae: 0.2132 - mse: 0.0664 - val_loss: 0.0293 - val_mae: 0.1497 - val_mse: 0.0293
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0594 - mae: 0.2017 - mse: 0.0594
 64/106 [=================>............] - ETA: 0s - loss: 0.0647 - mae: 0.2070 - mse: 0.0647
 96/106 [==========================>...] - ETA: 0s - loss: 0.0616 - mae: 0.2026 - mse: 0.0616
106/106 [==============================] - 1s 7ms/step - loss: 0.0596 - mae: 0.1995 - mse: 0.0596 - val_loss: 0.0514 - val_mae: 0.1959 - val_mse: 0.0514
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0335 - mae: 0.1644 - mse: 0.0335
 64/106 [=================>............] - ETA: 0s - loss: 0.0395 - mae: 0.1674 - mse: 0.0395
 96/106 [==========================>...] - ETA: 0s - loss: 0.0420 - mae: 0.1701 - mse: 0.0420
106/106 [==============================] - 1s 7ms/step - loss: 0.0413 - mae: 0.1685 - mse: 0.0413 - val_loss: 0.0828 - val_mae: 0.2502 - val_mse: 0.0828
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0500 - mae: 0.1970 - mse: 0.0500
 64/106 [=================>............] - ETA: 0s - loss: 0.0496 - mae: 0.1898 - mse: 0.0496
 96/106 [==========================>...] - ETA: 0s - loss: 0.0497 - mae: 0.1888 - mse: 0.0497
106/106 [==============================] - 1s 7ms/step - loss: 0.0489 - mae: 0.1865 - mse: 0.0489 - val_loss: 0.0324 - val_mae: 0.1543 - val_mse: 0.0324
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0332 - mae: 0.1486 - mse: 0.0332
 64/106 [=================>............] - ETA: 0s - loss: 0.0329 - mae: 0.1476 - mse: 0.0329
 96/106 [==========================>...] - ETA: 0s - loss: 0.0301 - mae: 0.1395 - mse: 0.0301
106/106 [==============================] - 1s 7ms/step - loss: 0.0324 - mae: 0.1450 - mse: 0.0324 - val_loss: 0.0290 - val_mae: 0.1440 - val_mse: 0.0290
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0350 - mae: 0.1327 - mse: 0.0350
 64/106 [=================>............] - ETA: 0s - loss: 0.0357 - mae: 0.1449 - mse: 0.0357
 96/106 [==========================>...] - ETA: 0s - loss: 0.0361 - mae: 0.1461 - mse: 0.0361
106/106 [==============================] - 1s 7ms/step - loss: 0.0343 - mae: 0.1415 - mse: 0.0343 - val_loss: 0.0407 - val_mae: 0.1752 - val_mse: 0.0407
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0393 - mae: 0.1530 - mse: 0.0393
 64/106 [=================>............] - ETA: 0s - loss: 0.0293 - mae: 0.1312 - mse: 0.0293
 96/106 [==========================>...] - ETA: 0s - loss: 0.0305 - mae: 0.1357 - mse: 0.0305
106/106 [==============================] - 1s 7ms/step - loss: 0.0299 - mae: 0.1355 - mse: 0.0299 - val_loss: 0.0304 - val_mae: 0.1477 - val_mse: 0.0304
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0299 - mae: 0.1398 - mse: 0.0299
 64/106 [=================>............] - ETA: 0s - loss: 0.0264 - mae: 0.1261 - mse: 0.0264
 96/106 [==========================>...] - ETA: 0s - loss: 0.0293 - mae: 0.1339 - mse: 0.0293
106/106 [==============================] - 1s 7ms/step - loss: 0.0300 - mae: 0.1356 - mse: 0.0300 - val_loss: 0.0203 - val_mae: 0.1159 - val_mse: 0.0203
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0282 - mae: 0.1336 - mse: 0.0282
 64/106 [=================>............] - ETA: 0s - loss: 0.0245 - mae: 0.1262 - mse: 0.0245
 96/106 [==========================>...] - ETA: 0s - loss: 0.0223 - mae: 0.1211 - mse: 0.0223
106/106 [==============================] - 1s 7ms/step - loss: 0.0213 - mae: 0.1185 - mse: 0.0213 - val_loss: 0.0373 - val_mae: 0.1612 - val_mse: 0.0373
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0234 - mae: 0.1268 - mse: 0.0234
 64/106 [=================>............] - ETA: 0s - loss: 0.0267 - mae: 0.1248 - mse: 0.0267
 96/106 [==========================>...] - ETA: 0s - loss: 0.0276 - mae: 0.1271 - mse: 0.0276
106/106 [==============================] - 1s 7ms/step - loss: 0.0284 - mae: 0.1296 - mse: 0.0284 - val_loss: 0.0123 - val_mae: 0.0892 - val_mse: 0.0123
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0411 - mae: 0.1627 - mse: 0.0411
 64/106 [=================>............] - ETA: 0s - loss: 0.0332 - mae: 0.1379 - mse: 0.0332
 96/106 [==========================>...] - ETA: 0s - loss: 0.0311 - mae: 0.1352 - mse: 0.0311
106/106 [==============================] - 1s 7ms/step - loss: 0.0300 - mae: 0.1321 - mse: 0.0300 - val_loss: 0.0262 - val_mae: 0.1343 - val_mse: 0.0262
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0168 - mae: 0.1000 - mse: 0.0168
 64/106 [=================>............] - ETA: 0s - loss: 0.0220 - mae: 0.1144 - mse: 0.0220
 96/106 [==========================>...] - ETA: 0s - loss: 0.0237 - mae: 0.1170 - mse: 0.0237
106/106 [==============================] - 1s 7ms/step - loss: 0.0236 - mae: 0.1173 - mse: 0.0236 - val_loss: 0.0370 - val_mae: 0.1680 - val_mse: 0.0370
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0327 - mae: 0.1332 - mse: 0.0327
 64/106 [=================>............] - ETA: 0s - loss: 0.0263 - mae: 0.1150 - mse: 0.0263
 96/106 [==========================>...] - ETA: 0s - loss: 0.0240 - mae: 0.1090 - mse: 0.0240
106/106 [==============================] - 1s 7ms/step - loss: 0.0232 - mae: 0.1087 - mse: 0.0232 - val_loss: 0.0142 - val_mae: 0.0974 - val_mse: 0.0142
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0128 - mae: 0.0900 - mse: 0.0128
 64/106 [=================>............] - ETA: 0s - loss: 0.0170 - mae: 0.0991 - mse: 0.0170
 96/106 [==========================>...] - ETA: 0s - loss: 0.0172 - mae: 0.1037 - mse: 0.0172
106/106 [==============================] - 1s 7ms/step - loss: 0.0177 - mae: 0.1033 - mse: 0.0177 - val_loss: 0.0247 - val_mae: 0.1261 - val_mse: 0.0247
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0191 - mae: 0.1042 - mse: 0.0191
 64/106 [=================>............] - ETA: 0s - loss: 0.0239 - mae: 0.1129 - mse: 0.0239
 96/106 [==========================>...] - ETA: 0s - loss: 0.0209 - mae: 0.1057 - mse: 0.0209
106/106 [==============================] - 1s 7ms/step - loss: 0.0195 - mae: 0.1018 - mse: 0.0195 - val_loss: 0.0265 - val_mae: 0.1333 - val_mse: 0.0265
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0202 - mae: 0.1039 - mse: 0.0202
 64/106 [=================>............] - ETA: 0s - loss: 0.0196 - mae: 0.1041 - mse: 0.0196
 96/106 [==========================>...] - ETA: 0s - loss: 0.0208 - mae: 0.1103 - mse: 0.0208
106/106 [==============================] - 1s 7ms/step - loss: 0.0195 - mae: 0.1070 - mse: 0.0195 - val_loss: 0.0183 - val_mae: 0.1116 - val_mse: 0.0183
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0211 - mae: 0.1197 - mse: 0.0211
 64/106 [=================>............] - ETA: 0s - loss: 0.0171 - mae: 0.1083 - mse: 0.0171
 96/106 [==========================>...] - ETA: 0s - loss: 0.0219 - mae: 0.1124 - mse: 0.0219
106/106 [==============================] - 1s 7ms/step - loss: 0.0211 - mae: 0.1109 - mse: 0.0211 - val_loss: 0.0228 - val_mae: 0.1279 - val_mse: 0.0228
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0159 - mae: 0.0976 - mse: 0.0159
 64/106 [=================>............] - ETA: 0s - loss: 0.0170 - mae: 0.1011 - mse: 0.0170
 96/106 [==========================>...] - ETA: 0s - loss: 0.0158 - mae: 0.0981 - mse: 0.0158
106/106 [==============================] - 1s 7ms/step - loss: 0.0158 - mae: 0.0995 - mse: 0.0158 - val_loss: 0.0228 - val_mae: 0.1269 - val_mse: 0.0228
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0127 - mae: 0.0959 - mse: 0.0127
 64/106 [=================>............] - ETA: 0s - loss: 0.0100 - mae: 0.0818 - mse: 0.0100
 96/106 [==========================>...] - ETA: 0s - loss: 0.0115 - mae: 0.0855 - mse: 0.0115
106/106 [==============================] - 1s 7ms/step - loss: 0.0122 - mae: 0.0872 - mse: 0.0122 - val_loss: 0.0120 - val_mae: 0.0933 - val_mse: 0.0120
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0168 - mae: 0.1072 - mse: 0.0168
 64/106 [=================>............] - ETA: 0s - loss: 0.0126 - mae: 0.0885 - mse: 0.0126
 96/106 [==========================>...] - ETA: 0s - loss: 0.0158 - mae: 0.0948 - mse: 0.0158
106/106 [==============================] - 1s 7ms/step - loss: 0.0155 - mae: 0.0943 - mse: 0.0155 - val_loss: 0.0279 - val_mae: 0.1447 - val_mse: 0.0279
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0160 - mae: 0.1007 - mse: 0.0160
 64/106 [=================>............] - ETA: 0s - loss: 0.0150 - mae: 0.0951 - mse: 0.0150
 96/106 [==========================>...] - ETA: 0s - loss: 0.0165 - mae: 0.1009 - mse: 0.0165
106/106 [==============================] - 1s 7ms/step - loss: 0.0159 - mae: 0.0998 - mse: 0.0159 - val_loss: 0.0170 - val_mae: 0.1091 - val_mse: 0.0170
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0149 - mae: 0.0901 - mse: 0.0149
 64/106 [=================>............] - ETA: 0s - loss: 0.0139 - mae: 0.0879 - mse: 0.0139
 96/106 [==========================>...] - ETA: 0s - loss: 0.0146 - mae: 0.0914 - mse: 0.0146
106/106 [==============================] - 1s 7ms/step - loss: 0.0137 - mae: 0.0885 - mse: 0.0137 - val_loss: 0.0183 - val_mae: 0.1134 - val_mse: 0.0183
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0089 - mae: 0.0722 - mse: 0.0089
 64/106 [=================>............] - ETA: 0s - loss: 0.0093 - mae: 0.0756 - mse: 0.0093
 96/106 [==========================>...] - ETA: 0s - loss: 0.0103 - mae: 0.0783 - mse: 0.0103
106/106 [==============================] - 1s 7ms/step - loss: 0.0101 - mae: 0.0770 - mse: 0.0101 - val_loss: 0.0270 - val_mae: 0.1444 - val_mse: 0.0270
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0086 - mae: 0.0789 - mse: 0.0086
 64/106 [=================>............] - ETA: 0s - loss: 0.0155 - mae: 0.0961 - mse: 0.0155
 96/106 [==========================>...] - ETA: 0s - loss: 0.0125 - mae: 0.0833 - mse: 0.0125
106/106 [==============================] - 1s 7ms/step - loss: 0.0132 - mae: 0.0860 - mse: 0.0132 - val_loss: 0.0205 - val_mae: 0.1206 - val_mse: 0.0205
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0165 - mae: 0.0998 - mse: 0.0165
 64/106 [=================>............] - ETA: 0s - loss: 0.0143 - mae: 0.0895 - mse: 0.0143
 96/106 [==========================>...] - ETA: 0s - loss: 0.0136 - mae: 0.0862 - mse: 0.0136
106/106 [==============================] - 1s 7ms/step - loss: 0.0160 - mae: 0.0915 - mse: 0.0160 - val_loss: 0.0382 - val_mae: 0.1734 - val_mse: 0.0382
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0076 - mae: 0.0674 - mse: 0.0076
 64/106 [=================>............] - ETA: 0s - loss: 0.0089 - mae: 0.0724 - mse: 0.0089
 96/106 [==========================>...] - ETA: 0s - loss: 0.0111 - mae: 0.0827 - mse: 0.0111
106/106 [==============================] - 1s 7ms/step - loss: 0.0129 - mae: 0.0865 - mse: 0.0129 - val_loss: 0.0296 - val_mae: 0.1511 - val_mse: 0.0296
Saving trained model...
72
Testing...
heightdiff= [ 0.          0.          0.         10.36216354  0.          0.        ]
average prediction= [4.4891734]
baseline= 10.5
eachuser= [0. 0. 0. 7. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.480309077671596
85 -:- nan
60 -:- nan
['train-weight-15.py', '1']
65 1
65 2
65 3
2_155_65_15_csi_a15_22.dat
65 5
65 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
2_155_65_15_csi_a15_1.dat
65 18
2_155_65_15_csi_a15_4.dat
65 20
65 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
65 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
65 41
1_165_65_15_csi_a15_12.dat
65 43
65 44
65 45
65 46
65 47
1_165_65_15_csi_a15_14.dat
65 49
65 50
1_165_65_15_csi_a15_18.dat
65 52
65 53
65 54
65 55
65 56
65 57
65 58
65 59
65 60
65 61
65 62
65 63
65 64
65 65
1_165_65_15_csi_a15_15.dat
65 67
65 68
65 69
65 70
50 71
2_165_50_15_csi_a15_10.dat
50 73
50 74
50 75
50 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
2_165_50_15_csi_a15_22.dat
50 91
50 92
50 93
2_165_50_15_csi_a15_14.dat
50 95
50 96
50 97
2_165_50_15_csi_a15_20.dat
50 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
1_175_70_15_csi_a15_28.dat
70 112
70 113
70 114
70 115
1_175_70_15_csi_a15_27.dat
70 117
70 118
70 119
1_175_70_15_csi_a15_29.dat
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
85 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
85 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
85 139
85 140
85 141
85 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
85 145
1_180_85_15_csi_a15_24.dat
85 147
85 148
85 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
85 152
85 153
85 154
1_180_85_15_csi_a15_27.dat
85 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
85 159
85 160
1_180_75_15_csi_a15_23.dat
75 162
1_180_75_15_csi_a15_17.dat
75 164
75 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
75 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
75 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
75 174
1_180_75_15_csi_a15_18.dat
75 176
1_180_75_15_csi_a15_15.dat
75 178
1_180_75_15_csi_a15_13.dat
75 180
1_180_75_15_csi_a15_3.dat
75 182
1_180_75_15_csi_a15_25.dat
75 184
75 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
75 190
85 191
1_173_85_15_csi_a15_7.dat
85 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
85 198
85 199
85 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
85 203
85 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
85 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
85 211
85 212
85 213
85 214
85 215
1_173_85_15_csi_a15_29.dat
85 217
85 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60
 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 85]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.2677 - mae: 0.4571 - mse: 0.2677
 64/106 [=================>............] - ETA: 0s - loss: 0.2180 - mae: 0.3997 - mse: 0.2180
 96/106 [==========================>...] - ETA: 0s - loss: 0.1821 - mae: 0.3620 - mse: 0.1821
106/106 [==============================] - 1s 10ms/step - loss: 0.1730 - mae: 0.3512 - mse: 0.1730 - val_loss: 0.0629 - val_mae: 0.2055 - val_mse: 0.0629
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1093 - mae: 0.2897 - mse: 0.1093
 64/106 [=================>............] - ETA: 0s - loss: 0.1435 - mae: 0.3221 - mse: 0.1435
 96/106 [==========================>...] - ETA: 0s - loss: 0.1269 - mae: 0.2997 - mse: 0.1269
106/106 [==============================] - 1s 7ms/step - loss: 0.1211 - mae: 0.2931 - mse: 0.1211 - val_loss: 0.0948 - val_mae: 0.2912 - val_mse: 0.0948
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0827 - mae: 0.2441 - mse: 0.0827
 64/106 [=================>............] - ETA: 0s - loss: 0.0801 - mae: 0.2367 - mse: 0.0801
 96/106 [==========================>...] - ETA: 0s - loss: 0.0972 - mae: 0.2606 - mse: 0.0972
106/106 [==============================] - 1s 7ms/step - loss: 0.0960 - mae: 0.2587 - mse: 0.0960 - val_loss: 0.1316 - val_mae: 0.3314 - val_mse: 0.1316
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1067 - mae: 0.2602 - mse: 0.1067
 64/106 [=================>............] - ETA: 0s - loss: 0.0844 - mae: 0.2418 - mse: 0.0844
 96/106 [==========================>...] - ETA: 0s - loss: 0.0877 - mae: 0.2445 - mse: 0.0877
106/106 [==============================] - 1s 7ms/step - loss: 0.0853 - mae: 0.2391 - mse: 0.0853 - val_loss: 0.0785 - val_mae: 0.2557 - val_mse: 0.0785
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0647 - mae: 0.2119 - mse: 0.0647
 64/106 [=================>............] - ETA: 0s - loss: 0.0611 - mae: 0.2111 - mse: 0.0611
 96/106 [==========================>...] - ETA: 0s - loss: 0.0648 - mae: 0.2145 - mse: 0.0648
106/106 [==============================] - 1s 7ms/step - loss: 0.0620 - mae: 0.2077 - mse: 0.0620 - val_loss: 0.0359 - val_mae: 0.1796 - val_mse: 0.0359
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0613 - mae: 0.2118 - mse: 0.0613
 64/106 [=================>............] - ETA: 0s - loss: 0.0558 - mae: 0.2007 - mse: 0.0558
 96/106 [==========================>...] - ETA: 0s - loss: 0.0551 - mae: 0.1988 - mse: 0.0551
106/106 [==============================] - 1s 7ms/step - loss: 0.0518 - mae: 0.1904 - mse: 0.0518 - val_loss: 0.0314 - val_mae: 0.1591 - val_mse: 0.0314
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0524 - mae: 0.1742 - mse: 0.0524
 64/106 [=================>............] - ETA: 0s - loss: 0.0526 - mae: 0.1811 - mse: 0.0526
 96/106 [==========================>...] - ETA: 0s - loss: 0.0466 - mae: 0.1731 - mse: 0.0466
106/106 [==============================] - 1s 7ms/step - loss: 0.0476 - mae: 0.1750 - mse: 0.0476 - val_loss: 0.0467 - val_mae: 0.1841 - val_mse: 0.0467
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0316 - mae: 0.1429 - mse: 0.0316
 64/106 [=================>............] - ETA: 0s - loss: 0.0323 - mae: 0.1424 - mse: 0.0323
 96/106 [==========================>...] - ETA: 0s - loss: 0.0411 - mae: 0.1566 - mse: 0.0411
106/106 [==============================] - 1s 7ms/step - loss: 0.0404 - mae: 0.1567 - mse: 0.0404 - val_loss: 0.0189 - val_mae: 0.1050 - val_mse: 0.0189
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0354 - mae: 0.1480 - mse: 0.0354
 64/106 [=================>............] - ETA: 0s - loss: 0.0515 - mae: 0.1714 - mse: 0.0515
 96/106 [==========================>...] - ETA: 0s - loss: 0.0459 - mae: 0.1592 - mse: 0.0459
106/106 [==============================] - 1s 7ms/step - loss: 0.0441 - mae: 0.1563 - mse: 0.0441 - val_loss: 0.0249 - val_mae: 0.1231 - val_mse: 0.0249
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0374 - mae: 0.1499 - mse: 0.0374
 64/106 [=================>............] - ETA: 0s - loss: 0.0406 - mae: 0.1574 - mse: 0.0406
 96/106 [==========================>...] - ETA: 0s - loss: 0.0412 - mae: 0.1579 - mse: 0.0412
106/106 [==============================] - 1s 7ms/step - loss: 0.0398 - mae: 0.1549 - mse: 0.0398 - val_loss: 0.0330 - val_mae: 0.1488 - val_mse: 0.0330
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0294 - mae: 0.1296 - mse: 0.0294
 64/106 [=================>............] - ETA: 0s - loss: 0.0347 - mae: 0.1382 - mse: 0.0347
 96/106 [==========================>...] - ETA: 0s - loss: 0.0387 - mae: 0.1478 - mse: 0.0387
106/106 [==============================] - 1s 7ms/step - loss: 0.0363 - mae: 0.1429 - mse: 0.0363 - val_loss: 0.0417 - val_mae: 0.1721 - val_mse: 0.0417
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0439 - mae: 0.1574 - mse: 0.0439
 64/106 [=================>............] - ETA: 0s - loss: 0.0349 - mae: 0.1351 - mse: 0.0349
 96/106 [==========================>...] - ETA: 0s - loss: 0.0377 - mae: 0.1417 - mse: 0.0377
106/106 [==============================] - 1s 7ms/step - loss: 0.0362 - mae: 0.1397 - mse: 0.0362 - val_loss: 0.0361 - val_mae: 0.1568 - val_mse: 0.0361
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0234 - mae: 0.1170 - mse: 0.0234
 64/106 [=================>............] - ETA: 0s - loss: 0.0304 - mae: 0.1267 - mse: 0.0304
 96/106 [==========================>...] - ETA: 0s - loss: 0.0334 - mae: 0.1343 - mse: 0.0334
106/106 [==============================] - 1s 7ms/step - loss: 0.0309 - mae: 0.1284 - mse: 0.0309 - val_loss: 0.0288 - val_mae: 0.1360 - val_mse: 0.0288
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0434 - mae: 0.1649 - mse: 0.0434
 64/106 [=================>............] - ETA: 0s - loss: 0.0321 - mae: 0.1435 - mse: 0.0321
 96/106 [==========================>...] - ETA: 0s - loss: 0.0352 - mae: 0.1492 - mse: 0.0352
106/106 [==============================] - 1s 7ms/step - loss: 0.0322 - mae: 0.1404 - mse: 0.0322 - val_loss: 0.0456 - val_mae: 0.1787 - val_mse: 0.0456
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0240 - mae: 0.1157 - mse: 0.0240
 64/106 [=================>............] - ETA: 0s - loss: 0.0261 - mae: 0.1196 - mse: 0.0261
 96/106 [==========================>...] - ETA: 0s - loss: 0.0241 - mae: 0.1178 - mse: 0.0241
106/106 [==============================] - 1s 7ms/step - loss: 0.0242 - mae: 0.1188 - mse: 0.0242 - val_loss: 0.0330 - val_mae: 0.1474 - val_mse: 0.0330
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0202 - mae: 0.1106 - mse: 0.0202
 64/106 [=================>............] - ETA: 0s - loss: 0.0321 - mae: 0.1389 - mse: 0.0321
 96/106 [==========================>...] - ETA: 0s - loss: 0.0299 - mae: 0.1345 - mse: 0.0299
106/106 [==============================] - 1s 7ms/step - loss: 0.0312 - mae: 0.1328 - mse: 0.0312 - val_loss: 0.0296 - val_mae: 0.1386 - val_mse: 0.0296
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0265 - mae: 0.1239 - mse: 0.0265
 64/106 [=================>............] - ETA: 0s - loss: 0.0271 - mae: 0.1324 - mse: 0.0271
 96/106 [==========================>...] - ETA: 0s - loss: 0.0264 - mae: 0.1282 - mse: 0.0264
106/106 [==============================] - 1s 7ms/step - loss: 0.0263 - mae: 0.1295 - mse: 0.0263 - val_loss: 0.0266 - val_mae: 0.1331 - val_mse: 0.0266
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0252 - mae: 0.1146 - mse: 0.0252
 64/106 [=================>............] - ETA: 0s - loss: 0.0212 - mae: 0.1099 - mse: 0.0212
 96/106 [==========================>...] - ETA: 0s - loss: 0.0247 - mae: 0.1204 - mse: 0.0247
106/106 [==============================] - 1s 7ms/step - loss: 0.0251 - mae: 0.1212 - mse: 0.0251 - val_loss: 0.0367 - val_mae: 0.1684 - val_mse: 0.0367
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0220 - mae: 0.1060 - mse: 0.0220
 64/106 [=================>............] - ETA: 0s - loss: 0.0267 - mae: 0.1184 - mse: 0.0267
 96/106 [==========================>...] - ETA: 0s - loss: 0.0258 - mae: 0.1176 - mse: 0.0258
106/106 [==============================] - 1s 7ms/step - loss: 0.0250 - mae: 0.1167 - mse: 0.0250 - val_loss: 0.0321 - val_mae: 0.1542 - val_mse: 0.0321
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0161 - mae: 0.0984 - mse: 0.0161
 64/106 [=================>............] - ETA: 0s - loss: 0.0227 - mae: 0.1123 - mse: 0.0227
 96/106 [==========================>...] - ETA: 0s - loss: 0.0272 - mae: 0.1266 - mse: 0.0272
106/106 [==============================] - 1s 7ms/step - loss: 0.0264 - mae: 0.1241 - mse: 0.0264 - val_loss: 0.0213 - val_mae: 0.1181 - val_mse: 0.0213
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0292 - mae: 0.1322 - mse: 0.0292
 64/106 [=================>............] - ETA: 0s - loss: 0.0236 - mae: 0.1161 - mse: 0.0236
 96/106 [==========================>...] - ETA: 0s - loss: 0.0237 - mae: 0.1157 - mse: 0.0237
106/106 [==============================] - 1s 7ms/step - loss: 0.0263 - mae: 0.1187 - mse: 0.0263 - val_loss: 0.0383 - val_mae: 0.1649 - val_mse: 0.0383
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0185 - mae: 0.1057 - mse: 0.0185
 64/106 [=================>............] - ETA: 0s - loss: 0.0200 - mae: 0.1042 - mse: 0.0200
 96/106 [==========================>...] - ETA: 0s - loss: 0.0262 - mae: 0.1176 - mse: 0.0262
106/106 [==============================] - 1s 7ms/step - loss: 0.0260 - mae: 0.1182 - mse: 0.0260 - val_loss: 0.0130 - val_mae: 0.0919 - val_mse: 0.0130
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0271 - mae: 0.1328 - mse: 0.0271
 64/106 [=================>............] - ETA: 0s - loss: 0.0266 - mae: 0.1270 - mse: 0.0266
 96/106 [==========================>...] - ETA: 0s - loss: 0.0254 - mae: 0.1201 - mse: 0.0254
106/106 [==============================] - 1s 7ms/step - loss: 0.0249 - mae: 0.1187 - mse: 0.0249 - val_loss: 0.0283 - val_mae: 0.1435 - val_mse: 0.0283
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0145 - mae: 0.0919 - mse: 0.0145
 64/106 [=================>............] - ETA: 0s - loss: 0.0197 - mae: 0.0992 - mse: 0.0197
 96/106 [==========================>...] - ETA: 0s - loss: 0.0208 - mae: 0.1051 - mse: 0.0208
106/106 [==============================] - 1s 7ms/step - loss: 0.0209 - mae: 0.1063 - mse: 0.0209 - val_loss: 0.0303 - val_mae: 0.1513 - val_mse: 0.0303
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0349 - mae: 0.1442 - mse: 0.0349
 64/106 [=================>............] - ETA: 0s - loss: 0.0319 - mae: 0.1362 - mse: 0.0319
 96/106 [==========================>...] - ETA: 0s - loss: 0.0281 - mae: 0.1249 - mse: 0.0281
106/106 [==============================] - 1s 7ms/step - loss: 0.0260 - mae: 0.1189 - mse: 0.0260 - val_loss: 0.0378 - val_mae: 0.1692 - val_mse: 0.0378
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0172 - mae: 0.0953 - mse: 0.0172
 64/106 [=================>............] - ETA: 0s - loss: 0.0149 - mae: 0.0894 - mse: 0.0149
 96/106 [==========================>...] - ETA: 0s - loss: 0.0230 - mae: 0.1050 - mse: 0.0230
106/106 [==============================] - 1s 7ms/step - loss: 0.0223 - mae: 0.1034 - mse: 0.0223 - val_loss: 0.0296 - val_mae: 0.1453 - val_mse: 0.0296
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0100 - mae: 0.0768 - mse: 0.0100
 64/106 [=================>............] - ETA: 0s - loss: 0.0162 - mae: 0.0952 - mse: 0.0162
 96/106 [==========================>...] - ETA: 0s - loss: 0.0164 - mae: 0.0937 - mse: 0.0164
106/106 [==============================] - 1s 7ms/step - loss: 0.0176 - mae: 0.0974 - mse: 0.0176 - val_loss: 0.0210 - val_mae: 0.1208 - val_mse: 0.0210
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0173 - mae: 0.1002 - mse: 0.0173
 64/106 [=================>............] - ETA: 0s - loss: 0.0188 - mae: 0.1061 - mse: 0.0188
 96/106 [==========================>...] - ETA: 0s - loss: 0.0177 - mae: 0.1032 - mse: 0.0177
106/106 [==============================] - 1s 7ms/step - loss: 0.0171 - mae: 0.0999 - mse: 0.0171 - val_loss: 0.0408 - val_mae: 0.1802 - val_mse: 0.0408
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0189 - mae: 0.1028 - mse: 0.0189
 64/106 [=================>............] - ETA: 0s - loss: 0.0167 - mae: 0.0952 - mse: 0.0167
 96/106 [==========================>...] - ETA: 0s - loss: 0.0193 - mae: 0.1003 - mse: 0.0193
106/106 [==============================] - 1s 7ms/step - loss: 0.0190 - mae: 0.0985 - mse: 0.0190 - val_loss: 0.0313 - val_mae: 0.1610 - val_mse: 0.0313
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0190 - mae: 0.1108 - mse: 0.0190
 64/106 [=================>............] - ETA: 0s - loss: 0.0156 - mae: 0.0962 - mse: 0.0156
 96/106 [==========================>...] - ETA: 0s - loss: 0.0166 - mae: 0.1003 - mse: 0.0166
106/106 [==============================] - 1s 7ms/step - loss: 0.0187 - mae: 0.1033 - mse: 0.0187 - val_loss: 0.0086 - val_mae: 0.0798 - val_mse: 0.0086
Saving trained model...
72
Testing...
heightdiff= [0.         0.         0.         8.86435318 0.         0.        ]
average prediction= [2.9555848]
baseline= 7.833333333333333
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 2.21608829498291
85 -:- nan
60 -:- nan
['train-weight-15.py', '1']
65 1
65 2
65 3
2_155_65_15_csi_a15_22.dat
65 5
65 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
2_155_65_15_csi_a15_1.dat
65 18
2_155_65_15_csi_a15_4.dat
65 20
65 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
65 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
65 41
1_165_65_15_csi_a15_12.dat
65 43
65 44
65 45
65 46
65 47
1_165_65_15_csi_a15_14.dat
65 49
65 50
1_165_65_15_csi_a15_18.dat
65 52
65 53
65 54
65 55
65 56
65 57
65 58
65 59
65 60
65 61
65 62
65 63
65 64
65 65
1_165_65_15_csi_a15_15.dat
65 67
65 68
65 69
65 70
50 71
2_165_50_15_csi_a15_10.dat
50 73
50 74
50 75
50 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
2_165_50_15_csi_a15_22.dat
50 91
50 92
50 93
2_165_50_15_csi_a15_14.dat
50 95
50 96
50 97
2_165_50_15_csi_a15_20.dat
50 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
1_175_70_15_csi_a15_28.dat
70 112
70 113
70 114
70 115
1_175_70_15_csi_a15_27.dat
70 117
70 118
70 119
1_175_70_15_csi_a15_29.dat
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
85 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
85 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
85 139
85 140
85 141
85 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
85 145
1_180_85_15_csi_a15_24.dat
85 147
85 148
85 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
85 152
85 153
85 154
1_180_85_15_csi_a15_27.dat
85 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
85 159
85 160
1_180_75_15_csi_a15_23.dat
75 162
1_180_75_15_csi_a15_17.dat
75 164
75 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
75 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
75 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
75 174
1_180_75_15_csi_a15_18.dat
75 176
1_180_75_15_csi_a15_15.dat
75 178
1_180_75_15_csi_a15_13.dat
75 180
1_180_75_15_csi_a15_3.dat
75 182
1_180_75_15_csi_a15_25.dat
75 184
75 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
75 190
85 191
1_173_85_15_csi_a15_7.dat
85 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
85 198
85 199
85 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
85 203
85 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
85 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
85 211
85 212
85 213
85 214
85 215
1_173_85_15_csi_a15_29.dat
85 217
85 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60
 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 85]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.4029 - mae: 0.5567 - mse: 0.4029
 64/106 [=================>............] - ETA: 0s - loss: 0.3515 - mae: 0.5110 - mse: 0.3515
 96/106 [==========================>...] - ETA: 0s - loss: 0.2849 - mae: 0.4504 - mse: 0.2849
106/106 [==============================] - 1s 10ms/step - loss: 0.2612 - mae: 0.4202 - mse: 0.2612 - val_loss: 0.1458 - val_mae: 0.3078 - val_mse: 0.1458
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1839 - mae: 0.3444 - mse: 0.1839
 64/106 [=================>............] - ETA: 0s - loss: 0.1764 - mae: 0.3387 - mse: 0.1764
 96/106 [==========================>...] - ETA: 0s - loss: 0.1819 - mae: 0.3469 - mse: 0.1819
106/106 [==============================] - 1s 7ms/step - loss: 0.1752 - mae: 0.3402 - mse: 0.1752 - val_loss: 0.1078 - val_mae: 0.2562 - val_mse: 0.1078
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0970 - mae: 0.2408 - mse: 0.0970
 64/106 [=================>............] - ETA: 0s - loss: 0.1094 - mae: 0.2630 - mse: 0.1094
 96/106 [==========================>...] - ETA: 0s - loss: 0.1164 - mae: 0.2723 - mse: 0.1164
106/106 [==============================] - 1s 7ms/step - loss: 0.1155 - mae: 0.2716 - mse: 0.1155 - val_loss: 0.1336 - val_mae: 0.3272 - val_mse: 0.1336
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0969 - mae: 0.2303 - mse: 0.0969
 64/106 [=================>............] - ETA: 0s - loss: 0.1060 - mae: 0.2585 - mse: 0.1060
 96/106 [==========================>...] - ETA: 0s - loss: 0.0960 - mae: 0.2473 - mse: 0.0960
106/106 [==============================] - 1s 7ms/step - loss: 0.0933 - mae: 0.2418 - mse: 0.0933 - val_loss: 0.1191 - val_mae: 0.3094 - val_mse: 0.1191
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0845 - mae: 0.2309 - mse: 0.0845
 64/106 [=================>............] - ETA: 0s - loss: 0.0785 - mae: 0.2251 - mse: 0.0785
 96/106 [==========================>...] - ETA: 0s - loss: 0.0721 - mae: 0.2189 - mse: 0.0721
106/106 [==============================] - 1s 7ms/step - loss: 0.0722 - mae: 0.2207 - mse: 0.0722 - val_loss: 0.0689 - val_mae: 0.2484 - val_mse: 0.0689
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0647 - mae: 0.2180 - mse: 0.0647
 64/106 [=================>............] - ETA: 0s - loss: 0.0748 - mae: 0.2350 - mse: 0.0748
 96/106 [==========================>...] - ETA: 0s - loss: 0.0662 - mae: 0.2184 - mse: 0.0662
106/106 [==============================] - 1s 7ms/step - loss: 0.0646 - mae: 0.2156 - mse: 0.0646 - val_loss: 0.0538 - val_mae: 0.2230 - val_mse: 0.0538
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0545 - mae: 0.1998 - mse: 0.0545
 64/106 [=================>............] - ETA: 0s - loss: 0.0469 - mae: 0.1774 - mse: 0.0469
 96/106 [==========================>...] - ETA: 0s - loss: 0.0526 - mae: 0.1880 - mse: 0.0526
106/106 [==============================] - 1s 7ms/step - loss: 0.0493 - mae: 0.1810 - mse: 0.0493 - val_loss: 0.0689 - val_mae: 0.2412 - val_mse: 0.0689
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0569 - mae: 0.2138 - mse: 0.0569
 64/106 [=================>............] - ETA: 0s - loss: 0.0520 - mae: 0.2017 - mse: 0.0520
 96/106 [==========================>...] - ETA: 0s - loss: 0.0572 - mae: 0.2076 - mse: 0.0572
106/106 [==============================] - 1s 7ms/step - loss: 0.0551 - mae: 0.2030 - mse: 0.0551 - val_loss: 0.0723 - val_mae: 0.2414 - val_mse: 0.0723
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0671 - mae: 0.2201 - mse: 0.0671
 64/106 [=================>............] - ETA: 0s - loss: 0.0539 - mae: 0.1883 - mse: 0.0539
 96/106 [==========================>...] - ETA: 0s - loss: 0.0440 - mae: 0.1704 - mse: 0.0440
106/106 [==============================] - 1s 7ms/step - loss: 0.0454 - mae: 0.1727 - mse: 0.0454 - val_loss: 0.0553 - val_mae: 0.2116 - val_mse: 0.0553
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0360 - mae: 0.1509 - mse: 0.0360
 64/106 [=================>............] - ETA: 0s - loss: 0.0382 - mae: 0.1561 - mse: 0.0382
 96/106 [==========================>...] - ETA: 0s - loss: 0.0436 - mae: 0.1682 - mse: 0.0436
106/106 [==============================] - 1s 7ms/step - loss: 0.0438 - mae: 0.1701 - mse: 0.0438 - val_loss: 0.0689 - val_mae: 0.2260 - val_mse: 0.0689
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0563 - mae: 0.1954 - mse: 0.0563
 64/106 [=================>............] - ETA: 0s - loss: 0.0445 - mae: 0.1751 - mse: 0.0445
 96/106 [==========================>...] - ETA: 0s - loss: 0.0406 - mae: 0.1662 - mse: 0.0406
106/106 [==============================] - 1s 7ms/step - loss: 0.0398 - mae: 0.1658 - mse: 0.0398 - val_loss: 0.0631 - val_mae: 0.2093 - val_mse: 0.0631
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0381 - mae: 0.1684 - mse: 0.0381
 64/106 [=================>............] - ETA: 0s - loss: 0.0332 - mae: 0.1537 - mse: 0.0332
 96/106 [==========================>...] - ETA: 0s - loss: 0.0358 - mae: 0.1565 - mse: 0.0358
106/106 [==============================] - 1s 7ms/step - loss: 0.0372 - mae: 0.1600 - mse: 0.0372 - val_loss: 0.0334 - val_mae: 0.1480 - val_mse: 0.0334
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0267 - mae: 0.1294 - mse: 0.0267
 64/106 [=================>............] - ETA: 0s - loss: 0.0352 - mae: 0.1512 - mse: 0.0352
 96/106 [==========================>...] - ETA: 0s - loss: 0.0355 - mae: 0.1521 - mse: 0.0355
106/106 [==============================] - 1s 8ms/step - loss: 0.0342 - mae: 0.1499 - mse: 0.0342 - val_loss: 0.0381 - val_mae: 0.1516 - val_mse: 0.0381
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0265 - mae: 0.1275 - mse: 0.0265
 64/106 [=================>............] - ETA: 0s - loss: 0.0248 - mae: 0.1245 - mse: 0.0248
 96/106 [==========================>...] - ETA: 0s - loss: 0.0275 - mae: 0.1312 - mse: 0.0275
106/106 [==============================] - 1s 7ms/step - loss: 0.0284 - mae: 0.1335 - mse: 0.0284 - val_loss: 0.0596 - val_mae: 0.1868 - val_mse: 0.0596
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0290 - mae: 0.1353 - mse: 0.0290
 64/106 [=================>............] - ETA: 0s - loss: 0.0258 - mae: 0.1222 - mse: 0.0258
 96/106 [==========================>...] - ETA: 0s - loss: 0.0322 - mae: 0.1385 - mse: 0.0322
106/106 [==============================] - 1s 8ms/step - loss: 0.0308 - mae: 0.1369 - mse: 0.0308 - val_loss: 0.0276 - val_mae: 0.1166 - val_mse: 0.0276
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0339 - mae: 0.1456 - mse: 0.0339
 64/106 [=================>............] - ETA: 0s - loss: 0.0322 - mae: 0.1425 - mse: 0.0322
 96/106 [==========================>...] - ETA: 0s - loss: 0.0313 - mae: 0.1359 - mse: 0.0313
106/106 [==============================] - 1s 7ms/step - loss: 0.0312 - mae: 0.1354 - mse: 0.0312 - val_loss: 0.0327 - val_mae: 0.1354 - val_mse: 0.0327
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0209 - mae: 0.1223 - mse: 0.0209
 64/106 [=================>............] - ETA: 0s - loss: 0.0279 - mae: 0.1323 - mse: 0.0279
 96/106 [==========================>...] - ETA: 0s - loss: 0.0239 - mae: 0.1201 - mse: 0.0239
106/106 [==============================] - 1s 7ms/step - loss: 0.0253 - mae: 0.1244 - mse: 0.0253 - val_loss: 0.0434 - val_mae: 0.1655 - val_mse: 0.0434
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0337 - mae: 0.1330 - mse: 0.0337
 64/106 [=================>............] - ETA: 0s - loss: 0.0277 - mae: 0.1213 - mse: 0.0277
 96/106 [==========================>...] - ETA: 0s - loss: 0.0283 - mae: 0.1247 - mse: 0.0283
106/106 [==============================] - 1s 7ms/step - loss: 0.0298 - mae: 0.1275 - mse: 0.0298 - val_loss: 0.0211 - val_mae: 0.1040 - val_mse: 0.0211
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0266 - mae: 0.1089 - mse: 0.0266
 64/106 [=================>............] - ETA: 0s - loss: 0.0313 - mae: 0.1245 - mse: 0.0313
 96/106 [==========================>...] - ETA: 0s - loss: 0.0312 - mae: 0.1320 - mse: 0.0312
106/106 [==============================] - 1s 7ms/step - loss: 0.0292 - mae: 0.1269 - mse: 0.0292 - val_loss: 0.0247 - val_mae: 0.1121 - val_mse: 0.0247
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0177 - mae: 0.1036 - mse: 0.0177
 64/106 [=================>............] - ETA: 0s - loss: 0.0216 - mae: 0.1099 - mse: 0.0216
 96/106 [==========================>...] - ETA: 0s - loss: 0.0206 - mae: 0.1077 - mse: 0.0206
106/106 [==============================] - 1s 7ms/step - loss: 0.0203 - mae: 0.1075 - mse: 0.0203 - val_loss: 0.0348 - val_mae: 0.1395 - val_mse: 0.0348
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0180 - mae: 0.0981 - mse: 0.0180
 64/106 [=================>............] - ETA: 0s - loss: 0.0225 - mae: 0.1143 - mse: 0.0225
 96/106 [==========================>...] - ETA: 0s - loss: 0.0286 - mae: 0.1253 - mse: 0.0286
106/106 [==============================] - 1s 7ms/step - loss: 0.0263 - mae: 0.1184 - mse: 0.0263 - val_loss: 0.0277 - val_mae: 0.1158 - val_mse: 0.0277
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0142 - mae: 0.0873 - mse: 0.0142
 64/106 [=================>............] - ETA: 0s - loss: 0.0170 - mae: 0.0984 - mse: 0.0170
 96/106 [==========================>...] - ETA: 0s - loss: 0.0209 - mae: 0.1103 - mse: 0.0209
106/106 [==============================] - 1s 7ms/step - loss: 0.0209 - mae: 0.1101 - mse: 0.0209 - val_loss: 0.0276 - val_mae: 0.1096 - val_mse: 0.0276
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0107 - mae: 0.0805 - mse: 0.0107
 64/106 [=================>............] - ETA: 0s - loss: 0.0177 - mae: 0.1004 - mse: 0.0177
 96/106 [==========================>...] - ETA: 0s - loss: 0.0196 - mae: 0.1058 - mse: 0.0196
106/106 [==============================] - 1s 7ms/step - loss: 0.0189 - mae: 0.1037 - mse: 0.0189 - val_loss: 0.0406 - val_mae: 0.1521 - val_mse: 0.0406
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0239 - mae: 0.1196 - mse: 0.0239
 64/106 [=================>............] - ETA: 0s - loss: 0.0187 - mae: 0.1018 - mse: 0.0187
 96/106 [==========================>...] - ETA: 0s - loss: 0.0218 - mae: 0.1099 - mse: 0.0218
106/106 [==============================] - 1s 7ms/step - loss: 0.0216 - mae: 0.1104 - mse: 0.0216 - val_loss: 0.0360 - val_mae: 0.1424 - val_mse: 0.0360
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0162 - mae: 0.0947 - mse: 0.0162
 64/106 [=================>............] - ETA: 0s - loss: 0.0170 - mae: 0.0989 - mse: 0.0170
 96/106 [==========================>...] - ETA: 0s - loss: 0.0203 - mae: 0.1077 - mse: 0.0203
106/106 [==============================] - 1s 7ms/step - loss: 0.0190 - mae: 0.1039 - mse: 0.0190 - val_loss: 0.0305 - val_mae: 0.1252 - val_mse: 0.0305
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0311 - mae: 0.1427 - mse: 0.0311
 64/106 [=================>............] - ETA: 0s - loss: 0.0272 - mae: 0.1327 - mse: 0.0272
 96/106 [==========================>...] - ETA: 0s - loss: 0.0265 - mae: 0.1288 - mse: 0.0265
106/106 [==============================] - 1s 7ms/step - loss: 0.0257 - mae: 0.1274 - mse: 0.0257 - val_loss: 0.0299 - val_mae: 0.1294 - val_mse: 0.0299
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0144 - mae: 0.0995 - mse: 0.0144
 64/106 [=================>............] - ETA: 0s - loss: 0.0202 - mae: 0.1160 - mse: 0.0202
 96/106 [==========================>...] - ETA: 0s - loss: 0.0208 - mae: 0.1177 - mse: 0.0208
106/106 [==============================] - 1s 7ms/step - loss: 0.0209 - mae: 0.1173 - mse: 0.0209 - val_loss: 0.0421 - val_mae: 0.1621 - val_mse: 0.0421
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0228 - mae: 0.1073 - mse: 0.0228
 64/106 [=================>............] - ETA: 0s - loss: 0.0219 - mae: 0.1135 - mse: 0.0219
 96/106 [==========================>...] - ETA: 0s - loss: 0.0221 - mae: 0.1123 - mse: 0.0221
106/106 [==============================] - 1s 7ms/step - loss: 0.0228 - mae: 0.1150 - mse: 0.0228 - val_loss: 0.0294 - val_mae: 0.1259 - val_mse: 0.0294
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0178 - mae: 0.1036 - mse: 0.0178
 64/106 [=================>............] - ETA: 0s - loss: 0.0193 - mae: 0.1032 - mse: 0.0193
 96/106 [==========================>...] - ETA: 0s - loss: 0.0218 - mae: 0.1106 - mse: 0.0218
106/106 [==============================] - 1s 7ms/step - loss: 0.0221 - mae: 0.1086 - mse: 0.0221 - val_loss: 0.0422 - val_mae: 0.1538 - val_mse: 0.0422
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0190 - mae: 0.1115 - mse: 0.0190
 64/106 [=================>............] - ETA: 0s - loss: 0.0175 - mae: 0.1007 - mse: 0.0175
 96/106 [==========================>...] - ETA: 0s - loss: 0.0208 - mae: 0.1055 - mse: 0.0208
106/106 [==============================] - 1s 7ms/step - loss: 0.0195 - mae: 0.1008 - mse: 0.0195 - val_loss: 0.0290 - val_mae: 0.1176 - val_mse: 0.0290
Saving trained model...
72
Testing...
heightdiff= [ 0.         0.         0.        11.0292778  0.         0.       ]
average prediction= [3.4589264]
baseline= 8.0
eachuser= [0. 0. 0. 6. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.8382129669189453
85 -:- nan
60 -:- nan
['train-weight-15.py', '1']
65 1
65 2
65 3
2_155_65_15_csi_a15_22.dat
65 5
65 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
2_155_65_15_csi_a15_1.dat
65 18
2_155_65_15_csi_a15_4.dat
65 20
65 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
65 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
65 41
1_165_65_15_csi_a15_12.dat
65 43
65 44
65 45
65 46
65 47
1_165_65_15_csi_a15_14.dat
65 49
65 50
1_165_65_15_csi_a15_18.dat
65 52
65 53
65 54
65 55
65 56
65 57
65 58
65 59
65 60
65 61
65 62
65 63
65 64
65 65
1_165_65_15_csi_a15_15.dat
65 67
65 68
65 69
65 70
50 71
2_165_50_15_csi_a15_10.dat
50 73
50 74
50 75
50 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
2_165_50_15_csi_a15_22.dat
50 91
50 92
50 93
2_165_50_15_csi_a15_14.dat
50 95
50 96
50 97
2_165_50_15_csi_a15_20.dat
50 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
1_175_70_15_csi_a15_28.dat
70 112
70 113
70 114
70 115
1_175_70_15_csi_a15_27.dat
70 117
70 118
70 119
1_175_70_15_csi_a15_29.dat
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
85 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
85 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
85 139
85 140
85 141
85 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
85 145
1_180_85_15_csi_a15_24.dat
85 147
85 148
85 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
85 152
85 153
85 154
1_180_85_15_csi_a15_27.dat
85 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
85 159
85 160
1_180_75_15_csi_a15_23.dat
75 162
1_180_75_15_csi_a15_17.dat
75 164
75 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
75 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
75 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
75 174
1_180_75_15_csi_a15_18.dat
75 176
1_180_75_15_csi_a15_15.dat
75 178
1_180_75_15_csi_a15_13.dat
75 180
1_180_75_15_csi_a15_3.dat
75 182
1_180_75_15_csi_a15_25.dat
75 184
75 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
75 190
85 191
1_173_85_15_csi_a15_7.dat
85 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
85 198
85 199
85 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
85 203
85 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
85 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
85 211
85 212
85 213
85 214
85 215
1_173_85_15_csi_a15_29.dat
85 217
85 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60
 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 85]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.3267 - mae: 0.4937 - mse: 0.3267
 64/106 [=================>............] - ETA: 0s - loss: 0.2881 - mae: 0.4643 - mse: 0.2881
 96/106 [==========================>...] - ETA: 0s - loss: 0.2426 - mae: 0.4108 - mse: 0.2426
106/106 [==============================] - 1s 10ms/step - loss: 0.2271 - mae: 0.3899 - mse: 0.2271 - val_loss: 0.1004 - val_mae: 0.2566 - val_mse: 0.1004
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1462 - mae: 0.3125 - mse: 0.1462
 64/106 [=================>............] - ETA: 0s - loss: 0.1403 - mae: 0.3130 - mse: 0.1403
 96/106 [==========================>...] - ETA: 0s - loss: 0.1274 - mae: 0.2961 - mse: 0.1274
106/106 [==============================] - 1s 7ms/step - loss: 0.1318 - mae: 0.3035 - mse: 0.1318 - val_loss: 0.0712 - val_mae: 0.2203 - val_mse: 0.0712
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0756 - mae: 0.2377 - mse: 0.0756
 64/106 [=================>............] - ETA: 0s - loss: 0.0833 - mae: 0.2437 - mse: 0.0833
 96/106 [==========================>...] - ETA: 0s - loss: 0.0785 - mae: 0.2373 - mse: 0.0785
106/106 [==============================] - 1s 7ms/step - loss: 0.0768 - mae: 0.2345 - mse: 0.0768 - val_loss: 0.1055 - val_mae: 0.2860 - val_mse: 0.1055
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0684 - mae: 0.2070 - mse: 0.0684
 64/106 [=================>............] - ETA: 0s - loss: 0.0651 - mae: 0.2073 - mse: 0.0651
 96/106 [==========================>...] - ETA: 0s - loss: 0.0743 - mae: 0.2210 - mse: 0.0743
106/106 [==============================] - 1s 7ms/step - loss: 0.0725 - mae: 0.2209 - mse: 0.0725 - val_loss: 0.1066 - val_mae: 0.2906 - val_mse: 0.1066
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0658 - mae: 0.2211 - mse: 0.0658
 64/106 [=================>............] - ETA: 0s - loss: 0.0614 - mae: 0.2109 - mse: 0.0614
 96/106 [==========================>...] - ETA: 0s - loss: 0.0523 - mae: 0.1879 - mse: 0.0523
106/106 [==============================] - 1s 7ms/step - loss: 0.0518 - mae: 0.1879 - mse: 0.0518 - val_loss: 0.0654 - val_mae: 0.2454 - val_mse: 0.0654
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0449 - mae: 0.1939 - mse: 0.0449
 64/106 [=================>............] - ETA: 0s - loss: 0.0500 - mae: 0.2002 - mse: 0.0500
 96/106 [==========================>...] - ETA: 0s - loss: 0.0444 - mae: 0.1843 - mse: 0.0444
106/106 [==============================] - 1s 7ms/step - loss: 0.0434 - mae: 0.1805 - mse: 0.0434 - val_loss: 0.0401 - val_mae: 0.1943 - val_mse: 0.0401
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0410 - mae: 0.1714 - mse: 0.0410
 64/106 [=================>............] - ETA: 0s - loss: 0.0376 - mae: 0.1626 - mse: 0.0376
 96/106 [==========================>...] - ETA: 0s - loss: 0.0344 - mae: 0.1538 - mse: 0.0344
106/106 [==============================] - 1s 7ms/step - loss: 0.0364 - mae: 0.1571 - mse: 0.0364 - val_loss: 0.0472 - val_mae: 0.1996 - val_mse: 0.0472
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0335 - mae: 0.1566 - mse: 0.0335
 64/106 [=================>............] - ETA: 0s - loss: 0.0380 - mae: 0.1667 - mse: 0.0380
 96/106 [==========================>...] - ETA: 0s - loss: 0.0423 - mae: 0.1693 - mse: 0.0423
106/106 [==============================] - 1s 7ms/step - loss: 0.0408 - mae: 0.1665 - mse: 0.0408 - val_loss: 0.0632 - val_mae: 0.2181 - val_mse: 0.0632
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0367 - mae: 0.1573 - mse: 0.0367
 64/106 [=================>............] - ETA: 0s - loss: 0.0383 - mae: 0.1508 - mse: 0.0383
 96/106 [==========================>...] - ETA: 0s - loss: 0.0342 - mae: 0.1421 - mse: 0.0342
106/106 [==============================] - 1s 7ms/step - loss: 0.0350 - mae: 0.1453 - mse: 0.0350 - val_loss: 0.0271 - val_mae: 0.1374 - val_mse: 0.0271
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0243 - mae: 0.1156 - mse: 0.0243
 64/106 [=================>............] - ETA: 0s - loss: 0.0322 - mae: 0.1403 - mse: 0.0322
 96/106 [==========================>...] - ETA: 0s - loss: 0.0306 - mae: 0.1378 - mse: 0.0306
106/106 [==============================] - 1s 7ms/step - loss: 0.0294 - mae: 0.1366 - mse: 0.0294 - val_loss: 0.0160 - val_mae: 0.0949 - val_mse: 0.0160
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0240 - mae: 0.1350 - mse: 0.0240
 64/106 [=================>............] - ETA: 0s - loss: 0.0327 - mae: 0.1484 - mse: 0.0327
 96/106 [==========================>...] - ETA: 0s - loss: 0.0279 - mae: 0.1359 - mse: 0.0279
106/106 [==============================] - 1s 7ms/step - loss: 0.0277 - mae: 0.1358 - mse: 0.0277 - val_loss: 0.0313 - val_mae: 0.1433 - val_mse: 0.0313
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0316 - mae: 0.1331 - mse: 0.0316
 64/106 [=================>............] - ETA: 0s - loss: 0.0220 - mae: 0.1113 - mse: 0.0220
 96/106 [==========================>...] - ETA: 0s - loss: 0.0222 - mae: 0.1165 - mse: 0.0222
106/106 [==============================] - 1s 7ms/step - loss: 0.0219 - mae: 0.1159 - mse: 0.0219 - val_loss: 0.0285 - val_mae: 0.1417 - val_mse: 0.0285
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0163 - mae: 0.1003 - mse: 0.0163
 64/106 [=================>............] - ETA: 0s - loss: 0.0154 - mae: 0.1006 - mse: 0.0154
 96/106 [==========================>...] - ETA: 0s - loss: 0.0204 - mae: 0.1096 - mse: 0.0204
106/106 [==============================] - 1s 7ms/step - loss: 0.0243 - mae: 0.1161 - mse: 0.0243 - val_loss: 0.0237 - val_mae: 0.1294 - val_mse: 0.0237
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0222 - mae: 0.1161 - mse: 0.0222
 64/106 [=================>............] - ETA: 0s - loss: 0.0265 - mae: 0.1294 - mse: 0.0265
 96/106 [==========================>...] - ETA: 0s - loss: 0.0216 - mae: 0.1156 - mse: 0.0216
106/106 [==============================] - 1s 7ms/step - loss: 0.0224 - mae: 0.1162 - mse: 0.0224 - val_loss: 0.0325 - val_mae: 0.1538 - val_mse: 0.0325
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0230 - mae: 0.1194 - mse: 0.0230
 64/106 [=================>............] - ETA: 0s - loss: 0.0241 - mae: 0.1172 - mse: 0.0241
 96/106 [==========================>...] - ETA: 0s - loss: 0.0221 - mae: 0.1116 - mse: 0.0221
106/106 [==============================] - 1s 7ms/step - loss: 0.0215 - mae: 0.1099 - mse: 0.0215 - val_loss: 0.0228 - val_mae: 0.1292 - val_mse: 0.0228
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0168 - mae: 0.0982 - mse: 0.0168
 64/106 [=================>............] - ETA: 0s - loss: 0.0216 - mae: 0.1141 - mse: 0.0216
 96/106 [==========================>...] - ETA: 0s - loss: 0.0201 - mae: 0.1114 - mse: 0.0201
106/106 [==============================] - 1s 7ms/step - loss: 0.0224 - mae: 0.1162 - mse: 0.0224 - val_loss: 0.0226 - val_mae: 0.1292 - val_mse: 0.0226
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0325 - mae: 0.1408 - mse: 0.0325
 64/106 [=================>............] - ETA: 0s - loss: 0.0228 - mae: 0.1180 - mse: 0.0228
 96/106 [==========================>...] - ETA: 0s - loss: 0.0232 - mae: 0.1148 - mse: 0.0232
106/106 [==============================] - 1s 7ms/step - loss: 0.0237 - mae: 0.1157 - mse: 0.0237 - val_loss: 0.0239 - val_mae: 0.1326 - val_mse: 0.0239
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0279 - mae: 0.1153 - mse: 0.0279
 64/106 [=================>............] - ETA: 0s - loss: 0.0259 - mae: 0.1170 - mse: 0.0259
 96/106 [==========================>...] - ETA: 0s - loss: 0.0223 - mae: 0.1071 - mse: 0.0223
106/106 [==============================] - 1s 7ms/step - loss: 0.0213 - mae: 0.1071 - mse: 0.0213 - val_loss: 0.0271 - val_mae: 0.1416 - val_mse: 0.0271
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0156 - mae: 0.0908 - mse: 0.0156
 64/106 [=================>............] - ETA: 0s - loss: 0.0208 - mae: 0.1053 - mse: 0.0208
 96/106 [==========================>...] - ETA: 0s - loss: 0.0233 - mae: 0.1149 - mse: 0.0233
106/106 [==============================] - 1s 7ms/step - loss: 0.0233 - mae: 0.1161 - mse: 0.0233 - val_loss: 0.0243 - val_mae: 0.1323 - val_mse: 0.0243
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0154 - mae: 0.0993 - mse: 0.0154
 64/106 [=================>............] - ETA: 0s - loss: 0.0167 - mae: 0.1013 - mse: 0.0167
 96/106 [==========================>...] - ETA: 0s - loss: 0.0172 - mae: 0.1026 - mse: 0.0172
106/106 [==============================] - 1s 7ms/step - loss: 0.0188 - mae: 0.1059 - mse: 0.0188 - val_loss: 0.0168 - val_mae: 0.1094 - val_mse: 0.0168
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0147 - mae: 0.0923 - mse: 0.0147
 64/106 [=================>............] - ETA: 0s - loss: 0.0167 - mae: 0.0996 - mse: 0.0167
 96/106 [==========================>...] - ETA: 0s - loss: 0.0196 - mae: 0.1067 - mse: 0.0196
106/106 [==============================] - 1s 7ms/step - loss: 0.0197 - mae: 0.1066 - mse: 0.0197 - val_loss: 0.0189 - val_mae: 0.1174 - val_mse: 0.0189
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0162 - mae: 0.0979 - mse: 0.0162
 64/106 [=================>............] - ETA: 0s - loss: 0.0136 - mae: 0.0892 - mse: 0.0136
 96/106 [==========================>...] - ETA: 0s - loss: 0.0179 - mae: 0.0958 - mse: 0.0179
106/106 [==============================] - 1s 7ms/step - loss: 0.0195 - mae: 0.0984 - mse: 0.0195 - val_loss: 0.0243 - val_mae: 0.1319 - val_mse: 0.0243
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0169 - mae: 0.0922 - mse: 0.0169
 64/106 [=================>............] - ETA: 0s - loss: 0.0147 - mae: 0.0898 - mse: 0.0147
 96/106 [==========================>...] - ETA: 0s - loss: 0.0146 - mae: 0.0901 - mse: 0.0146
106/106 [==============================] - 1s 7ms/step - loss: 0.0137 - mae: 0.0871 - mse: 0.0137 - val_loss: 0.0133 - val_mae: 0.0873 - val_mse: 0.0133
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0171 - mae: 0.0938 - mse: 0.0171
 64/106 [=================>............] - ETA: 0s - loss: 0.0179 - mae: 0.0954 - mse: 0.0179
 96/106 [==========================>...] - ETA: 0s - loss: 0.0167 - mae: 0.0926 - mse: 0.0167
106/106 [==============================] - 1s 7ms/step - loss: 0.0208 - mae: 0.1027 - mse: 0.0208 - val_loss: 0.0240 - val_mae: 0.1277 - val_mse: 0.0240
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0293 - mae: 0.1218 - mse: 0.0293
 64/106 [=================>............] - ETA: 0s - loss: 0.0225 - mae: 0.1113 - mse: 0.0225
 96/106 [==========================>...] - ETA: 0s - loss: 0.0190 - mae: 0.1024 - mse: 0.0190
106/106 [==============================] - 1s 7ms/step - loss: 0.0200 - mae: 0.1068 - mse: 0.0200 - val_loss: 0.0217 - val_mae: 0.1273 - val_mse: 0.0217
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0096 - mae: 0.0726 - mse: 0.0096
 64/106 [=================>............] - ETA: 0s - loss: 0.0120 - mae: 0.0830 - mse: 0.0120
 96/106 [==========================>...] - ETA: 0s - loss: 0.0144 - mae: 0.0886 - mse: 0.0144
106/106 [==============================] - 1s 7ms/step - loss: 0.0137 - mae: 0.0867 - mse: 0.0137 - val_loss: 0.0188 - val_mae: 0.1201 - val_mse: 0.0188
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0210 - mae: 0.0969 - mse: 0.0210
 64/106 [=================>............] - ETA: 0s - loss: 0.0178 - mae: 0.0958 - mse: 0.0178
 96/106 [==========================>...] - ETA: 0s - loss: 0.0180 - mae: 0.0973 - mse: 0.0180
106/106 [==============================] - 1s 7ms/step - loss: 0.0176 - mae: 0.0952 - mse: 0.0176 - val_loss: 0.0259 - val_mae: 0.1386 - val_mse: 0.0259
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0107 - mae: 0.0888 - mse: 0.0107
 64/106 [=================>............] - ETA: 0s - loss: 0.0132 - mae: 0.0929 - mse: 0.0132
 96/106 [==========================>...] - ETA: 0s - loss: 0.0170 - mae: 0.1001 - mse: 0.0170
106/106 [==============================] - 1s 7ms/step - loss: 0.0163 - mae: 0.0987 - mse: 0.0163 - val_loss: 0.0158 - val_mae: 0.1036 - val_mse: 0.0158
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0167 - mae: 0.0950 - mse: 0.0167
 64/106 [=================>............] - ETA: 0s - loss: 0.0142 - mae: 0.0891 - mse: 0.0142
 96/106 [==========================>...] - ETA: 0s - loss: 0.0155 - mae: 0.0932 - mse: 0.0155
106/106 [==============================] - 1s 7ms/step - loss: 0.0147 - mae: 0.0911 - mse: 0.0147 - val_loss: 0.0110 - val_mae: 0.0848 - val_mse: 0.0110
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0120 - mae: 0.0876 - mse: 0.0120
 64/106 [=================>............] - ETA: 0s - loss: 0.0142 - mae: 0.0946 - mse: 0.0142
 96/106 [==========================>...] - ETA: 0s - loss: 0.0147 - mae: 0.0934 - mse: 0.0147
106/106 [==============================] - 1s 7ms/step - loss: 0.0154 - mae: 0.0933 - mse: 0.0154 - val_loss: 0.0296 - val_mae: 0.1480 - val_mse: 0.0296
Saving trained model...
72
Testing...
heightdiff= [ 0.          0.          0.         10.27614975  0.          0.        ]
average prediction= [6.1824217]
baseline= 9.666666666666666
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 2.0552299499511717
85 -:- nan
60 -:- nan
['train-weight-15.py', '1']
65 1
65 2
65 3
2_155_65_15_csi_a15_22.dat
65 5
65 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
2_155_65_15_csi_a15_1.dat
65 18
2_155_65_15_csi_a15_4.dat
65 20
65 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
65 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
65 41
1_165_65_15_csi_a15_12.dat
65 43
65 44
65 45
65 46
65 47
1_165_65_15_csi_a15_14.dat
65 49
65 50
1_165_65_15_csi_a15_18.dat
65 52
65 53
65 54
65 55
65 56
65 57
65 58
65 59
65 60
65 61
65 62
65 63
65 64
65 65
1_165_65_15_csi_a15_15.dat
65 67
65 68
65 69
65 70
50 71
2_165_50_15_csi_a15_10.dat
50 73
50 74
50 75
50 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
2_165_50_15_csi_a15_22.dat
50 91
50 92
50 93
2_165_50_15_csi_a15_14.dat
50 95
50 96
50 97
2_165_50_15_csi_a15_20.dat
50 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
1_175_70_15_csi_a15_28.dat
70 112
70 113
70 114
70 115
1_175_70_15_csi_a15_27.dat
70 117
70 118
70 119
1_175_70_15_csi_a15_29.dat
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
85 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
85 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
85 139
85 140
85 141
85 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
85 145
1_180_85_15_csi_a15_24.dat
85 147
85 148
85 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
85 152
85 153
85 154
1_180_85_15_csi_a15_27.dat
85 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
85 159
85 160
1_180_75_15_csi_a15_23.dat
75 162
1_180_75_15_csi_a15_17.dat
75 164
75 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
75 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
75 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
75 174
1_180_75_15_csi_a15_18.dat
75 176
1_180_75_15_csi_a15_15.dat
75 178
1_180_75_15_csi_a15_13.dat
75 180
1_180_75_15_csi_a15_3.dat
75 182
1_180_75_15_csi_a15_25.dat
75 184
75 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
75 190
85 191
1_173_85_15_csi_a15_7.dat
85 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
85 198
85 199
85 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
85 203
85 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
85 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
85 211
85 212
85 213
85 214
85 215
1_173_85_15_csi_a15_29.dat
85 217
85 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60
 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 85]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.2750 - mae: 0.4597 - mse: 0.2750
 64/106 [=================>............] - ETA: 0s - loss: 0.2350 - mae: 0.4200 - mse: 0.2350
 96/106 [==========================>...] - ETA: 0s - loss: 0.1933 - mae: 0.3708 - mse: 0.1933
106/106 [==============================] - 1s 10ms/step - loss: 0.1857 - mae: 0.3632 - mse: 0.1857 - val_loss: 0.0723 - val_mae: 0.2453 - val_mse: 0.0723
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1423 - mae: 0.3155 - mse: 0.1423
 64/106 [=================>............] - ETA: 0s - loss: 0.1144 - mae: 0.2885 - mse: 0.1144
 96/106 [==========================>...] - ETA: 0s - loss: 0.1092 - mae: 0.2743 - mse: 0.1092
106/106 [==============================] - 1s 7ms/step - loss: 0.1068 - mae: 0.2719 - mse: 0.1068 - val_loss: 0.0751 - val_mae: 0.2205 - val_mse: 0.0751
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0586 - mae: 0.1942 - mse: 0.0586
 64/106 [=================>............] - ETA: 0s - loss: 0.0634 - mae: 0.2044 - mse: 0.0634
 96/106 [==========================>...] - ETA: 0s - loss: 0.0645 - mae: 0.2051 - mse: 0.0645
106/106 [==============================] - 1s 7ms/step - loss: 0.0681 - mae: 0.2094 - mse: 0.0681 - val_loss: 0.0881 - val_mae: 0.2435 - val_mse: 0.0881
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0499 - mae: 0.1749 - mse: 0.0499
 64/106 [=================>............] - ETA: 0s - loss: 0.0561 - mae: 0.1892 - mse: 0.0561
 96/106 [==========================>...] - ETA: 0s - loss: 0.0556 - mae: 0.1875 - mse: 0.0556
106/106 [==============================] - 1s 7ms/step - loss: 0.0570 - mae: 0.1923 - mse: 0.0570 - val_loss: 0.0480 - val_mae: 0.1805 - val_mse: 0.0480
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0535 - mae: 0.2048 - mse: 0.0535
 64/106 [=================>............] - ETA: 0s - loss: 0.0399 - mae: 0.1697 - mse: 0.0399
 96/106 [==========================>...] - ETA: 0s - loss: 0.0492 - mae: 0.1856 - mse: 0.0492
106/106 [==============================] - 1s 7ms/step - loss: 0.0473 - mae: 0.1795 - mse: 0.0473 - val_loss: 0.0357 - val_mae: 0.1556 - val_mse: 0.0357
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0384 - mae: 0.1645 - mse: 0.0384
 64/106 [=================>............] - ETA: 0s - loss: 0.0398 - mae: 0.1679 - mse: 0.0398
 96/106 [==========================>...] - ETA: 0s - loss: 0.0402 - mae: 0.1617 - mse: 0.0402
106/106 [==============================] - 1s 7ms/step - loss: 0.0384 - mae: 0.1565 - mse: 0.0384 - val_loss: 0.0510 - val_mae: 0.1937 - val_mse: 0.0510
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0372 - mae: 0.1559 - mse: 0.0372
 64/106 [=================>............] - ETA: 0s - loss: 0.0409 - mae: 0.1653 - mse: 0.0409
 96/106 [==========================>...] - ETA: 0s - loss: 0.0422 - mae: 0.1697 - mse: 0.0422
106/106 [==============================] - 1s 7ms/step - loss: 0.0395 - mae: 0.1615 - mse: 0.0395 - val_loss: 0.0414 - val_mae: 0.1810 - val_mse: 0.0414
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0368 - mae: 0.1372 - mse: 0.0368
 64/106 [=================>............] - ETA: 0s - loss: 0.0391 - mae: 0.1380 - mse: 0.0391
 96/106 [==========================>...] - ETA: 0s - loss: 0.0349 - mae: 0.1334 - mse: 0.0349
106/106 [==============================] - 1s 7ms/step - loss: 0.0348 - mae: 0.1352 - mse: 0.0348 - val_loss: 0.0271 - val_mae: 0.1396 - val_mse: 0.0271
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0414 - mae: 0.1424 - mse: 0.0414
 64/106 [=================>............] - ETA: 0s - loss: 0.0362 - mae: 0.1362 - mse: 0.0362
 96/106 [==========================>...] - ETA: 0s - loss: 0.0352 - mae: 0.1399 - mse: 0.0352
106/106 [==============================] - 1s 7ms/step - loss: 0.0353 - mae: 0.1392 - mse: 0.0353 - val_loss: 0.0523 - val_mae: 0.2020 - val_mse: 0.0523
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0271 - mae: 0.1424 - mse: 0.0271
 64/106 [=================>............] - ETA: 0s - loss: 0.0412 - mae: 0.1663 - mse: 0.0412
 96/106 [==========================>...] - ETA: 0s - loss: 0.0408 - mae: 0.1618 - mse: 0.0408
106/106 [==============================] - 1s 7ms/step - loss: 0.0393 - mae: 0.1581 - mse: 0.0393 - val_loss: 0.0485 - val_mae: 0.1887 - val_mse: 0.0485
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0362 - mae: 0.1460 - mse: 0.0362
 64/106 [=================>............] - ETA: 0s - loss: 0.0394 - mae: 0.1439 - mse: 0.0394
 96/106 [==========================>...] - ETA: 0s - loss: 0.0341 - mae: 0.1364 - mse: 0.0341
106/106 [==============================] - 1s 7ms/step - loss: 0.0342 - mae: 0.1387 - mse: 0.0342 - val_loss: 0.0303 - val_mae: 0.1437 - val_mse: 0.0303
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0472 - mae: 0.1540 - mse: 0.0472
 64/106 [=================>............] - ETA: 0s - loss: 0.0377 - mae: 0.1432 - mse: 0.0377
 96/106 [==========================>...] - ETA: 0s - loss: 0.0301 - mae: 0.1292 - mse: 0.0301
106/106 [==============================] - 1s 7ms/step - loss: 0.0287 - mae: 0.1263 - mse: 0.0287 - val_loss: 0.0424 - val_mae: 0.1713 - val_mse: 0.0424
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0449 - mae: 0.1620 - mse: 0.0449
 64/106 [=================>............] - ETA: 0s - loss: 0.0372 - mae: 0.1486 - mse: 0.0372
 96/106 [==========================>...] - ETA: 0s - loss: 0.0311 - mae: 0.1331 - mse: 0.0311
106/106 [==============================] - 1s 7ms/step - loss: 0.0311 - mae: 0.1317 - mse: 0.0311 - val_loss: 0.0257 - val_mae: 0.1238 - val_mse: 0.0257
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0224 - mae: 0.1156 - mse: 0.0224
 64/106 [=================>............] - ETA: 0s - loss: 0.0258 - mae: 0.1269 - mse: 0.0258
 96/106 [==========================>...] - ETA: 0s - loss: 0.0336 - mae: 0.1369 - mse: 0.0336
106/106 [==============================] - 1s 7ms/step - loss: 0.0325 - mae: 0.1361 - mse: 0.0325 - val_loss: 0.0262 - val_mae: 0.1239 - val_mse: 0.0262
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0309 - mae: 0.1366 - mse: 0.0309
 64/106 [=================>............] - ETA: 0s - loss: 0.0297 - mae: 0.1351 - mse: 0.0297
 96/106 [==========================>...] - ETA: 0s - loss: 0.0299 - mae: 0.1356 - mse: 0.0299
106/106 [==============================] - 1s 7ms/step - loss: 0.0329 - mae: 0.1415 - mse: 0.0329 - val_loss: 0.0400 - val_mae: 0.1624 - val_mse: 0.0400
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0339 - mae: 0.1353 - mse: 0.0339
 64/106 [=================>............] - ETA: 0s - loss: 0.0266 - mae: 0.1256 - mse: 0.0266
 96/106 [==========================>...] - ETA: 0s - loss: 0.0286 - mae: 0.1279 - mse: 0.0286
106/106 [==============================] - 1s 7ms/step - loss: 0.0267 - mae: 0.1230 - mse: 0.0267 - val_loss: 0.0215 - val_mae: 0.1143 - val_mse: 0.0215
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0278 - mae: 0.1295 - mse: 0.0278
 64/106 [=================>............] - ETA: 0s - loss: 0.0243 - mae: 0.1203 - mse: 0.0243
 96/106 [==========================>...] - ETA: 0s - loss: 0.0238 - mae: 0.1173 - mse: 0.0238
106/106 [==============================] - 1s 7ms/step - loss: 0.0243 - mae: 0.1187 - mse: 0.0243 - val_loss: 0.0250 - val_mae: 0.1290 - val_mse: 0.0250
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0220 - mae: 0.1170 - mse: 0.0220
 64/106 [=================>............] - ETA: 0s - loss: 0.0237 - mae: 0.1258 - mse: 0.0237
 96/106 [==========================>...] - ETA: 0s - loss: 0.0217 - mae: 0.1201 - mse: 0.0217
106/106 [==============================] - 1s 7ms/step - loss: 0.0209 - mae: 0.1183 - mse: 0.0209 - val_loss: 0.0268 - val_mae: 0.1346 - val_mse: 0.0268
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0225 - mae: 0.1201 - mse: 0.0225
 64/106 [=================>............] - ETA: 0s - loss: 0.0294 - mae: 0.1291 - mse: 0.0294
 96/106 [==========================>...] - ETA: 0s - loss: 0.0241 - mae: 0.1163 - mse: 0.0241
106/106 [==============================] - 1s 7ms/step - loss: 0.0238 - mae: 0.1168 - mse: 0.0238 - val_loss: 0.0178 - val_mae: 0.1020 - val_mse: 0.0178
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0169 - mae: 0.1069 - mse: 0.0169
 64/106 [=================>............] - ETA: 0s - loss: 0.0250 - mae: 0.1283 - mse: 0.0250
 96/106 [==========================>...] - ETA: 0s - loss: 0.0260 - mae: 0.1280 - mse: 0.0260
106/106 [==============================] - 1s 7ms/step - loss: 0.0258 - mae: 0.1261 - mse: 0.0258 - val_loss: 0.0209 - val_mae: 0.1171 - val_mse: 0.0209
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0257 - mae: 0.1234 - mse: 0.0257
 64/106 [=================>............] - ETA: 0s - loss: 0.0300 - mae: 0.1248 - mse: 0.0300
 96/106 [==========================>...] - ETA: 0s - loss: 0.0260 - mae: 0.1169 - mse: 0.0260
106/106 [==============================] - 1s 7ms/step - loss: 0.0247 - mae: 0.1135 - mse: 0.0247 - val_loss: 0.0347 - val_mae: 0.1543 - val_mse: 0.0347
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0416 - mae: 0.1327 - mse: 0.0416
 64/106 [=================>............] - ETA: 0s - loss: 0.0303 - mae: 0.1191 - mse: 0.0303
 96/106 [==========================>...] - ETA: 0s - loss: 0.0264 - mae: 0.1142 - mse: 0.0264
106/106 [==============================] - 1s 7ms/step - loss: 0.0268 - mae: 0.1153 - mse: 0.0268 - val_loss: 0.0187 - val_mae: 0.1062 - val_mse: 0.0187
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0205 - mae: 0.1130 - mse: 0.0205
 64/106 [=================>............] - ETA: 0s - loss: 0.0215 - mae: 0.1104 - mse: 0.0215
 96/106 [==========================>...] - ETA: 0s - loss: 0.0232 - mae: 0.1156 - mse: 0.0232
106/106 [==============================] - 1s 7ms/step - loss: 0.0216 - mae: 0.1104 - mse: 0.0216 - val_loss: 0.0220 - val_mae: 0.1183 - val_mse: 0.0220
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0140 - mae: 0.0926 - mse: 0.0140
 64/106 [=================>............] - ETA: 0s - loss: 0.0119 - mae: 0.0853 - mse: 0.0119
 96/106 [==========================>...] - ETA: 0s - loss: 0.0140 - mae: 0.0956 - mse: 0.0140
106/106 [==============================] - 1s 7ms/step - loss: 0.0141 - mae: 0.0961 - mse: 0.0141 - val_loss: 0.0228 - val_mae: 0.1196 - val_mse: 0.0228
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0106 - mae: 0.0778 - mse: 0.0106
 64/106 [=================>............] - ETA: 0s - loss: 0.0166 - mae: 0.0868 - mse: 0.0166
 96/106 [==========================>...] - ETA: 0s - loss: 0.0163 - mae: 0.0915 - mse: 0.0163
106/106 [==============================] - 1s 7ms/step - loss: 0.0152 - mae: 0.0879 - mse: 0.0152 - val_loss: 0.0223 - val_mae: 0.1183 - val_mse: 0.0223
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0153 - mae: 0.0999 - mse: 0.0153
 64/106 [=================>............] - ETA: 0s - loss: 0.0203 - mae: 0.1131 - mse: 0.0203
 96/106 [==========================>...] - ETA: 0s - loss: 0.0200 - mae: 0.1121 - mse: 0.0200
106/106 [==============================] - 1s 7ms/step - loss: 0.0202 - mae: 0.1111 - mse: 0.0202 - val_loss: 0.0230 - val_mae: 0.1219 - val_mse: 0.0230
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0287 - mae: 0.1254 - mse: 0.0287
 64/106 [=================>............] - ETA: 0s - loss: 0.0239 - mae: 0.1136 - mse: 0.0239
 96/106 [==========================>...] - ETA: 0s - loss: 0.0216 - mae: 0.1083 - mse: 0.0216
106/106 [==============================] - 1s 7ms/step - loss: 0.0210 - mae: 0.1069 - mse: 0.0210 - val_loss: 0.0246 - val_mae: 0.1299 - val_mse: 0.0246
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0247 - mae: 0.1211 - mse: 0.0247
 64/106 [=================>............] - ETA: 0s - loss: 0.0210 - mae: 0.1033 - mse: 0.0210
 96/106 [==========================>...] - ETA: 0s - loss: 0.0197 - mae: 0.1030 - mse: 0.0197
106/106 [==============================] - 1s 7ms/step - loss: 0.0187 - mae: 0.1008 - mse: 0.0187 - val_loss: 0.0165 - val_mae: 0.1046 - val_mse: 0.0165
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0207 - mae: 0.0961 - mse: 0.0207
 64/106 [=================>............] - ETA: 0s - loss: 0.0171 - mae: 0.0922 - mse: 0.0171
 96/106 [==========================>...] - ETA: 0s - loss: 0.0166 - mae: 0.0954 - mse: 0.0166
106/106 [==============================] - 1s 7ms/step - loss: 0.0161 - mae: 0.0949 - mse: 0.0161 - val_loss: 0.0234 - val_mae: 0.1288 - val_mse: 0.0234
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0146 - mae: 0.0772 - mse: 0.0146
 64/106 [=================>............] - ETA: 0s - loss: 0.0171 - mae: 0.0878 - mse: 0.0171
 96/106 [==========================>...] - ETA: 0s - loss: 0.0157 - mae: 0.0885 - mse: 0.0157
106/106 [==============================] - 1s 7ms/step - loss: 0.0160 - mae: 0.0912 - mse: 0.0160 - val_loss: 0.0236 - val_mae: 0.1299 - val_mse: 0.0236
Saving trained model...
72
Testing...
heightdiff= [0.         0.         0.         1.89525986 0.         0.        ]
average prediction= [5.3761168]
baseline= 9.166666666666666
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.4738149642944336
85 -:- nan
60 -:- nan
['train-weight-15.py', '1']
65 1
65 2
65 3
2_155_65_15_csi_a15_22.dat
65 5
65 6
2_155_65_15_csi_a15_6.dat
2_155_65_15_csi_a15_10.dat
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
2_155_65_15_csi_a15_1.dat
65 18
2_155_65_15_csi_a15_4.dat
65 20
65 21
2_155_65_15_csi_a15_26.dat
2_155_65_15_csi_a15_13.dat
2_155_65_15_csi_a15_11.dat
65 25
2_155_65_15_csi_a15_15.dat
2_155_65_15_csi_a15_8.dat
2_155_65_15_csi_a15_23.dat
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
65 41
1_165_65_15_csi_a15_12.dat
65 43
65 44
65 45
65 46
65 47
1_165_65_15_csi_a15_14.dat
65 49
65 50
1_165_65_15_csi_a15_18.dat
65 52
65 53
65 54
65 55
65 56
65 57
65 58
65 59
65 60
65 61
65 62
65 63
65 64
65 65
1_165_65_15_csi_a15_15.dat
65 67
65 68
65 69
65 70
50 71
2_165_50_15_csi_a15_10.dat
50 73
50 74
50 75
50 76
2_165_50_15_csi_a15_6.dat
2_165_50_15_csi_a15_30.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
2_165_50_15_csi_a15_22.dat
50 91
50 92
50 93
2_165_50_15_csi_a15_14.dat
50 95
50 96
50 97
2_165_50_15_csi_a15_20.dat
50 99
2_165_50_15_csi_a15_13.dat
1_175_70_15_csi_a15_30.dat
70 102
70 103
70 104
70 105
70 106
70 107
70 108
70 109
70 110
1_175_70_15_csi_a15_28.dat
70 112
70 113
70 114
70 115
1_175_70_15_csi_a15_27.dat
70 117
70 118
70 119
1_175_70_15_csi_a15_29.dat
70 121
70 122
70 123
70 124
70 125
70 126
70 127
70 128
70 129
70 130
85 131
1_180_85_15_csi_a15_13.dat
1_180_85_15_csi_a15_3.dat
1_180_85_15_csi_a15_20.dat
1_180_85_15_csi_a15_23.dat
85 136
1_180_85_15_csi_a15_29.dat
1_180_85_15_csi_a15_21.dat
85 139
85 140
85 141
85 142
1_180_85_15_csi_a15_30.dat
1_180_85_15_csi_a15_10.dat
85 145
1_180_85_15_csi_a15_24.dat
85 147
85 148
85 149
1_180_85_15_csi_a15_26.dat
1_180_85_15_csi_a15_6.dat
85 152
85 153
85 154
1_180_85_15_csi_a15_27.dat
85 156
1_180_85_15_csi_a15_17.dat
1_180_85_15_csi_a15_22.dat
85 159
85 160
1_180_75_15_csi_a15_23.dat
75 162
1_180_75_15_csi_a15_17.dat
75 164
75 165
1_180_75_15_csi_a15_2.dat
1_180_75_15_csi_a15_24.dat
75 168
1_180_75_15_csi_a15_20.dat
1_180_75_15_csi_a15_9.dat
75 171
1_180_75_15_csi_a15_10.dat
1_180_75_15_csi_a15_11.dat
75 174
1_180_75_15_csi_a15_18.dat
75 176
1_180_75_15_csi_a15_15.dat
75 178
1_180_75_15_csi_a15_13.dat
75 180
1_180_75_15_csi_a15_3.dat
75 182
1_180_75_15_csi_a15_25.dat
75 184
75 185
1_180_75_15_csi_a15_16.dat
1_180_75_15_csi_a15_21.dat
1_180_75_15_csi_a15_1.dat
1_180_75_15_csi_a15_22.dat
75 190
85 191
1_173_85_15_csi_a15_7.dat
85 193
1_173_85_15_csi_a15_21.dat
1_173_85_15_csi_a15_14.dat
1_173_85_15_csi_a15_30.dat
1_173_85_15_csi_a15_27.dat
85 198
85 199
85 200
1_173_85_15_csi_a15_23.dat
1_173_85_15_csi_a15_15.dat
85 203
85 204
1_173_85_15_csi_a15_13.dat
1_173_85_15_csi_a15_22.dat
85 207
1_173_85_15_csi_a15_16.dat
1_173_85_15_csi_a15_8.dat
1_173_85_15_csi_a15_18.dat
85 211
85 212
85 213
85 214
85 215
1_173_85_15_csi_a15_29.dat
85 217
85 218
1_173_85_15_csi_a15_5.dat
1_173_85_15_csi_a15_6.dat
(148, 30, 3)
(148, 531, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60
 60 60 60 60 60 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 85]
(148, 531, 30, 3, 1)

Loaded dataset of 148 samples, each sized (531, 30, 3, 1)


Train on 118 samples
Test on 30 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 531, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 531, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 531, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 531, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 531, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 531, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 531, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 106 samples, validate on 12 samples
Epoch 1/30

 32/106 [========>.....................] - ETA: 1s - loss: 0.2960 - mae: 0.4611 - mse: 0.2960
 64/106 [=================>............] - ETA: 0s - loss: 0.2866 - mae: 0.4474 - mse: 0.2866
 96/106 [==========================>...] - ETA: 0s - loss: 0.2372 - mae: 0.3988 - mse: 0.2372
106/106 [==============================] - 1s 10ms/step - loss: 0.2181 - mae: 0.3747 - mse: 0.2181 - val_loss: 0.0760 - val_mae: 0.2301 - val_mse: 0.0760
Epoch 2/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1211 - mae: 0.2914 - mse: 0.1211
 64/106 [=================>............] - ETA: 0s - loss: 0.1219 - mae: 0.2970 - mse: 0.1219
 96/106 [==========================>...] - ETA: 0s - loss: 0.1267 - mae: 0.3006 - mse: 0.1267
106/106 [==============================] - 1s 7ms/step - loss: 0.1202 - mae: 0.2932 - mse: 0.1202 - val_loss: 0.0575 - val_mae: 0.2194 - val_mse: 0.0575
Epoch 3/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0695 - mae: 0.2084 - mse: 0.0695
 64/106 [=================>............] - ETA: 0s - loss: 0.0636 - mae: 0.2024 - mse: 0.0636
 96/106 [==========================>...] - ETA: 0s - loss: 0.0833 - mae: 0.2319 - mse: 0.0833
106/106 [==============================] - 1s 8ms/step - loss: 0.0832 - mae: 0.2323 - mse: 0.0832 - val_loss: 0.0865 - val_mae: 0.2439 - val_mse: 0.0865
Epoch 4/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.1188 - mae: 0.2792 - mse: 0.1188
 64/106 [=================>............] - ETA: 0s - loss: 0.0955 - mae: 0.2627 - mse: 0.0955
 96/106 [==========================>...] - ETA: 0s - loss: 0.0781 - mae: 0.2277 - mse: 0.0781
106/106 [==============================] - 1s 7ms/step - loss: 0.0794 - mae: 0.2281 - mse: 0.0794 - val_loss: 0.0670 - val_mae: 0.2198 - val_mse: 0.0670
Epoch 5/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0382 - mae: 0.1675 - mse: 0.0382
 64/106 [=================>............] - ETA: 0s - loss: 0.0471 - mae: 0.1827 - mse: 0.0471
 96/106 [==========================>...] - ETA: 0s - loss: 0.0598 - mae: 0.2046 - mse: 0.0598
106/106 [==============================] - 1s 7ms/step - loss: 0.0586 - mae: 0.2045 - mse: 0.0586 - val_loss: 0.0394 - val_mae: 0.1942 - val_mse: 0.0394
Epoch 6/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0609 - mae: 0.2061 - mse: 0.0609
 64/106 [=================>............] - ETA: 0s - loss: 0.0678 - mae: 0.2207 - mse: 0.0678
 96/106 [==========================>...] - ETA: 0s - loss: 0.0699 - mae: 0.2258 - mse: 0.0699
106/106 [==============================] - 1s 7ms/step - loss: 0.0671 - mae: 0.2194 - mse: 0.0671 - val_loss: 0.0362 - val_mae: 0.1850 - val_mse: 0.0362
Epoch 7/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0406 - mae: 0.1769 - mse: 0.0406
 64/106 [=================>............] - ETA: 0s - loss: 0.0471 - mae: 0.1873 - mse: 0.0471
 96/106 [==========================>...] - ETA: 0s - loss: 0.0478 - mae: 0.1862 - mse: 0.0478
106/106 [==============================] - 1s 7ms/step - loss: 0.0467 - mae: 0.1847 - mse: 0.0467 - val_loss: 0.0500 - val_mae: 0.1887 - val_mse: 0.0500
Epoch 8/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0588 - mae: 0.2021 - mse: 0.0588
 64/106 [=================>............] - ETA: 0s - loss: 0.0515 - mae: 0.1877 - mse: 0.0515
 96/106 [==========================>...] - ETA: 0s - loss: 0.0485 - mae: 0.1831 - mse: 0.0485
106/106 [==============================] - 1s 7ms/step - loss: 0.0530 - mae: 0.1902 - mse: 0.0530 - val_loss: 0.0489 - val_mae: 0.1839 - val_mse: 0.0489
Epoch 9/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0502 - mae: 0.1613 - mse: 0.0502
 64/106 [=================>............] - ETA: 0s - loss: 0.0425 - mae: 0.1593 - mse: 0.0425
 96/106 [==========================>...] - ETA: 0s - loss: 0.0388 - mae: 0.1556 - mse: 0.0388
106/106 [==============================] - 1s 7ms/step - loss: 0.0377 - mae: 0.1542 - mse: 0.0377 - val_loss: 0.0241 - val_mae: 0.1417 - val_mse: 0.0241
Epoch 10/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0558 - mae: 0.2021 - mse: 0.0558
 64/106 [=================>............] - ETA: 0s - loss: 0.0439 - mae: 0.1737 - mse: 0.0439
 96/106 [==========================>...] - ETA: 0s - loss: 0.0418 - mae: 0.1707 - mse: 0.0418
106/106 [==============================] - 1s 7ms/step - loss: 0.0414 - mae: 0.1707 - mse: 0.0414 - val_loss: 0.0213 - val_mae: 0.1249 - val_mse: 0.0213
Epoch 11/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0324 - mae: 0.1371 - mse: 0.0324
 64/106 [=================>............] - ETA: 0s - loss: 0.0386 - mae: 0.1533 - mse: 0.0386
 96/106 [==========================>...] - ETA: 0s - loss: 0.0345 - mae: 0.1447 - mse: 0.0345
106/106 [==============================] - 1s 7ms/step - loss: 0.0336 - mae: 0.1425 - mse: 0.0336 - val_loss: 0.0203 - val_mae: 0.1188 - val_mse: 0.0203
Epoch 12/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0273 - mae: 0.1360 - mse: 0.0273
 64/106 [=================>............] - ETA: 0s - loss: 0.0385 - mae: 0.1567 - mse: 0.0385
 96/106 [==========================>...] - ETA: 0s - loss: 0.0320 - mae: 0.1395 - mse: 0.0320
106/106 [==============================] - 1s 7ms/step - loss: 0.0301 - mae: 0.1341 - mse: 0.0301 - val_loss: 0.0228 - val_mae: 0.1263 - val_mse: 0.0228
Epoch 13/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0218 - mae: 0.1072 - mse: 0.0218
 64/106 [=================>............] - ETA: 0s - loss: 0.0258 - mae: 0.1197 - mse: 0.0258
 96/106 [==========================>...] - ETA: 0s - loss: 0.0257 - mae: 0.1200 - mse: 0.0257
106/106 [==============================] - 1s 7ms/step - loss: 0.0256 - mae: 0.1215 - mse: 0.0256 - val_loss: 0.0192 - val_mae: 0.1150 - val_mse: 0.0192
Epoch 14/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0238 - mae: 0.1099 - mse: 0.0238
 64/106 [=================>............] - ETA: 0s - loss: 0.0274 - mae: 0.1235 - mse: 0.0274
 96/106 [==========================>...] - ETA: 0s - loss: 0.0277 - mae: 0.1294 - mse: 0.0277
106/106 [==============================] - 1s 7ms/step - loss: 0.0282 - mae: 0.1297 - mse: 0.0282 - val_loss: 0.0155 - val_mae: 0.1004 - val_mse: 0.0155
Epoch 15/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0251 - mae: 0.1069 - mse: 0.0251
 64/106 [=================>............] - ETA: 0s - loss: 0.0289 - mae: 0.1253 - mse: 0.0289
 96/106 [==========================>...] - ETA: 0s - loss: 0.0291 - mae: 0.1287 - mse: 0.0291
106/106 [==============================] - 1s 7ms/step - loss: 0.0280 - mae: 0.1253 - mse: 0.0280 - val_loss: 0.0229 - val_mae: 0.1199 - val_mse: 0.0229
Epoch 16/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0136 - mae: 0.0878 - mse: 0.0136
 64/106 [=================>............] - ETA: 0s - loss: 0.0221 - mae: 0.1110 - mse: 0.0221
 96/106 [==========================>...] - ETA: 0s - loss: 0.0281 - mae: 0.1224 - mse: 0.0281
106/106 [==============================] - 1s 7ms/step - loss: 0.0290 - mae: 0.1229 - mse: 0.0290 - val_loss: 0.0144 - val_mae: 0.0949 - val_mse: 0.0144
Epoch 17/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0149 - mae: 0.0898 - mse: 0.0149
 64/106 [=================>............] - ETA: 0s - loss: 0.0183 - mae: 0.1015 - mse: 0.0183
 96/106 [==========================>...] - ETA: 0s - loss: 0.0246 - mae: 0.1152 - mse: 0.0246
106/106 [==============================] - 1s 7ms/step - loss: 0.0265 - mae: 0.1203 - mse: 0.0265 - val_loss: 0.0136 - val_mae: 0.0955 - val_mse: 0.0136
Epoch 18/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0177 - mae: 0.0984 - mse: 0.0177
 64/106 [=================>............] - ETA: 0s - loss: 0.0286 - mae: 0.1223 - mse: 0.0286
 96/106 [==========================>...] - ETA: 0s - loss: 0.0275 - mae: 0.1242 - mse: 0.0275
106/106 [==============================] - 1s 7ms/step - loss: 0.0271 - mae: 0.1228 - mse: 0.0271 - val_loss: 0.0305 - val_mae: 0.1394 - val_mse: 0.0305
Epoch 19/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0160 - mae: 0.0960 - mse: 0.0160
 64/106 [=================>............] - ETA: 0s - loss: 0.0238 - mae: 0.1190 - mse: 0.0238
 96/106 [==========================>...] - ETA: 0s - loss: 0.0229 - mae: 0.1168 - mse: 0.0229
106/106 [==============================] - 1s 6ms/step - loss: 0.0239 - mae: 0.1199 - mse: 0.0239 - val_loss: 0.0141 - val_mae: 0.0972 - val_mse: 0.0141
Epoch 20/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0213 - mae: 0.1122 - mse: 0.0213
 64/106 [=================>............] - ETA: 0s - loss: 0.0178 - mae: 0.1040 - mse: 0.0178
 96/106 [==========================>...] - ETA: 0s - loss: 0.0224 - mae: 0.1194 - mse: 0.0224
106/106 [==============================] - 1s 6ms/step - loss: 0.0209 - mae: 0.1136 - mse: 0.0209 - val_loss: 0.0119 - val_mae: 0.0855 - val_mse: 0.0119
Epoch 21/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0217 - mae: 0.1118 - mse: 0.0217
 64/106 [=================>............] - ETA: 0s - loss: 0.0269 - mae: 0.1275 - mse: 0.0269
 96/106 [==========================>...] - ETA: 0s - loss: 0.0268 - mae: 0.1260 - mse: 0.0268
106/106 [==============================] - 1s 6ms/step - loss: 0.0266 - mae: 0.1257 - mse: 0.0266 - val_loss: 0.0290 - val_mae: 0.1269 - val_mse: 0.0290
Epoch 22/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0354 - mae: 0.1204 - mse: 0.0354
 64/106 [=================>............] - ETA: 0s - loss: 0.0293 - mae: 0.1181 - mse: 0.0293
 96/106 [==========================>...] - ETA: 0s - loss: 0.0276 - mae: 0.1169 - mse: 0.0276
106/106 [==============================] - 1s 6ms/step - loss: 0.0284 - mae: 0.1204 - mse: 0.0284 - val_loss: 0.0186 - val_mae: 0.1054 - val_mse: 0.0186
Epoch 23/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0294 - mae: 0.1260 - mse: 0.0294
 64/106 [=================>............] - ETA: 0s - loss: 0.0240 - mae: 0.1168 - mse: 0.0240
 96/106 [==========================>...] - ETA: 0s - loss: 0.0286 - mae: 0.1295 - mse: 0.0286
106/106 [==============================] - 1s 6ms/step - loss: 0.0285 - mae: 0.1295 - mse: 0.0285 - val_loss: 0.0099 - val_mae: 0.0793 - val_mse: 0.0099
Epoch 24/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0309 - mae: 0.1332 - mse: 0.0309
 64/106 [=================>............] - ETA: 0s - loss: 0.0247 - mae: 0.1119 - mse: 0.0247
 96/106 [==========================>...] - ETA: 0s - loss: 0.0252 - mae: 0.1174 - mse: 0.0252
106/106 [==============================] - 1s 6ms/step - loss: 0.0256 - mae: 0.1172 - mse: 0.0256 - val_loss: 0.0289 - val_mae: 0.1321 - val_mse: 0.0289
Epoch 25/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0176 - mae: 0.0944 - mse: 0.0176
 64/106 [=================>............] - ETA: 0s - loss: 0.0209 - mae: 0.1039 - mse: 0.0209
 96/106 [==========================>...] - ETA: 0s - loss: 0.0230 - mae: 0.1129 - mse: 0.0230
106/106 [==============================] - 1s 6ms/step - loss: 0.0234 - mae: 0.1157 - mse: 0.0234 - val_loss: 0.0195 - val_mae: 0.1112 - val_mse: 0.0195
Epoch 26/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0248 - mae: 0.1181 - mse: 0.0248
 64/106 [=================>............] - ETA: 0s - loss: 0.0221 - mae: 0.1137 - mse: 0.0221
 96/106 [==========================>...] - ETA: 0s - loss: 0.0200 - mae: 0.1090 - mse: 0.0200
106/106 [==============================] - 1s 6ms/step - loss: 0.0205 - mae: 0.1116 - mse: 0.0205 - val_loss: 0.0087 - val_mae: 0.0762 - val_mse: 0.0087
Epoch 27/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0262 - mae: 0.1230 - mse: 0.0262
 64/106 [=================>............] - ETA: 0s - loss: 0.0221 - mae: 0.1149 - mse: 0.0221
 96/106 [==========================>...] - ETA: 0s - loss: 0.0211 - mae: 0.1124 - mse: 0.0211
106/106 [==============================] - 1s 6ms/step - loss: 0.0213 - mae: 0.1134 - mse: 0.0213 - val_loss: 0.0286 - val_mae: 0.1323 - val_mse: 0.0286
Epoch 28/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0226 - mae: 0.1205 - mse: 0.0226
 64/106 [=================>............] - ETA: 0s - loss: 0.0257 - mae: 0.1259 - mse: 0.0257
 96/106 [==========================>...] - ETA: 0s - loss: 0.0229 - mae: 0.1156 - mse: 0.0229
106/106 [==============================] - 1s 7ms/step - loss: 0.0216 - mae: 0.1113 - mse: 0.0216 - val_loss: 0.0222 - val_mae: 0.1165 - val_mse: 0.0222
Epoch 29/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0191 - mae: 0.0978 - mse: 0.0191
 64/106 [=================>............] - ETA: 0s - loss: 0.0178 - mae: 0.0945 - mse: 0.0178
 96/106 [==========================>...] - ETA: 0s - loss: 0.0159 - mae: 0.0884 - mse: 0.0159
106/106 [==============================] - 1s 12ms/step - loss: 0.0158 - mae: 0.0900 - mse: 0.0158 - val_loss: 0.0122 - val_mae: 0.0855 - val_mse: 0.0122
Epoch 30/30

 32/106 [========>.....................] - ETA: 0s - loss: 0.0160 - mae: 0.0974 - mse: 0.0160
 64/106 [=================>............] - ETA: 0s - loss: 0.0192 - mae: 0.1072 - mse: 0.0192
 96/106 [==========================>...] - ETA: 0s - loss: 0.0185 - mae: 0.1063 - mse: 0.0185
106/106 [==============================] - 1s 13ms/step - loss: 0.0190 - mae: 0.1065 - mse: 0.0190 - val_loss: 0.0161 - val_mae: 0.0977 - val_mse: 0.0161
Saving trained model...
72
Testing...
heightdiff= [0.         0.         0.         4.02874374 0.         0.        ]
average prediction= [4.6037316]
baseline= 9.0
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.007185935974121
85 -:- nan
60 -:- nan
