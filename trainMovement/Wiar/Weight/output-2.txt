['train-weight-2.py', '1']
2_155_65_2_csi_a2_20.dat
65 2
2_155_65_2_csi_a2_23.dat
65 4
2_155_65_2_csi_a2_16.dat
65 6
65 7
65 8
65 9
2_155_65_2_csi_a2_1.dat
2_155_65_2_csi_a2_21.dat
65 12
65 13
65 14
2_155_65_2_csi_a2_25.dat
2_155_65_2_csi_a2_18.dat
2_155_65_2_csi_a2_17.dat
2_155_65_2_csi_a2_14.dat
65 19
65 20
65 21
65 22
65 23
65 24
2_155_65_2_csi_a2_27.dat
2_155_65_2_csi_a2_24.dat
65 27
65 28
2_155_65_2_csi_a2_7.dat
65 30
60 31
60 32
60 33
2_170_60_2_csi_a2_2.dat
60 35
60 36
60 37
60 38
2_170_60_2_csi_a2_10.dat
60 40
1_165_65_2_csi_a2_30.dat
1_165_65_2_csi_a2_15.dat
1_165_65_2_csi_a2_10.dat
1_165_65_2_csi_a2_21.dat
1_165_65_2_csi_a2_9.dat
1_165_65_2_csi_a2_13.dat
1_165_65_2_csi_a2_19.dat
1_165_65_2_csi_a2_18.dat
1_165_65_2_csi_a2_7.dat
1_165_65_2_csi_a2_20.dat
1_165_65_2_csi_a2_11.dat
1_165_65_2_csi_a2_26.dat
1_165_65_2_csi_a2_16.dat
1_165_65_2_csi_a2_28.dat
1_165_65_2_csi_a2_5.dat
1_165_65_2_csi_a2_6.dat
1_165_65_2_csi_a2_25.dat
1_165_65_2_csi_a2_29.dat
1_165_65_2_csi_a2_23.dat
1_165_65_2_csi_a2_3.dat
1_165_65_2_csi_a2_27.dat
1_165_65_2_csi_a2_2.dat
1_165_65_2_csi_a2_17.dat
1_165_65_2_csi_a2_8.dat
1_165_65_2_csi_a2_14.dat
1_165_65_2_csi_a2_1.dat
1_165_65_2_csi_a2_24.dat
1_165_65_2_csi_a2_4.dat
1_165_65_2_csi_a2_22.dat
1_165_65_2_csi_a2_12.dat
50 71
50 72
50 73
50 74
50 75
50 76
50 77
2_165_50_2_csi_a2_13.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
50 97
50 98
2_165_50_2_csi_a2_24.dat
50 100
1_175_70_2_csi_a2_25.dat
70 102
1_175_70_2_csi_a2_20.dat
1_175_70_2_csi_a2_28.dat
70 105
1_175_70_2_csi_a2_22.dat
1_175_70_2_csi_a2_5.dat
1_175_70_2_csi_a2_11.dat
1_175_70_2_csi_a2_6.dat
1_175_70_2_csi_a2_8.dat
1_175_70_2_csi_a2_3.dat
1_175_70_2_csi_a2_16.dat
1_175_70_2_csi_a2_19.dat
1_175_70_2_csi_a2_1.dat
1_175_70_2_csi_a2_27.dat
70 116
1_175_70_2_csi_a2_18.dat
1_175_70_2_csi_a2_23.dat
1_175_70_2_csi_a2_21.dat
1_175_70_2_csi_a2_12.dat
1_175_70_2_csi_a2_30.dat
1_175_70_2_csi_a2_15.dat
1_175_70_2_csi_a2_17.dat
1_175_70_2_csi_a2_14.dat
1_175_70_2_csi_a2_9.dat
1_175_70_2_csi_a2_24.dat
1_175_70_2_csi_a2_10.dat
1_175_70_2_csi_a2_4.dat
1_175_70_2_csi_a2_29.dat
1_175_70_2_csi_a2_13.dat
1_180_85_2_csi_a2_22.dat
1_180_85_2_csi_a2_17.dat
1_180_85_2_csi_a2_15.dat
1_180_85_2_csi_a2_21.dat
85 135
1_180_85_2_csi_a2_7.dat
1_180_85_2_csi_a2_25.dat
1_180_85_2_csi_a2_19.dat
85 139
1_180_85_2_csi_a2_6.dat
1_180_85_2_csi_a2_1.dat
1_180_85_2_csi_a2_16.dat
1_180_85_2_csi_a2_14.dat
1_180_85_2_csi_a2_23.dat
1_180_85_2_csi_a2_24.dat
1_180_85_2_csi_a2_8.dat
85 147
1_180_85_2_csi_a2_13.dat
1_180_85_2_csi_a2_29.dat
1_180_85_2_csi_a2_9.dat
1_180_85_2_csi_a2_18.dat
1_180_85_2_csi_a2_28.dat
1_180_85_2_csi_a2_12.dat
1_180_85_2_csi_a2_30.dat
1_180_85_2_csi_a2_20.dat
85 156
1_180_85_2_csi_a2_26.dat
1_180_85_2_csi_a2_11.dat
85 159
1_180_85_2_csi_a2_10.dat
75 161
75 162
75 163
75 164
75 165
75 166
1_180_75_2_csi_a2_9.dat
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
75 180
75 181
1_180_75_2_csi_a2_1.dat
75 183
75 184
75 185
1_180_75_2_csi_a2_4.dat
75 187
75 188
75 189
75 190
85 191
85 192
85 193
85 194
85 195
85 196
85 197
85 198
85 199
1_173_85_2_csi_a2_23.dat
85 201
85 202
85 203
85 204
85 205
85 206
85 207
1_173_85_2_csi_a2_13.dat
85 209
85 210
85 211
85 212
85 213
85 214
85 215
85 216
1_173_85_2_csi_a2_28.dat
85 218
1_173_85_2_csi_a2_4.dat
85 220
(115, 30, 3)
(115, 421, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60 60
 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85]
(115, 421, 30, 3, 1)

Loaded dataset of 115 samples, each sized (421, 30, 3, 1)


Train on 92 samples
Test on 23 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 421, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 421, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 421, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 421, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 421, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 421, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 421, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 82 samples, validate on 10 samples
Epoch 1/30

32/82 [==========>...................] - ETA: 0s - loss: 0.5459 - mae: 0.6422 - mse: 0.5459
64/82 [======================>.......] - ETA: 0s - loss: 0.4615 - mae: 0.5745 - mse: 0.4615
82/82 [==============================] - 1s 9ms/step - loss: 0.4080 - mae: 0.5338 - mse: 0.4080 - val_loss: 0.2293 - val_mae: 0.4286 - val_mse: 0.2293
Epoch 2/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1898 - mae: 0.3690 - mse: 0.1898
64/82 [======================>.......] - ETA: 0s - loss: 0.1641 - mae: 0.3435 - mse: 0.1641
82/82 [==============================] - 0s 5ms/step - loss: 0.1594 - mae: 0.3393 - mse: 0.1594 - val_loss: 0.0775 - val_mae: 0.2465 - val_mse: 0.0775
Epoch 3/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1360 - mae: 0.3119 - mse: 0.1360
64/82 [======================>.......] - ETA: 0s - loss: 0.1719 - mae: 0.3648 - mse: 0.1719
82/82 [==============================] - 0s 5ms/step - loss: 0.1681 - mae: 0.3657 - mse: 0.1681 - val_loss: 0.0622 - val_mae: 0.2114 - val_mse: 0.0622
Epoch 4/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1136 - mae: 0.3078 - mse: 0.1136
64/82 [======================>.......] - ETA: 0s - loss: 0.1072 - mae: 0.2919 - mse: 0.1072
82/82 [==============================] - 0s 5ms/step - loss: 0.1032 - mae: 0.2828 - mse: 0.1032 - val_loss: 0.0971 - val_mae: 0.2410 - val_mse: 0.0971
Epoch 5/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1183 - mae: 0.2893 - mse: 0.1183
64/82 [======================>.......] - ETA: 0s - loss: 0.0988 - mae: 0.2462 - mse: 0.0988
82/82 [==============================] - 0s 5ms/step - loss: 0.1005 - mae: 0.2457 - mse: 0.1005 - val_loss: 0.1030 - val_mae: 0.2519 - val_mse: 0.1030
Epoch 6/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1042 - mae: 0.2482 - mse: 0.1042
64/82 [======================>.......] - ETA: 0s - loss: 0.0832 - mae: 0.2195 - mse: 0.0832
82/82 [==============================] - 0s 5ms/step - loss: 0.0887 - mae: 0.2269 - mse: 0.0887 - val_loss: 0.0708 - val_mae: 0.1875 - val_mse: 0.0708
Epoch 7/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1083 - mae: 0.2542 - mse: 0.1083
64/82 [======================>.......] - ETA: 0s - loss: 0.0981 - mae: 0.2371 - mse: 0.0981
82/82 [==============================] - 0s 5ms/step - loss: 0.0865 - mae: 0.2191 - mse: 0.0865 - val_loss: 0.0413 - val_mae: 0.1525 - val_mse: 0.0413
Epoch 8/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0728 - mae: 0.2238 - mse: 0.0728
64/82 [======================>.......] - ETA: 0s - loss: 0.0666 - mae: 0.2144 - mse: 0.0666
82/82 [==============================] - 0s 5ms/step - loss: 0.0685 - mae: 0.2163 - mse: 0.0685 - val_loss: 0.0349 - val_mae: 0.1569 - val_mse: 0.0349
Epoch 9/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0465 - mae: 0.1751 - mse: 0.0465
64/82 [======================>.......] - ETA: 0s - loss: 0.0605 - mae: 0.1950 - mse: 0.0605
82/82 [==============================] - 0s 5ms/step - loss: 0.0626 - mae: 0.2006 - mse: 0.0626 - val_loss: 0.0324 - val_mae: 0.1536 - val_mse: 0.0324
Epoch 10/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0394 - mae: 0.1620 - mse: 0.0394
64/82 [======================>.......] - ETA: 0s - loss: 0.0548 - mae: 0.1873 - mse: 0.0548
82/82 [==============================] - 0s 5ms/step - loss: 0.0642 - mae: 0.1961 - mse: 0.0642 - val_loss: 0.0314 - val_mae: 0.1382 - val_mse: 0.0314
Epoch 11/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0500 - mae: 0.1791 - mse: 0.0500
64/82 [======================>.......] - ETA: 0s - loss: 0.0574 - mae: 0.1819 - mse: 0.0574
82/82 [==============================] - 0s 5ms/step - loss: 0.0489 - mae: 0.1622 - mse: 0.0489 - val_loss: 0.0319 - val_mae: 0.1279 - val_mse: 0.0319
Epoch 12/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0679 - mae: 0.1836 - mse: 0.0679
64/82 [======================>.......] - ETA: 0s - loss: 0.0619 - mae: 0.1683 - mse: 0.0619
82/82 [==============================] - 0s 5ms/step - loss: 0.0572 - mae: 0.1632 - mse: 0.0572 - val_loss: 0.0267 - val_mae: 0.1243 - val_mse: 0.0267
Epoch 13/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0518 - mae: 0.1736 - mse: 0.0518
64/82 [======================>.......] - ETA: 0s - loss: 0.0441 - mae: 0.1573 - mse: 0.0441
82/82 [==============================] - 0s 5ms/step - loss: 0.0459 - mae: 0.1574 - mse: 0.0459 - val_loss: 0.0224 - val_mae: 0.1244 - val_mse: 0.0224
Epoch 14/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0474 - mae: 0.1641 - mse: 0.0474
64/82 [======================>.......] - ETA: 0s - loss: 0.0434 - mae: 0.1585 - mse: 0.0434
82/82 [==============================] - 0s 5ms/step - loss: 0.0450 - mae: 0.1619 - mse: 0.0450 - val_loss: 0.0199 - val_mae: 0.1203 - val_mse: 0.0199
Epoch 15/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0406 - mae: 0.1485 - mse: 0.0406
64/82 [======================>.......] - ETA: 0s - loss: 0.0405 - mae: 0.1527 - mse: 0.0405
82/82 [==============================] - 0s 5ms/step - loss: 0.0362 - mae: 0.1440 - mse: 0.0362 - val_loss: 0.0183 - val_mae: 0.1038 - val_mse: 0.0183
Epoch 16/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0305 - mae: 0.1324 - mse: 0.0305
64/82 [======================>.......] - ETA: 0s - loss: 0.0313 - mae: 0.1291 - mse: 0.0313
82/82 [==============================] - 0s 5ms/step - loss: 0.0351 - mae: 0.1334 - mse: 0.0351 - val_loss: 0.0159 - val_mae: 0.1005 - val_mse: 0.0159
Epoch 17/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0390 - mae: 0.1423 - mse: 0.0390
64/82 [======================>.......] - ETA: 0s - loss: 0.0341 - mae: 0.1431 - mse: 0.0341
82/82 [==============================] - 0s 4ms/step - loss: 0.0301 - mae: 0.1354 - mse: 0.0301 - val_loss: 0.0132 - val_mae: 0.1061 - val_mse: 0.0132
Epoch 18/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0347 - mae: 0.1385 - mse: 0.0347
64/82 [======================>.......] - ETA: 0s - loss: 0.0267 - mae: 0.1243 - mse: 0.0267
82/82 [==============================] - 0s 5ms/step - loss: 0.0250 - mae: 0.1229 - mse: 0.0250 - val_loss: 0.0112 - val_mae: 0.0909 - val_mse: 0.0112
Epoch 19/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0325 - mae: 0.1392 - mse: 0.0325
64/82 [======================>.......] - ETA: 0s - loss: 0.0271 - mae: 0.1254 - mse: 0.0271
82/82 [==============================] - 0s 5ms/step - loss: 0.0244 - mae: 0.1163 - mse: 0.0244 - val_loss: 0.0153 - val_mae: 0.0972 - val_mse: 0.0153
Epoch 20/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0192 - mae: 0.1140 - mse: 0.0192
64/82 [======================>.......] - ETA: 0s - loss: 0.0306 - mae: 0.1253 - mse: 0.0306
82/82 [==============================] - 0s 5ms/step - loss: 0.0324 - mae: 0.1287 - mse: 0.0324 - val_loss: 0.0105 - val_mae: 0.0827 - val_mse: 0.0105
Epoch 21/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0340 - mae: 0.1419 - mse: 0.0340
64/82 [======================>.......] - ETA: 0s - loss: 0.0252 - mae: 0.1196 - mse: 0.0252
82/82 [==============================] - 0s 4ms/step - loss: 0.0246 - mae: 0.1184 - mse: 0.0246 - val_loss: 0.0050 - val_mae: 0.0542 - val_mse: 0.0050
Epoch 22/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0182 - mae: 0.0920 - mse: 0.0182
64/82 [======================>.......] - ETA: 0s - loss: 0.0192 - mae: 0.1053 - mse: 0.0192
82/82 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 0.1018 - mse: 0.0195 - val_loss: 0.0040 - val_mae: 0.0426 - val_mse: 0.0040
Epoch 23/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0207 - mae: 0.1150 - mse: 0.0207
64/82 [======================>.......] - ETA: 0s - loss: 0.0222 - mae: 0.1080 - mse: 0.0222
82/82 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 0.1034 - mse: 0.0196 - val_loss: 0.0090 - val_mae: 0.0902 - val_mse: 0.0090
Epoch 24/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0184 - mae: 0.1015 - mse: 0.0184
64/82 [======================>.......] - ETA: 0s - loss: 0.0208 - mae: 0.1042 - mse: 0.0208
82/82 [==============================] - 0s 5ms/step - loss: 0.0225 - mae: 0.1083 - mse: 0.0225 - val_loss: 0.0093 - val_mae: 0.0915 - val_mse: 0.0093
Epoch 25/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0227 - mae: 0.1128 - mse: 0.0227
64/82 [======================>.......] - ETA: 0s - loss: 0.0205 - mae: 0.1013 - mse: 0.0205
82/82 [==============================] - 0s 5ms/step - loss: 0.0213 - mae: 0.1056 - mse: 0.0213 - val_loss: 0.0055 - val_mae: 0.0462 - val_mse: 0.0055
Epoch 26/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0095 - mae: 0.0729 - mse: 0.0095
64/82 [======================>.......] - ETA: 0s - loss: 0.0189 - mae: 0.0991 - mse: 0.0189
82/82 [==============================] - 0s 5ms/step - loss: 0.0204 - mae: 0.1028 - mse: 0.0204 - val_loss: 0.0065 - val_mae: 0.0568 - val_mse: 0.0065
Epoch 27/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0142 - mae: 0.0854 - mse: 0.0142
64/82 [======================>.......] - ETA: 0s - loss: 0.0155 - mae: 0.0896 - mse: 0.0155
82/82 [==============================] - 0s 5ms/step - loss: 0.0156 - mae: 0.0899 - mse: 0.0156 - val_loss: 0.0114 - val_mae: 0.0936 - val_mse: 0.0114
Epoch 28/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0145 - mae: 0.0893 - mse: 0.0145
64/82 [======================>.......] - ETA: 0s - loss: 0.0195 - mae: 0.1045 - mse: 0.0195
82/82 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 0.1096 - mse: 0.0219 - val_loss: 0.0062 - val_mae: 0.0501 - val_mse: 0.0062
Epoch 29/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0285 - mae: 0.1209 - mse: 0.0285
64/82 [======================>.......] - ETA: 0s - loss: 0.0239 - mae: 0.1096 - mse: 0.0239
82/82 [==============================] - 0s 5ms/step - loss: 0.0227 - mae: 0.1091 - mse: 0.0227 - val_loss: 0.0055 - val_mae: 0.0349 - val_mse: 0.0055
Epoch 30/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0202 - mae: 0.1014 - mse: 0.0202
64/82 [======================>.......] - ETA: 0s - loss: 0.0214 - mae: 0.1061 - mse: 0.0214
82/82 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 0.1001 - mse: 0.0192 - val_loss: 0.0085 - val_mae: 0.0823 - val_mse: 0.0085
Saving trained model...
105
Testing...
heightdiff= [0.         0.         0.         4.25118637 0.         0.        ]
average prediction= [3.2438853]
baseline= 12.717391304347826
eachuser= [0. 0. 0. 6. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.7085310618082682
85 -:- nan
60 -:- nan
['train-weight-2.py', '1']
2_155_65_2_csi_a2_20.dat
65 2
2_155_65_2_csi_a2_23.dat
65 4
2_155_65_2_csi_a2_16.dat
65 6
65 7
65 8
65 9
2_155_65_2_csi_a2_1.dat
2_155_65_2_csi_a2_21.dat
65 12
65 13
65 14
2_155_65_2_csi_a2_25.dat
2_155_65_2_csi_a2_18.dat
2_155_65_2_csi_a2_17.dat
2_155_65_2_csi_a2_14.dat
65 19
65 20
65 21
65 22
65 23
65 24
2_155_65_2_csi_a2_27.dat
2_155_65_2_csi_a2_24.dat
65 27
65 28
2_155_65_2_csi_a2_7.dat
65 30
60 31
60 32
60 33
2_170_60_2_csi_a2_2.dat
60 35
60 36
60 37
60 38
2_170_60_2_csi_a2_10.dat
60 40
1_165_65_2_csi_a2_30.dat
1_165_65_2_csi_a2_15.dat
1_165_65_2_csi_a2_10.dat
1_165_65_2_csi_a2_21.dat
1_165_65_2_csi_a2_9.dat
1_165_65_2_csi_a2_13.dat
1_165_65_2_csi_a2_19.dat
1_165_65_2_csi_a2_18.dat
1_165_65_2_csi_a2_7.dat
1_165_65_2_csi_a2_20.dat
1_165_65_2_csi_a2_11.dat
1_165_65_2_csi_a2_26.dat
1_165_65_2_csi_a2_16.dat
1_165_65_2_csi_a2_28.dat
1_165_65_2_csi_a2_5.dat
1_165_65_2_csi_a2_6.dat
1_165_65_2_csi_a2_25.dat
1_165_65_2_csi_a2_29.dat
1_165_65_2_csi_a2_23.dat
1_165_65_2_csi_a2_3.dat
1_165_65_2_csi_a2_27.dat
1_165_65_2_csi_a2_2.dat
1_165_65_2_csi_a2_17.dat
1_165_65_2_csi_a2_8.dat
1_165_65_2_csi_a2_14.dat
1_165_65_2_csi_a2_1.dat
1_165_65_2_csi_a2_24.dat
1_165_65_2_csi_a2_4.dat
1_165_65_2_csi_a2_22.dat
1_165_65_2_csi_a2_12.dat
50 71
50 72
50 73
50 74
50 75
50 76
50 77
2_165_50_2_csi_a2_13.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
50 97
50 98
2_165_50_2_csi_a2_24.dat
50 100
1_175_70_2_csi_a2_25.dat
70 102
1_175_70_2_csi_a2_20.dat
1_175_70_2_csi_a2_28.dat
70 105
1_175_70_2_csi_a2_22.dat
1_175_70_2_csi_a2_5.dat
1_175_70_2_csi_a2_11.dat
1_175_70_2_csi_a2_6.dat
1_175_70_2_csi_a2_8.dat
1_175_70_2_csi_a2_3.dat
1_175_70_2_csi_a2_16.dat
1_175_70_2_csi_a2_19.dat
1_175_70_2_csi_a2_1.dat
1_175_70_2_csi_a2_27.dat
70 116
1_175_70_2_csi_a2_18.dat
1_175_70_2_csi_a2_23.dat
1_175_70_2_csi_a2_21.dat
1_175_70_2_csi_a2_12.dat
1_175_70_2_csi_a2_30.dat
1_175_70_2_csi_a2_15.dat
1_175_70_2_csi_a2_17.dat
1_175_70_2_csi_a2_14.dat
1_175_70_2_csi_a2_9.dat
1_175_70_2_csi_a2_24.dat
1_175_70_2_csi_a2_10.dat
1_175_70_2_csi_a2_4.dat
1_175_70_2_csi_a2_29.dat
1_175_70_2_csi_a2_13.dat
1_180_85_2_csi_a2_22.dat
1_180_85_2_csi_a2_17.dat
1_180_85_2_csi_a2_15.dat
1_180_85_2_csi_a2_21.dat
85 135
1_180_85_2_csi_a2_7.dat
1_180_85_2_csi_a2_25.dat
1_180_85_2_csi_a2_19.dat
85 139
1_180_85_2_csi_a2_6.dat
1_180_85_2_csi_a2_1.dat
1_180_85_2_csi_a2_16.dat
1_180_85_2_csi_a2_14.dat
1_180_85_2_csi_a2_23.dat
1_180_85_2_csi_a2_24.dat
1_180_85_2_csi_a2_8.dat
85 147
1_180_85_2_csi_a2_13.dat
1_180_85_2_csi_a2_29.dat
1_180_85_2_csi_a2_9.dat
1_180_85_2_csi_a2_18.dat
1_180_85_2_csi_a2_28.dat
1_180_85_2_csi_a2_12.dat
1_180_85_2_csi_a2_30.dat
1_180_85_2_csi_a2_20.dat
85 156
1_180_85_2_csi_a2_26.dat
1_180_85_2_csi_a2_11.dat
85 159
1_180_85_2_csi_a2_10.dat
75 161
75 162
75 163
75 164
75 165
75 166
1_180_75_2_csi_a2_9.dat
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
75 180
75 181
1_180_75_2_csi_a2_1.dat
75 183
75 184
75 185
1_180_75_2_csi_a2_4.dat
75 187
75 188
75 189
75 190
85 191
85 192
85 193
85 194
85 195
85 196
85 197
85 198
85 199
1_173_85_2_csi_a2_23.dat
85 201
85 202
85 203
85 204
85 205
85 206
85 207
1_173_85_2_csi_a2_13.dat
85 209
85 210
85 211
85 212
85 213
85 214
85 215
85 216
1_173_85_2_csi_a2_28.dat
85 218
1_173_85_2_csi_a2_4.dat
85 220
(115, 30, 3)
(115, 421, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60 60
 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85]
(115, 421, 30, 3, 1)

Loaded dataset of 115 samples, each sized (421, 30, 3, 1)


Train on 92 samples
Test on 23 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 421, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 421, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 421, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 421, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 421, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 421, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 421, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 82 samples, validate on 10 samples
Epoch 1/30

32/82 [==========>...................] - ETA: 0s - loss: 0.3771 - mae: 0.5095 - mse: 0.3771
64/82 [======================>.......] - ETA: 0s - loss: 0.3305 - mae: 0.4772 - mse: 0.3305
82/82 [==============================] - 1s 10ms/step - loss: 0.3056 - mae: 0.4542 - mse: 0.3056 - val_loss: 0.3090 - val_mae: 0.4601 - val_mse: 0.3090
Epoch 2/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1796 - mae: 0.3742 - mse: 0.1796
64/82 [======================>.......] - ETA: 0s - loss: 0.1815 - mae: 0.3809 - mse: 0.1815
82/82 [==============================] - 0s 5ms/step - loss: 0.1800 - mae: 0.3828 - mse: 0.1800 - val_loss: 0.1489 - val_mae: 0.3434 - val_mse: 0.1489
Epoch 3/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1566 - mae: 0.3548 - mse: 0.1566
64/82 [======================>.......] - ETA: 0s - loss: 0.1575 - mae: 0.3474 - mse: 0.1575
82/82 [==============================] - 0s 6ms/step - loss: 0.1423 - mae: 0.3284 - mse: 0.1423 - val_loss: 0.1035 - val_mae: 0.2663 - val_mse: 0.1035
Epoch 4/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0743 - mae: 0.2277 - mse: 0.0743
64/82 [======================>.......] - ETA: 0s - loss: 0.0880 - mae: 0.2552 - mse: 0.0880
82/82 [==============================] - 0s 5ms/step - loss: 0.0864 - mae: 0.2523 - mse: 0.0864 - val_loss: 0.1039 - val_mae: 0.2479 - val_mse: 0.1039
Epoch 5/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0694 - mae: 0.2112 - mse: 0.0694
64/82 [======================>.......] - ETA: 0s - loss: 0.0841 - mae: 0.2304 - mse: 0.0841
82/82 [==============================] - 0s 5ms/step - loss: 0.0747 - mae: 0.2118 - mse: 0.0747 - val_loss: 0.0767 - val_mae: 0.2087 - val_mse: 0.0767
Epoch 6/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0606 - mae: 0.1869 - mse: 0.0606
64/82 [======================>.......] - ETA: 0s - loss: 0.0673 - mae: 0.1918 - mse: 0.0673
82/82 [==============================] - 0s 4ms/step - loss: 0.0661 - mae: 0.1926 - mse: 0.0661 - val_loss: 0.0444 - val_mae: 0.1639 - val_mse: 0.0444
Epoch 7/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0635 - mae: 0.1749 - mse: 0.0635
64/82 [======================>.......] - ETA: 0s - loss: 0.0512 - mae: 0.1685 - mse: 0.0512
82/82 [==============================] - 0s 5ms/step - loss: 0.0568 - mae: 0.1742 - mse: 0.0568 - val_loss: 0.0395 - val_mae: 0.1698 - val_mse: 0.0395
Epoch 8/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0386 - mae: 0.1384 - mse: 0.0386
64/82 [======================>.......] - ETA: 0s - loss: 0.0456 - mae: 0.1584 - mse: 0.0456
82/82 [==============================] - 0s 5ms/step - loss: 0.0460 - mae: 0.1578 - mse: 0.0460 - val_loss: 0.0403 - val_mae: 0.1702 - val_mse: 0.0403
Epoch 9/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0595 - mae: 0.1695 - mse: 0.0595
64/82 [======================>.......] - ETA: 0s - loss: 0.0427 - mae: 0.1478 - mse: 0.0427
82/82 [==============================] - 0s 5ms/step - loss: 0.0425 - mae: 0.1490 - mse: 0.0425 - val_loss: 0.0304 - val_mae: 0.1437 - val_mse: 0.0304
Epoch 10/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0691 - mae: 0.1955 - mse: 0.0691
64/82 [======================>.......] - ETA: 0s - loss: 0.0479 - mae: 0.1658 - mse: 0.0479
82/82 [==============================] - 0s 5ms/step - loss: 0.0457 - mae: 0.1640 - mse: 0.0457 - val_loss: 0.0320 - val_mae: 0.1390 - val_mse: 0.0320
Epoch 11/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0395 - mae: 0.1485 - mse: 0.0395
64/82 [======================>.......] - ETA: 0s - loss: 0.0441 - mae: 0.1590 - mse: 0.0441
82/82 [==============================] - 0s 5ms/step - loss: 0.0395 - mae: 0.1509 - mse: 0.0395 - val_loss: 0.0550 - val_mae: 0.1676 - val_mse: 0.0550
Epoch 12/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0463 - mae: 0.1510 - mse: 0.0463
64/82 [======================>.......] - ETA: 0s - loss: 0.0477 - mae: 0.1547 - mse: 0.0477
82/82 [==============================] - 0s 5ms/step - loss: 0.0391 - mae: 0.1364 - mse: 0.0391 - val_loss: 0.0487 - val_mae: 0.1523 - val_mse: 0.0487
Epoch 13/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0292 - mae: 0.1280 - mse: 0.0292
64/82 [======================>.......] - ETA: 0s - loss: 0.0390 - mae: 0.1436 - mse: 0.0390
82/82 [==============================] - 0s 5ms/step - loss: 0.0347 - mae: 0.1365 - mse: 0.0347 - val_loss: 0.0234 - val_mae: 0.1180 - val_mse: 0.0234
Epoch 14/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0256 - mae: 0.1251 - mse: 0.0256
64/82 [======================>.......] - ETA: 0s - loss: 0.0347 - mae: 0.1438 - mse: 0.0347
82/82 [==============================] - 1s 6ms/step - loss: 0.0313 - mae: 0.1362 - mse: 0.0313 - val_loss: 0.0245 - val_mae: 0.1070 - val_mse: 0.0245
Epoch 15/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0148 - mae: 0.0973 - mse: 0.0148
64/82 [======================>.......] - ETA: 0s - loss: 0.0264 - mae: 0.1260 - mse: 0.0264
82/82 [==============================] - 0s 5ms/step - loss: 0.0281 - mae: 0.1323 - mse: 0.0281 - val_loss: 0.0312 - val_mae: 0.1360 - val_mse: 0.0312
Epoch 16/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0192 - mae: 0.1022 - mse: 0.0192
64/82 [======================>.......] - ETA: 0s - loss: 0.0227 - mae: 0.1101 - mse: 0.0227
82/82 [==============================] - 0s 5ms/step - loss: 0.0229 - mae: 0.1120 - mse: 0.0229 - val_loss: 0.0260 - val_mae: 0.1278 - val_mse: 0.0260
Epoch 17/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0354 - mae: 0.1436 - mse: 0.0354
64/82 [======================>.......] - ETA: 0s - loss: 0.0271 - mae: 0.1206 - mse: 0.0271
82/82 [==============================] - 0s 5ms/step - loss: 0.0247 - mae: 0.1149 - mse: 0.0247 - val_loss: 0.0256 - val_mae: 0.1271 - val_mse: 0.0256
Epoch 18/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0104 - mae: 0.0763 - mse: 0.0104
64/82 [======================>.......] - ETA: 0s - loss: 0.0179 - mae: 0.0914 - mse: 0.0179
82/82 [==============================] - 0s 5ms/step - loss: 0.0236 - mae: 0.1040 - mse: 0.0236 - val_loss: 0.0264 - val_mae: 0.1263 - val_mse: 0.0264
Epoch 19/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0359 - mae: 0.1415 - mse: 0.0359
64/82 [======================>.......] - ETA: 0s - loss: 0.0247 - mae: 0.1122 - mse: 0.0247
82/82 [==============================] - 0s 6ms/step - loss: 0.0201 - mae: 0.0970 - mse: 0.0201 - val_loss: 0.0277 - val_mae: 0.1305 - val_mse: 0.0277
Epoch 20/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0280 - mae: 0.1206 - mse: 0.0280
64/82 [======================>.......] - ETA: 0s - loss: 0.0215 - mae: 0.1079 - mse: 0.0215
82/82 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 0.1011 - mse: 0.0190 - val_loss: 0.0276 - val_mae: 0.1322 - val_mse: 0.0276
Epoch 21/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0154 - mae: 0.0981 - mse: 0.0154
64/82 [======================>.......] - ETA: 0s - loss: 0.0189 - mae: 0.1071 - mse: 0.0189
82/82 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 0.1063 - mse: 0.0197 - val_loss: 0.0257 - val_mae: 0.1311 - val_mse: 0.0257
Epoch 22/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0105 - mae: 0.0741 - mse: 0.0105
64/82 [======================>.......] - ETA: 0s - loss: 0.0134 - mae: 0.0833 - mse: 0.0134
82/82 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0879 - mse: 0.0148 - val_loss: 0.0158 - val_mae: 0.1003 - val_mse: 0.0158
Epoch 23/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0133 - mae: 0.0938 - mse: 0.0133
64/82 [======================>.......] - ETA: 0s - loss: 0.0238 - mae: 0.1070 - mse: 0.0238
82/82 [==============================] - 0s 4ms/step - loss: 0.0232 - mae: 0.1084 - mse: 0.0232 - val_loss: 0.0367 - val_mae: 0.1612 - val_mse: 0.0367
Epoch 24/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0253 - mae: 0.1295 - mse: 0.0253
64/82 [======================>.......] - ETA: 0s - loss: 0.0229 - mae: 0.1125 - mse: 0.0229
82/82 [==============================] - 0s 4ms/step - loss: 0.0221 - mae: 0.1061 - mse: 0.0221 - val_loss: 0.0366 - val_mae: 0.1605 - val_mse: 0.0366
Epoch 25/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0291 - mae: 0.1321 - mse: 0.0291
64/82 [======================>.......] - ETA: 0s - loss: 0.0214 - mae: 0.1117 - mse: 0.0214
82/82 [==============================] - 0s 5ms/step - loss: 0.0200 - mae: 0.1085 - mse: 0.0200 - val_loss: 0.0147 - val_mae: 0.0991 - val_mse: 0.0147
Epoch 26/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0240 - mae: 0.1132 - mse: 0.0240
64/82 [======================>.......] - ETA: 0s - loss: 0.0233 - mae: 0.1069 - mse: 0.0233
82/82 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 0.1076 - mse: 0.0219 - val_loss: 0.0310 - val_mae: 0.1532 - val_mse: 0.0310
Epoch 27/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0222 - mae: 0.1118 - mse: 0.0222
64/82 [======================>.......] - ETA: 0s - loss: 0.0188 - mae: 0.0973 - mse: 0.0188
82/82 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 0.1001 - mse: 0.0186 - val_loss: 0.0426 - val_mae: 0.1841 - val_mse: 0.0426
Epoch 28/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0211 - mae: 0.1040 - mse: 0.0211
64/82 [======================>.......] - ETA: 0s - loss: 0.0194 - mae: 0.0960 - mse: 0.0194
82/82 [==============================] - 0s 5ms/step - loss: 0.0229 - mae: 0.1060 - mse: 0.0229 - val_loss: 0.0112 - val_mae: 0.0842 - val_mse: 0.0112
Epoch 29/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0210 - mae: 0.1047 - mse: 0.0210
64/82 [======================>.......] - ETA: 0s - loss: 0.0156 - mae: 0.0918 - mse: 0.0156
82/82 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.0991 - mse: 0.0177 - val_loss: 0.0267 - val_mae: 0.1366 - val_mse: 0.0267
Epoch 30/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0130 - mae: 0.0880 - mse: 0.0130
64/82 [======================>.......] - ETA: 0s - loss: 0.0187 - mae: 0.0970 - mse: 0.0187
82/82 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 0.0948 - mse: 0.0181 - val_loss: 0.0415 - val_mae: 0.1761 - val_mse: 0.0415
Saving trained model...
105
Testing...
heightdiff= [0.         0.         0.         6.45055771 0.         0.        ]
average prediction= [5.795666]
baseline= 12.717391304347826
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.2901115417480469
85 -:- nan
60 -:- nan
['train-weight-2.py', '1']
2_155_65_2_csi_a2_20.dat
65 2
2_155_65_2_csi_a2_23.dat
65 4
2_155_65_2_csi_a2_16.dat
65 6
65 7
65 8
65 9
2_155_65_2_csi_a2_1.dat
2_155_65_2_csi_a2_21.dat
65 12
65 13
65 14
2_155_65_2_csi_a2_25.dat
2_155_65_2_csi_a2_18.dat
2_155_65_2_csi_a2_17.dat
2_155_65_2_csi_a2_14.dat
65 19
65 20
65 21
65 22
65 23
65 24
2_155_65_2_csi_a2_27.dat
2_155_65_2_csi_a2_24.dat
65 27
65 28
2_155_65_2_csi_a2_7.dat
65 30
60 31
60 32
60 33
2_170_60_2_csi_a2_2.dat
60 35
60 36
60 37
60 38
2_170_60_2_csi_a2_10.dat
60 40
1_165_65_2_csi_a2_30.dat
1_165_65_2_csi_a2_15.dat
1_165_65_2_csi_a2_10.dat
1_165_65_2_csi_a2_21.dat
1_165_65_2_csi_a2_9.dat
1_165_65_2_csi_a2_13.dat
1_165_65_2_csi_a2_19.dat
1_165_65_2_csi_a2_18.dat
1_165_65_2_csi_a2_7.dat
1_165_65_2_csi_a2_20.dat
1_165_65_2_csi_a2_11.dat
1_165_65_2_csi_a2_26.dat
1_165_65_2_csi_a2_16.dat
1_165_65_2_csi_a2_28.dat
1_165_65_2_csi_a2_5.dat
1_165_65_2_csi_a2_6.dat
1_165_65_2_csi_a2_25.dat
1_165_65_2_csi_a2_29.dat
1_165_65_2_csi_a2_23.dat
1_165_65_2_csi_a2_3.dat
1_165_65_2_csi_a2_27.dat
1_165_65_2_csi_a2_2.dat
1_165_65_2_csi_a2_17.dat
1_165_65_2_csi_a2_8.dat
1_165_65_2_csi_a2_14.dat
1_165_65_2_csi_a2_1.dat
1_165_65_2_csi_a2_24.dat
1_165_65_2_csi_a2_4.dat
1_165_65_2_csi_a2_22.dat
1_165_65_2_csi_a2_12.dat
50 71
50 72
50 73
50 74
50 75
50 76
50 77
2_165_50_2_csi_a2_13.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
50 97
50 98
2_165_50_2_csi_a2_24.dat
50 100
1_175_70_2_csi_a2_25.dat
70 102
1_175_70_2_csi_a2_20.dat
1_175_70_2_csi_a2_28.dat
70 105
1_175_70_2_csi_a2_22.dat
1_175_70_2_csi_a2_5.dat
1_175_70_2_csi_a2_11.dat
1_175_70_2_csi_a2_6.dat
1_175_70_2_csi_a2_8.dat
1_175_70_2_csi_a2_3.dat
1_175_70_2_csi_a2_16.dat
1_175_70_2_csi_a2_19.dat
1_175_70_2_csi_a2_1.dat
1_175_70_2_csi_a2_27.dat
70 116
1_175_70_2_csi_a2_18.dat
1_175_70_2_csi_a2_23.dat
1_175_70_2_csi_a2_21.dat
1_175_70_2_csi_a2_12.dat
1_175_70_2_csi_a2_30.dat
1_175_70_2_csi_a2_15.dat
1_175_70_2_csi_a2_17.dat
1_175_70_2_csi_a2_14.dat
1_175_70_2_csi_a2_9.dat
1_175_70_2_csi_a2_24.dat
1_175_70_2_csi_a2_10.dat
1_175_70_2_csi_a2_4.dat
1_175_70_2_csi_a2_29.dat
1_175_70_2_csi_a2_13.dat
1_180_85_2_csi_a2_22.dat
1_180_85_2_csi_a2_17.dat
1_180_85_2_csi_a2_15.dat
1_180_85_2_csi_a2_21.dat
85 135
1_180_85_2_csi_a2_7.dat
1_180_85_2_csi_a2_25.dat
1_180_85_2_csi_a2_19.dat
85 139
1_180_85_2_csi_a2_6.dat
1_180_85_2_csi_a2_1.dat
1_180_85_2_csi_a2_16.dat
1_180_85_2_csi_a2_14.dat
1_180_85_2_csi_a2_23.dat
1_180_85_2_csi_a2_24.dat
1_180_85_2_csi_a2_8.dat
85 147
1_180_85_2_csi_a2_13.dat
1_180_85_2_csi_a2_29.dat
1_180_85_2_csi_a2_9.dat
1_180_85_2_csi_a2_18.dat
1_180_85_2_csi_a2_28.dat
1_180_85_2_csi_a2_12.dat
1_180_85_2_csi_a2_30.dat
1_180_85_2_csi_a2_20.dat
85 156
1_180_85_2_csi_a2_26.dat
1_180_85_2_csi_a2_11.dat
85 159
1_180_85_2_csi_a2_10.dat
75 161
75 162
75 163
75 164
75 165
75 166
1_180_75_2_csi_a2_9.dat
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
75 180
75 181
1_180_75_2_csi_a2_1.dat
75 183
75 184
75 185
1_180_75_2_csi_a2_4.dat
75 187
75 188
75 189
75 190
85 191
85 192
85 193
85 194
85 195
85 196
85 197
85 198
85 199
1_173_85_2_csi_a2_23.dat
85 201
85 202
85 203
85 204
85 205
85 206
85 207
1_173_85_2_csi_a2_13.dat
85 209
85 210
85 211
85 212
85 213
85 214
85 215
85 216
1_173_85_2_csi_a2_28.dat
85 218
1_173_85_2_csi_a2_4.dat
85 220
(115, 30, 3)
(115, 421, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60 60
 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85]
(115, 421, 30, 3, 1)

Loaded dataset of 115 samples, each sized (421, 30, 3, 1)


Train on 92 samples
Test on 23 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 421, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 421, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 421, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 421, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 421, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 421, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 421, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 82 samples, validate on 10 samples
Epoch 1/30

32/82 [==========>...................] - ETA: 0s - loss: 0.4790 - mae: 0.5979 - mse: 0.4790
64/82 [======================>.......] - ETA: 0s - loss: 0.3873 - mae: 0.5144 - mse: 0.3873
82/82 [==============================] - 1s 10ms/step - loss: 0.3380 - mae: 0.4764 - mse: 0.3380 - val_loss: 0.0711 - val_mae: 0.2523 - val_mse: 0.0711
Epoch 2/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1468 - mae: 0.3333 - mse: 0.1468
64/82 [======================>.......] - ETA: 0s - loss: 0.1418 - mae: 0.3297 - mse: 0.1418
82/82 [==============================] - 0s 6ms/step - loss: 0.1494 - mae: 0.3350 - mse: 0.1494 - val_loss: 0.1283 - val_mae: 0.3060 - val_mse: 0.1283
Epoch 3/30

32/82 [==========>...................] - ETA: 0s - loss: 0.2022 - mae: 0.3942 - mse: 0.2022
64/82 [======================>.......] - ETA: 0s - loss: 0.1584 - mae: 0.3478 - mse: 0.1584
82/82 [==============================] - 0s 6ms/step - loss: 0.1510 - mae: 0.3421 - mse: 0.1510 - val_loss: 0.0509 - val_mae: 0.1976 - val_mse: 0.0509
Epoch 4/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0989 - mae: 0.2798 - mse: 0.0989
64/82 [======================>.......] - ETA: 0s - loss: 0.0880 - mae: 0.2545 - mse: 0.0880
82/82 [==============================] - 0s 6ms/step - loss: 0.0940 - mae: 0.2643 - mse: 0.0940 - val_loss: 0.0289 - val_mae: 0.1572 - val_mse: 0.0289
Epoch 5/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0957 - mae: 0.2576 - mse: 0.0957
64/82 [======================>.......] - ETA: 0s - loss: 0.1031 - mae: 0.2673 - mse: 0.1031
82/82 [==============================] - 0s 6ms/step - loss: 0.0969 - mae: 0.2556 - mse: 0.0969 - val_loss: 0.0218 - val_mae: 0.1253 - val_mse: 0.0218
Epoch 6/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0709 - mae: 0.2210 - mse: 0.0709
64/82 [======================>.......] - ETA: 0s - loss: 0.0755 - mae: 0.2304 - mse: 0.0755
82/82 [==============================] - 0s 6ms/step - loss: 0.0737 - mae: 0.2311 - mse: 0.0737 - val_loss: 0.0229 - val_mae: 0.1292 - val_mse: 0.0229
Epoch 7/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0710 - mae: 0.2124 - mse: 0.0710
64/82 [======================>.......] - ETA: 0s - loss: 0.0654 - mae: 0.2115 - mse: 0.0654
82/82 [==============================] - 0s 6ms/step - loss: 0.0668 - mae: 0.2141 - mse: 0.0668 - val_loss: 0.0160 - val_mae: 0.1090 - val_mse: 0.0160
Epoch 8/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0485 - mae: 0.1765 - mse: 0.0485
64/82 [======================>.......] - ETA: 0s - loss: 0.0540 - mae: 0.1848 - mse: 0.0540
82/82 [==============================] - 0s 5ms/step - loss: 0.0498 - mae: 0.1777 - mse: 0.0498 - val_loss: 0.0036 - val_mae: 0.0487 - val_mse: 0.0036
Epoch 9/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0367 - mae: 0.1545 - mse: 0.0367
64/82 [======================>.......] - ETA: 0s - loss: 0.0579 - mae: 0.1860 - mse: 0.0579
82/82 [==============================] - 0s 5ms/step - loss: 0.0619 - mae: 0.1873 - mse: 0.0619 - val_loss: 0.0025 - val_mae: 0.0420 - val_mse: 0.0025
Epoch 10/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0387 - mae: 0.1386 - mse: 0.0387
64/82 [======================>.......] - ETA: 0s - loss: 0.0526 - mae: 0.1703 - mse: 0.0526
82/82 [==============================] - 0s 6ms/step - loss: 0.0487 - mae: 0.1692 - mse: 0.0487 - val_loss: 0.0145 - val_mae: 0.0956 - val_mse: 0.0145
Epoch 11/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0312 - mae: 0.1378 - mse: 0.0312
64/82 [======================>.......] - ETA: 0s - loss: 0.0572 - mae: 0.1785 - mse: 0.0572
82/82 [==============================] - 0s 6ms/step - loss: 0.0539 - mae: 0.1771 - mse: 0.0539 - val_loss: 0.0110 - val_mae: 0.0815 - val_mse: 0.0110
Epoch 12/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0486 - mae: 0.1590 - mse: 0.0486
64/82 [======================>.......] - ETA: 0s - loss: 0.0377 - mae: 0.1430 - mse: 0.0377
82/82 [==============================] - 0s 6ms/step - loss: 0.0418 - mae: 0.1478 - mse: 0.0418 - val_loss: 0.0018 - val_mae: 0.0369 - val_mse: 0.0018
Epoch 13/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0412 - mae: 0.1512 - mse: 0.0412
64/82 [======================>.......] - ETA: 0s - loss: 0.0349 - mae: 0.1376 - mse: 0.0349
82/82 [==============================] - 0s 6ms/step - loss: 0.0356 - mae: 0.1374 - mse: 0.0356 - val_loss: 0.0020 - val_mae: 0.0395 - val_mse: 0.0020
Epoch 14/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0171 - mae: 0.1005 - mse: 0.0171
64/82 [======================>.......] - ETA: 0s - loss: 0.0237 - mae: 0.1156 - mse: 0.0237
82/82 [==============================] - 0s 6ms/step - loss: 0.0292 - mae: 0.1195 - mse: 0.0292 - val_loss: 0.0046 - val_mae: 0.0600 - val_mse: 0.0046
Epoch 15/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0231 - mae: 0.1073 - mse: 0.0231
64/82 [======================>.......] - ETA: 0s - loss: 0.0289 - mae: 0.1207 - mse: 0.0289
82/82 [==============================] - 0s 6ms/step - loss: 0.0306 - mae: 0.1267 - mse: 0.0306 - val_loss: 0.0071 - val_mae: 0.0714 - val_mse: 0.0071
Epoch 16/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0315 - mae: 0.1245 - mse: 0.0315
64/82 [======================>.......] - ETA: 0s - loss: 0.0344 - mae: 0.1397 - mse: 0.0344
82/82 [==============================] - 0s 6ms/step - loss: 0.0315 - mae: 0.1338 - mse: 0.0315 - val_loss: 0.0012 - val_mae: 0.0317 - val_mse: 0.0012
Epoch 17/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0234 - mae: 0.0966 - mse: 0.0234
64/82 [======================>.......] - ETA: 0s - loss: 0.0259 - mae: 0.1098 - mse: 0.0259
82/82 [==============================] - 0s 6ms/step - loss: 0.0279 - mae: 0.1153 - mse: 0.0279 - val_loss: 0.0044 - val_mae: 0.0491 - val_mse: 0.0044
Epoch 18/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0404 - mae: 0.1447 - mse: 0.0404
64/82 [======================>.......] - ETA: 0s - loss: 0.0419 - mae: 0.1482 - mse: 0.0419
82/82 [==============================] - 0s 6ms/step - loss: 0.0377 - mae: 0.1429 - mse: 0.0377 - val_loss: 0.0015 - val_mae: 0.0303 - val_mse: 0.0015
Epoch 19/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0233 - mae: 0.1159 - mse: 0.0233
64/82 [======================>.......] - ETA: 0s - loss: 0.0246 - mae: 0.1177 - mse: 0.0246
82/82 [==============================] - 0s 6ms/step - loss: 0.0230 - mae: 0.1111 - mse: 0.0230 - val_loss: 0.0018 - val_mae: 0.0389 - val_mse: 0.0018
Epoch 20/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0443 - mae: 0.1557 - mse: 0.0443
64/82 [======================>.......] - ETA: 0s - loss: 0.0375 - mae: 0.1409 - mse: 0.0375
82/82 [==============================] - 0s 6ms/step - loss: 0.0317 - mae: 0.1267 - mse: 0.0317 - val_loss: 0.0103 - val_mae: 0.0847 - val_mse: 0.0103
Epoch 21/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0506 - mae: 0.1604 - mse: 0.0506
64/82 [======================>.......] - ETA: 0s - loss: 0.0358 - mae: 0.1387 - mse: 0.0358
82/82 [==============================] - 0s 6ms/step - loss: 0.0334 - mae: 0.1363 - mse: 0.0334 - val_loss: 0.0051 - val_mae: 0.0562 - val_mse: 0.0051
Epoch 22/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0272 - mae: 0.1311 - mse: 0.0272
64/82 [======================>.......] - ETA: 0s - loss: 0.0296 - mae: 0.1302 - mse: 0.0296
82/82 [==============================] - 0s 5ms/step - loss: 0.0294 - mae: 0.1298 - mse: 0.0294 - val_loss: 0.0026 - val_mae: 0.0406 - val_mse: 0.0026
Epoch 23/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0316 - mae: 0.1458 - mse: 0.0316
64/82 [======================>.......] - ETA: 0s - loss: 0.0275 - mae: 0.1336 - mse: 0.0275
82/82 [==============================] - 0s 6ms/step - loss: 0.0251 - mae: 0.1255 - mse: 0.0251 - val_loss: 0.0017 - val_mae: 0.0278 - val_mse: 0.0017
Epoch 24/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0244 - mae: 0.1154 - mse: 0.0244
64/82 [======================>.......] - ETA: 0s - loss: 0.0249 - mae: 0.1221 - mse: 0.0249
82/82 [==============================] - 0s 6ms/step - loss: 0.0231 - mae: 0.1163 - mse: 0.0231 - val_loss: 0.0026 - val_mae: 0.0411 - val_mse: 0.0026
Epoch 25/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0143 - mae: 0.0885 - mse: 0.0143
64/82 [======================>.......] - ETA: 0s - loss: 0.0175 - mae: 0.0952 - mse: 0.0175
82/82 [==============================] - 0s 6ms/step - loss: 0.0192 - mae: 0.0990 - mse: 0.0192 - val_loss: 0.0041 - val_mae: 0.0493 - val_mse: 0.0041
Epoch 26/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0143 - mae: 0.0898 - mse: 0.0143
64/82 [======================>.......] - ETA: 0s - loss: 0.0215 - mae: 0.1030 - mse: 0.0215
82/82 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.1026 - mse: 0.0215 - val_loss: 0.0019 - val_mae: 0.0370 - val_mse: 0.0019
Epoch 27/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0188 - mae: 0.1020 - mse: 0.0188
64/82 [======================>.......] - ETA: 0s - loss: 0.0226 - mae: 0.1093 - mse: 0.0226
82/82 [==============================] - 0s 6ms/step - loss: 0.0244 - mae: 0.1135 - mse: 0.0244 - val_loss: 9.9409e-04 - val_mae: 0.0215 - val_mse: 9.9409e-04
Epoch 28/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0291 - mae: 0.1238 - mse: 0.0291
64/82 [======================>.......] - ETA: 0s - loss: 0.0219 - mae: 0.1037 - mse: 0.0219
82/82 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1056 - mse: 0.0221 - val_loss: 0.0020 - val_mae: 0.0363 - val_mse: 0.0020
Epoch 29/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0229 - mae: 0.1211 - mse: 0.0229
64/82 [======================>.......] - ETA: 0s - loss: 0.0264 - mae: 0.1214 - mse: 0.0264
82/82 [==============================] - 0s 6ms/step - loss: 0.0246 - mae: 0.1151 - mse: 0.0246 - val_loss: 0.0027 - val_mae: 0.0438 - val_mse: 0.0027
Epoch 30/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0260 - mae: 0.1024 - mse: 0.0260
64/82 [======================>.......] - ETA: 0s - loss: 0.0223 - mae: 0.0980 - mse: 0.0223
82/82 [==============================] - 0s 6ms/step - loss: 0.0204 - mae: 0.0955 - mse: 0.0204 - val_loss: 0.0012 - val_mae: 0.0283 - val_mse: 0.0012
Saving trained model...
105
Testing...
heightdiff= [0.         0.         0.         5.57374573 0.         0.        ]
average prediction= [1.9290459]
baseline= 10.108695652173912
eachuser= [0. 0. 0. 3. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.8579152425130208
85 -:- nan
60 -:- nan
['train-weight-2.py', '1']
2_155_65_2_csi_a2_20.dat
65 2
2_155_65_2_csi_a2_23.dat
65 4
2_155_65_2_csi_a2_16.dat
65 6
65 7
65 8
65 9
2_155_65_2_csi_a2_1.dat
2_155_65_2_csi_a2_21.dat
65 12
65 13
65 14
2_155_65_2_csi_a2_25.dat
2_155_65_2_csi_a2_18.dat
2_155_65_2_csi_a2_17.dat
2_155_65_2_csi_a2_14.dat
65 19
65 20
65 21
65 22
65 23
65 24
2_155_65_2_csi_a2_27.dat
2_155_65_2_csi_a2_24.dat
65 27
65 28
2_155_65_2_csi_a2_7.dat
65 30
60 31
60 32
60 33
2_170_60_2_csi_a2_2.dat
60 35
60 36
60 37
60 38
2_170_60_2_csi_a2_10.dat
60 40
1_165_65_2_csi_a2_30.dat
1_165_65_2_csi_a2_15.dat
1_165_65_2_csi_a2_10.dat
1_165_65_2_csi_a2_21.dat
1_165_65_2_csi_a2_9.dat
1_165_65_2_csi_a2_13.dat
1_165_65_2_csi_a2_19.dat
1_165_65_2_csi_a2_18.dat
1_165_65_2_csi_a2_7.dat
1_165_65_2_csi_a2_20.dat
1_165_65_2_csi_a2_11.dat
1_165_65_2_csi_a2_26.dat
1_165_65_2_csi_a2_16.dat
1_165_65_2_csi_a2_28.dat
1_165_65_2_csi_a2_5.dat
1_165_65_2_csi_a2_6.dat
1_165_65_2_csi_a2_25.dat
1_165_65_2_csi_a2_29.dat
1_165_65_2_csi_a2_23.dat
1_165_65_2_csi_a2_3.dat
1_165_65_2_csi_a2_27.dat
1_165_65_2_csi_a2_2.dat
1_165_65_2_csi_a2_17.dat
1_165_65_2_csi_a2_8.dat
1_165_65_2_csi_a2_14.dat
1_165_65_2_csi_a2_1.dat
1_165_65_2_csi_a2_24.dat
1_165_65_2_csi_a2_4.dat
1_165_65_2_csi_a2_22.dat
1_165_65_2_csi_a2_12.dat
50 71
50 72
50 73
50 74
50 75
50 76
50 77
2_165_50_2_csi_a2_13.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
50 97
50 98
2_165_50_2_csi_a2_24.dat
50 100
1_175_70_2_csi_a2_25.dat
70 102
1_175_70_2_csi_a2_20.dat
1_175_70_2_csi_a2_28.dat
70 105
1_175_70_2_csi_a2_22.dat
1_175_70_2_csi_a2_5.dat
1_175_70_2_csi_a2_11.dat
1_175_70_2_csi_a2_6.dat
1_175_70_2_csi_a2_8.dat
1_175_70_2_csi_a2_3.dat
1_175_70_2_csi_a2_16.dat
1_175_70_2_csi_a2_19.dat
1_175_70_2_csi_a2_1.dat
1_175_70_2_csi_a2_27.dat
70 116
1_175_70_2_csi_a2_18.dat
1_175_70_2_csi_a2_23.dat
1_175_70_2_csi_a2_21.dat
1_175_70_2_csi_a2_12.dat
1_175_70_2_csi_a2_30.dat
1_175_70_2_csi_a2_15.dat
1_175_70_2_csi_a2_17.dat
1_175_70_2_csi_a2_14.dat
1_175_70_2_csi_a2_9.dat
1_175_70_2_csi_a2_24.dat
1_175_70_2_csi_a2_10.dat
1_175_70_2_csi_a2_4.dat
1_175_70_2_csi_a2_29.dat
1_175_70_2_csi_a2_13.dat
1_180_85_2_csi_a2_22.dat
1_180_85_2_csi_a2_17.dat
1_180_85_2_csi_a2_15.dat
1_180_85_2_csi_a2_21.dat
85 135
1_180_85_2_csi_a2_7.dat
1_180_85_2_csi_a2_25.dat
1_180_85_2_csi_a2_19.dat
85 139
1_180_85_2_csi_a2_6.dat
1_180_85_2_csi_a2_1.dat
1_180_85_2_csi_a2_16.dat
1_180_85_2_csi_a2_14.dat
1_180_85_2_csi_a2_23.dat
1_180_85_2_csi_a2_24.dat
1_180_85_2_csi_a2_8.dat
85 147
1_180_85_2_csi_a2_13.dat
1_180_85_2_csi_a2_29.dat
1_180_85_2_csi_a2_9.dat
1_180_85_2_csi_a2_18.dat
1_180_85_2_csi_a2_28.dat
1_180_85_2_csi_a2_12.dat
1_180_85_2_csi_a2_30.dat
1_180_85_2_csi_a2_20.dat
85 156
1_180_85_2_csi_a2_26.dat
1_180_85_2_csi_a2_11.dat
85 159
1_180_85_2_csi_a2_10.dat
75 161
75 162
75 163
75 164
75 165
75 166
1_180_75_2_csi_a2_9.dat
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
75 180
75 181
1_180_75_2_csi_a2_1.dat
75 183
75 184
75 185
1_180_75_2_csi_a2_4.dat
75 187
75 188
75 189
75 190
85 191
85 192
85 193
85 194
85 195
85 196
85 197
85 198
85 199
1_173_85_2_csi_a2_23.dat
85 201
85 202
85 203
85 204
85 205
85 206
85 207
1_173_85_2_csi_a2_13.dat
85 209
85 210
85 211
85 212
85 213
85 214
85 215
85 216
1_173_85_2_csi_a2_28.dat
85 218
1_173_85_2_csi_a2_4.dat
85 220
(115, 30, 3)
(115, 421, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60 60
 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85]
(115, 421, 30, 3, 1)

Loaded dataset of 115 samples, each sized (421, 30, 3, 1)


Train on 92 samples
Test on 23 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 421, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 421, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 421, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 421, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 421, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 421, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 421, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 82 samples, validate on 10 samples
Epoch 1/30

32/82 [==========>...................] - ETA: 0s - loss: 0.4328 - mae: 0.5371 - mse: 0.4328
64/82 [======================>.......] - ETA: 0s - loss: 0.4002 - mae: 0.5278 - mse: 0.4002
82/82 [==============================] - 1s 10ms/step - loss: 0.4007 - mae: 0.5342 - mse: 0.4007 - val_loss: 0.1980 - val_mae: 0.3774 - val_mse: 0.1980
Epoch 2/30

32/82 [==========>...................] - ETA: 0s - loss: 0.2965 - mae: 0.4826 - mse: 0.2965
64/82 [======================>.......] - ETA: 0s - loss: 0.2715 - mae: 0.4607 - mse: 0.2715
82/82 [==============================] - 0s 6ms/step - loss: 0.2578 - mae: 0.4533 - mse: 0.2578 - val_loss: 0.1570 - val_mae: 0.3576 - val_mse: 0.1570
Epoch 3/30

32/82 [==========>...................] - ETA: 0s - loss: 0.2446 - mae: 0.4242 - mse: 0.2446
64/82 [======================>.......] - ETA: 0s - loss: 0.2324 - mae: 0.4076 - mse: 0.2324
82/82 [==============================] - 0s 6ms/step - loss: 0.2120 - mae: 0.3906 - mse: 0.2120 - val_loss: 0.1343 - val_mae: 0.3135 - val_mse: 0.1343
Epoch 4/30

32/82 [==========>...................] - ETA: 0s - loss: 0.2601 - mae: 0.4568 - mse: 0.2601
64/82 [======================>.......] - ETA: 0s - loss: 0.2139 - mae: 0.4023 - mse: 0.2139
82/82 [==============================] - 0s 5ms/step - loss: 0.1978 - mae: 0.3845 - mse: 0.1978 - val_loss: 0.0912 - val_mae: 0.2555 - val_mse: 0.0912
Epoch 5/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1277 - mae: 0.3082 - mse: 0.1277
64/82 [======================>.......] - ETA: 0s - loss: 0.1459 - mae: 0.3338 - mse: 0.1459
82/82 [==============================] - 0s 5ms/step - loss: 0.1464 - mae: 0.3386 - mse: 0.1464 - val_loss: 0.0658 - val_mae: 0.2113 - val_mse: 0.0658
Epoch 6/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1384 - mae: 0.3352 - mse: 0.1384
64/82 [======================>.......] - ETA: 0s - loss: 0.1136 - mae: 0.2921 - mse: 0.1136
82/82 [==============================] - 0s 6ms/step - loss: 0.1161 - mae: 0.2955 - mse: 0.1161 - val_loss: 0.0436 - val_mae: 0.1715 - val_mse: 0.0436
Epoch 7/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1022 - mae: 0.2697 - mse: 0.1022
64/82 [======================>.......] - ETA: 0s - loss: 0.0947 - mae: 0.2627 - mse: 0.0947
82/82 [==============================] - 0s 6ms/step - loss: 0.0890 - mae: 0.2497 - mse: 0.0890 - val_loss: 0.0270 - val_mae: 0.1213 - val_mse: 0.0270
Epoch 8/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0700 - mae: 0.2231 - mse: 0.0700
64/82 [======================>.......] - ETA: 0s - loss: 0.0642 - mae: 0.2164 - mse: 0.0642
82/82 [==============================] - 0s 6ms/step - loss: 0.0665 - mae: 0.2246 - mse: 0.0665 - val_loss: 0.0249 - val_mae: 0.1402 - val_mse: 0.0249
Epoch 9/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0436 - mae: 0.1822 - mse: 0.0436
64/82 [======================>.......] - ETA: 0s - loss: 0.0538 - mae: 0.2038 - mse: 0.0538
82/82 [==============================] - 0s 6ms/step - loss: 0.0553 - mae: 0.1997 - mse: 0.0553 - val_loss: 0.0138 - val_mae: 0.1019 - val_mse: 0.0138
Epoch 10/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0328 - mae: 0.1523 - mse: 0.0328
64/82 [======================>.......] - ETA: 0s - loss: 0.0458 - mae: 0.1712 - mse: 0.0458
82/82 [==============================] - 0s 6ms/step - loss: 0.0461 - mae: 0.1702 - mse: 0.0461 - val_loss: 0.0110 - val_mae: 0.0847 - val_mse: 0.0110
Epoch 11/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0570 - mae: 0.1959 - mse: 0.0570
64/82 [======================>.......] - ETA: 0s - loss: 0.0503 - mae: 0.1719 - mse: 0.0503
82/82 [==============================] - 0s 6ms/step - loss: 0.0487 - mae: 0.1690 - mse: 0.0487 - val_loss: 0.0121 - val_mae: 0.0979 - val_mse: 0.0121
Epoch 12/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0479 - mae: 0.1817 - mse: 0.0479
64/82 [======================>.......] - ETA: 0s - loss: 0.0552 - mae: 0.1937 - mse: 0.0552
82/82 [==============================] - 0s 6ms/step - loss: 0.0546 - mae: 0.1908 - mse: 0.0546 - val_loss: 0.0183 - val_mae: 0.1319 - val_mse: 0.0183
Epoch 13/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0466 - mae: 0.1679 - mse: 0.0466
64/82 [======================>.......] - ETA: 0s - loss: 0.0430 - mae: 0.1670 - mse: 0.0430
82/82 [==============================] - 0s 5ms/step - loss: 0.0451 - mae: 0.1717 - mse: 0.0451 - val_loss: 0.0231 - val_mae: 0.1460 - val_mse: 0.0231
Epoch 14/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0440 - mae: 0.1753 - mse: 0.0440
64/82 [======================>.......] - ETA: 0s - loss: 0.0494 - mae: 0.1816 - mse: 0.0494
82/82 [==============================] - 0s 6ms/step - loss: 0.0496 - mae: 0.1826 - mse: 0.0496 - val_loss: 0.0181 - val_mae: 0.1058 - val_mse: 0.0181
Epoch 15/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0360 - mae: 0.1491 - mse: 0.0360
64/82 [======================>.......] - ETA: 0s - loss: 0.0330 - mae: 0.1382 - mse: 0.0330
82/82 [==============================] - 0s 6ms/step - loss: 0.0402 - mae: 0.1497 - mse: 0.0402 - val_loss: 0.0098 - val_mae: 0.0841 - val_mse: 0.0098
Epoch 16/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0301 - mae: 0.1337 - mse: 0.0301
64/82 [======================>.......] - ETA: 0s - loss: 0.0350 - mae: 0.1423 - mse: 0.0350
82/82 [==============================] - 0s 6ms/step - loss: 0.0349 - mae: 0.1411 - mse: 0.0349 - val_loss: 0.0107 - val_mae: 0.0922 - val_mse: 0.0107
Epoch 17/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0273 - mae: 0.1209 - mse: 0.0273
64/82 [======================>.......] - ETA: 0s - loss: 0.0397 - mae: 0.1544 - mse: 0.0397
82/82 [==============================] - 0s 6ms/step - loss: 0.0373 - mae: 0.1507 - mse: 0.0373 - val_loss: 0.0029 - val_mae: 0.0485 - val_mse: 0.0029
Epoch 18/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0341 - mae: 0.1335 - mse: 0.0341
64/82 [======================>.......] - ETA: 0s - loss: 0.0330 - mae: 0.1291 - mse: 0.0330
82/82 [==============================] - 0s 6ms/step - loss: 0.0333 - mae: 0.1351 - mse: 0.0333 - val_loss: 0.0034 - val_mae: 0.0494 - val_mse: 0.0034
Epoch 19/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0180 - mae: 0.0946 - mse: 0.0180
64/82 [======================>.......] - ETA: 0s - loss: 0.0263 - mae: 0.1149 - mse: 0.0263
82/82 [==============================] - 0s 6ms/step - loss: 0.0307 - mae: 0.1275 - mse: 0.0307 - val_loss: 0.0020 - val_mae: 0.0369 - val_mse: 0.0020
Epoch 20/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0459 - mae: 0.1596 - mse: 0.0459
64/82 [======================>.......] - ETA: 0s - loss: 0.0358 - mae: 0.1449 - mse: 0.0358
82/82 [==============================] - 0s 6ms/step - loss: 0.0328 - mae: 0.1356 - mse: 0.0328 - val_loss: 0.0034 - val_mae: 0.0496 - val_mse: 0.0034
Epoch 21/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0164 - mae: 0.1035 - mse: 0.0164
64/82 [======================>.......] - ETA: 0s - loss: 0.0254 - mae: 0.1152 - mse: 0.0254
82/82 [==============================] - 0s 6ms/step - loss: 0.0219 - mae: 0.1061 - mse: 0.0219 - val_loss: 0.0053 - val_mae: 0.0640 - val_mse: 0.0053
Epoch 22/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0261 - mae: 0.1160 - mse: 0.0261
64/82 [======================>.......] - ETA: 0s - loss: 0.0208 - mae: 0.1058 - mse: 0.0208
82/82 [==============================] - 0s 6ms/step - loss: 0.0252 - mae: 0.1176 - mse: 0.0252 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076
Epoch 23/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0260 - mae: 0.1306 - mse: 0.0260
64/82 [======================>.......] - ETA: 0s - loss: 0.0245 - mae: 0.1234 - mse: 0.0245
82/82 [==============================] - 0s 6ms/step - loss: 0.0230 - mae: 0.1195 - mse: 0.0230 - val_loss: 0.0084 - val_mae: 0.0763 - val_mse: 0.0084
Epoch 24/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0251 - mae: 0.1128 - mse: 0.0251
64/82 [======================>.......] - ETA: 0s - loss: 0.0253 - mae: 0.1140 - mse: 0.0253
82/82 [==============================] - 0s 6ms/step - loss: 0.0249 - mae: 0.1135 - mse: 0.0249 - val_loss: 0.0055 - val_mae: 0.0574 - val_mse: 0.0055
Epoch 25/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0104 - mae: 0.0900 - mse: 0.0104
64/82 [======================>.......] - ETA: 0s - loss: 0.0166 - mae: 0.0972 - mse: 0.0166
82/82 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 0.1050 - mse: 0.0193 - val_loss: 0.0071 - val_mae: 0.0827 - val_mse: 0.0071
Epoch 26/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0353 - mae: 0.1406 - mse: 0.0353
64/82 [======================>.......] - ETA: 0s - loss: 0.0261 - mae: 0.1188 - mse: 0.0261
82/82 [==============================] - 0s 6ms/step - loss: 0.0245 - mae: 0.1175 - mse: 0.0245 - val_loss: 0.0066 - val_mae: 0.0736 - val_mse: 0.0066
Epoch 27/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0327 - mae: 0.1280 - mse: 0.0327
64/82 [======================>.......] - ETA: 0s - loss: 0.0247 - mae: 0.1122 - mse: 0.0247
82/82 [==============================] - 0s 6ms/step - loss: 0.0248 - mae: 0.1139 - mse: 0.0248 - val_loss: 0.0062 - val_mae: 0.0563 - val_mse: 0.0062
Epoch 28/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0203 - mae: 0.1055 - mse: 0.0203
64/82 [======================>.......] - ETA: 0s - loss: 0.0213 - mae: 0.1096 - mse: 0.0213
82/82 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 0.1032 - mse: 0.0187 - val_loss: 0.0049 - val_mae: 0.0610 - val_mse: 0.0049
Epoch 29/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0190 - mae: 0.0950 - mse: 0.0190
64/82 [======================>.......] - ETA: 0s - loss: 0.0258 - mae: 0.1124 - mse: 0.0258
82/82 [==============================] - 0s 6ms/step - loss: 0.0242 - mae: 0.1110 - mse: 0.0242 - val_loss: 0.0047 - val_mae: 0.0606 - val_mse: 0.0047
Epoch 30/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0280 - mae: 0.1209 - mse: 0.0280
64/82 [======================>.......] - ETA: 0s - loss: 0.0251 - mae: 0.1127 - mse: 0.0251
82/82 [==============================] - 0s 6ms/step - loss: 0.0224 - mae: 0.1077 - mse: 0.0224 - val_loss: 0.0040 - val_mae: 0.0488 - val_mse: 0.0040
Saving trained model...
105
Testing...
heightdiff= [ 0.          0.          0.         18.10601044  0.          0.        ]
average prediction= [2.1816752]
baseline= 11.41304347826087
eachuser= [0. 0. 0. 7. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 2.586572919573103
85 -:- nan
60 -:- nan
['train-weight-2.py', '1']
2_155_65_2_csi_a2_20.dat
65 2
2_155_65_2_csi_a2_23.dat
65 4
2_155_65_2_csi_a2_16.dat
65 6
65 7
65 8
65 9
2_155_65_2_csi_a2_1.dat
2_155_65_2_csi_a2_21.dat
65 12
65 13
65 14
2_155_65_2_csi_a2_25.dat
2_155_65_2_csi_a2_18.dat
2_155_65_2_csi_a2_17.dat
2_155_65_2_csi_a2_14.dat
65 19
65 20
65 21
65 22
65 23
65 24
2_155_65_2_csi_a2_27.dat
2_155_65_2_csi_a2_24.dat
65 27
65 28
2_155_65_2_csi_a2_7.dat
65 30
60 31
60 32
60 33
2_170_60_2_csi_a2_2.dat
60 35
60 36
60 37
60 38
2_170_60_2_csi_a2_10.dat
60 40
1_165_65_2_csi_a2_30.dat
1_165_65_2_csi_a2_15.dat
1_165_65_2_csi_a2_10.dat
1_165_65_2_csi_a2_21.dat
1_165_65_2_csi_a2_9.dat
1_165_65_2_csi_a2_13.dat
1_165_65_2_csi_a2_19.dat
1_165_65_2_csi_a2_18.dat
1_165_65_2_csi_a2_7.dat
1_165_65_2_csi_a2_20.dat
1_165_65_2_csi_a2_11.dat
1_165_65_2_csi_a2_26.dat
1_165_65_2_csi_a2_16.dat
1_165_65_2_csi_a2_28.dat
1_165_65_2_csi_a2_5.dat
1_165_65_2_csi_a2_6.dat
1_165_65_2_csi_a2_25.dat
1_165_65_2_csi_a2_29.dat
1_165_65_2_csi_a2_23.dat
1_165_65_2_csi_a2_3.dat
1_165_65_2_csi_a2_27.dat
1_165_65_2_csi_a2_2.dat
1_165_65_2_csi_a2_17.dat
1_165_65_2_csi_a2_8.dat
1_165_65_2_csi_a2_14.dat
1_165_65_2_csi_a2_1.dat
1_165_65_2_csi_a2_24.dat
1_165_65_2_csi_a2_4.dat
1_165_65_2_csi_a2_22.dat
1_165_65_2_csi_a2_12.dat
50 71
50 72
50 73
50 74
50 75
50 76
50 77
2_165_50_2_csi_a2_13.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
50 97
50 98
2_165_50_2_csi_a2_24.dat
50 100
1_175_70_2_csi_a2_25.dat
70 102
1_175_70_2_csi_a2_20.dat
1_175_70_2_csi_a2_28.dat
70 105
1_175_70_2_csi_a2_22.dat
1_175_70_2_csi_a2_5.dat
1_175_70_2_csi_a2_11.dat
1_175_70_2_csi_a2_6.dat
1_175_70_2_csi_a2_8.dat
1_175_70_2_csi_a2_3.dat
1_175_70_2_csi_a2_16.dat
1_175_70_2_csi_a2_19.dat
1_175_70_2_csi_a2_1.dat
1_175_70_2_csi_a2_27.dat
70 116
1_175_70_2_csi_a2_18.dat
1_175_70_2_csi_a2_23.dat
1_175_70_2_csi_a2_21.dat
1_175_70_2_csi_a2_12.dat
1_175_70_2_csi_a2_30.dat
1_175_70_2_csi_a2_15.dat
1_175_70_2_csi_a2_17.dat
1_175_70_2_csi_a2_14.dat
1_175_70_2_csi_a2_9.dat
1_175_70_2_csi_a2_24.dat
1_175_70_2_csi_a2_10.dat
1_175_70_2_csi_a2_4.dat
1_175_70_2_csi_a2_29.dat
1_175_70_2_csi_a2_13.dat
1_180_85_2_csi_a2_22.dat
1_180_85_2_csi_a2_17.dat
1_180_85_2_csi_a2_15.dat
1_180_85_2_csi_a2_21.dat
85 135
1_180_85_2_csi_a2_7.dat
1_180_85_2_csi_a2_25.dat
1_180_85_2_csi_a2_19.dat
85 139
1_180_85_2_csi_a2_6.dat
1_180_85_2_csi_a2_1.dat
1_180_85_2_csi_a2_16.dat
1_180_85_2_csi_a2_14.dat
1_180_85_2_csi_a2_23.dat
1_180_85_2_csi_a2_24.dat
1_180_85_2_csi_a2_8.dat
85 147
1_180_85_2_csi_a2_13.dat
1_180_85_2_csi_a2_29.dat
1_180_85_2_csi_a2_9.dat
1_180_85_2_csi_a2_18.dat
1_180_85_2_csi_a2_28.dat
1_180_85_2_csi_a2_12.dat
1_180_85_2_csi_a2_30.dat
1_180_85_2_csi_a2_20.dat
85 156
1_180_85_2_csi_a2_26.dat
1_180_85_2_csi_a2_11.dat
85 159
1_180_85_2_csi_a2_10.dat
75 161
75 162
75 163
75 164
75 165
75 166
1_180_75_2_csi_a2_9.dat
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
75 180
75 181
1_180_75_2_csi_a2_1.dat
75 183
75 184
75 185
1_180_75_2_csi_a2_4.dat
75 187
75 188
75 189
75 190
85 191
85 192
85 193
85 194
85 195
85 196
85 197
85 198
85 199
1_173_85_2_csi_a2_23.dat
85 201
85 202
85 203
85 204
85 205
85 206
85 207
1_173_85_2_csi_a2_13.dat
85 209
85 210
85 211
85 212
85 213
85 214
85 215
85 216
1_173_85_2_csi_a2_28.dat
85 218
1_173_85_2_csi_a2_4.dat
85 220
(115, 30, 3)
(115, 421, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60 60
 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85]
(115, 421, 30, 3, 1)

Loaded dataset of 115 samples, each sized (421, 30, 3, 1)


Train on 92 samples
Test on 23 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 421, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 421, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 421, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 421, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 421, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 421, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 421, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 82 samples, validate on 10 samples
Epoch 1/30

32/82 [==========>...................] - ETA: 0s - loss: 0.3263 - mae: 0.5028 - mse: 0.3263
64/82 [======================>.......] - ETA: 0s - loss: 0.3046 - mae: 0.4900 - mse: 0.3046
82/82 [==============================] - 1s 10ms/step - loss: 0.2662 - mae: 0.4536 - mse: 0.2662 - val_loss: 0.1346 - val_mae: 0.3154 - val_mse: 0.1346
Epoch 2/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1845 - mae: 0.3624 - mse: 0.1845
64/82 [======================>.......] - ETA: 0s - loss: 0.1614 - mae: 0.3294 - mse: 0.1614
82/82 [==============================] - 0s 6ms/step - loss: 0.1534 - mae: 0.3226 - mse: 0.1534 - val_loss: 0.0775 - val_mae: 0.2231 - val_mse: 0.0775
Epoch 3/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1346 - mae: 0.3032 - mse: 0.1346
64/82 [======================>.......] - ETA: 0s - loss: 0.1339 - mae: 0.3108 - mse: 0.1339
82/82 [==============================] - 0s 6ms/step - loss: 0.1295 - mae: 0.3046 - mse: 0.1295 - val_loss: 0.0455 - val_mae: 0.1644 - val_mse: 0.0455
Epoch 4/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0702 - mae: 0.2262 - mse: 0.0702
64/82 [======================>.......] - ETA: 0s - loss: 0.0733 - mae: 0.2232 - mse: 0.0733
82/82 [==============================] - 0s 5ms/step - loss: 0.0713 - mae: 0.2188 - mse: 0.0713 - val_loss: 0.0295 - val_mae: 0.1062 - val_mse: 0.0295
Epoch 5/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0493 - mae: 0.1771 - mse: 0.0493
64/82 [======================>.......] - ETA: 0s - loss: 0.0623 - mae: 0.2031 - mse: 0.0623
82/82 [==============================] - 0s 5ms/step - loss: 0.0597 - mae: 0.1945 - mse: 0.0597 - val_loss: 0.0164 - val_mae: 0.0993 - val_mse: 0.0164
Epoch 6/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0337 - mae: 0.1541 - mse: 0.0337
64/82 [======================>.......] - ETA: 0s - loss: 0.0492 - mae: 0.1822 - mse: 0.0492
82/82 [==============================] - 0s 6ms/step - loss: 0.0459 - mae: 0.1735 - mse: 0.0459 - val_loss: 0.0208 - val_mae: 0.1379 - val_mse: 0.0208
Epoch 7/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0515 - mae: 0.1699 - mse: 0.0515
64/82 [======================>.......] - ETA: 0s - loss: 0.0465 - mae: 0.1646 - mse: 0.0465
82/82 [==============================] - 0s 6ms/step - loss: 0.0444 - mae: 0.1579 - mse: 0.0444 - val_loss: 0.0265 - val_mae: 0.1531 - val_mse: 0.0265
Epoch 8/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0386 - mae: 0.1373 - mse: 0.0386
64/82 [======================>.......] - ETA: 0s - loss: 0.0438 - mae: 0.1520 - mse: 0.0438
82/82 [==============================] - 0s 6ms/step - loss: 0.0418 - mae: 0.1529 - mse: 0.0418 - val_loss: 0.0285 - val_mae: 0.1599 - val_mse: 0.0285
Epoch 9/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0405 - mae: 0.1634 - mse: 0.0405
64/82 [======================>.......] - ETA: 0s - loss: 0.0304 - mae: 0.1349 - mse: 0.0304
82/82 [==============================] - 0s 6ms/step - loss: 0.0353 - mae: 0.1446 - mse: 0.0353 - val_loss: 0.0366 - val_mae: 0.1558 - val_mse: 0.0366
Epoch 10/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0372 - mae: 0.1534 - mse: 0.0372
64/82 [======================>.......] - ETA: 0s - loss: 0.0350 - mae: 0.1481 - mse: 0.0350
82/82 [==============================] - 0s 6ms/step - loss: 0.0338 - mae: 0.1450 - mse: 0.0338 - val_loss: 0.0227 - val_mae: 0.1292 - val_mse: 0.0227
Epoch 11/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0257 - mae: 0.1171 - mse: 0.0257
64/82 [======================>.......] - ETA: 0s - loss: 0.0323 - mae: 0.1299 - mse: 0.0323
82/82 [==============================] - 0s 5ms/step - loss: 0.0324 - mae: 0.1333 - mse: 0.0324 - val_loss: 0.0201 - val_mae: 0.1134 - val_mse: 0.0201
Epoch 12/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0341 - mae: 0.1343 - mse: 0.0341
64/82 [======================>.......] - ETA: 0s - loss: 0.0303 - mae: 0.1312 - mse: 0.0303
82/82 [==============================] - 0s 6ms/step - loss: 0.0286 - mae: 0.1282 - mse: 0.0286 - val_loss: 0.0287 - val_mae: 0.1285 - val_mse: 0.0287
Epoch 13/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0335 - mae: 0.1436 - mse: 0.0335
64/82 [======================>.......] - ETA: 0s - loss: 0.0304 - mae: 0.1379 - mse: 0.0304
82/82 [==============================] - 0s 6ms/step - loss: 0.0296 - mae: 0.1338 - mse: 0.0296 - val_loss: 0.0215 - val_mae: 0.1154 - val_mse: 0.0215
Epoch 14/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0195 - mae: 0.1077 - mse: 0.0195
64/82 [======================>.......] - ETA: 0s - loss: 0.0248 - mae: 0.1234 - mse: 0.0248
82/82 [==============================] - 0s 6ms/step - loss: 0.0262 - mae: 0.1217 - mse: 0.0262 - val_loss: 0.0153 - val_mae: 0.1007 - val_mse: 0.0153
Epoch 15/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0375 - mae: 0.1404 - mse: 0.0375
64/82 [======================>.......] - ETA: 0s - loss: 0.0292 - mae: 0.1264 - mse: 0.0292
82/82 [==============================] - 0s 6ms/step - loss: 0.0281 - mae: 0.1232 - mse: 0.0281 - val_loss: 0.0169 - val_mae: 0.1015 - val_mse: 0.0169
Epoch 16/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0168 - mae: 0.0984 - mse: 0.0168
64/82 [======================>.......] - ETA: 0s - loss: 0.0247 - mae: 0.1156 - mse: 0.0247
82/82 [==============================] - 0s 6ms/step - loss: 0.0268 - mae: 0.1245 - mse: 0.0268 - val_loss: 0.0227 - val_mae: 0.1114 - val_mse: 0.0227
Epoch 17/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0187 - mae: 0.1023 - mse: 0.0187
64/82 [======================>.......] - ETA: 0s - loss: 0.0243 - mae: 0.1156 - mse: 0.0243
82/82 [==============================] - 0s 6ms/step - loss: 0.0236 - mae: 0.1151 - mse: 0.0236 - val_loss: 0.0310 - val_mae: 0.1389 - val_mse: 0.0310
Epoch 18/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0229 - mae: 0.1250 - mse: 0.0229
64/82 [======================>.......] - ETA: 0s - loss: 0.0207 - mae: 0.1169 - mse: 0.0207
82/82 [==============================] - 0s 6ms/step - loss: 0.0207 - mae: 0.1179 - mse: 0.0207 - val_loss: 0.0476 - val_mae: 0.1489 - val_mse: 0.0476
Epoch 19/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0191 - mae: 0.1041 - mse: 0.0191
64/82 [======================>.......] - ETA: 0s - loss: 0.0244 - mae: 0.1176 - mse: 0.0244
82/82 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1100 - mse: 0.0221 - val_loss: 0.0460 - val_mae: 0.1486 - val_mse: 0.0460
Epoch 20/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0201 - mae: 0.1094 - mse: 0.0201
64/82 [======================>.......] - ETA: 0s - loss: 0.0248 - mae: 0.1217 - mse: 0.0248
82/82 [==============================] - 0s 6ms/step - loss: 0.0236 - mae: 0.1173 - mse: 0.0236 - val_loss: 0.0356 - val_mae: 0.1519 - val_mse: 0.0356
Epoch 21/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0374 - mae: 0.1408 - mse: 0.0374
64/82 [======================>.......] - ETA: 0s - loss: 0.0287 - mae: 0.1186 - mse: 0.0287
82/82 [==============================] - 0s 6ms/step - loss: 0.0244 - mae: 0.1101 - mse: 0.0244 - val_loss: 0.0300 - val_mae: 0.1361 - val_mse: 0.0300
Epoch 22/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0216 - mae: 0.1029 - mse: 0.0216
64/82 [======================>.......] - ETA: 0s - loss: 0.0271 - mae: 0.1107 - mse: 0.0271
82/82 [==============================] - 0s 6ms/step - loss: 0.0280 - mae: 0.1148 - mse: 0.0280 - val_loss: 0.0310 - val_mae: 0.1148 - val_mse: 0.0310
Epoch 23/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0214 - mae: 0.1094 - mse: 0.0214
64/82 [======================>.......] - ETA: 0s - loss: 0.0243 - mae: 0.1190 - mse: 0.0243
82/82 [==============================] - 0s 5ms/step - loss: 0.0225 - mae: 0.1152 - mse: 0.0225 - val_loss: 0.0232 - val_mae: 0.1170 - val_mse: 0.0232
Epoch 24/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0155 - mae: 0.1056 - mse: 0.0155
64/82 [======================>.......] - ETA: 0s - loss: 0.0152 - mae: 0.0989 - mse: 0.0152
82/82 [==============================] - 0s 5ms/step - loss: 0.0204 - mae: 0.1117 - mse: 0.0204 - val_loss: 0.0240 - val_mae: 0.1219 - val_mse: 0.0240
Epoch 25/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0113 - mae: 0.0845 - mse: 0.0113
64/82 [======================>.......] - ETA: 0s - loss: 0.0187 - mae: 0.0967 - mse: 0.0187
82/82 [==============================] - 0s 6ms/step - loss: 0.0218 - mae: 0.1076 - mse: 0.0218 - val_loss: 0.0372 - val_mae: 0.1245 - val_mse: 0.0372
Epoch 26/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0304 - mae: 0.1352 - mse: 0.0304
64/82 [======================>.......] - ETA: 0s - loss: 0.0194 - mae: 0.1033 - mse: 0.0194
82/82 [==============================] - 0s 6ms/step - loss: 0.0222 - mae: 0.1057 - mse: 0.0222 - val_loss: 0.0312 - val_mae: 0.1430 - val_mse: 0.0312
Epoch 27/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0202 - mae: 0.1121 - mse: 0.0202
64/82 [======================>.......] - ETA: 0s - loss: 0.0211 - mae: 0.1124 - mse: 0.0211
82/82 [==============================] - 0s 6ms/step - loss: 0.0198 - mae: 0.1079 - mse: 0.0198 - val_loss: 0.0474 - val_mae: 0.1428 - val_mse: 0.0474
Epoch 28/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0267 - mae: 0.1170 - mse: 0.0267
64/82 [======================>.......] - ETA: 0s - loss: 0.0185 - mae: 0.0988 - mse: 0.0185
82/82 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.0958 - mse: 0.0177 - val_loss: 0.0443 - val_mae: 0.1515 - val_mse: 0.0443
Epoch 29/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0252 - mae: 0.1168 - mse: 0.0252
64/82 [======================>.......] - ETA: 0s - loss: 0.0222 - mae: 0.1036 - mse: 0.0222
82/82 [==============================] - 0s 6ms/step - loss: 0.0190 - mae: 0.0962 - mse: 0.0190 - val_loss: 0.0435 - val_mae: 0.1552 - val_mse: 0.0435
Epoch 30/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0080 - mae: 0.0732 - mse: 0.0080
64/82 [======================>.......] - ETA: 0s - loss: 0.0153 - mae: 0.0836 - mse: 0.0153
82/82 [==============================] - 0s 6ms/step - loss: 0.0149 - mae: 0.0835 - mse: 0.0149 - val_loss: 0.0461 - val_mae: 0.1475 - val_mse: 0.0461
Saving trained model...
105
Testing...
heightdiff= [0.         0.         0.         3.01255035 0.         0.        ]
average prediction= [4.3400297]
baseline= 9.021739130434783
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.6025100708007812
85 -:- nan
60 -:- nan
['train-weight-2.py', '1']
2_155_65_2_csi_a2_20.dat
65 2
2_155_65_2_csi_a2_23.dat
65 4
2_155_65_2_csi_a2_16.dat
65 6
65 7
65 8
65 9
2_155_65_2_csi_a2_1.dat
2_155_65_2_csi_a2_21.dat
65 12
65 13
65 14
2_155_65_2_csi_a2_25.dat
2_155_65_2_csi_a2_18.dat
2_155_65_2_csi_a2_17.dat
2_155_65_2_csi_a2_14.dat
65 19
65 20
65 21
65 22
65 23
65 24
2_155_65_2_csi_a2_27.dat
2_155_65_2_csi_a2_24.dat
65 27
65 28
2_155_65_2_csi_a2_7.dat
65 30
60 31
60 32
60 33
2_170_60_2_csi_a2_2.dat
60 35
60 36
60 37
60 38
2_170_60_2_csi_a2_10.dat
60 40
1_165_65_2_csi_a2_30.dat
1_165_65_2_csi_a2_15.dat
1_165_65_2_csi_a2_10.dat
1_165_65_2_csi_a2_21.dat
1_165_65_2_csi_a2_9.dat
1_165_65_2_csi_a2_13.dat
1_165_65_2_csi_a2_19.dat
1_165_65_2_csi_a2_18.dat
1_165_65_2_csi_a2_7.dat
1_165_65_2_csi_a2_20.dat
1_165_65_2_csi_a2_11.dat
1_165_65_2_csi_a2_26.dat
1_165_65_2_csi_a2_16.dat
1_165_65_2_csi_a2_28.dat
1_165_65_2_csi_a2_5.dat
1_165_65_2_csi_a2_6.dat
1_165_65_2_csi_a2_25.dat
1_165_65_2_csi_a2_29.dat
1_165_65_2_csi_a2_23.dat
1_165_65_2_csi_a2_3.dat
1_165_65_2_csi_a2_27.dat
1_165_65_2_csi_a2_2.dat
1_165_65_2_csi_a2_17.dat
1_165_65_2_csi_a2_8.dat
1_165_65_2_csi_a2_14.dat
1_165_65_2_csi_a2_1.dat
1_165_65_2_csi_a2_24.dat
1_165_65_2_csi_a2_4.dat
1_165_65_2_csi_a2_22.dat
1_165_65_2_csi_a2_12.dat
50 71
50 72
50 73
50 74
50 75
50 76
50 77
2_165_50_2_csi_a2_13.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
50 97
50 98
2_165_50_2_csi_a2_24.dat
50 100
1_175_70_2_csi_a2_25.dat
70 102
1_175_70_2_csi_a2_20.dat
1_175_70_2_csi_a2_28.dat
70 105
1_175_70_2_csi_a2_22.dat
1_175_70_2_csi_a2_5.dat
1_175_70_2_csi_a2_11.dat
1_175_70_2_csi_a2_6.dat
1_175_70_2_csi_a2_8.dat
1_175_70_2_csi_a2_3.dat
1_175_70_2_csi_a2_16.dat
1_175_70_2_csi_a2_19.dat
1_175_70_2_csi_a2_1.dat
1_175_70_2_csi_a2_27.dat
70 116
1_175_70_2_csi_a2_18.dat
1_175_70_2_csi_a2_23.dat
1_175_70_2_csi_a2_21.dat
1_175_70_2_csi_a2_12.dat
1_175_70_2_csi_a2_30.dat
1_175_70_2_csi_a2_15.dat
1_175_70_2_csi_a2_17.dat
1_175_70_2_csi_a2_14.dat
1_175_70_2_csi_a2_9.dat
1_175_70_2_csi_a2_24.dat
1_175_70_2_csi_a2_10.dat
1_175_70_2_csi_a2_4.dat
1_175_70_2_csi_a2_29.dat
1_175_70_2_csi_a2_13.dat
1_180_85_2_csi_a2_22.dat
1_180_85_2_csi_a2_17.dat
1_180_85_2_csi_a2_15.dat
1_180_85_2_csi_a2_21.dat
85 135
1_180_85_2_csi_a2_7.dat
1_180_85_2_csi_a2_25.dat
1_180_85_2_csi_a2_19.dat
85 139
1_180_85_2_csi_a2_6.dat
1_180_85_2_csi_a2_1.dat
1_180_85_2_csi_a2_16.dat
1_180_85_2_csi_a2_14.dat
1_180_85_2_csi_a2_23.dat
1_180_85_2_csi_a2_24.dat
1_180_85_2_csi_a2_8.dat
85 147
1_180_85_2_csi_a2_13.dat
1_180_85_2_csi_a2_29.dat
1_180_85_2_csi_a2_9.dat
1_180_85_2_csi_a2_18.dat
1_180_85_2_csi_a2_28.dat
1_180_85_2_csi_a2_12.dat
1_180_85_2_csi_a2_30.dat
1_180_85_2_csi_a2_20.dat
85 156
1_180_85_2_csi_a2_26.dat
1_180_85_2_csi_a2_11.dat
85 159
1_180_85_2_csi_a2_10.dat
75 161
75 162
75 163
75 164
75 165
75 166
1_180_75_2_csi_a2_9.dat
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
75 180
75 181
1_180_75_2_csi_a2_1.dat
75 183
75 184
75 185
1_180_75_2_csi_a2_4.dat
75 187
75 188
75 189
75 190
85 191
85 192
85 193
85 194
85 195
85 196
85 197
85 198
85 199
1_173_85_2_csi_a2_23.dat
85 201
85 202
85 203
85 204
85 205
85 206
85 207
1_173_85_2_csi_a2_13.dat
85 209
85 210
85 211
85 212
85 213
85 214
85 215
85 216
1_173_85_2_csi_a2_28.dat
85 218
1_173_85_2_csi_a2_4.dat
85 220
(115, 30, 3)
(115, 421, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60 60
 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85]
(115, 421, 30, 3, 1)

Loaded dataset of 115 samples, each sized (421, 30, 3, 1)


Train on 92 samples
Test on 23 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 421, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 421, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 421, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 421, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 421, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 421, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 421, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 82 samples, validate on 10 samples
Epoch 1/30

32/82 [==========>...................] - ETA: 0s - loss: 0.3706 - mae: 0.4880 - mse: 0.3706
64/82 [======================>.......] - ETA: 0s - loss: 0.3590 - mae: 0.4938 - mse: 0.3590
82/82 [==============================] - 1s 9ms/step - loss: 0.3136 - mae: 0.4464 - mse: 0.3136 - val_loss: 0.2456 - val_mae: 0.4272 - val_mse: 0.2456
Epoch 2/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1450 - mae: 0.3284 - mse: 0.1450
64/82 [======================>.......] - ETA: 0s - loss: 0.1398 - mae: 0.3316 - mse: 0.1398
82/82 [==============================] - 0s 6ms/step - loss: 0.1368 - mae: 0.3291 - mse: 0.1368 - val_loss: 0.1460 - val_mae: 0.3657 - val_mse: 0.1460
Epoch 3/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1302 - mae: 0.3142 - mse: 0.1302
64/82 [======================>.......] - ETA: 0s - loss: 0.1441 - mae: 0.3317 - mse: 0.1441
82/82 [==============================] - 0s 6ms/step - loss: 0.1452 - mae: 0.3374 - mse: 0.1452 - val_loss: 0.1354 - val_mae: 0.3439 - val_mse: 0.1354
Epoch 4/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1210 - mae: 0.3038 - mse: 0.1210
64/82 [======================>.......] - ETA: 0s - loss: 0.1027 - mae: 0.2789 - mse: 0.1027
82/82 [==============================] - 0s 5ms/step - loss: 0.0940 - mae: 0.2658 - mse: 0.0940 - val_loss: 0.1708 - val_mae: 0.3372 - val_mse: 0.1708
Epoch 5/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0971 - mae: 0.2551 - mse: 0.0971
64/82 [======================>.......] - ETA: 0s - loss: 0.0929 - mae: 0.2552 - mse: 0.0929
82/82 [==============================] - 0s 6ms/step - loss: 0.0893 - mae: 0.2458 - mse: 0.0893 - val_loss: 0.1612 - val_mae: 0.3283 - val_mse: 0.1612
Epoch 6/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1111 - mae: 0.2652 - mse: 0.1111
64/82 [======================>.......] - ETA: 0s - loss: 0.0862 - mae: 0.2277 - mse: 0.0862
82/82 [==============================] - 0s 6ms/step - loss: 0.0803 - mae: 0.2172 - mse: 0.0803 - val_loss: 0.0857 - val_mae: 0.2373 - val_mse: 0.0857
Epoch 7/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0675 - mae: 0.2067 - mse: 0.0675
64/82 [======================>.......] - ETA: 0s - loss: 0.0504 - mae: 0.1828 - mse: 0.0504
82/82 [==============================] - 0s 5ms/step - loss: 0.0563 - mae: 0.1959 - mse: 0.0563 - val_loss: 0.0426 - val_mae: 0.1926 - val_mse: 0.0426
Epoch 8/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0732 - mae: 0.2398 - mse: 0.0732
64/82 [======================>.......] - ETA: 0s - loss: 0.0684 - mae: 0.2239 - mse: 0.0684
82/82 [==============================] - 0s 6ms/step - loss: 0.0618 - mae: 0.2085 - mse: 0.0618 - val_loss: 0.0462 - val_mae: 0.1840 - val_mse: 0.0462
Epoch 9/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0416 - mae: 0.1653 - mse: 0.0416
64/82 [======================>.......] - ETA: 0s - loss: 0.0419 - mae: 0.1582 - mse: 0.0419
82/82 [==============================] - 0s 5ms/step - loss: 0.0445 - mae: 0.1601 - mse: 0.0445 - val_loss: 0.0715 - val_mae: 0.1964 - val_mse: 0.0715
Epoch 10/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0397 - mae: 0.1231 - mse: 0.0397
64/82 [======================>.......] - ETA: 0s - loss: 0.0397 - mae: 0.1374 - mse: 0.0397
82/82 [==============================] - 0s 5ms/step - loss: 0.0483 - mae: 0.1551 - mse: 0.0483 - val_loss: 0.0664 - val_mae: 0.1888 - val_mse: 0.0664
Epoch 11/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0324 - mae: 0.1194 - mse: 0.0324
64/82 [======================>.......] - ETA: 0s - loss: 0.0460 - mae: 0.1486 - mse: 0.0460
82/82 [==============================] - 0s 6ms/step - loss: 0.0458 - mae: 0.1519 - mse: 0.0458 - val_loss: 0.0335 - val_mae: 0.1512 - val_mse: 0.0335
Epoch 12/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0244 - mae: 0.1154 - mse: 0.0244
64/82 [======================>.......] - ETA: 0s - loss: 0.0391 - mae: 0.1478 - mse: 0.0391
82/82 [==============================] - 0s 6ms/step - loss: 0.0408 - mae: 0.1522 - mse: 0.0408 - val_loss: 0.0285 - val_mae: 0.1413 - val_mse: 0.0285
Epoch 13/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0356 - mae: 0.1359 - mse: 0.0356
64/82 [======================>.......] - ETA: 0s - loss: 0.0350 - mae: 0.1411 - mse: 0.0350
82/82 [==============================] - 0s 6ms/step - loss: 0.0366 - mae: 0.1431 - mse: 0.0366 - val_loss: 0.0436 - val_mae: 0.1596 - val_mse: 0.0436
Epoch 14/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0478 - mae: 0.1599 - mse: 0.0478
64/82 [======================>.......] - ETA: 0s - loss: 0.0310 - mae: 0.1258 - mse: 0.0310
82/82 [==============================] - 0s 6ms/step - loss: 0.0377 - mae: 0.1340 - mse: 0.0377 - val_loss: 0.0353 - val_mae: 0.1464 - val_mse: 0.0353
Epoch 15/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0276 - mae: 0.1267 - mse: 0.0276
64/82 [======================>.......] - ETA: 0s - loss: 0.0400 - mae: 0.1488 - mse: 0.0400
82/82 [==============================] - 0s 6ms/step - loss: 0.0385 - mae: 0.1460 - mse: 0.0385 - val_loss: 0.0261 - val_mae: 0.1289 - val_mse: 0.0261
Epoch 16/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0259 - mae: 0.1189 - mse: 0.0259
64/82 [======================>.......] - ETA: 0s - loss: 0.0320 - mae: 0.1334 - mse: 0.0320
82/82 [==============================] - 0s 5ms/step - loss: 0.0324 - mae: 0.1339 - mse: 0.0324 - val_loss: 0.0355 - val_mae: 0.1425 - val_mse: 0.0355
Epoch 17/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0313 - mae: 0.1378 - mse: 0.0313
64/82 [======================>.......] - ETA: 0s - loss: 0.0276 - mae: 0.1218 - mse: 0.0276
82/82 [==============================] - 0s 6ms/step - loss: 0.0273 - mae: 0.1215 - mse: 0.0273 - val_loss: 0.0347 - val_mae: 0.1431 - val_mse: 0.0347
Epoch 18/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0319 - mae: 0.1460 - mse: 0.0319
64/82 [======================>.......] - ETA: 0s - loss: 0.0349 - mae: 0.1478 - mse: 0.0349
82/82 [==============================] - 0s 5ms/step - loss: 0.0324 - mae: 0.1379 - mse: 0.0324 - val_loss: 0.0232 - val_mae: 0.1184 - val_mse: 0.0232
Epoch 19/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0311 - mae: 0.1222 - mse: 0.0311
64/82 [======================>.......] - ETA: 0s - loss: 0.0313 - mae: 0.1264 - mse: 0.0313
82/82 [==============================] - 0s 6ms/step - loss: 0.0292 - mae: 0.1239 - mse: 0.0292 - val_loss: 0.0176 - val_mae: 0.1053 - val_mse: 0.0176
Epoch 20/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0304 - mae: 0.1367 - mse: 0.0304
64/82 [======================>.......] - ETA: 0s - loss: 0.0359 - mae: 0.1385 - mse: 0.0359
82/82 [==============================] - 0s 6ms/step - loss: 0.0334 - mae: 0.1329 - mse: 0.0334 - val_loss: 0.0302 - val_mae: 0.1455 - val_mse: 0.0302
Epoch 21/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0312 - mae: 0.1172 - mse: 0.0312
64/82 [======================>.......] - ETA: 0s - loss: 0.0347 - mae: 0.1277 - mse: 0.0347
82/82 [==============================] - 0s 6ms/step - loss: 0.0299 - mae: 0.1172 - mse: 0.0299 - val_loss: 0.0278 - val_mae: 0.1390 - val_mse: 0.0278
Epoch 22/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0265 - mae: 0.1155 - mse: 0.0265
64/82 [======================>.......] - ETA: 0s - loss: 0.0220 - mae: 0.1055 - mse: 0.0220
82/82 [==============================] - 0s 6ms/step - loss: 0.0241 - mae: 0.1094 - mse: 0.0241 - val_loss: 0.0175 - val_mae: 0.1057 - val_mse: 0.0175
Epoch 23/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0185 - mae: 0.0961 - mse: 0.0185
64/82 [======================>.......] - ETA: 0s - loss: 0.0221 - mae: 0.1067 - mse: 0.0221
82/82 [==============================] - 0s 6ms/step - loss: 0.0222 - mae: 0.1082 - mse: 0.0222 - val_loss: 0.0200 - val_mae: 0.1153 - val_mse: 0.0200
Epoch 24/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0255 - mae: 0.1044 - mse: 0.0255
64/82 [======================>.......] - ETA: 0s - loss: 0.0242 - mae: 0.1047 - mse: 0.0242
82/82 [==============================] - 0s 6ms/step - loss: 0.0222 - mae: 0.1007 - mse: 0.0222 - val_loss: 0.0223 - val_mae: 0.1232 - val_mse: 0.0223
Epoch 25/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0295 - mae: 0.1180 - mse: 0.0295
64/82 [======================>.......] - ETA: 0s - loss: 0.0273 - mae: 0.1137 - mse: 0.0273
82/82 [==============================] - 0s 6ms/step - loss: 0.0254 - mae: 0.1114 - mse: 0.0254 - val_loss: 0.0142 - val_mae: 0.0951 - val_mse: 0.0142
Epoch 26/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0286 - mae: 0.1212 - mse: 0.0286
64/82 [======================>.......] - ETA: 0s - loss: 0.0270 - mae: 0.1190 - mse: 0.0270
82/82 [==============================] - 0s 5ms/step - loss: 0.0236 - mae: 0.1105 - mse: 0.0236 - val_loss: 0.0088 - val_mae: 0.0745 - val_mse: 0.0088
Epoch 27/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0230 - mae: 0.1199 - mse: 0.0230
64/82 [======================>.......] - ETA: 0s - loss: 0.0176 - mae: 0.1027 - mse: 0.0176
82/82 [==============================] - 0s 5ms/step - loss: 0.0173 - mae: 0.1015 - mse: 0.0173 - val_loss: 0.0130 - val_mae: 0.0981 - val_mse: 0.0130
Epoch 28/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0168 - mae: 0.0984 - mse: 0.0168
64/82 [======================>.......] - ETA: 0s - loss: 0.0169 - mae: 0.0967 - mse: 0.0169
82/82 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0974 - mse: 0.0178 - val_loss: 0.0203 - val_mae: 0.1259 - val_mse: 0.0203
Epoch 29/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0120 - mae: 0.0850 - mse: 0.0120
64/82 [======================>.......] - ETA: 0s - loss: 0.0176 - mae: 0.0986 - mse: 0.0176
82/82 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0987 - mse: 0.0173 - val_loss: 0.0082 - val_mae: 0.0771 - val_mse: 0.0082
Epoch 30/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0295 - mae: 0.1395 - mse: 0.0295
64/82 [======================>.......] - ETA: 0s - loss: 0.0247 - mae: 0.1242 - mse: 0.0247
82/82 [==============================] - 0s 5ms/step - loss: 0.0212 - mae: 0.1152 - mse: 0.0212 - val_loss: 0.0262 - val_mae: 0.1439 - val_mse: 0.0262
Saving trained model...
105
Testing...
heightdiff= [0.         0.         0.         2.34693146 0.         0.        ]
average prediction= [5.0849385]
baseline= 10.326086956521738
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.5867328643798828
85 -:- nan
60 -:- nan
['train-weight-2.py', '1']
2_155_65_2_csi_a2_20.dat
65 2
2_155_65_2_csi_a2_23.dat
65 4
2_155_65_2_csi_a2_16.dat
65 6
65 7
65 8
65 9
2_155_65_2_csi_a2_1.dat
2_155_65_2_csi_a2_21.dat
65 12
65 13
65 14
2_155_65_2_csi_a2_25.dat
2_155_65_2_csi_a2_18.dat
2_155_65_2_csi_a2_17.dat
2_155_65_2_csi_a2_14.dat
65 19
65 20
65 21
65 22
65 23
65 24
2_155_65_2_csi_a2_27.dat
2_155_65_2_csi_a2_24.dat
65 27
65 28
2_155_65_2_csi_a2_7.dat
65 30
60 31
60 32
60 33
2_170_60_2_csi_a2_2.dat
60 35
60 36
60 37
60 38
2_170_60_2_csi_a2_10.dat
60 40
1_165_65_2_csi_a2_30.dat
1_165_65_2_csi_a2_15.dat
1_165_65_2_csi_a2_10.dat
1_165_65_2_csi_a2_21.dat
1_165_65_2_csi_a2_9.dat
1_165_65_2_csi_a2_13.dat
1_165_65_2_csi_a2_19.dat
1_165_65_2_csi_a2_18.dat
1_165_65_2_csi_a2_7.dat
1_165_65_2_csi_a2_20.dat
1_165_65_2_csi_a2_11.dat
1_165_65_2_csi_a2_26.dat
1_165_65_2_csi_a2_16.dat
1_165_65_2_csi_a2_28.dat
1_165_65_2_csi_a2_5.dat
1_165_65_2_csi_a2_6.dat
1_165_65_2_csi_a2_25.dat
1_165_65_2_csi_a2_29.dat
1_165_65_2_csi_a2_23.dat
1_165_65_2_csi_a2_3.dat
1_165_65_2_csi_a2_27.dat
1_165_65_2_csi_a2_2.dat
1_165_65_2_csi_a2_17.dat
1_165_65_2_csi_a2_8.dat
1_165_65_2_csi_a2_14.dat
1_165_65_2_csi_a2_1.dat
1_165_65_2_csi_a2_24.dat
1_165_65_2_csi_a2_4.dat
1_165_65_2_csi_a2_22.dat
1_165_65_2_csi_a2_12.dat
50 71
50 72
50 73
50 74
50 75
50 76
50 77
2_165_50_2_csi_a2_13.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
50 97
50 98
2_165_50_2_csi_a2_24.dat
50 100
1_175_70_2_csi_a2_25.dat
70 102
1_175_70_2_csi_a2_20.dat
1_175_70_2_csi_a2_28.dat
70 105
1_175_70_2_csi_a2_22.dat
1_175_70_2_csi_a2_5.dat
1_175_70_2_csi_a2_11.dat
1_175_70_2_csi_a2_6.dat
1_175_70_2_csi_a2_8.dat
1_175_70_2_csi_a2_3.dat
1_175_70_2_csi_a2_16.dat
1_175_70_2_csi_a2_19.dat
1_175_70_2_csi_a2_1.dat
1_175_70_2_csi_a2_27.dat
70 116
1_175_70_2_csi_a2_18.dat
1_175_70_2_csi_a2_23.dat
1_175_70_2_csi_a2_21.dat
1_175_70_2_csi_a2_12.dat
1_175_70_2_csi_a2_30.dat
1_175_70_2_csi_a2_15.dat
1_175_70_2_csi_a2_17.dat
1_175_70_2_csi_a2_14.dat
1_175_70_2_csi_a2_9.dat
1_175_70_2_csi_a2_24.dat
1_175_70_2_csi_a2_10.dat
1_175_70_2_csi_a2_4.dat
1_175_70_2_csi_a2_29.dat
1_175_70_2_csi_a2_13.dat
1_180_85_2_csi_a2_22.dat
1_180_85_2_csi_a2_17.dat
1_180_85_2_csi_a2_15.dat
1_180_85_2_csi_a2_21.dat
85 135
1_180_85_2_csi_a2_7.dat
1_180_85_2_csi_a2_25.dat
1_180_85_2_csi_a2_19.dat
85 139
1_180_85_2_csi_a2_6.dat
1_180_85_2_csi_a2_1.dat
1_180_85_2_csi_a2_16.dat
1_180_85_2_csi_a2_14.dat
1_180_85_2_csi_a2_23.dat
1_180_85_2_csi_a2_24.dat
1_180_85_2_csi_a2_8.dat
85 147
1_180_85_2_csi_a2_13.dat
1_180_85_2_csi_a2_29.dat
1_180_85_2_csi_a2_9.dat
1_180_85_2_csi_a2_18.dat
1_180_85_2_csi_a2_28.dat
1_180_85_2_csi_a2_12.dat
1_180_85_2_csi_a2_30.dat
1_180_85_2_csi_a2_20.dat
85 156
1_180_85_2_csi_a2_26.dat
1_180_85_2_csi_a2_11.dat
85 159
1_180_85_2_csi_a2_10.dat
75 161
75 162
75 163
75 164
75 165
75 166
1_180_75_2_csi_a2_9.dat
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
75 180
75 181
1_180_75_2_csi_a2_1.dat
75 183
75 184
75 185
1_180_75_2_csi_a2_4.dat
75 187
75 188
75 189
75 190
85 191
85 192
85 193
85 194
85 195
85 196
85 197
85 198
85 199
1_173_85_2_csi_a2_23.dat
85 201
85 202
85 203
85 204
85 205
85 206
85 207
1_173_85_2_csi_a2_13.dat
85 209
85 210
85 211
85 212
85 213
85 214
85 215
85 216
1_173_85_2_csi_a2_28.dat
85 218
1_173_85_2_csi_a2_4.dat
85 220
(115, 30, 3)
(115, 421, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60 60
 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85]
(115, 421, 30, 3, 1)

Loaded dataset of 115 samples, each sized (421, 30, 3, 1)


Train on 92 samples
Test on 23 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 421, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 421, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 421, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 421, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 421, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 421, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 421, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 82 samples, validate on 10 samples
Epoch 1/30

32/82 [==========>...................] - ETA: 0s - loss: 0.3160 - mae: 0.4561 - mse: 0.3160
64/82 [======================>.......] - ETA: 0s - loss: 0.2999 - mae: 0.4497 - mse: 0.2999
82/82 [==============================] - 1s 9ms/step - loss: 0.2741 - mae: 0.4307 - mse: 0.2741 - val_loss: 0.1859 - val_mae: 0.3953 - val_mse: 0.1859
Epoch 2/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1383 - mae: 0.3306 - mse: 0.1383
64/82 [======================>.......] - ETA: 0s - loss: 0.1506 - mae: 0.3405 - mse: 0.1506
82/82 [==============================] - 0s 6ms/step - loss: 0.1561 - mae: 0.3463 - mse: 0.1561 - val_loss: 0.1150 - val_mae: 0.3049 - val_mse: 0.1150
Epoch 3/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1173 - mae: 0.2993 - mse: 0.1173
64/82 [======================>.......] - ETA: 0s - loss: 0.1093 - mae: 0.2917 - mse: 0.1093
82/82 [==============================] - 0s 6ms/step - loss: 0.0989 - mae: 0.2748 - mse: 0.0989 - val_loss: 0.0904 - val_mae: 0.2477 - val_mse: 0.0904
Epoch 4/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0823 - mae: 0.2274 - mse: 0.0823
64/82 [======================>.......] - ETA: 0s - loss: 0.0798 - mae: 0.2234 - mse: 0.0798
82/82 [==============================] - 0s 6ms/step - loss: 0.0875 - mae: 0.2356 - mse: 0.0875 - val_loss: 0.0761 - val_mae: 0.2161 - val_mse: 0.0761
Epoch 5/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0879 - mae: 0.2390 - mse: 0.0879
64/82 [======================>.......] - ETA: 0s - loss: 0.0778 - mae: 0.2223 - mse: 0.0778
82/82 [==============================] - 0s 5ms/step - loss: 0.0728 - mae: 0.2152 - mse: 0.0728 - val_loss: 0.0386 - val_mae: 0.1393 - val_mse: 0.0386
Epoch 6/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0382 - mae: 0.1661 - mse: 0.0382
64/82 [======================>.......] - ETA: 0s - loss: 0.0580 - mae: 0.2035 - mse: 0.0580
82/82 [==============================] - 0s 6ms/step - loss: 0.0632 - mae: 0.2054 - mse: 0.0632 - val_loss: 0.0177 - val_mae: 0.1095 - val_mse: 0.0177
Epoch 7/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0841 - mae: 0.2136 - mse: 0.0841
64/82 [======================>.......] - ETA: 0s - loss: 0.0564 - mae: 0.1737 - mse: 0.0564
82/82 [==============================] - 0s 6ms/step - loss: 0.0580 - mae: 0.1816 - mse: 0.0580 - val_loss: 0.0388 - val_mae: 0.1310 - val_mse: 0.0388
Epoch 8/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0717 - mae: 0.1970 - mse: 0.0717
64/82 [======================>.......] - ETA: 0s - loss: 0.0498 - mae: 0.1536 - mse: 0.0498
82/82 [==============================] - 0s 6ms/step - loss: 0.0458 - mae: 0.1443 - mse: 0.0458 - val_loss: 0.0530 - val_mae: 0.1732 - val_mse: 0.0530
Epoch 9/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0318 - mae: 0.1297 - mse: 0.0318
64/82 [======================>.......] - ETA: 0s - loss: 0.0394 - mae: 0.1451 - mse: 0.0394
82/82 [==============================] - 0s 6ms/step - loss: 0.0457 - mae: 0.1563 - mse: 0.0457 - val_loss: 0.0281 - val_mae: 0.1160 - val_mse: 0.0281
Epoch 10/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0383 - mae: 0.1339 - mse: 0.0383
64/82 [======================>.......] - ETA: 0s - loss: 0.0360 - mae: 0.1376 - mse: 0.0360
82/82 [==============================] - 0s 6ms/step - loss: 0.0359 - mae: 0.1357 - mse: 0.0359 - val_loss: 0.0121 - val_mae: 0.0787 - val_mse: 0.0121
Epoch 11/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0596 - mae: 0.1545 - mse: 0.0596
64/82 [======================>.......] - ETA: 0s - loss: 0.0479 - mae: 0.1517 - mse: 0.0479
82/82 [==============================] - 0s 5ms/step - loss: 0.0490 - mae: 0.1576 - mse: 0.0490 - val_loss: 0.0328 - val_mae: 0.1317 - val_mse: 0.0328
Epoch 12/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0431 - mae: 0.1546 - mse: 0.0431
64/82 [======================>.......] - ETA: 0s - loss: 0.0377 - mae: 0.1499 - mse: 0.0377
82/82 [==============================] - 0s 6ms/step - loss: 0.0364 - mae: 0.1449 - mse: 0.0364 - val_loss: 0.0352 - val_mae: 0.1391 - val_mse: 0.0352
Epoch 13/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0445 - mae: 0.1604 - mse: 0.0445
64/82 [======================>.......] - ETA: 0s - loss: 0.0362 - mae: 0.1419 - mse: 0.0362
82/82 [==============================] - 0s 6ms/step - loss: 0.0339 - mae: 0.1382 - mse: 0.0339 - val_loss: 0.0136 - val_mae: 0.0832 - val_mse: 0.0136
Epoch 14/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0291 - mae: 0.1308 - mse: 0.0291
64/82 [======================>.......] - ETA: 0s - loss: 0.0326 - mae: 0.1356 - mse: 0.0326
82/82 [==============================] - 0s 5ms/step - loss: 0.0280 - mae: 0.1263 - mse: 0.0280 - val_loss: 0.0109 - val_mae: 0.0743 - val_mse: 0.0109
Epoch 15/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0320 - mae: 0.1336 - mse: 0.0320
64/82 [======================>.......] - ETA: 0s - loss: 0.0243 - mae: 0.1112 - mse: 0.0243
82/82 [==============================] - 0s 6ms/step - loss: 0.0268 - mae: 0.1174 - mse: 0.0268 - val_loss: 0.0209 - val_mae: 0.1151 - val_mse: 0.0209
Epoch 16/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0131 - mae: 0.0834 - mse: 0.0131
64/82 [======================>.......] - ETA: 0s - loss: 0.0223 - mae: 0.0990 - mse: 0.0223
82/82 [==============================] - 0s 6ms/step - loss: 0.0222 - mae: 0.0987 - mse: 0.0222 - val_loss: 0.0076 - val_mae: 0.0611 - val_mse: 0.0076
Epoch 17/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0364 - mae: 0.1312 - mse: 0.0364
64/82 [======================>.......] - ETA: 0s - loss: 0.0298 - mae: 0.1175 - mse: 0.0298
82/82 [==============================] - 0s 6ms/step - loss: 0.0266 - mae: 0.1126 - mse: 0.0266 - val_loss: 0.0054 - val_mae: 0.0453 - val_mse: 0.0054
Epoch 18/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0311 - mae: 0.1200 - mse: 0.0311
64/82 [======================>.......] - ETA: 0s - loss: 0.0277 - mae: 0.1164 - mse: 0.0277
82/82 [==============================] - 0s 5ms/step - loss: 0.0275 - mae: 0.1188 - mse: 0.0275 - val_loss: 0.0224 - val_mae: 0.1126 - val_mse: 0.0224
Epoch 19/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0473 - mae: 0.1697 - mse: 0.0473
64/82 [======================>.......] - ETA: 0s - loss: 0.0352 - mae: 0.1448 - mse: 0.0352
82/82 [==============================] - 0s 5ms/step - loss: 0.0340 - mae: 0.1436 - mse: 0.0340 - val_loss: 0.0251 - val_mae: 0.1131 - val_mse: 0.0251
Epoch 20/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0223 - mae: 0.1153 - mse: 0.0223
64/82 [======================>.......] - ETA: 0s - loss: 0.0298 - mae: 0.1226 - mse: 0.0298
82/82 [==============================] - 0s 6ms/step - loss: 0.0282 - mae: 0.1196 - mse: 0.0282 - val_loss: 0.0122 - val_mae: 0.0829 - val_mse: 0.0122
Epoch 21/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0244 - mae: 0.1267 - mse: 0.0244
64/82 [======================>.......] - ETA: 0s - loss: 0.0225 - mae: 0.1182 - mse: 0.0225
82/82 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 0.1066 - mse: 0.0205 - val_loss: 0.0077 - val_mae: 0.0644 - val_mse: 0.0077
Epoch 22/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0184 - mae: 0.1063 - mse: 0.0184
64/82 [======================>.......] - ETA: 0s - loss: 0.0200 - mae: 0.1011 - mse: 0.0200
82/82 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.1058 - mse: 0.0215 - val_loss: 0.0165 - val_mae: 0.0893 - val_mse: 0.0165
Epoch 23/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0314 - mae: 0.1309 - mse: 0.0314
64/82 [======================>.......] - ETA: 0s - loss: 0.0224 - mae: 0.1020 - mse: 0.0224
82/82 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.0957 - mse: 0.0197 - val_loss: 0.0080 - val_mae: 0.0562 - val_mse: 0.0080
Epoch 24/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0142 - mae: 0.0845 - mse: 0.0142
64/82 [======================>.......] - ETA: 0s - loss: 0.0195 - mae: 0.0945 - mse: 0.0195
82/82 [==============================] - 0s 5ms/step - loss: 0.0162 - mae: 0.0860 - mse: 0.0162 - val_loss: 0.0124 - val_mae: 0.0732 - val_mse: 0.0124
Epoch 25/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0156 - mae: 0.0825 - mse: 0.0156
64/82 [======================>.......] - ETA: 0s - loss: 0.0171 - mae: 0.0852 - mse: 0.0171
82/82 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0873 - mse: 0.0170 - val_loss: 0.0277 - val_mae: 0.1195 - val_mse: 0.0277
Epoch 26/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0255 - mae: 0.1102 - mse: 0.0255
64/82 [======================>.......] - ETA: 0s - loss: 0.0212 - mae: 0.1002 - mse: 0.0212
82/82 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 0.0978 - mse: 0.0191 - val_loss: 0.0199 - val_mae: 0.1033 - val_mse: 0.0199
Epoch 27/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0200 - mae: 0.0950 - mse: 0.0200
64/82 [======================>.......] - ETA: 0s - loss: 0.0164 - mae: 0.0881 - mse: 0.0164
82/82 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0934 - mse: 0.0170 - val_loss: 0.0167 - val_mae: 0.0955 - val_mse: 0.0167
Epoch 28/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0115 - mae: 0.0851 - mse: 0.0115
64/82 [======================>.......] - ETA: 0s - loss: 0.0186 - mae: 0.1043 - mse: 0.0186
82/82 [==============================] - 0s 6ms/step - loss: 0.0160 - mae: 0.0941 - mse: 0.0160 - val_loss: 0.0280 - val_mae: 0.1281 - val_mse: 0.0280
Epoch 29/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0271 - mae: 0.1078 - mse: 0.0271
64/82 [======================>.......] - ETA: 0s - loss: 0.0179 - mae: 0.0910 - mse: 0.0179
82/82 [==============================] - 0s 6ms/step - loss: 0.0180 - mae: 0.0914 - mse: 0.0180 - val_loss: 0.0136 - val_mae: 0.0817 - val_mse: 0.0136
Epoch 30/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0094 - mae: 0.0783 - mse: 0.0094
64/82 [======================>.......] - ETA: 0s - loss: 0.0113 - mae: 0.0768 - mse: 0.0113
82/82 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0800 - mse: 0.0117 - val_loss: 0.0145 - val_mae: 0.0829 - val_mse: 0.0145
Saving trained model...
105
Testing...
heightdiff= [0.         0.         0.         0.93156815 0.         0.        ]
average prediction= [4.1786504]
baseline= 9.891304347826088
eachuser= [0. 0. 0. 2. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.46578407287597656
85 -:- nan
60 -:- nan
['train-weight-2.py', '1']
2_155_65_2_csi_a2_20.dat
65 2
2_155_65_2_csi_a2_23.dat
65 4
2_155_65_2_csi_a2_16.dat
65 6
65 7
65 8
65 9
2_155_65_2_csi_a2_1.dat
2_155_65_2_csi_a2_21.dat
65 12
65 13
65 14
2_155_65_2_csi_a2_25.dat
2_155_65_2_csi_a2_18.dat
2_155_65_2_csi_a2_17.dat
2_155_65_2_csi_a2_14.dat
65 19
65 20
65 21
65 22
65 23
65 24
2_155_65_2_csi_a2_27.dat
2_155_65_2_csi_a2_24.dat
65 27
65 28
2_155_65_2_csi_a2_7.dat
65 30
60 31
60 32
60 33
2_170_60_2_csi_a2_2.dat
60 35
60 36
60 37
60 38
2_170_60_2_csi_a2_10.dat
60 40
1_165_65_2_csi_a2_30.dat
1_165_65_2_csi_a2_15.dat
1_165_65_2_csi_a2_10.dat
1_165_65_2_csi_a2_21.dat
1_165_65_2_csi_a2_9.dat
1_165_65_2_csi_a2_13.dat
1_165_65_2_csi_a2_19.dat
1_165_65_2_csi_a2_18.dat
1_165_65_2_csi_a2_7.dat
1_165_65_2_csi_a2_20.dat
1_165_65_2_csi_a2_11.dat
1_165_65_2_csi_a2_26.dat
1_165_65_2_csi_a2_16.dat
1_165_65_2_csi_a2_28.dat
1_165_65_2_csi_a2_5.dat
1_165_65_2_csi_a2_6.dat
1_165_65_2_csi_a2_25.dat
1_165_65_2_csi_a2_29.dat
1_165_65_2_csi_a2_23.dat
1_165_65_2_csi_a2_3.dat
1_165_65_2_csi_a2_27.dat
1_165_65_2_csi_a2_2.dat
1_165_65_2_csi_a2_17.dat
1_165_65_2_csi_a2_8.dat
1_165_65_2_csi_a2_14.dat
1_165_65_2_csi_a2_1.dat
1_165_65_2_csi_a2_24.dat
1_165_65_2_csi_a2_4.dat
1_165_65_2_csi_a2_22.dat
1_165_65_2_csi_a2_12.dat
50 71
50 72
50 73
50 74
50 75
50 76
50 77
2_165_50_2_csi_a2_13.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
50 97
50 98
2_165_50_2_csi_a2_24.dat
50 100
1_175_70_2_csi_a2_25.dat
70 102
1_175_70_2_csi_a2_20.dat
1_175_70_2_csi_a2_28.dat
70 105
1_175_70_2_csi_a2_22.dat
1_175_70_2_csi_a2_5.dat
1_175_70_2_csi_a2_11.dat
1_175_70_2_csi_a2_6.dat
1_175_70_2_csi_a2_8.dat
1_175_70_2_csi_a2_3.dat
1_175_70_2_csi_a2_16.dat
1_175_70_2_csi_a2_19.dat
1_175_70_2_csi_a2_1.dat
1_175_70_2_csi_a2_27.dat
70 116
1_175_70_2_csi_a2_18.dat
1_175_70_2_csi_a2_23.dat
1_175_70_2_csi_a2_21.dat
1_175_70_2_csi_a2_12.dat
1_175_70_2_csi_a2_30.dat
1_175_70_2_csi_a2_15.dat
1_175_70_2_csi_a2_17.dat
1_175_70_2_csi_a2_14.dat
1_175_70_2_csi_a2_9.dat
1_175_70_2_csi_a2_24.dat
1_175_70_2_csi_a2_10.dat
1_175_70_2_csi_a2_4.dat
1_175_70_2_csi_a2_29.dat
1_175_70_2_csi_a2_13.dat
1_180_85_2_csi_a2_22.dat
1_180_85_2_csi_a2_17.dat
1_180_85_2_csi_a2_15.dat
1_180_85_2_csi_a2_21.dat
85 135
1_180_85_2_csi_a2_7.dat
1_180_85_2_csi_a2_25.dat
1_180_85_2_csi_a2_19.dat
85 139
1_180_85_2_csi_a2_6.dat
1_180_85_2_csi_a2_1.dat
1_180_85_2_csi_a2_16.dat
1_180_85_2_csi_a2_14.dat
1_180_85_2_csi_a2_23.dat
1_180_85_2_csi_a2_24.dat
1_180_85_2_csi_a2_8.dat
85 147
1_180_85_2_csi_a2_13.dat
1_180_85_2_csi_a2_29.dat
1_180_85_2_csi_a2_9.dat
1_180_85_2_csi_a2_18.dat
1_180_85_2_csi_a2_28.dat
1_180_85_2_csi_a2_12.dat
1_180_85_2_csi_a2_30.dat
1_180_85_2_csi_a2_20.dat
85 156
1_180_85_2_csi_a2_26.dat
1_180_85_2_csi_a2_11.dat
85 159
1_180_85_2_csi_a2_10.dat
75 161
75 162
75 163
75 164
75 165
75 166
1_180_75_2_csi_a2_9.dat
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
75 180
75 181
1_180_75_2_csi_a2_1.dat
75 183
75 184
75 185
1_180_75_2_csi_a2_4.dat
75 187
75 188
75 189
75 190
85 191
85 192
85 193
85 194
85 195
85 196
85 197
85 198
85 199
1_173_85_2_csi_a2_23.dat
85 201
85 202
85 203
85 204
85 205
85 206
85 207
1_173_85_2_csi_a2_13.dat
85 209
85 210
85 211
85 212
85 213
85 214
85 215
85 216
1_173_85_2_csi_a2_28.dat
85 218
1_173_85_2_csi_a2_4.dat
85 220
(115, 30, 3)
(115, 421, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60 60
 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85]
(115, 421, 30, 3, 1)

Loaded dataset of 115 samples, each sized (421, 30, 3, 1)


Train on 92 samples
Test on 23 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 421, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 421, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 421, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 421, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 421, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 421, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 421, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 82 samples, validate on 10 samples
Epoch 1/30

32/82 [==========>...................] - ETA: 0s - loss: 0.4284 - mae: 0.5771 - mse: 0.4284
64/82 [======================>.......] - ETA: 0s - loss: 0.3262 - mae: 0.4955 - mse: 0.3262
82/82 [==============================] - 1s 10ms/step - loss: 0.2997 - mae: 0.4704 - mse: 0.2997 - val_loss: 0.1838 - val_mae: 0.3944 - val_mse: 0.1838
Epoch 2/30

32/82 [==========>...................] - ETA: 0s - loss: 0.2253 - mae: 0.4155 - mse: 0.2253
64/82 [======================>.......] - ETA: 0s - loss: 0.2462 - mae: 0.4360 - mse: 0.2462
82/82 [==============================] - 0s 6ms/step - loss: 0.2250 - mae: 0.4103 - mse: 0.2250 - val_loss: 0.1669 - val_mae: 0.3628 - val_mse: 0.1669
Epoch 3/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1468 - mae: 0.3474 - mse: 0.1468
64/82 [======================>.......] - ETA: 0s - loss: 0.1490 - mae: 0.3412 - mse: 0.1490
82/82 [==============================] - 0s 6ms/step - loss: 0.1422 - mae: 0.3302 - mse: 0.1422 - val_loss: 0.1591 - val_mae: 0.3305 - val_mse: 0.1591
Epoch 4/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1217 - mae: 0.2903 - mse: 0.1217
64/82 [======================>.......] - ETA: 0s - loss: 0.1270 - mae: 0.2856 - mse: 0.1270
82/82 [==============================] - 0s 6ms/step - loss: 0.1206 - mae: 0.2820 - mse: 0.1206 - val_loss: 0.0823 - val_mae: 0.2204 - val_mse: 0.0823
Epoch 5/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0591 - mae: 0.2015 - mse: 0.0591
64/82 [======================>.......] - ETA: 0s - loss: 0.0597 - mae: 0.2051 - mse: 0.0597
82/82 [==============================] - 0s 5ms/step - loss: 0.0606 - mae: 0.2089 - mse: 0.0606 - val_loss: 0.0416 - val_mae: 0.1782 - val_mse: 0.0416
Epoch 6/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0437 - mae: 0.1639 - mse: 0.0437
64/82 [======================>.......] - ETA: 0s - loss: 0.0591 - mae: 0.1880 - mse: 0.0591
82/82 [==============================] - 0s 6ms/step - loss: 0.0616 - mae: 0.1940 - mse: 0.0616 - val_loss: 0.0314 - val_mae: 0.1629 - val_mse: 0.0314
Epoch 7/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0496 - mae: 0.1874 - mse: 0.0496
64/82 [======================>.......] - ETA: 0s - loss: 0.0485 - mae: 0.1799 - mse: 0.0485
82/82 [==============================] - 0s 6ms/step - loss: 0.0462 - mae: 0.1721 - mse: 0.0462 - val_loss: 0.0414 - val_mae: 0.1671 - val_mse: 0.0414
Epoch 8/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0367 - mae: 0.1334 - mse: 0.0367
64/82 [======================>.......] - ETA: 0s - loss: 0.0652 - mae: 0.1720 - mse: 0.0652
82/82 [==============================] - 0s 5ms/step - loss: 0.0592 - mae: 0.1681 - mse: 0.0592 - val_loss: 0.0340 - val_mae: 0.1522 - val_mse: 0.0340
Epoch 9/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0369 - mae: 0.1363 - mse: 0.0369
64/82 [======================>.......] - ETA: 0s - loss: 0.0333 - mae: 0.1273 - mse: 0.0333
82/82 [==============================] - 0s 5ms/step - loss: 0.0365 - mae: 0.1340 - mse: 0.0365 - val_loss: 0.0235 - val_mae: 0.1373 - val_mse: 0.0235
Epoch 10/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0666 - mae: 0.1978 - mse: 0.0666
64/82 [======================>.......] - ETA: 0s - loss: 0.0611 - mae: 0.1874 - mse: 0.0611
82/82 [==============================] - 0s 6ms/step - loss: 0.0568 - mae: 0.1819 - mse: 0.0568 - val_loss: 0.0248 - val_mae: 0.1264 - val_mse: 0.0248
Epoch 11/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0461 - mae: 0.1729 - mse: 0.0461
64/82 [======================>.......] - ETA: 0s - loss: 0.0412 - mae: 0.1583 - mse: 0.0412
82/82 [==============================] - 0s 6ms/step - loss: 0.0419 - mae: 0.1582 - mse: 0.0419 - val_loss: 0.0368 - val_mae: 0.1374 - val_mse: 0.0368
Epoch 12/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0320 - mae: 0.1357 - mse: 0.0320
64/82 [======================>.......] - ETA: 0s - loss: 0.0458 - mae: 0.1574 - mse: 0.0458
82/82 [==============================] - 0s 6ms/step - loss: 0.0447 - mae: 0.1560 - mse: 0.0447 - val_loss: 0.0293 - val_mae: 0.1255 - val_mse: 0.0293
Epoch 13/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0202 - mae: 0.1013 - mse: 0.0202
64/82 [======================>.......] - ETA: 0s - loss: 0.0324 - mae: 0.1240 - mse: 0.0324
82/82 [==============================] - 0s 6ms/step - loss: 0.0298 - mae: 0.1224 - mse: 0.0298 - val_loss: 0.0181 - val_mae: 0.1112 - val_mse: 0.0181
Epoch 14/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0409 - mae: 0.1504 - mse: 0.0409
64/82 [======================>.......] - ETA: 0s - loss: 0.0401 - mae: 0.1555 - mse: 0.0401
82/82 [==============================] - 0s 6ms/step - loss: 0.0412 - mae: 0.1564 - mse: 0.0412 - val_loss: 0.0258 - val_mae: 0.1277 - val_mse: 0.0258
Epoch 15/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0372 - mae: 0.1487 - mse: 0.0372
64/82 [======================>.......] - ETA: 0s - loss: 0.0436 - mae: 0.1556 - mse: 0.0436
82/82 [==============================] - 0s 5ms/step - loss: 0.0405 - mae: 0.1500 - mse: 0.0405 - val_loss: 0.0413 - val_mae: 0.1746 - val_mse: 0.0413
Epoch 16/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0482 - mae: 0.1530 - mse: 0.0482
64/82 [======================>.......] - ETA: 0s - loss: 0.0524 - mae: 0.1628 - mse: 0.0524
82/82 [==============================] - 0s 6ms/step - loss: 0.0444 - mae: 0.1478 - mse: 0.0444 - val_loss: 0.0098 - val_mae: 0.0818 - val_mse: 0.0098
Epoch 17/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0528 - mae: 0.1771 - mse: 0.0528
64/82 [======================>.......] - ETA: 0s - loss: 0.0388 - mae: 0.1502 - mse: 0.0388
82/82 [==============================] - 0s 6ms/step - loss: 0.0364 - mae: 0.1459 - mse: 0.0364 - val_loss: 0.0135 - val_mae: 0.0881 - val_mse: 0.0135
Epoch 18/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0314 - mae: 0.1483 - mse: 0.0314
64/82 [======================>.......] - ETA: 0s - loss: 0.0272 - mae: 0.1348 - mse: 0.0272
82/82 [==============================] - 0s 5ms/step - loss: 0.0309 - mae: 0.1387 - mse: 0.0309 - val_loss: 0.0445 - val_mae: 0.1855 - val_mse: 0.0445
Epoch 19/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0239 - mae: 0.1196 - mse: 0.0239
64/82 [======================>.......] - ETA: 0s - loss: 0.0323 - mae: 0.1308 - mse: 0.0323
82/82 [==============================] - 0s 6ms/step - loss: 0.0313 - mae: 0.1301 - mse: 0.0313 - val_loss: 0.0282 - val_mae: 0.1404 - val_mse: 0.0282
Epoch 20/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0275 - mae: 0.1316 - mse: 0.0275
64/82 [======================>.......] - ETA: 0s - loss: 0.0266 - mae: 0.1251 - mse: 0.0266
82/82 [==============================] - 0s 6ms/step - loss: 0.0333 - mae: 0.1383 - mse: 0.0333 - val_loss: 0.0083 - val_mae: 0.0702 - val_mse: 0.0083
Epoch 21/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0345 - mae: 0.1277 - mse: 0.0345
64/82 [======================>.......] - ETA: 0s - loss: 0.0319 - mae: 0.1333 - mse: 0.0319
82/82 [==============================] - 0s 5ms/step - loss: 0.0289 - mae: 0.1273 - mse: 0.0289 - val_loss: 0.0176 - val_mae: 0.1051 - val_mse: 0.0176
Epoch 22/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0145 - mae: 0.0906 - mse: 0.0145
64/82 [======================>.......] - ETA: 0s - loss: 0.0235 - mae: 0.1122 - mse: 0.0235
82/82 [==============================] - 0s 6ms/step - loss: 0.0268 - mae: 0.1237 - mse: 0.0268 - val_loss: 0.0448 - val_mae: 0.1901 - val_mse: 0.0448
Epoch 23/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0253 - mae: 0.1191 - mse: 0.0253
64/82 [======================>.......] - ETA: 0s - loss: 0.0289 - mae: 0.1268 - mse: 0.0289
82/82 [==============================] - 0s 6ms/step - loss: 0.0281 - mae: 0.1265 - mse: 0.0281 - val_loss: 0.0314 - val_mae: 0.1534 - val_mse: 0.0314
Epoch 24/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0241 - mae: 0.1188 - mse: 0.0241
64/82 [======================>.......] - ETA: 0s - loss: 0.0251 - mae: 0.1199 - mse: 0.0251
82/82 [==============================] - 0s 6ms/step - loss: 0.0260 - mae: 0.1213 - mse: 0.0260 - val_loss: 0.0090 - val_mae: 0.0660 - val_mse: 0.0090
Epoch 25/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0208 - mae: 0.1045 - mse: 0.0208
64/82 [======================>.......] - ETA: 0s - loss: 0.0273 - mae: 0.1209 - mse: 0.0273
82/82 [==============================] - 0s 6ms/step - loss: 0.0263 - mae: 0.1193 - mse: 0.0263 - val_loss: 0.0196 - val_mae: 0.1133 - val_mse: 0.0196
Epoch 26/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0207 - mae: 0.0998 - mse: 0.0207
64/82 [======================>.......] - ETA: 0s - loss: 0.0241 - mae: 0.1086 - mse: 0.0241
82/82 [==============================] - 0s 6ms/step - loss: 0.0237 - mae: 0.1073 - mse: 0.0237 - val_loss: 0.0274 - val_mae: 0.1434 - val_mse: 0.0274
Epoch 27/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0216 - mae: 0.1154 - mse: 0.0216
64/82 [======================>.......] - ETA: 0s - loss: 0.0216 - mae: 0.1099 - mse: 0.0216
82/82 [==============================] - 0s 5ms/step - loss: 0.0193 - mae: 0.1030 - mse: 0.0193 - val_loss: 0.0151 - val_mae: 0.0990 - val_mse: 0.0151
Epoch 28/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0386 - mae: 0.1539 - mse: 0.0386
64/82 [======================>.......] - ETA: 0s - loss: 0.0270 - mae: 0.1247 - mse: 0.0270
82/82 [==============================] - 0s 6ms/step - loss: 0.0261 - mae: 0.1232 - mse: 0.0261 - val_loss: 0.0108 - val_mae: 0.0755 - val_mse: 0.0108
Epoch 29/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0389 - mae: 0.1416 - mse: 0.0389
64/82 [======================>.......] - ETA: 0s - loss: 0.0354 - mae: 0.1333 - mse: 0.0354
82/82 [==============================] - 0s 6ms/step - loss: 0.0306 - mae: 0.1244 - mse: 0.0306 - val_loss: 0.0315 - val_mae: 0.1580 - val_mse: 0.0315
Epoch 30/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0199 - mae: 0.1039 - mse: 0.0199
64/82 [======================>.......] - ETA: 0s - loss: 0.0230 - mae: 0.1076 - mse: 0.0230
82/82 [==============================] - 0s 6ms/step - loss: 0.0231 - mae: 0.1067 - mse: 0.0231 - val_loss: 0.0338 - val_mae: 0.1622 - val_mse: 0.0338
Saving trained model...
105
Testing...
heightdiff= [0.         0.         0.         4.99109268 0.         0.        ]
average prediction= [4.352268]
baseline= 10.978260869565217
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.2477731704711914
85 -:- nan
60 -:- nan
['train-weight-2.py', '1']
2_155_65_2_csi_a2_20.dat
65 2
2_155_65_2_csi_a2_23.dat
65 4
2_155_65_2_csi_a2_16.dat
65 6
65 7
65 8
65 9
2_155_65_2_csi_a2_1.dat
2_155_65_2_csi_a2_21.dat
65 12
65 13
65 14
2_155_65_2_csi_a2_25.dat
2_155_65_2_csi_a2_18.dat
2_155_65_2_csi_a2_17.dat
2_155_65_2_csi_a2_14.dat
65 19
65 20
65 21
65 22
65 23
65 24
2_155_65_2_csi_a2_27.dat
2_155_65_2_csi_a2_24.dat
65 27
65 28
2_155_65_2_csi_a2_7.dat
65 30
60 31
60 32
60 33
2_170_60_2_csi_a2_2.dat
60 35
60 36
60 37
60 38
2_170_60_2_csi_a2_10.dat
60 40
1_165_65_2_csi_a2_30.dat
1_165_65_2_csi_a2_15.dat
1_165_65_2_csi_a2_10.dat
1_165_65_2_csi_a2_21.dat
1_165_65_2_csi_a2_9.dat
1_165_65_2_csi_a2_13.dat
1_165_65_2_csi_a2_19.dat
1_165_65_2_csi_a2_18.dat
1_165_65_2_csi_a2_7.dat
1_165_65_2_csi_a2_20.dat
1_165_65_2_csi_a2_11.dat
1_165_65_2_csi_a2_26.dat
1_165_65_2_csi_a2_16.dat
1_165_65_2_csi_a2_28.dat
1_165_65_2_csi_a2_5.dat
1_165_65_2_csi_a2_6.dat
1_165_65_2_csi_a2_25.dat
1_165_65_2_csi_a2_29.dat
1_165_65_2_csi_a2_23.dat
1_165_65_2_csi_a2_3.dat
1_165_65_2_csi_a2_27.dat
1_165_65_2_csi_a2_2.dat
1_165_65_2_csi_a2_17.dat
1_165_65_2_csi_a2_8.dat
1_165_65_2_csi_a2_14.dat
1_165_65_2_csi_a2_1.dat
1_165_65_2_csi_a2_24.dat
1_165_65_2_csi_a2_4.dat
1_165_65_2_csi_a2_22.dat
1_165_65_2_csi_a2_12.dat
50 71
50 72
50 73
50 74
50 75
50 76
50 77
2_165_50_2_csi_a2_13.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
50 97
50 98
2_165_50_2_csi_a2_24.dat
50 100
1_175_70_2_csi_a2_25.dat
70 102
1_175_70_2_csi_a2_20.dat
1_175_70_2_csi_a2_28.dat
70 105
1_175_70_2_csi_a2_22.dat
1_175_70_2_csi_a2_5.dat
1_175_70_2_csi_a2_11.dat
1_175_70_2_csi_a2_6.dat
1_175_70_2_csi_a2_8.dat
1_175_70_2_csi_a2_3.dat
1_175_70_2_csi_a2_16.dat
1_175_70_2_csi_a2_19.dat
1_175_70_2_csi_a2_1.dat
1_175_70_2_csi_a2_27.dat
70 116
1_175_70_2_csi_a2_18.dat
1_175_70_2_csi_a2_23.dat
1_175_70_2_csi_a2_21.dat
1_175_70_2_csi_a2_12.dat
1_175_70_2_csi_a2_30.dat
1_175_70_2_csi_a2_15.dat
1_175_70_2_csi_a2_17.dat
1_175_70_2_csi_a2_14.dat
1_175_70_2_csi_a2_9.dat
1_175_70_2_csi_a2_24.dat
1_175_70_2_csi_a2_10.dat
1_175_70_2_csi_a2_4.dat
1_175_70_2_csi_a2_29.dat
1_175_70_2_csi_a2_13.dat
1_180_85_2_csi_a2_22.dat
1_180_85_2_csi_a2_17.dat
1_180_85_2_csi_a2_15.dat
1_180_85_2_csi_a2_21.dat
85 135
1_180_85_2_csi_a2_7.dat
1_180_85_2_csi_a2_25.dat
1_180_85_2_csi_a2_19.dat
85 139
1_180_85_2_csi_a2_6.dat
1_180_85_2_csi_a2_1.dat
1_180_85_2_csi_a2_16.dat
1_180_85_2_csi_a2_14.dat
1_180_85_2_csi_a2_23.dat
1_180_85_2_csi_a2_24.dat
1_180_85_2_csi_a2_8.dat
85 147
1_180_85_2_csi_a2_13.dat
1_180_85_2_csi_a2_29.dat
1_180_85_2_csi_a2_9.dat
1_180_85_2_csi_a2_18.dat
1_180_85_2_csi_a2_28.dat
1_180_85_2_csi_a2_12.dat
1_180_85_2_csi_a2_30.dat
1_180_85_2_csi_a2_20.dat
85 156
1_180_85_2_csi_a2_26.dat
1_180_85_2_csi_a2_11.dat
85 159
1_180_85_2_csi_a2_10.dat
75 161
75 162
75 163
75 164
75 165
75 166
1_180_75_2_csi_a2_9.dat
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
75 180
75 181
1_180_75_2_csi_a2_1.dat
75 183
75 184
75 185
1_180_75_2_csi_a2_4.dat
75 187
75 188
75 189
75 190
85 191
85 192
85 193
85 194
85 195
85 196
85 197
85 198
85 199
1_173_85_2_csi_a2_23.dat
85 201
85 202
85 203
85 204
85 205
85 206
85 207
1_173_85_2_csi_a2_13.dat
85 209
85 210
85 211
85 212
85 213
85 214
85 215
85 216
1_173_85_2_csi_a2_28.dat
85 218
1_173_85_2_csi_a2_4.dat
85 220
(115, 30, 3)
(115, 421, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60 60
 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85]
(115, 421, 30, 3, 1)

Loaded dataset of 115 samples, each sized (421, 30, 3, 1)


Train on 92 samples
Test on 23 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 421, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 421, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 421, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 421, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 421, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 421, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 421, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 82 samples, validate on 10 samples
Epoch 1/30

32/82 [==========>...................] - ETA: 0s - loss: 0.5085 - mae: 0.6381 - mse: 0.5085
64/82 [======================>.......] - ETA: 0s - loss: 0.4362 - mae: 0.5812 - mse: 0.4362
82/82 [==============================] - 1s 9ms/step - loss: 0.3968 - mae: 0.5568 - mse: 0.3968 - val_loss: 0.1808 - val_mae: 0.3722 - val_mse: 0.1808
Epoch 2/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1987 - mae: 0.3948 - mse: 0.1987
64/82 [======================>.......] - ETA: 0s - loss: 0.1851 - mae: 0.3732 - mse: 0.1851
82/82 [==============================] - 0s 6ms/step - loss: 0.1725 - mae: 0.3504 - mse: 0.1725 - val_loss: 0.2241 - val_mae: 0.4264 - val_mse: 0.2241
Epoch 3/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1898 - mae: 0.3407 - mse: 0.1898
64/82 [======================>.......] - ETA: 0s - loss: 0.2002 - mae: 0.3337 - mse: 0.2002
82/82 [==============================] - 0s 6ms/step - loss: 0.1939 - mae: 0.3375 - mse: 0.1939 - val_loss: 0.1236 - val_mae: 0.3134 - val_mse: 0.1236
Epoch 4/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1318 - mae: 0.2865 - mse: 0.1318
64/82 [======================>.......] - ETA: 0s - loss: 0.1026 - mae: 0.2472 - mse: 0.1026
82/82 [==============================] - 0s 5ms/step - loss: 0.1240 - mae: 0.2815 - mse: 0.1240 - val_loss: 0.0917 - val_mae: 0.2383 - val_mse: 0.0917
Epoch 5/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0821 - mae: 0.2294 - mse: 0.0821
64/82 [======================>.......] - ETA: 0s - loss: 0.0821 - mae: 0.2277 - mse: 0.0821
82/82 [==============================] - 0s 6ms/step - loss: 0.0867 - mae: 0.2326 - mse: 0.0867 - val_loss: 0.0829 - val_mae: 0.1904 - val_mse: 0.0829
Epoch 6/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1024 - mae: 0.2528 - mse: 0.1024
64/82 [======================>.......] - ETA: 0s - loss: 0.0859 - mae: 0.2341 - mse: 0.0859
82/82 [==============================] - 0s 6ms/step - loss: 0.0879 - mae: 0.2338 - mse: 0.0879 - val_loss: 0.0657 - val_mae: 0.1466 - val_mse: 0.0657
Epoch 7/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0702 - mae: 0.2104 - mse: 0.0702
64/82 [======================>.......] - ETA: 0s - loss: 0.0728 - mae: 0.2040 - mse: 0.0728
82/82 [==============================] - 0s 6ms/step - loss: 0.0643 - mae: 0.1919 - mse: 0.0643 - val_loss: 0.0533 - val_mae: 0.1237 - val_mse: 0.0533
Epoch 8/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0676 - mae: 0.1860 - mse: 0.0676
64/82 [======================>.......] - ETA: 0s - loss: 0.0519 - mae: 0.1596 - mse: 0.0519
82/82 [==============================] - 0s 5ms/step - loss: 0.0548 - mae: 0.1673 - mse: 0.0548 - val_loss: 0.0494 - val_mae: 0.1249 - val_mse: 0.0494
Epoch 9/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0256 - mae: 0.1014 - mse: 0.0256
64/82 [======================>.......] - ETA: 0s - loss: 0.0323 - mae: 0.1180 - mse: 0.0323
82/82 [==============================] - 0s 6ms/step - loss: 0.0373 - mae: 0.1317 - mse: 0.0373 - val_loss: 0.0473 - val_mae: 0.1480 - val_mse: 0.0473
Epoch 10/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0350 - mae: 0.1375 - mse: 0.0350
64/82 [======================>.......] - ETA: 0s - loss: 0.0329 - mae: 0.1350 - mse: 0.0329
82/82 [==============================] - 0s 6ms/step - loss: 0.0321 - mae: 0.1371 - mse: 0.0321 - val_loss: 0.0310 - val_mae: 0.1177 - val_mse: 0.0310
Epoch 11/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0390 - mae: 0.1659 - mse: 0.0390
64/82 [======================>.......] - ETA: 0s - loss: 0.0341 - mae: 0.1459 - mse: 0.0341
82/82 [==============================] - 0s 6ms/step - loss: 0.0395 - mae: 0.1568 - mse: 0.0395 - val_loss: 0.0266 - val_mae: 0.1114 - val_mse: 0.0266
Epoch 12/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0565 - mae: 0.1901 - mse: 0.0565
64/82 [======================>.......] - ETA: 0s - loss: 0.0497 - mae: 0.1711 - mse: 0.0497
82/82 [==============================] - 0s 6ms/step - loss: 0.0429 - mae: 0.1579 - mse: 0.0429 - val_loss: 0.0409 - val_mae: 0.1559 - val_mse: 0.0409
Epoch 13/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0359 - mae: 0.1481 - mse: 0.0359
64/82 [======================>.......] - ETA: 0s - loss: 0.0369 - mae: 0.1482 - mse: 0.0369
82/82 [==============================] - 0s 6ms/step - loss: 0.0354 - mae: 0.1420 - mse: 0.0354 - val_loss: 0.0457 - val_mae: 0.1572 - val_mse: 0.0457
Epoch 14/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0162 - mae: 0.0952 - mse: 0.0162
64/82 [======================>.......] - ETA: 0s - loss: 0.0262 - mae: 0.1075 - mse: 0.0262
82/82 [==============================] - 0s 5ms/step - loss: 0.0307 - mae: 0.1168 - mse: 0.0307 - val_loss: 0.0338 - val_mae: 0.1061 - val_mse: 0.0338
Epoch 15/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0337 - mae: 0.1141 - mse: 0.0337
64/82 [======================>.......] - ETA: 0s - loss: 0.0249 - mae: 0.1067 - mse: 0.0249
82/82 [==============================] - 0s 6ms/step - loss: 0.0279 - mae: 0.1136 - mse: 0.0279 - val_loss: 0.0252 - val_mae: 0.0708 - val_mse: 0.0252
Epoch 16/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0330 - mae: 0.1398 - mse: 0.0330
64/82 [======================>.......] - ETA: 0s - loss: 0.0346 - mae: 0.1412 - mse: 0.0346
82/82 [==============================] - 0s 6ms/step - loss: 0.0331 - mae: 0.1382 - mse: 0.0331 - val_loss: 0.0272 - val_mae: 0.0929 - val_mse: 0.0272
Epoch 17/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0193 - mae: 0.1075 - mse: 0.0193
64/82 [======================>.......] - ETA: 0s - loss: 0.0245 - mae: 0.1211 - mse: 0.0245
82/82 [==============================] - 0s 6ms/step - loss: 0.0223 - mae: 0.1171 - mse: 0.0223 - val_loss: 0.0296 - val_mae: 0.1143 - val_mse: 0.0296
Epoch 18/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0279 - mae: 0.1214 - mse: 0.0279
64/82 [======================>.......] - ETA: 0s - loss: 0.0266 - mae: 0.1163 - mse: 0.0266
82/82 [==============================] - 0s 5ms/step - loss: 0.0237 - mae: 0.1106 - mse: 0.0237 - val_loss: 0.0332 - val_mae: 0.1356 - val_mse: 0.0332
Epoch 19/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0391 - mae: 0.1462 - mse: 0.0391
64/82 [======================>.......] - ETA: 0s - loss: 0.0288 - mae: 0.1283 - mse: 0.0288
82/82 [==============================] - 0s 6ms/step - loss: 0.0273 - mae: 0.1232 - mse: 0.0273 - val_loss: 0.0296 - val_mae: 0.1230 - val_mse: 0.0296
Epoch 20/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0191 - mae: 0.0989 - mse: 0.0191
64/82 [======================>.......] - ETA: 0s - loss: 0.0215 - mae: 0.0958 - mse: 0.0215
82/82 [==============================] - 0s 6ms/step - loss: 0.0189 - mae: 0.0924 - mse: 0.0189 - val_loss: 0.0305 - val_mae: 0.1221 - val_mse: 0.0305
Epoch 21/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0236 - mae: 0.1033 - mse: 0.0236
64/82 [======================>.......] - ETA: 0s - loss: 0.0183 - mae: 0.0948 - mse: 0.0183
82/82 [==============================] - 0s 6ms/step - loss: 0.0206 - mae: 0.0959 - mse: 0.0206 - val_loss: 0.0338 - val_mae: 0.1308 - val_mse: 0.0338
Epoch 22/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0113 - mae: 0.0802 - mse: 0.0113
64/82 [======================>.......] - ETA: 0s - loss: 0.0168 - mae: 0.0959 - mse: 0.0168
82/82 [==============================] - 0s 6ms/step - loss: 0.0223 - mae: 0.1080 - mse: 0.0223 - val_loss: 0.0254 - val_mae: 0.0972 - val_mse: 0.0254
Epoch 23/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0313 - mae: 0.1276 - mse: 0.0313
64/82 [======================>.......] - ETA: 0s - loss: 0.0265 - mae: 0.1213 - mse: 0.0265
82/82 [==============================] - 0s 5ms/step - loss: 0.0286 - mae: 0.1282 - mse: 0.0286 - val_loss: 0.0222 - val_mae: 0.0836 - val_mse: 0.0222
Epoch 24/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0288 - mae: 0.1276 - mse: 0.0288
64/82 [======================>.......] - ETA: 0s - loss: 0.0291 - mae: 0.1210 - mse: 0.0291
82/82 [==============================] - 0s 6ms/step - loss: 0.0299 - mae: 0.1270 - mse: 0.0299 - val_loss: 0.0292 - val_mae: 0.1105 - val_mse: 0.0292
Epoch 25/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0229 - mae: 0.1065 - mse: 0.0229
64/82 [======================>.......] - ETA: 0s - loss: 0.0176 - mae: 0.0961 - mse: 0.0176
82/82 [==============================] - 0s 6ms/step - loss: 0.0207 - mae: 0.1032 - mse: 0.0207 - val_loss: 0.0257 - val_mae: 0.0972 - val_mse: 0.0257
Epoch 26/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0435 - mae: 0.1613 - mse: 0.0435
64/82 [======================>.......] - ETA: 0s - loss: 0.0311 - mae: 0.1352 - mse: 0.0311
82/82 [==============================] - 0s 6ms/step - loss: 0.0270 - mae: 0.1252 - mse: 0.0270 - val_loss: 0.0223 - val_mae: 0.0878 - val_mse: 0.0223
Epoch 27/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0319 - mae: 0.1381 - mse: 0.0319
64/82 [======================>.......] - ETA: 0s - loss: 0.0289 - mae: 0.1260 - mse: 0.0289
82/82 [==============================] - 0s 6ms/step - loss: 0.0261 - mae: 0.1193 - mse: 0.0261 - val_loss: 0.0312 - val_mae: 0.1136 - val_mse: 0.0312
Epoch 28/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0167 - mae: 0.1011 - mse: 0.0167
64/82 [======================>.......] - ETA: 0s - loss: 0.0208 - mae: 0.1024 - mse: 0.0208
82/82 [==============================] - 0s 5ms/step - loss: 0.0260 - mae: 0.1103 - mse: 0.0260 - val_loss: 0.0334 - val_mae: 0.1123 - val_mse: 0.0334
Epoch 29/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0171 - mae: 0.0887 - mse: 0.0171
64/82 [======================>.......] - ETA: 0s - loss: 0.0241 - mae: 0.1009 - mse: 0.0241
82/82 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 0.0966 - mse: 0.0210 - val_loss: 0.0243 - val_mae: 0.0845 - val_mse: 0.0243
Epoch 30/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0164 - mae: 0.0913 - mse: 0.0164
64/82 [======================>.......] - ETA: 0s - loss: 0.0127 - mae: 0.0833 - mse: 0.0127
82/82 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.0914 - mse: 0.0153 - val_loss: 0.0238 - val_mae: 0.0977 - val_mse: 0.0238
Saving trained model...
105
Testing...
heightdiff= [ 0.          0.          0.         10.93365097  0.          0.        ]
average prediction= [3.2539656]
baseline= 11.847826086956522
eachuser= [0. 0. 0. 7. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.5619501386369978
85 -:- nan
60 -:- nan
['train-weight-2.py', '1']
2_155_65_2_csi_a2_20.dat
65 2
2_155_65_2_csi_a2_23.dat
65 4
2_155_65_2_csi_a2_16.dat
65 6
65 7
65 8
65 9
2_155_65_2_csi_a2_1.dat
2_155_65_2_csi_a2_21.dat
65 12
65 13
65 14
2_155_65_2_csi_a2_25.dat
2_155_65_2_csi_a2_18.dat
2_155_65_2_csi_a2_17.dat
2_155_65_2_csi_a2_14.dat
65 19
65 20
65 21
65 22
65 23
65 24
2_155_65_2_csi_a2_27.dat
2_155_65_2_csi_a2_24.dat
65 27
65 28
2_155_65_2_csi_a2_7.dat
65 30
60 31
60 32
60 33
2_170_60_2_csi_a2_2.dat
60 35
60 36
60 37
60 38
2_170_60_2_csi_a2_10.dat
60 40
1_165_65_2_csi_a2_30.dat
1_165_65_2_csi_a2_15.dat
1_165_65_2_csi_a2_10.dat
1_165_65_2_csi_a2_21.dat
1_165_65_2_csi_a2_9.dat
1_165_65_2_csi_a2_13.dat
1_165_65_2_csi_a2_19.dat
1_165_65_2_csi_a2_18.dat
1_165_65_2_csi_a2_7.dat
1_165_65_2_csi_a2_20.dat
1_165_65_2_csi_a2_11.dat
1_165_65_2_csi_a2_26.dat
1_165_65_2_csi_a2_16.dat
1_165_65_2_csi_a2_28.dat
1_165_65_2_csi_a2_5.dat
1_165_65_2_csi_a2_6.dat
1_165_65_2_csi_a2_25.dat
1_165_65_2_csi_a2_29.dat
1_165_65_2_csi_a2_23.dat
1_165_65_2_csi_a2_3.dat
1_165_65_2_csi_a2_27.dat
1_165_65_2_csi_a2_2.dat
1_165_65_2_csi_a2_17.dat
1_165_65_2_csi_a2_8.dat
1_165_65_2_csi_a2_14.dat
1_165_65_2_csi_a2_1.dat
1_165_65_2_csi_a2_24.dat
1_165_65_2_csi_a2_4.dat
1_165_65_2_csi_a2_22.dat
1_165_65_2_csi_a2_12.dat
50 71
50 72
50 73
50 74
50 75
50 76
50 77
2_165_50_2_csi_a2_13.dat
50 79
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
50 96
50 97
50 98
2_165_50_2_csi_a2_24.dat
50 100
1_175_70_2_csi_a2_25.dat
70 102
1_175_70_2_csi_a2_20.dat
1_175_70_2_csi_a2_28.dat
70 105
1_175_70_2_csi_a2_22.dat
1_175_70_2_csi_a2_5.dat
1_175_70_2_csi_a2_11.dat
1_175_70_2_csi_a2_6.dat
1_175_70_2_csi_a2_8.dat
1_175_70_2_csi_a2_3.dat
1_175_70_2_csi_a2_16.dat
1_175_70_2_csi_a2_19.dat
1_175_70_2_csi_a2_1.dat
1_175_70_2_csi_a2_27.dat
70 116
1_175_70_2_csi_a2_18.dat
1_175_70_2_csi_a2_23.dat
1_175_70_2_csi_a2_21.dat
1_175_70_2_csi_a2_12.dat
1_175_70_2_csi_a2_30.dat
1_175_70_2_csi_a2_15.dat
1_175_70_2_csi_a2_17.dat
1_175_70_2_csi_a2_14.dat
1_175_70_2_csi_a2_9.dat
1_175_70_2_csi_a2_24.dat
1_175_70_2_csi_a2_10.dat
1_175_70_2_csi_a2_4.dat
1_175_70_2_csi_a2_29.dat
1_175_70_2_csi_a2_13.dat
1_180_85_2_csi_a2_22.dat
1_180_85_2_csi_a2_17.dat
1_180_85_2_csi_a2_15.dat
1_180_85_2_csi_a2_21.dat
85 135
1_180_85_2_csi_a2_7.dat
1_180_85_2_csi_a2_25.dat
1_180_85_2_csi_a2_19.dat
85 139
1_180_85_2_csi_a2_6.dat
1_180_85_2_csi_a2_1.dat
1_180_85_2_csi_a2_16.dat
1_180_85_2_csi_a2_14.dat
1_180_85_2_csi_a2_23.dat
1_180_85_2_csi_a2_24.dat
1_180_85_2_csi_a2_8.dat
85 147
1_180_85_2_csi_a2_13.dat
1_180_85_2_csi_a2_29.dat
1_180_85_2_csi_a2_9.dat
1_180_85_2_csi_a2_18.dat
1_180_85_2_csi_a2_28.dat
1_180_85_2_csi_a2_12.dat
1_180_85_2_csi_a2_30.dat
1_180_85_2_csi_a2_20.dat
85 156
1_180_85_2_csi_a2_26.dat
1_180_85_2_csi_a2_11.dat
85 159
1_180_85_2_csi_a2_10.dat
75 161
75 162
75 163
75 164
75 165
75 166
1_180_75_2_csi_a2_9.dat
75 168
75 169
75 170
75 171
75 172
75 173
75 174
75 175
75 176
75 177
75 178
75 179
75 180
75 181
1_180_75_2_csi_a2_1.dat
75 183
75 184
75 185
1_180_75_2_csi_a2_4.dat
75 187
75 188
75 189
75 190
85 191
85 192
85 193
85 194
85 195
85 196
85 197
85 198
85 199
1_173_85_2_csi_a2_23.dat
85 201
85 202
85 203
85 204
85 205
85 206
85 207
1_173_85_2_csi_a2_13.dat
85 209
85 210
85 211
85 212
85 213
85 214
85 215
85 216
1_173_85_2_csi_a2_28.dat
85 218
1_173_85_2_csi_a2_4.dat
85 220
(115, 30, 3)
(115, 421, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 60 60 60 60 60 60
 60 60 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 70 70 70 85 85 85 85 85 75 75 75 75 75 75 75 75 75 75
 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 85 85 85 85 85 85 85
 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85]
(115, 421, 30, 3, 1)

Loaded dataset of 115 samples, each sized (421, 30, 3, 1)


Train on 92 samples
Test on 23 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 421, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 421, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 421, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 421, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 421, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 421, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 421, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 82 samples, validate on 10 samples
Epoch 1/30

32/82 [==========>...................] - ETA: 0s - loss: 0.3761 - mae: 0.4880 - mse: 0.3761
64/82 [======================>.......] - ETA: 0s - loss: 0.3687 - mae: 0.5100 - mse: 0.3687
82/82 [==============================] - 1s 10ms/step - loss: 0.3250 - mae: 0.4764 - mse: 0.3250 - val_loss: 0.2292 - val_mae: 0.4532 - val_mse: 0.2292
Epoch 2/30

32/82 [==========>...................] - ETA: 0s - loss: 0.2139 - mae: 0.4173 - mse: 0.2139
64/82 [======================>.......] - ETA: 0s - loss: 0.2157 - mae: 0.4081 - mse: 0.2157
82/82 [==============================] - 0s 6ms/step - loss: 0.2196 - mae: 0.4134 - mse: 0.2196 - val_loss: 0.1668 - val_mae: 0.3716 - val_mse: 0.1668
Epoch 3/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1682 - mae: 0.3415 - mse: 0.1682
64/82 [======================>.......] - ETA: 0s - loss: 0.1924 - mae: 0.3862 - mse: 0.1924
82/82 [==============================] - 0s 6ms/step - loss: 0.1692 - mae: 0.3575 - mse: 0.1692 - val_loss: 0.1707 - val_mae: 0.3827 - val_mse: 0.1707
Epoch 4/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1313 - mae: 0.3129 - mse: 0.1313
64/82 [======================>.......] - ETA: 0s - loss: 0.1472 - mae: 0.3306 - mse: 0.1472
82/82 [==============================] - 0s 5ms/step - loss: 0.1398 - mae: 0.3249 - mse: 0.1398 - val_loss: 0.1672 - val_mae: 0.3676 - val_mse: 0.1672
Epoch 5/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1459 - mae: 0.3138 - mse: 0.1459
64/82 [======================>.......] - ETA: 0s - loss: 0.1381 - mae: 0.3029 - mse: 0.1381
82/82 [==============================] - 0s 6ms/step - loss: 0.1295 - mae: 0.2962 - mse: 0.1295 - val_loss: 0.1245 - val_mae: 0.3131 - val_mse: 0.1245
Epoch 6/30

32/82 [==========>...................] - ETA: 0s - loss: 0.1058 - mae: 0.2722 - mse: 0.1058
64/82 [======================>.......] - ETA: 0s - loss: 0.1131 - mae: 0.2888 - mse: 0.1131
82/82 [==============================] - 0s 6ms/step - loss: 0.1060 - mae: 0.2697 - mse: 0.1060 - val_loss: 0.0746 - val_mae: 0.2263 - val_mse: 0.0746
Epoch 7/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0786 - mae: 0.2123 - mse: 0.0786
64/82 [======================>.......] - ETA: 0s - loss: 0.0893 - mae: 0.2421 - mse: 0.0893
82/82 [==============================] - 0s 6ms/step - loss: 0.0929 - mae: 0.2504 - mse: 0.0929 - val_loss: 0.0550 - val_mae: 0.2088 - val_mse: 0.0550
Epoch 8/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0884 - mae: 0.2500 - mse: 0.0884
64/82 [======================>.......] - ETA: 0s - loss: 0.0936 - mae: 0.2532 - mse: 0.0936
82/82 [==============================] - 0s 6ms/step - loss: 0.0936 - mae: 0.2535 - mse: 0.0936 - val_loss: 0.0463 - val_mae: 0.1744 - val_mse: 0.0463
Epoch 9/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0711 - mae: 0.2025 - mse: 0.0711
64/82 [======================>.......] - ETA: 0s - loss: 0.0585 - mae: 0.1799 - mse: 0.0585
82/82 [==============================] - 0s 6ms/step - loss: 0.0721 - mae: 0.2044 - mse: 0.0721 - val_loss: 0.0527 - val_mae: 0.1723 - val_mse: 0.0527
Epoch 10/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0729 - mae: 0.2118 - mse: 0.0729
64/82 [======================>.......] - ETA: 0s - loss: 0.0745 - mae: 0.2109 - mse: 0.0745
82/82 [==============================] - 0s 6ms/step - loss: 0.0667 - mae: 0.1935 - mse: 0.0667 - val_loss: 0.0491 - val_mae: 0.1611 - val_mse: 0.0491
Epoch 11/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0836 - mae: 0.2198 - mse: 0.0836
64/82 [======================>.......] - ETA: 0s - loss: 0.0642 - mae: 0.1942 - mse: 0.0642
82/82 [==============================] - 0s 6ms/step - loss: 0.0609 - mae: 0.1907 - mse: 0.0609 - val_loss: 0.0351 - val_mae: 0.1295 - val_mse: 0.0351
Epoch 12/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0596 - mae: 0.1797 - mse: 0.0596
64/82 [======================>.......] - ETA: 0s - loss: 0.0526 - mae: 0.1800 - mse: 0.0526
82/82 [==============================] - 0s 6ms/step - loss: 0.0481 - mae: 0.1728 - mse: 0.0481 - val_loss: 0.0252 - val_mae: 0.1321 - val_mse: 0.0252
Epoch 13/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0549 - mae: 0.2031 - mse: 0.0549
64/82 [======================>.......] - ETA: 0s - loss: 0.0430 - mae: 0.1765 - mse: 0.0430
82/82 [==============================] - 0s 5ms/step - loss: 0.0487 - mae: 0.1856 - mse: 0.0487 - val_loss: 0.0261 - val_mae: 0.1132 - val_mse: 0.0261
Epoch 14/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0462 - mae: 0.1666 - mse: 0.0462
64/82 [======================>.......] - ETA: 0s - loss: 0.0426 - mae: 0.1589 - mse: 0.0426
82/82 [==============================] - 0s 6ms/step - loss: 0.0379 - mae: 0.1501 - mse: 0.0379 - val_loss: 0.0364 - val_mae: 0.1359 - val_mse: 0.0364
Epoch 15/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0368 - mae: 0.1542 - mse: 0.0368
64/82 [======================>.......] - ETA: 0s - loss: 0.0476 - mae: 0.1724 - mse: 0.0476
82/82 [==============================] - 0s 6ms/step - loss: 0.0466 - mae: 0.1705 - mse: 0.0466 - val_loss: 0.0261 - val_mae: 0.1073 - val_mse: 0.0261
Epoch 16/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0363 - mae: 0.1399 - mse: 0.0363
64/82 [======================>.......] - ETA: 0s - loss: 0.0454 - mae: 0.1555 - mse: 0.0454
82/82 [==============================] - 0s 6ms/step - loss: 0.0445 - mae: 0.1524 - mse: 0.0445 - val_loss: 0.0163 - val_mae: 0.1094 - val_mse: 0.0163
Epoch 17/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0543 - mae: 0.1726 - mse: 0.0543
64/82 [======================>.......] - ETA: 0s - loss: 0.0491 - mae: 0.1664 - mse: 0.0491
82/82 [==============================] - 0s 6ms/step - loss: 0.0474 - mae: 0.1584 - mse: 0.0474 - val_loss: 0.0160 - val_mae: 0.1155 - val_mse: 0.0160
Epoch 18/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0281 - mae: 0.1195 - mse: 0.0281
64/82 [======================>.......] - ETA: 0s - loss: 0.0291 - mae: 0.1211 - mse: 0.0291
82/82 [==============================] - 0s 6ms/step - loss: 0.0337 - mae: 0.1322 - mse: 0.0337 - val_loss: 0.0148 - val_mae: 0.1088 - val_mse: 0.0148
Epoch 19/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0424 - mae: 0.1525 - mse: 0.0424
64/82 [======================>.......] - ETA: 0s - loss: 0.0423 - mae: 0.1522 - mse: 0.0423
82/82 [==============================] - 0s 6ms/step - loss: 0.0403 - mae: 0.1463 - mse: 0.0403 - val_loss: 0.0160 - val_mae: 0.0915 - val_mse: 0.0160
Epoch 20/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0260 - mae: 0.1253 - mse: 0.0260
64/82 [======================>.......] - ETA: 0s - loss: 0.0287 - mae: 0.1177 - mse: 0.0287
82/82 [==============================] - 0s 6ms/step - loss: 0.0329 - mae: 0.1305 - mse: 0.0329 - val_loss: 0.0173 - val_mae: 0.0992 - val_mse: 0.0173
Epoch 21/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0385 - mae: 0.1485 - mse: 0.0385
64/82 [======================>.......] - ETA: 0s - loss: 0.0385 - mae: 0.1475 - mse: 0.0385
82/82 [==============================] - 0s 6ms/step - loss: 0.0406 - mae: 0.1575 - mse: 0.0406 - val_loss: 0.0154 - val_mae: 0.0949 - val_mse: 0.0154
Epoch 22/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0489 - mae: 0.1881 - mse: 0.0489
64/82 [======================>.......] - ETA: 0s - loss: 0.0387 - mae: 0.1575 - mse: 0.0387
82/82 [==============================] - 0s 6ms/step - loss: 0.0340 - mae: 0.1434 - mse: 0.0340 - val_loss: 0.0153 - val_mae: 0.0940 - val_mse: 0.0153
Epoch 23/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0440 - mae: 0.1595 - mse: 0.0440
64/82 [======================>.......] - ETA: 0s - loss: 0.0378 - mae: 0.1390 - mse: 0.0378
82/82 [==============================] - 0s 5ms/step - loss: 0.0381 - mae: 0.1408 - mse: 0.0381 - val_loss: 0.0157 - val_mae: 0.0957 - val_mse: 0.0157
Epoch 24/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0374 - mae: 0.1328 - mse: 0.0374
64/82 [======================>.......] - ETA: 0s - loss: 0.0300 - mae: 0.1193 - mse: 0.0300
82/82 [==============================] - 0s 6ms/step - loss: 0.0336 - mae: 0.1283 - mse: 0.0336 - val_loss: 0.0077 - val_mae: 0.0604 - val_mse: 0.0077
Epoch 25/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0418 - mae: 0.1354 - mse: 0.0418
64/82 [======================>.......] - ETA: 0s - loss: 0.0404 - mae: 0.1410 - mse: 0.0404
82/82 [==============================] - 0s 6ms/step - loss: 0.0371 - mae: 0.1360 - mse: 0.0371 - val_loss: 0.0052 - val_mae: 0.0550 - val_mse: 0.0052
Epoch 26/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0360 - mae: 0.1531 - mse: 0.0360
64/82 [======================>.......] - ETA: 0s - loss: 0.0360 - mae: 0.1498 - mse: 0.0360
82/82 [==============================] - 0s 6ms/step - loss: 0.0370 - mae: 0.1521 - mse: 0.0370 - val_loss: 0.0115 - val_mae: 0.0817 - val_mse: 0.0115
Epoch 27/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0344 - mae: 0.1453 - mse: 0.0344
64/82 [======================>.......] - ETA: 0s - loss: 0.0362 - mae: 0.1378 - mse: 0.0362
82/82 [==============================] - 0s 5ms/step - loss: 0.0346 - mae: 0.1382 - mse: 0.0346 - val_loss: 0.0242 - val_mae: 0.1328 - val_mse: 0.0242
Epoch 28/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0394 - mae: 0.1610 - mse: 0.0394
64/82 [======================>.......] - ETA: 0s - loss: 0.0349 - mae: 0.1513 - mse: 0.0349
82/82 [==============================] - 0s 6ms/step - loss: 0.0308 - mae: 0.1384 - mse: 0.0308 - val_loss: 0.0063 - val_mae: 0.0605 - val_mse: 0.0063
Epoch 29/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0273 - mae: 0.1102 - mse: 0.0273
64/82 [======================>.......] - ETA: 0s - loss: 0.0244 - mae: 0.1117 - mse: 0.0244
82/82 [==============================] - 0s 6ms/step - loss: 0.0244 - mae: 0.1090 - mse: 0.0244 - val_loss: 0.0028 - val_mae: 0.0449 - val_mse: 0.0028
Epoch 30/30

32/82 [==========>...................] - ETA: 0s - loss: 0.0313 - mae: 0.1318 - mse: 0.0313
64/82 [======================>.......] - ETA: 0s - loss: 0.0329 - mae: 0.1342 - mse: 0.0329
82/82 [==============================] - 0s 5ms/step - loss: 0.0297 - mae: 0.1269 - mse: 0.0297 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045
Saving trained model...
105
Testing...
heightdiff= [ 0.          0.          0.         13.99734879  0.          0.        ]
average prediction= [2.3661923]
baseline= 14.456521739130435
eachuser= [0. 0. 0. 9. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.5552609761555989
85 -:- nan
60 -:- nan
