['train-weight-4.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_4_csi_a4_18.dat
65 42
65 43
1_165_65_4_csi_a4_5.dat
65 45
65 46
65 47
65 48
65 49
1_165_65_4_csi_a4_24.dat
65 51
65 52
65 53
65 54
1_165_65_4_csi_a4_7.dat
65 56
65 57
65 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
65 61
65 62
65 63
65 64
65 65
65 66
65 67
65 68
1_165_65_4_csi_a4_29.dat
65 70
50 71
50 72
50 73
2_165_50_4_csi_a4_13.dat
50 75
50 76
50 77
50 78
2_165_50_4_csi_a4_15.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
2_165_50_4_csi_a4_25.dat
50 97
50 98
50 99
50 100
70 101
1_175_70_4_csi_a4_14.dat
70 103
1_175_70_4_csi_a4_16.dat
70 105
1_175_70_4_csi_a4_8.dat
70 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
70 111
70 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
70 115
1_175_70_4_csi_a4_28.dat
70 117
70 118
70 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
70 122
1_175_70_4_csi_a4_5.dat
70 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
70 127
1_175_70_4_csi_a4_22.dat
70 129
70 130
85 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
85 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
85 142
1_180_85_4_csi_a4_30.dat
85 144
85 145
85 146
85 147
1_180_85_4_csi_a4_20.dat
85 149
85 150
85 151
85 152
85 153
1_180_85_4_csi_a4_29.dat
85 155
85 156
85 157
85 158
85 159
85 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
75 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 75]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.2140 - mae: 0.3771 - mse: 0.2140
64/89 [====================>.........] - ETA: 0s - loss: 0.2139 - mae: 0.3796 - mse: 0.2139
89/89 [==============================] - 1s 8ms/step - loss: 0.2012 - mae: 0.3653 - mse: 0.2012 - val_loss: 0.0823 - val_mae: 0.2013 - val_mse: 0.0823
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0909 - mae: 0.2219 - mse: 0.0909
64/89 [====================>.........] - ETA: 0s - loss: 0.1180 - mae: 0.2697 - mse: 0.1180
89/89 [==============================] - 0s 4ms/step - loss: 0.1191 - mae: 0.2758 - mse: 0.1191 - val_loss: 0.0734 - val_mae: 0.2240 - val_mse: 0.0734
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1340 - mae: 0.3323 - mse: 0.1340
64/89 [====================>.........] - ETA: 0s - loss: 0.1238 - mae: 0.3082 - mse: 0.1238
89/89 [==============================] - 0s 4ms/step - loss: 0.1189 - mae: 0.3011 - mse: 0.1189 - val_loss: 0.0442 - val_mae: 0.1459 - val_mse: 0.0442
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0596 - mae: 0.2057 - mse: 0.0596
64/89 [====================>.........] - ETA: 0s - loss: 0.0772 - mae: 0.2278 - mse: 0.0772
89/89 [==============================] - 0s 4ms/step - loss: 0.0697 - mae: 0.2094 - mse: 0.0697 - val_loss: 0.0482 - val_mae: 0.1432 - val_mse: 0.0482
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0596 - mae: 0.1773 - mse: 0.0596
64/89 [====================>.........] - ETA: 0s - loss: 0.0692 - mae: 0.1904 - mse: 0.0692
89/89 [==============================] - 0s 4ms/step - loss: 0.0742 - mae: 0.1931 - mse: 0.0742 - val_loss: 0.0457 - val_mae: 0.1439 - val_mse: 0.0457
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0512 - mae: 0.1630 - mse: 0.0512
64/89 [====================>.........] - ETA: 0s - loss: 0.0622 - mae: 0.1884 - mse: 0.0622
89/89 [==============================] - 0s 4ms/step - loss: 0.0596 - mae: 0.1886 - mse: 0.0596 - val_loss: 0.0350 - val_mae: 0.1456 - val_mse: 0.0350
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0299 - mae: 0.1435 - mse: 0.0299
64/89 [====================>.........] - ETA: 0s - loss: 0.0425 - mae: 0.1737 - mse: 0.0425
89/89 [==============================] - 0s 4ms/step - loss: 0.0494 - mae: 0.1852 - mse: 0.0494 - val_loss: 0.0338 - val_mae: 0.1570 - val_mse: 0.0338
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0335 - mae: 0.1494 - mse: 0.0335
64/89 [====================>.........] - ETA: 0s - loss: 0.0441 - mae: 0.1747 - mse: 0.0441
89/89 [==============================] - 0s 4ms/step - loss: 0.0467 - mae: 0.1766 - mse: 0.0467 - val_loss: 0.0320 - val_mae: 0.1421 - val_mse: 0.0320
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0457 - mae: 0.1696 - mse: 0.0457
64/89 [====================>.........] - ETA: 0s - loss: 0.0451 - mae: 0.1697 - mse: 0.0451
89/89 [==============================] - 0s 5ms/step - loss: 0.0434 - mae: 0.1641 - mse: 0.0434 - val_loss: 0.0339 - val_mae: 0.1417 - val_mse: 0.0339
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0449 - mae: 0.1514 - mse: 0.0449
64/89 [====================>.........] - ETA: 0s - loss: 0.0419 - mae: 0.1488 - mse: 0.0419
89/89 [==============================] - 0s 4ms/step - loss: 0.0413 - mae: 0.1469 - mse: 0.0413 - val_loss: 0.0311 - val_mae: 0.1338 - val_mse: 0.0311
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0267 - mae: 0.1146 - mse: 0.0267
64/89 [====================>.........] - ETA: 0s - loss: 0.0330 - mae: 0.1411 - mse: 0.0330
89/89 [==============================] - 0s 4ms/step - loss: 0.0367 - mae: 0.1452 - mse: 0.0367 - val_loss: 0.0253 - val_mae: 0.1189 - val_mse: 0.0253
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0441 - mae: 0.1665 - mse: 0.0441
64/89 [====================>.........] - ETA: 0s - loss: 0.0315 - mae: 0.1385 - mse: 0.0315
89/89 [==============================] - 0s 5ms/step - loss: 0.0280 - mae: 0.1274 - mse: 0.0280 - val_loss: 0.0178 - val_mae: 0.0948 - val_mse: 0.0178
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0386 - mae: 0.1501 - mse: 0.0386
64/89 [====================>.........] - ETA: 0s - loss: 0.0394 - mae: 0.1476 - mse: 0.0394
89/89 [==============================] - 0s 4ms/step - loss: 0.0367 - mae: 0.1445 - mse: 0.0367 - val_loss: 0.0156 - val_mae: 0.0947 - val_mse: 0.0156
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0315 - mae: 0.1449 - mse: 0.0315
64/89 [====================>.........] - ETA: 0s - loss: 0.0246 - mae: 0.1209 - mse: 0.0246
89/89 [==============================] - 0s 4ms/step - loss: 0.0297 - mae: 0.1279 - mse: 0.0297 - val_loss: 0.0220 - val_mae: 0.1216 - val_mse: 0.0220
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0167 - mae: 0.0942 - mse: 0.0167
64/89 [====================>.........] - ETA: 0s - loss: 0.0231 - mae: 0.1072 - mse: 0.0231
89/89 [==============================] - 0s 4ms/step - loss: 0.0232 - mae: 0.1067 - mse: 0.0232 - val_loss: 0.0245 - val_mae: 0.1257 - val_mse: 0.0245
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0234 - mae: 0.1198 - mse: 0.0234
64/89 [====================>.........] - ETA: 0s - loss: 0.0209 - mae: 0.1080 - mse: 0.0209
89/89 [==============================] - 0s 4ms/step - loss: 0.0212 - mae: 0.1068 - mse: 0.0212 - val_loss: 0.0159 - val_mae: 0.1051 - val_mse: 0.0159
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0097 - mae: 0.0745 - mse: 0.0097
64/89 [====================>.........] - ETA: 0s - loss: 0.0147 - mae: 0.0869 - mse: 0.0147
89/89 [==============================] - 0s 4ms/step - loss: 0.0196 - mae: 0.0983 - mse: 0.0196 - val_loss: 0.0123 - val_mae: 0.0928 - val_mse: 0.0123
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0250 - mae: 0.1110 - mse: 0.0250
64/89 [====================>.........] - ETA: 0s - loss: 0.0208 - mae: 0.1001 - mse: 0.0208
89/89 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 0.1016 - mse: 0.0210 - val_loss: 0.0145 - val_mae: 0.0944 - val_mse: 0.0145
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0272 - mae: 0.1243 - mse: 0.0272
64/89 [====================>.........] - ETA: 0s - loss: 0.0172 - mae: 0.0945 - mse: 0.0172
89/89 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 0.1002 - mse: 0.0187 - val_loss: 0.0163 - val_mae: 0.1032 - val_mse: 0.0163
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0142 - mae: 0.0850 - mse: 0.0142
64/89 [====================>.........] - ETA: 0s - loss: 0.0172 - mae: 0.0924 - mse: 0.0172
89/89 [==============================] - 0s 4ms/step - loss: 0.0144 - mae: 0.0847 - mse: 0.0144 - val_loss: 0.0146 - val_mae: 0.1011 - val_mse: 0.0146
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0102 - mae: 0.0785 - mse: 0.0102
64/89 [====================>.........] - ETA: 0s - loss: 0.0103 - mae: 0.0751 - mse: 0.0103
89/89 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0783 - mse: 0.0116 - val_loss: 0.0118 - val_mae: 0.0928 - val_mse: 0.0118
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0181 - mae: 0.1043 - mse: 0.0181
64/89 [====================>.........] - ETA: 0s - loss: 0.0109 - mae: 0.0772 - mse: 0.0109
89/89 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0821 - mse: 0.0136 - val_loss: 0.0188 - val_mae: 0.1203 - val_mse: 0.0188
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0114 - mae: 0.0804 - mse: 0.0114
64/89 [====================>.........] - ETA: 0s - loss: 0.0113 - mae: 0.0733 - mse: 0.0113
89/89 [==============================] - 0s 4ms/step - loss: 0.0137 - mae: 0.0819 - mse: 0.0137 - val_loss: 0.0176 - val_mae: 0.1145 - val_mse: 0.0176
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0050 - mae: 0.0580 - mse: 0.0050
64/89 [====================>.........] - ETA: 0s - loss: 0.0135 - mae: 0.0855 - mse: 0.0135
89/89 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0785 - mse: 0.0113 - val_loss: 0.0122 - val_mae: 0.0970 - val_mse: 0.0122
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0115 - mae: 0.0915 - mse: 0.0115
64/89 [====================>.........] - ETA: 0s - loss: 0.0092 - mae: 0.0766 - mse: 0.0092
89/89 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0736 - mse: 0.0087 - val_loss: 0.0186 - val_mae: 0.1235 - val_mse: 0.0186
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0080 - mae: 0.0553 - mse: 0.0080
64/89 [====================>.........] - ETA: 0s - loss: 0.0072 - mae: 0.0584 - mse: 0.0072
89/89 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0663 - mse: 0.0088 - val_loss: 0.0153 - val_mae: 0.1152 - val_mse: 0.0153
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0174 - mae: 0.0867 - mse: 0.0174
64/89 [====================>.........] - ETA: 0s - loss: 0.0142 - mae: 0.0809 - mse: 0.0142
89/89 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0769 - mse: 0.0125 - val_loss: 0.0237 - val_mae: 0.1410 - val_mse: 0.0237
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0047 - mae: 0.0518 - mse: 0.0047
64/89 [====================>.........] - ETA: 0s - loss: 0.0071 - mae: 0.0605 - mse: 0.0071
89/89 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0655 - mse: 0.0083 - val_loss: 0.0271 - val_mae: 0.1470 - val_mse: 0.0271
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0065 - mae: 0.0596 - mse: 0.0065
64/89 [====================>.........] - ETA: 0s - loss: 0.0074 - mae: 0.0641 - mse: 0.0074
89/89 [==============================] - 0s 4ms/step - loss: 0.0067 - mae: 0.0619 - mse: 0.0067 - val_loss: 0.0160 - val_mae: 0.1136 - val_mse: 0.0160
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0057 - mae: 0.0583 - mse: 0.0057
64/89 [====================>.........] - ETA: 0s - loss: 0.0090 - mae: 0.0754 - mse: 0.0090
89/89 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0679 - mse: 0.0077 - val_loss: 0.0170 - val_mae: 0.1168 - val_mse: 0.0170
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         3.80348969 0.         0.        ]
average prediction= [4.3260365]
baseline= 6.5
eachuser= [0. 0. 0. 3. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.2678298950195312
85 -:- nan
60 -:- nan
['train-weight-4.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_4_csi_a4_18.dat
65 42
65 43
1_165_65_4_csi_a4_5.dat
65 45
65 46
65 47
65 48
65 49
1_165_65_4_csi_a4_24.dat
65 51
65 52
65 53
65 54
1_165_65_4_csi_a4_7.dat
65 56
65 57
65 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
65 61
65 62
65 63
65 64
65 65
65 66
65 67
65 68
1_165_65_4_csi_a4_29.dat
65 70
50 71
50 72
50 73
2_165_50_4_csi_a4_13.dat
50 75
50 76
50 77
50 78
2_165_50_4_csi_a4_15.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
2_165_50_4_csi_a4_25.dat
50 97
50 98
50 99
50 100
70 101
1_175_70_4_csi_a4_14.dat
70 103
1_175_70_4_csi_a4_16.dat
70 105
1_175_70_4_csi_a4_8.dat
70 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
70 111
70 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
70 115
1_175_70_4_csi_a4_28.dat
70 117
70 118
70 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
70 122
1_175_70_4_csi_a4_5.dat
70 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
70 127
1_175_70_4_csi_a4_22.dat
70 129
70 130
85 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
85 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
85 142
1_180_85_4_csi_a4_30.dat
85 144
85 145
85 146
85 147
1_180_85_4_csi_a4_20.dat
85 149
85 150
85 151
85 152
85 153
1_180_85_4_csi_a4_29.dat
85 155
85 156
85 157
85 158
85 159
85 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
75 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 75]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.2205 - mae: 0.4077 - mse: 0.2205
64/89 [====================>.........] - ETA: 0s - loss: 0.1777 - mae: 0.3491 - mse: 0.1777
89/89 [==============================] - 1s 8ms/step - loss: 0.1553 - mae: 0.3180 - mse: 0.1553 - val_loss: 0.1104 - val_mae: 0.2984 - val_mse: 0.1104
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0808 - mae: 0.2249 - mse: 0.0808
64/89 [====================>.........] - ETA: 0s - loss: 0.1256 - mae: 0.2915 - mse: 0.1256
89/89 [==============================] - 0s 5ms/step - loss: 0.1229 - mae: 0.2907 - mse: 0.1229 - val_loss: 0.0664 - val_mae: 0.2345 - val_mse: 0.0664
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0832 - mae: 0.2618 - mse: 0.0832
64/89 [====================>.........] - ETA: 0s - loss: 0.0737 - mae: 0.2348 - mse: 0.0737
89/89 [==============================] - 0s 4ms/step - loss: 0.0845 - mae: 0.2404 - mse: 0.0845 - val_loss: 0.0406 - val_mae: 0.1265 - val_mse: 0.0406
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1182 - mae: 0.2806 - mse: 0.1182
64/89 [====================>.........] - ETA: 0s - loss: 0.0945 - mae: 0.2365 - mse: 0.0945
89/89 [==============================] - 0s 5ms/step - loss: 0.0787 - mae: 0.2122 - mse: 0.0787 - val_loss: 0.0366 - val_mae: 0.1055 - val_mse: 0.0366
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0903 - mae: 0.2306 - mse: 0.0903
64/89 [====================>.........] - ETA: 0s - loss: 0.0762 - mae: 0.2025 - mse: 0.0762
89/89 [==============================] - 1s 6ms/step - loss: 0.0776 - mae: 0.2064 - mse: 0.0776 - val_loss: 0.0302 - val_mae: 0.1098 - val_mse: 0.0302
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0484 - mae: 0.1711 - mse: 0.0484
64/89 [====================>.........] - ETA: 0s - loss: 0.0556 - mae: 0.1915 - mse: 0.0556
89/89 [==============================] - 0s 4ms/step - loss: 0.0548 - mae: 0.1923 - mse: 0.0548 - val_loss: 0.0338 - val_mae: 0.1589 - val_mse: 0.0338
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0737 - mae: 0.2363 - mse: 0.0737
64/89 [====================>.........] - ETA: 0s - loss: 0.0692 - mae: 0.2296 - mse: 0.0692
89/89 [==============================] - 0s 4ms/step - loss: 0.0684 - mae: 0.2299 - mse: 0.0684 - val_loss: 0.0342 - val_mae: 0.1621 - val_mse: 0.0342
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0586 - mae: 0.1952 - mse: 0.0586
64/89 [====================>.........] - ETA: 0s - loss: 0.0510 - mae: 0.1874 - mse: 0.0510
89/89 [==============================] - 0s 4ms/step - loss: 0.0531 - mae: 0.1911 - mse: 0.0531 - val_loss: 0.0274 - val_mae: 0.1127 - val_mse: 0.0274
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0647 - mae: 0.2066 - mse: 0.0647
64/89 [====================>.........] - ETA: 0s - loss: 0.0616 - mae: 0.1920 - mse: 0.0616
89/89 [==============================] - 0s 4ms/step - loss: 0.0583 - mae: 0.1852 - mse: 0.0583 - val_loss: 0.0275 - val_mae: 0.0826 - val_mse: 0.0275
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0459 - mae: 0.1488 - mse: 0.0459
64/89 [====================>.........] - ETA: 0s - loss: 0.0527 - mae: 0.1632 - mse: 0.0527
89/89 [==============================] - 0s 4ms/step - loss: 0.0517 - mae: 0.1634 - mse: 0.0517 - val_loss: 0.0271 - val_mae: 0.0789 - val_mse: 0.0271
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0560 - mae: 0.1706 - mse: 0.0560
64/89 [====================>.........] - ETA: 0s - loss: 0.0450 - mae: 0.1559 - mse: 0.0450
89/89 [==============================] - 0s 4ms/step - loss: 0.0406 - mae: 0.1489 - mse: 0.0406 - val_loss: 0.0251 - val_mae: 0.1009 - val_mse: 0.0251
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0331 - mae: 0.1391 - mse: 0.0331
64/89 [====================>.........] - ETA: 0s - loss: 0.0343 - mae: 0.1432 - mse: 0.0343
89/89 [==============================] - 0s 4ms/step - loss: 0.0316 - mae: 0.1407 - mse: 0.0316 - val_loss: 0.0249 - val_mae: 0.1106 - val_mse: 0.0249
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0309 - mae: 0.1369 - mse: 0.0309
64/89 [====================>.........] - ETA: 0s - loss: 0.0362 - mae: 0.1579 - mse: 0.0362
89/89 [==============================] - 0s 4ms/step - loss: 0.0389 - mae: 0.1615 - mse: 0.0389 - val_loss: 0.0239 - val_mae: 0.1097 - val_mse: 0.0239
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0284 - mae: 0.1279 - mse: 0.0284
64/89 [====================>.........] - ETA: 0s - loss: 0.0291 - mae: 0.1314 - mse: 0.0291
89/89 [==============================] - 0s 4ms/step - loss: 0.0399 - mae: 0.1495 - mse: 0.0399 - val_loss: 0.0279 - val_mae: 0.1167 - val_mse: 0.0279
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0298 - mae: 0.1320 - mse: 0.0298
64/89 [====================>.........] - ETA: 0s - loss: 0.0361 - mae: 0.1461 - mse: 0.0361
89/89 [==============================] - 0s 4ms/step - loss: 0.0369 - mae: 0.1458 - mse: 0.0369 - val_loss: 0.0251 - val_mae: 0.1122 - val_mse: 0.0251
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0398 - mae: 0.1451 - mse: 0.0398
64/89 [====================>.........] - ETA: 0s - loss: 0.0340 - mae: 0.1302 - mse: 0.0340
89/89 [==============================] - 0s 4ms/step - loss: 0.0346 - mae: 0.1380 - mse: 0.0346 - val_loss: 0.0208 - val_mae: 0.0960 - val_mse: 0.0208
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0283 - mae: 0.1257 - mse: 0.0283
64/89 [====================>.........] - ETA: 0s - loss: 0.0414 - mae: 0.1512 - mse: 0.0414
89/89 [==============================] - 0s 4ms/step - loss: 0.0385 - mae: 0.1461 - mse: 0.0385 - val_loss: 0.0186 - val_mae: 0.0828 - val_mse: 0.0186
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0303 - mae: 0.1287 - mse: 0.0303
64/89 [====================>.........] - ETA: 0s - loss: 0.0297 - mae: 0.1245 - mse: 0.0297
89/89 [==============================] - 0s 4ms/step - loss: 0.0345 - mae: 0.1331 - mse: 0.0345 - val_loss: 0.0186 - val_mae: 0.0814 - val_mse: 0.0186
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0243 - mae: 0.1006 - mse: 0.0243
64/89 [====================>.........] - ETA: 0s - loss: 0.0238 - mae: 0.1047 - mse: 0.0238
89/89 [==============================] - 0s 4ms/step - loss: 0.0307 - mae: 0.1222 - mse: 0.0307 - val_loss: 0.0159 - val_mae: 0.0813 - val_mse: 0.0159
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0419 - mae: 0.1556 - mse: 0.0419
64/89 [====================>.........] - ETA: 0s - loss: 0.0412 - mae: 0.1509 - mse: 0.0412
89/89 [==============================] - 0s 4ms/step - loss: 0.0354 - mae: 0.1340 - mse: 0.0354 - val_loss: 0.0140 - val_mae: 0.0778 - val_mse: 0.0140
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0241 - mae: 0.1217 - mse: 0.0241
64/89 [====================>.........] - ETA: 0s - loss: 0.0302 - mae: 0.1278 - mse: 0.0302
89/89 [==============================] - 0s 4ms/step - loss: 0.0288 - mae: 0.1241 - mse: 0.0288 - val_loss: 0.0159 - val_mae: 0.0863 - val_mse: 0.0159
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0262 - mae: 0.1168 - mse: 0.0262
64/89 [====================>.........] - ETA: 0s - loss: 0.0253 - mae: 0.1142 - mse: 0.0253
89/89 [==============================] - 0s 4ms/step - loss: 0.0226 - mae: 0.1074 - mse: 0.0226 - val_loss: 0.0124 - val_mae: 0.0762 - val_mse: 0.0124
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0084 - mae: 0.0735 - mse: 0.0084
64/89 [====================>.........] - ETA: 0s - loss: 0.0140 - mae: 0.0881 - mse: 0.0140
89/89 [==============================] - 0s 4ms/step - loss: 0.0164 - mae: 0.0971 - mse: 0.0164 - val_loss: 0.0074 - val_mae: 0.0537 - val_mse: 0.0074
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0177 - mae: 0.1009 - mse: 0.0177
64/89 [====================>.........] - ETA: 0s - loss: 0.0153 - mae: 0.0951 - mse: 0.0153
89/89 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0944 - mse: 0.0141 - val_loss: 0.0065 - val_mae: 0.0555 - val_mse: 0.0065
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0146 - mae: 0.0877 - mse: 0.0146
64/89 [====================>.........] - ETA: 0s - loss: 0.0148 - mae: 0.0864 - mse: 0.0148
89/89 [==============================] - 0s 4ms/step - loss: 0.0142 - mae: 0.0877 - mse: 0.0142 - val_loss: 0.0140 - val_mae: 0.1008 - val_mse: 0.0140
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0162 - mae: 0.0988 - mse: 0.0162
64/89 [====================>.........] - ETA: 0s - loss: 0.0160 - mae: 0.0971 - mse: 0.0160
89/89 [==============================] - 0s 4ms/step - loss: 0.0138 - mae: 0.0906 - mse: 0.0138 - val_loss: 0.0063 - val_mae: 0.0697 - val_mse: 0.0063
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0107 - mae: 0.0787 - mse: 0.0107
64/89 [====================>.........] - ETA: 0s - loss: 0.0110 - mae: 0.0803 - mse: 0.0110
89/89 [==============================] - 0s 4ms/step - loss: 0.0126 - mae: 0.0863 - mse: 0.0126 - val_loss: 0.0060 - val_mae: 0.0669 - val_mse: 0.0060
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0071 - mae: 0.0667 - mse: 0.0071
64/89 [====================>.........] - ETA: 0s - loss: 0.0102 - mae: 0.0743 - mse: 0.0102
89/89 [==============================] - 0s 4ms/step - loss: 0.0125 - mae: 0.0811 - mse: 0.0125 - val_loss: 0.0111 - val_mae: 0.0820 - val_mse: 0.0111
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0181 - mae: 0.0940 - mse: 0.0181
64/89 [====================>.........] - ETA: 0s - loss: 0.0151 - mae: 0.0890 - mse: 0.0151
89/89 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0827 - mse: 0.0130 - val_loss: 0.0037 - val_mae: 0.0514 - val_mse: 0.0037
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0134 - mae: 0.0865 - mse: 0.0134
64/89 [====================>.........] - ETA: 0s - loss: 0.0110 - mae: 0.0807 - mse: 0.0110
89/89 [==============================] - 0s 4ms/step - loss: 0.0120 - mae: 0.0820 - mse: 0.0120 - val_loss: 0.0072 - val_mae: 0.0677 - val_mse: 0.0072
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         3.75203323 0.         0.        ]
average prediction= [4.234144]
baseline= 8.5
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.7504066467285156
85 -:- nan
60 -:- nan
['train-weight-4.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_4_csi_a4_18.dat
65 42
65 43
1_165_65_4_csi_a4_5.dat
65 45
65 46
65 47
65 48
65 49
1_165_65_4_csi_a4_24.dat
65 51
65 52
65 53
65 54
1_165_65_4_csi_a4_7.dat
65 56
65 57
65 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
65 61
65 62
65 63
65 64
65 65
65 66
65 67
65 68
1_165_65_4_csi_a4_29.dat
65 70
50 71
50 72
50 73
2_165_50_4_csi_a4_13.dat
50 75
50 76
50 77
50 78
2_165_50_4_csi_a4_15.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
2_165_50_4_csi_a4_25.dat
50 97
50 98
50 99
50 100
70 101
1_175_70_4_csi_a4_14.dat
70 103
1_175_70_4_csi_a4_16.dat
70 105
1_175_70_4_csi_a4_8.dat
70 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
70 111
70 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
70 115
1_175_70_4_csi_a4_28.dat
70 117
70 118
70 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
70 122
1_175_70_4_csi_a4_5.dat
70 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
70 127
1_175_70_4_csi_a4_22.dat
70 129
70 130
85 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
85 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
85 142
1_180_85_4_csi_a4_30.dat
85 144
85 145
85 146
85 147
1_180_85_4_csi_a4_20.dat
85 149
85 150
85 151
85 152
85 153
1_180_85_4_csi_a4_29.dat
85 155
85 156
85 157
85 158
85 159
85 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
75 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 75]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.2224 - mae: 0.3845 - mse: 0.2224
64/89 [====================>.........] - ETA: 0s - loss: 0.1642 - mae: 0.3306 - mse: 0.1642
89/89 [==============================] - 1s 8ms/step - loss: 0.1498 - mae: 0.3070 - mse: 0.1498 - val_loss: 0.0936 - val_mae: 0.2450 - val_mse: 0.0936
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1116 - mae: 0.2870 - mse: 0.1116
64/89 [====================>.........] - ETA: 0s - loss: 0.1068 - mae: 0.2767 - mse: 0.1068
89/89 [==============================] - 0s 5ms/step - loss: 0.0966 - mae: 0.2546 - mse: 0.0966 - val_loss: 0.0991 - val_mae: 0.2052 - val_mse: 0.0991
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0550 - mae: 0.1700 - mse: 0.0550
64/89 [====================>.........] - ETA: 0s - loss: 0.0640 - mae: 0.1704 - mse: 0.0640
89/89 [==============================] - 0s 5ms/step - loss: 0.0727 - mae: 0.1884 - mse: 0.0727 - val_loss: 0.0929 - val_mae: 0.2026 - val_mse: 0.0929
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0461 - mae: 0.1594 - mse: 0.0461
64/89 [====================>.........] - ETA: 0s - loss: 0.0558 - mae: 0.1788 - mse: 0.0558
89/89 [==============================] - 0s 5ms/step - loss: 0.0612 - mae: 0.1865 - mse: 0.0612 - val_loss: 0.0623 - val_mae: 0.2216 - val_mse: 0.0623
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0608 - mae: 0.1962 - mse: 0.0608
64/89 [====================>.........] - ETA: 0s - loss: 0.0696 - mae: 0.2112 - mse: 0.0696
89/89 [==============================] - 0s 5ms/step - loss: 0.0662 - mae: 0.2104 - mse: 0.0662 - val_loss: 0.0593 - val_mae: 0.2139 - val_mse: 0.0593
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0233 - mae: 0.1182 - mse: 0.0233
64/89 [====================>.........] - ETA: 0s - loss: 0.0293 - mae: 0.1303 - mse: 0.0293
89/89 [==============================] - 0s 5ms/step - loss: 0.0467 - mae: 0.1590 - mse: 0.0467 - val_loss: 0.0713 - val_mae: 0.1975 - val_mse: 0.0713
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0418 - mae: 0.1447 - mse: 0.0418
64/89 [====================>.........] - ETA: 0s - loss: 0.0513 - mae: 0.1562 - mse: 0.0513
89/89 [==============================] - 0s 5ms/step - loss: 0.0478 - mae: 0.1498 - mse: 0.0478 - val_loss: 0.0671 - val_mae: 0.1915 - val_mse: 0.0671
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0683 - mae: 0.1940 - mse: 0.0683
64/89 [====================>.........] - ETA: 0s - loss: 0.0407 - mae: 0.1437 - mse: 0.0407
89/89 [==============================] - 0s 5ms/step - loss: 0.0420 - mae: 0.1451 - mse: 0.0420 - val_loss: 0.0553 - val_mae: 0.1862 - val_mse: 0.0553
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0593 - mae: 0.1797 - mse: 0.0593
64/89 [====================>.........] - ETA: 0s - loss: 0.0481 - mae: 0.1662 - mse: 0.0481
89/89 [==============================] - 0s 5ms/step - loss: 0.0519 - mae: 0.1716 - mse: 0.0519 - val_loss: 0.0536 - val_mae: 0.1754 - val_mse: 0.0536
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0305 - mae: 0.1149 - mse: 0.0305
64/89 [====================>.........] - ETA: 0s - loss: 0.0396 - mae: 0.1327 - mse: 0.0396
89/89 [==============================] - 0s 5ms/step - loss: 0.0451 - mae: 0.1464 - mse: 0.0451 - val_loss: 0.0558 - val_mae: 0.1650 - val_mse: 0.0558
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0371 - mae: 0.1425 - mse: 0.0371
64/89 [====================>.........] - ETA: 0s - loss: 0.0276 - mae: 0.1205 - mse: 0.0276
89/89 [==============================] - 0s 5ms/step - loss: 0.0280 - mae: 0.1219 - mse: 0.0280 - val_loss: 0.0525 - val_mae: 0.1687 - val_mse: 0.0525
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0439 - mae: 0.1416 - mse: 0.0439
64/89 [====================>.........] - ETA: 0s - loss: 0.0358 - mae: 0.1339 - mse: 0.0358
89/89 [==============================] - 0s 5ms/step - loss: 0.0300 - mae: 0.1233 - mse: 0.0300 - val_loss: 0.0394 - val_mae: 0.1449 - val_mse: 0.0394
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0321 - mae: 0.1330 - mse: 0.0321
64/89 [====================>.........] - ETA: 0s - loss: 0.0308 - mae: 0.1299 - mse: 0.0308
89/89 [==============================] - 0s 5ms/step - loss: 0.0292 - mae: 0.1276 - mse: 0.0292 - val_loss: 0.0382 - val_mae: 0.1532 - val_mse: 0.0382
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0216 - mae: 0.1084 - mse: 0.0216
64/89 [====================>.........] - ETA: 0s - loss: 0.0274 - mae: 0.1218 - mse: 0.0274
89/89 [==============================] - 0s 5ms/step - loss: 0.0290 - mae: 0.1241 - mse: 0.0290 - val_loss: 0.0378 - val_mae: 0.1618 - val_mse: 0.0378
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0265 - mae: 0.1154 - mse: 0.0265
64/89 [====================>.........] - ETA: 0s - loss: 0.0260 - mae: 0.1154 - mse: 0.0260
89/89 [==============================] - 0s 5ms/step - loss: 0.0299 - mae: 0.1209 - mse: 0.0299 - val_loss: 0.0386 - val_mae: 0.1675 - val_mse: 0.0386
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0309 - mae: 0.1327 - mse: 0.0309
64/89 [====================>.........] - ETA: 0s - loss: 0.0253 - mae: 0.1190 - mse: 0.0253
89/89 [==============================] - 0s 5ms/step - loss: 0.0225 - mae: 0.1115 - mse: 0.0225 - val_loss: 0.0313 - val_mae: 0.1488 - val_mse: 0.0313
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0224 - mae: 0.1071 - mse: 0.0224
64/89 [====================>.........] - ETA: 0s - loss: 0.0204 - mae: 0.1063 - mse: 0.0204
89/89 [==============================] - 0s 5ms/step - loss: 0.0237 - mae: 0.1133 - mse: 0.0237 - val_loss: 0.0233 - val_mae: 0.1205 - val_mse: 0.0233
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0161 - mae: 0.0909 - mse: 0.0161
64/89 [====================>.........] - ETA: 0s - loss: 0.0217 - mae: 0.1088 - mse: 0.0217
89/89 [==============================] - 0s 5ms/step - loss: 0.0216 - mae: 0.1062 - mse: 0.0216 - val_loss: 0.0338 - val_mae: 0.1524 - val_mse: 0.0338
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0322 - mae: 0.1288 - mse: 0.0322
64/89 [====================>.........] - ETA: 0s - loss: 0.0257 - mae: 0.1092 - mse: 0.0257
89/89 [==============================] - 0s 5ms/step - loss: 0.0218 - mae: 0.1019 - mse: 0.0218 - val_loss: 0.0262 - val_mae: 0.1318 - val_mse: 0.0262
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0271 - mae: 0.1134 - mse: 0.0271
64/89 [====================>.........] - ETA: 0s - loss: 0.0179 - mae: 0.0923 - mse: 0.0179
89/89 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 0.1029 - mse: 0.0205 - val_loss: 0.0180 - val_mae: 0.1037 - val_mse: 0.0180
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0215 - mae: 0.1160 - mse: 0.0215
64/89 [====================>.........] - ETA: 0s - loss: 0.0186 - mae: 0.1083 - mse: 0.0186
89/89 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.1022 - mse: 0.0169 - val_loss: 0.0203 - val_mae: 0.1269 - val_mse: 0.0203
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0080 - mae: 0.0665 - mse: 0.0080
64/89 [====================>.........] - ETA: 0s - loss: 0.0126 - mae: 0.0817 - mse: 0.0126
89/89 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0880 - mse: 0.0145 - val_loss: 0.0131 - val_mae: 0.0916 - val_mse: 0.0131
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0108 - mae: 0.0816 - mse: 0.0108
64/89 [====================>.........] - ETA: 0s - loss: 0.0148 - mae: 0.0853 - mse: 0.0148
89/89 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0860 - mse: 0.0145 - val_loss: 0.0122 - val_mae: 0.0868 - val_mse: 0.0122
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0103 - mae: 0.0816 - mse: 0.0103
64/89 [====================>.........] - ETA: 0s - loss: 0.0089 - mae: 0.0720 - mse: 0.0089
89/89 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0755 - mse: 0.0097 - val_loss: 0.0119 - val_mae: 0.0956 - val_mse: 0.0119
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0138 - mae: 0.0793 - mse: 0.0138
64/89 [====================>.........] - ETA: 0s - loss: 0.0137 - mae: 0.0897 - mse: 0.0137
89/89 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0884 - mse: 0.0128 - val_loss: 0.0135 - val_mae: 0.1012 - val_mse: 0.0135
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0111 - mae: 0.0829 - mse: 0.0111
64/89 [====================>.........] - ETA: 0s - loss: 0.0103 - mae: 0.0763 - mse: 0.0103
89/89 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0848 - mse: 0.0132 - val_loss: 0.0153 - val_mae: 0.1099 - val_mse: 0.0153
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0060 - mae: 0.0636 - mse: 0.0060
64/89 [====================>.........] - ETA: 0s - loss: 0.0080 - mae: 0.0670 - mse: 0.0080
89/89 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0722 - mse: 0.0097 - val_loss: 0.0115 - val_mae: 0.0810 - val_mse: 0.0115
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0036 - mae: 0.0431 - mse: 0.0036
64/89 [====================>.........] - ETA: 0s - loss: 0.0090 - mae: 0.0680 - mse: 0.0090
89/89 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0692 - mse: 0.0100 - val_loss: 0.0113 - val_mae: 0.0932 - val_mse: 0.0113
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0069 - mae: 0.0661 - mse: 0.0069
64/89 [====================>.........] - ETA: 0s - loss: 0.0069 - mae: 0.0643 - mse: 0.0069
89/89 [==============================] - 0s 4ms/step - loss: 0.0061 - mae: 0.0607 - mse: 0.0061 - val_loss: 0.0099 - val_mae: 0.0776 - val_mse: 0.0099
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0125 - mae: 0.0785 - mse: 0.0125
64/89 [====================>.........] - ETA: 0s - loss: 0.0097 - mae: 0.0685 - mse: 0.0097
89/89 [==============================] - 0s 4ms/step - loss: 0.0100 - mae: 0.0719 - mse: 0.0100 - val_loss: 0.0104 - val_mae: 0.0947 - val_mse: 0.0104
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         1.87639236 0.         0.        ]
average prediction= [3.0770655]
baseline= 7.1
eachuser= [0. 0. 0. 3. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.625464121500651
85 -:- nan
60 -:- nan
['train-weight-4.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_4_csi_a4_18.dat
65 42
65 43
1_165_65_4_csi_a4_5.dat
65 45
65 46
65 47
65 48
65 49
1_165_65_4_csi_a4_24.dat
65 51
65 52
65 53
65 54
1_165_65_4_csi_a4_7.dat
65 56
65 57
65 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
65 61
65 62
65 63
65 64
65 65
65 66
65 67
65 68
1_165_65_4_csi_a4_29.dat
65 70
50 71
50 72
50 73
2_165_50_4_csi_a4_13.dat
50 75
50 76
50 77
50 78
2_165_50_4_csi_a4_15.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
2_165_50_4_csi_a4_25.dat
50 97
50 98
50 99
50 100
70 101
1_175_70_4_csi_a4_14.dat
70 103
1_175_70_4_csi_a4_16.dat
70 105
1_175_70_4_csi_a4_8.dat
70 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
70 111
70 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
70 115
1_175_70_4_csi_a4_28.dat
70 117
70 118
70 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
70 122
1_175_70_4_csi_a4_5.dat
70 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
70 127
1_175_70_4_csi_a4_22.dat
70 129
70 130
85 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
85 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
85 142
1_180_85_4_csi_a4_30.dat
85 144
85 145
85 146
85 147
1_180_85_4_csi_a4_20.dat
85 149
85 150
85 151
85 152
85 153
1_180_85_4_csi_a4_29.dat
85 155
85 156
85 157
85 158
85 159
85 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
75 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 75]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.2668 - mae: 0.4007 - mse: 0.2668
64/89 [====================>.........] - ETA: 0s - loss: 0.2239 - mae: 0.3771 - mse: 0.2239
89/89 [==============================] - 1s 8ms/step - loss: 0.1922 - mae: 0.3483 - mse: 0.1922 - val_loss: 0.0235 - val_mae: 0.0975 - val_mse: 0.0235
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0890 - mae: 0.2380 - mse: 0.0890
64/89 [====================>.........] - ETA: 0s - loss: 0.0953 - mae: 0.2601 - mse: 0.0953
89/89 [==============================] - 0s 5ms/step - loss: 0.1041 - mae: 0.2754 - mse: 0.1041 - val_loss: 0.0674 - val_mae: 0.2485 - val_mse: 0.0674
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0811 - mae: 0.2507 - mse: 0.0811
64/89 [====================>.........] - ETA: 0s - loss: 0.0915 - mae: 0.2752 - mse: 0.0915
89/89 [==============================] - 0s 5ms/step - loss: 0.0812 - mae: 0.2521 - mse: 0.0812 - val_loss: 0.0142 - val_mae: 0.0885 - val_mse: 0.0142
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0632 - mae: 0.2004 - mse: 0.0632
64/89 [====================>.........] - ETA: 0s - loss: 0.0636 - mae: 0.1978 - mse: 0.0636
89/89 [==============================] - 0s 5ms/step - loss: 0.0560 - mae: 0.1826 - mse: 0.0560 - val_loss: 0.0093 - val_mae: 0.0925 - val_mse: 0.0093
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0669 - mae: 0.2016 - mse: 0.0669
64/89 [====================>.........] - ETA: 0s - loss: 0.0562 - mae: 0.1818 - mse: 0.0562
89/89 [==============================] - 0s 5ms/step - loss: 0.0635 - mae: 0.1835 - mse: 0.0635 - val_loss: 0.0095 - val_mae: 0.0957 - val_mse: 0.0095
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0533 - mae: 0.1656 - mse: 0.0533
64/89 [====================>.........] - ETA: 0s - loss: 0.0584 - mae: 0.1759 - mse: 0.0584
89/89 [==============================] - 0s 5ms/step - loss: 0.0548 - mae: 0.1722 - mse: 0.0548 - val_loss: 0.0050 - val_mae: 0.0631 - val_mse: 0.0050
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0342 - mae: 0.1451 - mse: 0.0342
64/89 [====================>.........] - ETA: 0s - loss: 0.0343 - mae: 0.1507 - mse: 0.0343
89/89 [==============================] - 0s 5ms/step - loss: 0.0426 - mae: 0.1681 - mse: 0.0426 - val_loss: 0.0065 - val_mae: 0.0717 - val_mse: 0.0065
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0355 - mae: 0.1617 - mse: 0.0355
64/89 [====================>.........] - ETA: 0s - loss: 0.0418 - mae: 0.1733 - mse: 0.0418
89/89 [==============================] - 0s 5ms/step - loss: 0.0474 - mae: 0.1839 - mse: 0.0474 - val_loss: 0.0086 - val_mae: 0.0842 - val_mse: 0.0086
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0547 - mae: 0.1890 - mse: 0.0547
64/89 [====================>.........] - ETA: 0s - loss: 0.0553 - mae: 0.1863 - mse: 0.0553
89/89 [==============================] - 0s 5ms/step - loss: 0.0493 - mae: 0.1765 - mse: 0.0493 - val_loss: 0.0033 - val_mae: 0.0475 - val_mse: 0.0033
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0427 - mae: 0.1771 - mse: 0.0427
64/89 [====================>.........] - ETA: 0s - loss: 0.0506 - mae: 0.1836 - mse: 0.0506
89/89 [==============================] - 0s 5ms/step - loss: 0.0413 - mae: 0.1630 - mse: 0.0413 - val_loss: 0.0032 - val_mae: 0.0535 - val_mse: 0.0032
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0272 - mae: 0.1234 - mse: 0.0272
64/89 [====================>.........] - ETA: 0s - loss: 0.0411 - mae: 0.1400 - mse: 0.0411
89/89 [==============================] - 0s 5ms/step - loss: 0.0386 - mae: 0.1342 - mse: 0.0386 - val_loss: 0.0054 - val_mae: 0.0668 - val_mse: 0.0054
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0558 - mae: 0.1547 - mse: 0.0558
64/89 [====================>.........] - ETA: 0s - loss: 0.0527 - mae: 0.1514 - mse: 0.0527
89/89 [==============================] - 0s 5ms/step - loss: 0.0435 - mae: 0.1383 - mse: 0.0435 - val_loss: 0.0030 - val_mae: 0.0501 - val_mse: 0.0030
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0421 - mae: 0.1426 - mse: 0.0421
64/89 [====================>.........] - ETA: 0s - loss: 0.0404 - mae: 0.1391 - mse: 0.0404
89/89 [==============================] - 0s 5ms/step - loss: 0.0390 - mae: 0.1408 - mse: 0.0390 - val_loss: 0.0026 - val_mae: 0.0438 - val_mse: 0.0026
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0403 - mae: 0.1546 - mse: 0.0403
64/89 [====================>.........] - ETA: 0s - loss: 0.0342 - mae: 0.1396 - mse: 0.0342
89/89 [==============================] - 0s 5ms/step - loss: 0.0325 - mae: 0.1353 - mse: 0.0325 - val_loss: 0.0039 - val_mae: 0.0526 - val_mse: 0.0039
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0265 - mae: 0.1178 - mse: 0.0265
64/89 [====================>.........] - ETA: 0s - loss: 0.0267 - mae: 0.1147 - mse: 0.0267
89/89 [==============================] - 0s 5ms/step - loss: 0.0256 - mae: 0.1140 - mse: 0.0256 - val_loss: 0.0067 - val_mae: 0.0635 - val_mse: 0.0067
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0177 - mae: 0.0964 - mse: 0.0177
64/89 [====================>.........] - ETA: 0s - loss: 0.0180 - mae: 0.0963 - mse: 0.0180
89/89 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 0.1020 - mse: 0.0194 - val_loss: 0.0075 - val_mae: 0.0668 - val_mse: 0.0075
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0301 - mae: 0.1115 - mse: 0.0301
64/89 [====================>.........] - ETA: 0s - loss: 0.0217 - mae: 0.0888 - mse: 0.0217
89/89 [==============================] - 0s 5ms/step - loss: 0.0221 - mae: 0.0945 - mse: 0.0221 - val_loss: 0.0075 - val_mae: 0.0695 - val_mse: 0.0075
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0274 - mae: 0.1158 - mse: 0.0274
64/89 [====================>.........] - ETA: 0s - loss: 0.0243 - mae: 0.1103 - mse: 0.0243
89/89 [==============================] - 0s 5ms/step - loss: 0.0216 - mae: 0.1019 - mse: 0.0216 - val_loss: 0.0089 - val_mae: 0.0734 - val_mse: 0.0089
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0123 - mae: 0.0758 - mse: 0.0123
64/89 [====================>.........] - ETA: 0s - loss: 0.0118 - mae: 0.0769 - mse: 0.0118
89/89 [==============================] - 0s 5ms/step - loss: 0.0119 - mae: 0.0776 - mse: 0.0119 - val_loss: 0.0129 - val_mae: 0.0846 - val_mse: 0.0129
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0120 - mae: 0.0839 - mse: 0.0120
64/89 [====================>.........] - ETA: 0s - loss: 0.0148 - mae: 0.0906 - mse: 0.0148
89/89 [==============================] - 0s 5ms/step - loss: 0.0194 - mae: 0.0982 - mse: 0.0194 - val_loss: 0.0155 - val_mae: 0.0915 - val_mse: 0.0155
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0178 - mae: 0.0976 - mse: 0.0178
64/89 [====================>.........] - ETA: 0s - loss: 0.0152 - mae: 0.0870 - mse: 0.0152
89/89 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 0.0949 - mse: 0.0188 - val_loss: 0.0156 - val_mae: 0.0924 - val_mse: 0.0156
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0184 - mae: 0.0987 - mse: 0.0184
64/89 [====================>.........] - ETA: 0s - loss: 0.0140 - mae: 0.0838 - mse: 0.0140
89/89 [==============================] - 0s 5ms/step - loss: 0.0155 - mae: 0.0886 - mse: 0.0155 - val_loss: 0.0181 - val_mae: 0.1002 - val_mse: 0.0181
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0035 - mae: 0.0394 - mse: 0.0035
64/89 [====================>.........] - ETA: 0s - loss: 0.0148 - mae: 0.0778 - mse: 0.0148
89/89 [==============================] - 0s 5ms/step - loss: 0.0131 - mae: 0.0781 - mse: 0.0131 - val_loss: 0.0159 - val_mae: 0.0958 - val_mse: 0.0159
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0086 - mae: 0.0708 - mse: 0.0086
64/89 [====================>.........] - ETA: 0s - loss: 0.0127 - mae: 0.0810 - mse: 0.0127
89/89 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0768 - mse: 0.0115 - val_loss: 0.0128 - val_mae: 0.0906 - val_mse: 0.0128
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0111 - mae: 0.0694 - mse: 0.0111
64/89 [====================>.........] - ETA: 0s - loss: 0.0100 - mae: 0.0698 - mse: 0.0100
89/89 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0773 - mse: 0.0108 - val_loss: 0.0097 - val_mae: 0.0786 - val_mse: 0.0097
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0053 - mae: 0.0583 - mse: 0.0053
64/89 [====================>.........] - ETA: 0s - loss: 0.0089 - mae: 0.0737 - mse: 0.0089
89/89 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0697 - mse: 0.0081 - val_loss: 0.0132 - val_mae: 0.0918 - val_mse: 0.0132
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0037 - mae: 0.0454 - mse: 0.0037
64/89 [====================>.........] - ETA: 0s - loss: 0.0067 - mae: 0.0583 - mse: 0.0067
89/89 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0608 - mse: 0.0070 - val_loss: 0.0152 - val_mae: 0.0973 - val_mse: 0.0152
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0087 - mae: 0.0721 - mse: 0.0087
64/89 [====================>.........] - ETA: 0s - loss: 0.0071 - mae: 0.0663 - mse: 0.0071
89/89 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0663 - mse: 0.0073 - val_loss: 0.0156 - val_mae: 0.0990 - val_mse: 0.0156
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0076 - mae: 0.0623 - mse: 0.0076
64/89 [====================>.........] - ETA: 0s - loss: 0.0105 - mae: 0.0718 - mse: 0.0105
89/89 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0724 - mse: 0.0101 - val_loss: 0.0184 - val_mae: 0.1104 - val_mse: 0.0184
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0104 - mae: 0.0750 - mse: 0.0104
64/89 [====================>.........] - ETA: 0s - loss: 0.0088 - mae: 0.0682 - mse: 0.0088
89/89 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0662 - mse: 0.0084 - val_loss: 0.0143 - val_mae: 0.0943 - val_mse: 0.0143
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         1.98325729 0.         0.        ]
average prediction= [4.3322344]
baseline= 8.9
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.49581432342529297
85 -:- nan
60 -:- nan
['train-weight-4.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_4_csi_a4_18.dat
65 42
65 43
1_165_65_4_csi_a4_5.dat
65 45
65 46
65 47
65 48
65 49
1_165_65_4_csi_a4_24.dat
65 51
65 52
65 53
65 54
1_165_65_4_csi_a4_7.dat
65 56
65 57
65 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
65 61
65 62
65 63
65 64
65 65
65 66
65 67
65 68
1_165_65_4_csi_a4_29.dat
65 70
50 71
50 72
50 73
2_165_50_4_csi_a4_13.dat
50 75
50 76
50 77
50 78
2_165_50_4_csi_a4_15.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
2_165_50_4_csi_a4_25.dat
50 97
50 98
50 99
50 100
70 101
1_175_70_4_csi_a4_14.dat
70 103
1_175_70_4_csi_a4_16.dat
70 105
1_175_70_4_csi_a4_8.dat
70 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
70 111
70 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
70 115
1_175_70_4_csi_a4_28.dat
70 117
70 118
70 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
70 122
1_175_70_4_csi_a4_5.dat
70 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
70 127
1_175_70_4_csi_a4_22.dat
70 129
70 130
85 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
85 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
85 142
1_180_85_4_csi_a4_30.dat
85 144
85 145
85 146
85 147
1_180_85_4_csi_a4_20.dat
85 149
85 150
85 151
85 152
85 153
1_180_85_4_csi_a4_29.dat
85 155
85 156
85 157
85 158
85 159
85 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
75 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 75]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.3701 - mae: 0.5022 - mse: 0.3701
64/89 [====================>.........] - ETA: 0s - loss: 0.2393 - mae: 0.3842 - mse: 0.2393
89/89 [==============================] - 1s 8ms/step - loss: 0.1936 - mae: 0.3370 - mse: 0.1936 - val_loss: 0.0736 - val_mae: 0.2380 - val_mse: 0.0736
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1060 - mae: 0.2772 - mse: 0.1060
64/89 [====================>.........] - ETA: 0s - loss: 0.1195 - mae: 0.3013 - mse: 0.1195
89/89 [==============================] - 0s 5ms/step - loss: 0.1094 - mae: 0.2876 - mse: 0.1094 - val_loss: 0.0729 - val_mae: 0.2126 - val_mse: 0.0729
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0574 - mae: 0.1942 - mse: 0.0574
64/89 [====================>.........] - ETA: 0s - loss: 0.0646 - mae: 0.2097 - mse: 0.0646
89/89 [==============================] - 0s 5ms/step - loss: 0.0744 - mae: 0.2174 - mse: 0.0744 - val_loss: 0.0938 - val_mae: 0.2164 - val_mse: 0.0938
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1287 - mae: 0.2921 - mse: 0.1287
64/89 [====================>.........] - ETA: 0s - loss: 0.0872 - mae: 0.2253 - mse: 0.0872
89/89 [==============================] - 0s 5ms/step - loss: 0.0715 - mae: 0.1988 - mse: 0.0715 - val_loss: 0.0776 - val_mae: 0.1876 - val_mse: 0.0776
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0622 - mae: 0.1966 - mse: 0.0622
64/89 [====================>.........] - ETA: 0s - loss: 0.0480 - mae: 0.1657 - mse: 0.0480
89/89 [==============================] - 0s 5ms/step - loss: 0.0506 - mae: 0.1702 - mse: 0.0506 - val_loss: 0.0601 - val_mae: 0.1782 - val_mse: 0.0601
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0514 - mae: 0.1787 - mse: 0.0514
64/89 [====================>.........] - ETA: 0s - loss: 0.0466 - mae: 0.1749 - mse: 0.0466
89/89 [==============================] - 0s 5ms/step - loss: 0.0537 - mae: 0.1798 - mse: 0.0537 - val_loss: 0.0503 - val_mae: 0.1715 - val_mse: 0.0503
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0364 - mae: 0.1574 - mse: 0.0364
64/89 [====================>.........] - ETA: 0s - loss: 0.0368 - mae: 0.1521 - mse: 0.0368
89/89 [==============================] - 0s 5ms/step - loss: 0.0359 - mae: 0.1474 - mse: 0.0359 - val_loss: 0.0466 - val_mae: 0.1636 - val_mse: 0.0466
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0330 - mae: 0.1465 - mse: 0.0330
64/89 [====================>.........] - ETA: 0s - loss: 0.0422 - mae: 0.1646 - mse: 0.0422
89/89 [==============================] - 0s 5ms/step - loss: 0.0409 - mae: 0.1616 - mse: 0.0409 - val_loss: 0.0463 - val_mae: 0.1552 - val_mse: 0.0463
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0640 - mae: 0.1793 - mse: 0.0640
64/89 [====================>.........] - ETA: 0s - loss: 0.0494 - mae: 0.1636 - mse: 0.0494
89/89 [==============================] - 0s 5ms/step - loss: 0.0446 - mae: 0.1543 - mse: 0.0446 - val_loss: 0.0508 - val_mae: 0.1531 - val_mse: 0.0508
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0584 - mae: 0.1591 - mse: 0.0584
64/89 [====================>.........] - ETA: 0s - loss: 0.0443 - mae: 0.1436 - mse: 0.0443
89/89 [==============================] - 0s 5ms/step - loss: 0.0456 - mae: 0.1434 - mse: 0.0456 - val_loss: 0.0487 - val_mae: 0.1509 - val_mse: 0.0487
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0202 - mae: 0.0985 - mse: 0.0202
64/89 [====================>.........] - ETA: 0s - loss: 0.0331 - mae: 0.1298 - mse: 0.0331
89/89 [==============================] - 0s 5ms/step - loss: 0.0366 - mae: 0.1378 - mse: 0.0366 - val_loss: 0.0403 - val_mae: 0.1399 - val_mse: 0.0403
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0116 - mae: 0.0797 - mse: 0.0116
64/89 [====================>.........] - ETA: 0s - loss: 0.0247 - mae: 0.1134 - mse: 0.0247
89/89 [==============================] - 0s 5ms/step - loss: 0.0310 - mae: 0.1232 - mse: 0.0310 - val_loss: 0.0337 - val_mae: 0.1344 - val_mse: 0.0337
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0448 - mae: 0.1465 - mse: 0.0448
64/89 [====================>.........] - ETA: 0s - loss: 0.0392 - mae: 0.1379 - mse: 0.0392
89/89 [==============================] - 0s 5ms/step - loss: 0.0338 - mae: 0.1267 - mse: 0.0338 - val_loss: 0.0284 - val_mae: 0.1318 - val_mse: 0.0284
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0342 - mae: 0.1229 - mse: 0.0342
64/89 [====================>.........] - ETA: 0s - loss: 0.0323 - mae: 0.1294 - mse: 0.0323
89/89 [==============================] - 0s 5ms/step - loss: 0.0277 - mae: 0.1184 - mse: 0.0277 - val_loss: 0.0321 - val_mae: 0.1322 - val_mse: 0.0321
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0286 - mae: 0.1302 - mse: 0.0286
64/89 [====================>.........] - ETA: 0s - loss: 0.0283 - mae: 0.1245 - mse: 0.0283
89/89 [==============================] - 0s 5ms/step - loss: 0.0233 - mae: 0.1109 - mse: 0.0233 - val_loss: 0.0304 - val_mae: 0.1311 - val_mse: 0.0304
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0335 - mae: 0.1347 - mse: 0.0335
64/89 [====================>.........] - ETA: 0s - loss: 0.0230 - mae: 0.1057 - mse: 0.0230
89/89 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 0.1035 - mse: 0.0211 - val_loss: 0.0293 - val_mae: 0.1236 - val_mse: 0.0293
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0279 - mae: 0.1182 - mse: 0.0279
64/89 [====================>.........] - ETA: 0s - loss: 0.0205 - mae: 0.0996 - mse: 0.0205
89/89 [==============================] - 0s 5ms/step - loss: 0.0256 - mae: 0.1056 - mse: 0.0256 - val_loss: 0.0250 - val_mae: 0.1058 - val_mse: 0.0250
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0184 - mae: 0.1036 - mse: 0.0184
64/89 [====================>.........] - ETA: 0s - loss: 0.0197 - mae: 0.1074 - mse: 0.0197
89/89 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 0.1023 - mse: 0.0188 - val_loss: 0.0170 - val_mae: 0.0974 - val_mse: 0.0170
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0302 - mae: 0.1361 - mse: 0.0302
64/89 [====================>.........] - ETA: 0s - loss: 0.0244 - mae: 0.1129 - mse: 0.0244
89/89 [==============================] - 0s 5ms/step - loss: 0.0215 - mae: 0.1043 - mse: 0.0215 - val_loss: 0.0283 - val_mae: 0.1214 - val_mse: 0.0283
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0237 - mae: 0.1143 - mse: 0.0237
64/89 [====================>.........] - ETA: 0s - loss: 0.0249 - mae: 0.1168 - mse: 0.0249
89/89 [==============================] - 0s 5ms/step - loss: 0.0286 - mae: 0.1187 - mse: 0.0286 - val_loss: 0.0429 - val_mae: 0.1638 - val_mse: 0.0429
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0231 - mae: 0.1029 - mse: 0.0231
64/89 [====================>.........] - ETA: 0s - loss: 0.0162 - mae: 0.0894 - mse: 0.0162
89/89 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0897 - mse: 0.0157 - val_loss: 0.0145 - val_mae: 0.0792 - val_mse: 0.0145
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0237 - mae: 0.1159 - mse: 0.0237
64/89 [====================>.........] - ETA: 0s - loss: 0.0201 - mae: 0.1063 - mse: 0.0201
89/89 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 0.1040 - mse: 0.0190 - val_loss: 0.0235 - val_mae: 0.1140 - val_mse: 0.0235
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0170 - mae: 0.0936 - mse: 0.0170
64/89 [====================>.........] - ETA: 0s - loss: 0.0176 - mae: 0.0944 - mse: 0.0176
89/89 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0934 - mse: 0.0169 - val_loss: 0.0307 - val_mae: 0.1375 - val_mse: 0.0307
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0069 - mae: 0.0664 - mse: 0.0069
64/89 [====================>.........] - ETA: 0s - loss: 0.0073 - mae: 0.0626 - mse: 0.0073
89/89 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0692 - mse: 0.0096 - val_loss: 0.0133 - val_mae: 0.0806 - val_mse: 0.0133
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0179 - mae: 0.0934 - mse: 0.0179
64/89 [====================>.........] - ETA: 0s - loss: 0.0181 - mae: 0.1003 - mse: 0.0181
89/89 [==============================] - 0s 5ms/step - loss: 0.0162 - mae: 0.0943 - mse: 0.0162 - val_loss: 0.0153 - val_mae: 0.0893 - val_mse: 0.0153
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0158 - mae: 0.1023 - mse: 0.0158
64/89 [====================>.........] - ETA: 0s - loss: 0.0153 - mae: 0.0901 - mse: 0.0153
89/89 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0850 - mse: 0.0142 - val_loss: 0.0344 - val_mae: 0.1552 - val_mse: 0.0344
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0101 - mae: 0.0662 - mse: 0.0101
64/89 [====================>.........] - ETA: 0s - loss: 0.0130 - mae: 0.0790 - mse: 0.0130
89/89 [==============================] - 0s 5ms/step - loss: 0.0131 - mae: 0.0835 - mse: 0.0131 - val_loss: 0.0182 - val_mae: 0.0982 - val_mse: 0.0182
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0075 - mae: 0.0647 - mse: 0.0075
64/89 [====================>.........] - ETA: 0s - loss: 0.0067 - mae: 0.0593 - mse: 0.0067
89/89 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0699 - mse: 0.0095 - val_loss: 0.0137 - val_mae: 0.0777 - val_mse: 0.0137
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0220 - mae: 0.1079 - mse: 0.0220
64/89 [====================>.........] - ETA: 0s - loss: 0.0180 - mae: 0.0953 - mse: 0.0180
89/89 [==============================] - 0s 5ms/step - loss: 0.0149 - mae: 0.0861 - mse: 0.0149 - val_loss: 0.0589 - val_mae: 0.2062 - val_mse: 0.0589
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0143 - mae: 0.0899 - mse: 0.0143
64/89 [====================>.........] - ETA: 0s - loss: 0.0160 - mae: 0.0947 - mse: 0.0160
89/89 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.1025 - mse: 0.0174 - val_loss: 0.0399 - val_mae: 0.1563 - val_mse: 0.0399
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         4.80084229 0.         0.        ]
average prediction= [4.2077804]
baseline= 7.5
eachuser= [0. 0. 0. 5. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.96016845703125
85 -:- nan
60 -:- nan
['train-weight-4.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_4_csi_a4_18.dat
65 42
65 43
1_165_65_4_csi_a4_5.dat
65 45
65 46
65 47
65 48
65 49
1_165_65_4_csi_a4_24.dat
65 51
65 52
65 53
65 54
1_165_65_4_csi_a4_7.dat
65 56
65 57
65 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
65 61
65 62
65 63
65 64
65 65
65 66
65 67
65 68
1_165_65_4_csi_a4_29.dat
65 70
50 71
50 72
50 73
2_165_50_4_csi_a4_13.dat
50 75
50 76
50 77
50 78
2_165_50_4_csi_a4_15.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
2_165_50_4_csi_a4_25.dat
50 97
50 98
50 99
50 100
70 101
1_175_70_4_csi_a4_14.dat
70 103
1_175_70_4_csi_a4_16.dat
70 105
1_175_70_4_csi_a4_8.dat
70 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
70 111
70 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
70 115
1_175_70_4_csi_a4_28.dat
70 117
70 118
70 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
70 122
1_175_70_4_csi_a4_5.dat
70 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
70 127
1_175_70_4_csi_a4_22.dat
70 129
70 130
85 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
85 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
85 142
1_180_85_4_csi_a4_30.dat
85 144
85 145
85 146
85 147
1_180_85_4_csi_a4_20.dat
85 149
85 150
85 151
85 152
85 153
1_180_85_4_csi_a4_29.dat
85 155
85 156
85 157
85 158
85 159
85 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
75 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 75]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.4088 - mae: 0.5702 - mse: 0.4088
64/89 [====================>.........] - ETA: 0s - loss: 0.3092 - mae: 0.4736 - mse: 0.3092
89/89 [==============================] - 1s 9ms/step - loss: 0.2584 - mae: 0.4151 - mse: 0.2584 - val_loss: 0.1267 - val_mae: 0.2784 - val_mse: 0.1267
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1198 - mae: 0.2702 - mse: 0.1198
64/89 [====================>.........] - ETA: 0s - loss: 0.1084 - mae: 0.2643 - mse: 0.1084
89/89 [==============================] - 0s 5ms/step - loss: 0.1115 - mae: 0.2731 - mse: 0.1115 - val_loss: 0.0706 - val_mae: 0.2237 - val_mse: 0.0706
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1067 - mae: 0.2833 - mse: 0.1067
64/89 [====================>.........] - ETA: 0s - loss: 0.1064 - mae: 0.2789 - mse: 0.1064
89/89 [==============================] - 0s 5ms/step - loss: 0.0975 - mae: 0.2623 - mse: 0.0975 - val_loss: 0.0996 - val_mae: 0.2303 - val_mse: 0.0996
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0678 - mae: 0.2179 - mse: 0.0678
64/89 [====================>.........] - ETA: 0s - loss: 0.0699 - mae: 0.2161 - mse: 0.0699
89/89 [==============================] - 0s 5ms/step - loss: 0.0779 - mae: 0.2199 - mse: 0.0779 - val_loss: 0.1367 - val_mae: 0.2882 - val_mse: 0.1367
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0940 - mae: 0.2208 - mse: 0.0940
64/89 [====================>.........] - ETA: 0s - loss: 0.0763 - mae: 0.2014 - mse: 0.0763
89/89 [==============================] - 0s 5ms/step - loss: 0.0791 - mae: 0.2086 - mse: 0.0791 - val_loss: 0.1243 - val_mae: 0.2654 - val_mse: 0.1243
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0865 - mae: 0.2275 - mse: 0.0865
64/89 [====================>.........] - ETA: 0s - loss: 0.0656 - mae: 0.1964 - mse: 0.0656
89/89 [==============================] - 0s 5ms/step - loss: 0.0702 - mae: 0.2056 - mse: 0.0702 - val_loss: 0.0898 - val_mae: 0.2480 - val_mse: 0.0898
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0658 - mae: 0.2122 - mse: 0.0658
64/89 [====================>.........] - ETA: 0s - loss: 0.0659 - mae: 0.2199 - mse: 0.0659
89/89 [==============================] - 0s 5ms/step - loss: 0.0648 - mae: 0.2192 - mse: 0.0648 - val_loss: 0.0727 - val_mae: 0.2384 - val_mse: 0.0727
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0657 - mae: 0.2269 - mse: 0.0657
64/89 [====================>.........] - ETA: 0s - loss: 0.0778 - mae: 0.2430 - mse: 0.0778
89/89 [==============================] - 0s 5ms/step - loss: 0.0665 - mae: 0.2213 - mse: 0.0665 - val_loss: 0.0747 - val_mae: 0.2360 - val_mse: 0.0747
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0388 - mae: 0.1686 - mse: 0.0388
64/89 [====================>.........] - ETA: 0s - loss: 0.0434 - mae: 0.1705 - mse: 0.0434
89/89 [==============================] - 0s 5ms/step - loss: 0.0458 - mae: 0.1743 - mse: 0.0458 - val_loss: 0.0790 - val_mae: 0.2320 - val_mse: 0.0790
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0555 - mae: 0.1982 - mse: 0.0555
64/89 [====================>.........] - ETA: 0s - loss: 0.0535 - mae: 0.1895 - mse: 0.0535
89/89 [==============================] - 0s 5ms/step - loss: 0.0494 - mae: 0.1812 - mse: 0.0494 - val_loss: 0.0785 - val_mae: 0.2224 - val_mse: 0.0785
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0502 - mae: 0.1892 - mse: 0.0502
64/89 [====================>.........] - ETA: 0s - loss: 0.0446 - mae: 0.1753 - mse: 0.0446
89/89 [==============================] - 0s 5ms/step - loss: 0.0425 - mae: 0.1664 - mse: 0.0425 - val_loss: 0.0693 - val_mae: 0.2055 - val_mse: 0.0693
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0551 - mae: 0.1838 - mse: 0.0551
64/89 [====================>.........] - ETA: 0s - loss: 0.0587 - mae: 0.1859 - mse: 0.0587
89/89 [==============================] - 0s 5ms/step - loss: 0.0508 - mae: 0.1724 - mse: 0.0508 - val_loss: 0.0634 - val_mae: 0.1917 - val_mse: 0.0634
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0415 - mae: 0.1661 - mse: 0.0415
64/89 [====================>.........] - ETA: 0s - loss: 0.0453 - mae: 0.1664 - mse: 0.0453
89/89 [==============================] - 0s 5ms/step - loss: 0.0411 - mae: 0.1592 - mse: 0.0411 - val_loss: 0.0667 - val_mae: 0.1882 - val_mse: 0.0667
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0545 - mae: 0.1699 - mse: 0.0545
64/89 [====================>.........] - ETA: 0s - loss: 0.0386 - mae: 0.1412 - mse: 0.0386
89/89 [==============================] - 0s 5ms/step - loss: 0.0372 - mae: 0.1416 - mse: 0.0372 - val_loss: 0.0621 - val_mae: 0.1819 - val_mse: 0.0621
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0204 - mae: 0.1085 - mse: 0.0204
64/89 [====================>.........] - ETA: 0s - loss: 0.0386 - mae: 0.1369 - mse: 0.0386
89/89 [==============================] - 0s 5ms/step - loss: 0.0316 - mae: 0.1249 - mse: 0.0316 - val_loss: 0.0583 - val_mae: 0.1801 - val_mse: 0.0583
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0344 - mae: 0.1374 - mse: 0.0344
64/89 [====================>.........] - ETA: 0s - loss: 0.0356 - mae: 0.1366 - mse: 0.0356
89/89 [==============================] - 0s 5ms/step - loss: 0.0353 - mae: 0.1390 - mse: 0.0353 - val_loss: 0.0566 - val_mae: 0.1813 - val_mse: 0.0566
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0260 - mae: 0.1254 - mse: 0.0260
64/89 [====================>.........] - ETA: 0s - loss: 0.0286 - mae: 0.1246 - mse: 0.0286
89/89 [==============================] - 0s 5ms/step - loss: 0.0330 - mae: 0.1369 - mse: 0.0330 - val_loss: 0.0624 - val_mae: 0.1887 - val_mse: 0.0624
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0264 - mae: 0.1221 - mse: 0.0264
64/89 [====================>.........] - ETA: 0s - loss: 0.0287 - mae: 0.1246 - mse: 0.0287
89/89 [==============================] - 0s 5ms/step - loss: 0.0277 - mae: 0.1209 - mse: 0.0277 - val_loss: 0.0525 - val_mae: 0.1732 - val_mse: 0.0525
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0342 - mae: 0.1245 - mse: 0.0342
64/89 [====================>.........] - ETA: 0s - loss: 0.0404 - mae: 0.1338 - mse: 0.0404
89/89 [==============================] - 0s 5ms/step - loss: 0.0382 - mae: 0.1345 - mse: 0.0382 - val_loss: 0.0502 - val_mae: 0.1666 - val_mse: 0.0502
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0250 - mae: 0.1064 - mse: 0.0250
64/89 [====================>.........] - ETA: 0s - loss: 0.0229 - mae: 0.1100 - mse: 0.0229
89/89 [==============================] - 0s 5ms/step - loss: 0.0225 - mae: 0.1068 - mse: 0.0225 - val_loss: 0.0553 - val_mae: 0.1693 - val_mse: 0.0553
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0168 - mae: 0.0946 - mse: 0.0168
64/89 [====================>.........] - ETA: 0s - loss: 0.0181 - mae: 0.1033 - mse: 0.0181
89/89 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 0.1112 - mse: 0.0211 - val_loss: 0.0512 - val_mae: 0.1594 - val_mse: 0.0512
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0250 - mae: 0.1070 - mse: 0.0250
64/89 [====================>.........] - ETA: 0s - loss: 0.0257 - mae: 0.1201 - mse: 0.0257
89/89 [==============================] - 0s 5ms/step - loss: 0.0209 - mae: 0.1064 - mse: 0.0209 - val_loss: 0.0430 - val_mae: 0.1458 - val_mse: 0.0430
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0255 - mae: 0.1152 - mse: 0.0255
64/89 [====================>.........] - ETA: 0s - loss: 0.0286 - mae: 0.1221 - mse: 0.0286
89/89 [==============================] - 0s 5ms/step - loss: 0.0273 - mae: 0.1211 - mse: 0.0273 - val_loss: 0.0507 - val_mae: 0.1481 - val_mse: 0.0507
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0176 - mae: 0.0906 - mse: 0.0176
64/89 [====================>.........] - ETA: 0s - loss: 0.0171 - mae: 0.0892 - mse: 0.0171
89/89 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.0936 - mse: 0.0185 - val_loss: 0.0597 - val_mae: 0.1666 - val_mse: 0.0597
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0241 - mae: 0.0908 - mse: 0.0241
64/89 [====================>.........] - ETA: 0s - loss: 0.0217 - mae: 0.0962 - mse: 0.0217
89/89 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 0.0910 - mse: 0.0197 - val_loss: 0.0417 - val_mae: 0.1324 - val_mse: 0.0417
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0178 - mae: 0.1039 - mse: 0.0178
64/89 [====================>.........] - ETA: 0s - loss: 0.0169 - mae: 0.1003 - mse: 0.0169
89/89 [==============================] - 0s 5ms/step - loss: 0.0192 - mae: 0.1071 - mse: 0.0192 - val_loss: 0.0355 - val_mae: 0.1246 - val_mse: 0.0355
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0160 - mae: 0.0829 - mse: 0.0160
64/89 [====================>.........] - ETA: 0s - loss: 0.0146 - mae: 0.0804 - mse: 0.0146
89/89 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0803 - mse: 0.0141 - val_loss: 0.0458 - val_mae: 0.1547 - val_mse: 0.0458
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0081 - mae: 0.0673 - mse: 0.0081
64/89 [====================>.........] - ETA: 0s - loss: 0.0099 - mae: 0.0777 - mse: 0.0099
89/89 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0771 - mse: 0.0102 - val_loss: 0.0403 - val_mae: 0.1423 - val_mse: 0.0403
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0081 - mae: 0.0612 - mse: 0.0081
64/89 [====================>.........] - ETA: 0s - loss: 0.0105 - mae: 0.0709 - mse: 0.0105
89/89 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0703 - mse: 0.0099 - val_loss: 0.0411 - val_mae: 0.1503 - val_mse: 0.0411
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0088 - mae: 0.0696 - mse: 0.0088
64/89 [====================>.........] - ETA: 0s - loss: 0.0090 - mae: 0.0727 - mse: 0.0090
89/89 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0739 - mse: 0.0090 - val_loss: 0.0492 - val_mae: 0.1756 - val_mse: 0.0492
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         3.44345856 0.         0.        ]
average prediction= [3.795551]
baseline= 7.7
eachuser= [0. 0. 0. 6. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.5739097595214844
85 -:- nan
60 -:- nan
['train-weight-4.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_4_csi_a4_18.dat
65 42
65 43
1_165_65_4_csi_a4_5.dat
65 45
65 46
65 47
65 48
65 49
1_165_65_4_csi_a4_24.dat
65 51
65 52
65 53
65 54
1_165_65_4_csi_a4_7.dat
65 56
65 57
65 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
65 61
65 62
65 63
65 64
65 65
65 66
65 67
65 68
1_165_65_4_csi_a4_29.dat
65 70
50 71
50 72
50 73
2_165_50_4_csi_a4_13.dat
50 75
50 76
50 77
50 78
2_165_50_4_csi_a4_15.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
2_165_50_4_csi_a4_25.dat
50 97
50 98
50 99
50 100
70 101
1_175_70_4_csi_a4_14.dat
70 103
1_175_70_4_csi_a4_16.dat
70 105
1_175_70_4_csi_a4_8.dat
70 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
70 111
70 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
70 115
1_175_70_4_csi_a4_28.dat
70 117
70 118
70 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
70 122
1_175_70_4_csi_a4_5.dat
70 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
70 127
1_175_70_4_csi_a4_22.dat
70 129
70 130
85 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
85 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
85 142
1_180_85_4_csi_a4_30.dat
85 144
85 145
85 146
85 147
1_180_85_4_csi_a4_20.dat
85 149
85 150
85 151
85 152
85 153
1_180_85_4_csi_a4_29.dat
85 155
85 156
85 157
85 158
85 159
85 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
75 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 75]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.3514 - mae: 0.4908 - mse: 0.3514
64/89 [====================>.........] - ETA: 0s - loss: 0.2824 - mae: 0.4261 - mse: 0.2824
89/89 [==============================] - 1s 8ms/step - loss: 0.2496 - mae: 0.3989 - mse: 0.2496 - val_loss: 0.0735 - val_mae: 0.2029 - val_mse: 0.0735
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0826 - mae: 0.2217 - mse: 0.0826
64/89 [====================>.........] - ETA: 0s - loss: 0.0876 - mae: 0.2312 - mse: 0.0876
89/89 [==============================] - 0s 5ms/step - loss: 0.1008 - mae: 0.2624 - mse: 0.1008 - val_loss: 0.0824 - val_mae: 0.2512 - val_mse: 0.0824
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1095 - mae: 0.2877 - mse: 0.1095
64/89 [====================>.........] - ETA: 0s - loss: 0.1136 - mae: 0.2881 - mse: 0.1136
89/89 [==============================] - 0s 5ms/step - loss: 0.1220 - mae: 0.3045 - mse: 0.1220 - val_loss: 0.0541 - val_mae: 0.1687 - val_mse: 0.0541
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1114 - mae: 0.2797 - mse: 0.1114
64/89 [====================>.........] - ETA: 0s - loss: 0.0886 - mae: 0.2401 - mse: 0.0886
89/89 [==============================] - 0s 5ms/step - loss: 0.0855 - mae: 0.2276 - mse: 0.0855 - val_loss: 0.0618 - val_mae: 0.1798 - val_mse: 0.0618
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1012 - mae: 0.2538 - mse: 0.1012
64/89 [====================>.........] - ETA: 0s - loss: 0.0868 - mae: 0.2205 - mse: 0.0868
89/89 [==============================] - 0s 5ms/step - loss: 0.0853 - mae: 0.2174 - mse: 0.0853 - val_loss: 0.0669 - val_mae: 0.1963 - val_mse: 0.0669
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1001 - mae: 0.2328 - mse: 0.1001
64/89 [====================>.........] - ETA: 0s - loss: 0.0879 - mae: 0.2127 - mse: 0.0879
89/89 [==============================] - 0s 5ms/step - loss: 0.0885 - mae: 0.2163 - mse: 0.0885 - val_loss: 0.0519 - val_mae: 0.1575 - val_mse: 0.0519
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0765 - mae: 0.2057 - mse: 0.0765
64/89 [====================>.........] - ETA: 0s - loss: 0.0671 - mae: 0.1918 - mse: 0.0671
89/89 [==============================] - 0s 5ms/step - loss: 0.0620 - mae: 0.1866 - mse: 0.0620 - val_loss: 0.0364 - val_mae: 0.1291 - val_mse: 0.0364
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0513 - mae: 0.1869 - mse: 0.0513
64/89 [====================>.........] - ETA: 0s - loss: 0.0569 - mae: 0.1928 - mse: 0.0569
89/89 [==============================] - 0s 5ms/step - loss: 0.0575 - mae: 0.1925 - mse: 0.0575 - val_loss: 0.0326 - val_mae: 0.1491 - val_mse: 0.0326
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0534 - mae: 0.1922 - mse: 0.0534
64/89 [====================>.........] - ETA: 0s - loss: 0.0554 - mae: 0.2026 - mse: 0.0554
89/89 [==============================] - 0s 5ms/step - loss: 0.0593 - mae: 0.2060 - mse: 0.0593 - val_loss: 0.0298 - val_mae: 0.1399 - val_mse: 0.0298
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0465 - mae: 0.1722 - mse: 0.0465
64/89 [====================>.........] - ETA: 0s - loss: 0.0528 - mae: 0.1928 - mse: 0.0528
89/89 [==============================] - 0s 5ms/step - loss: 0.0449 - mae: 0.1749 - mse: 0.0449 - val_loss: 0.0292 - val_mae: 0.1263 - val_mse: 0.0292
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0636 - mae: 0.1997 - mse: 0.0636
64/89 [====================>.........] - ETA: 0s - loss: 0.0515 - mae: 0.1781 - mse: 0.0515
89/89 [==============================] - 0s 5ms/step - loss: 0.0497 - mae: 0.1701 - mse: 0.0497 - val_loss: 0.0340 - val_mae: 0.1189 - val_mse: 0.0340
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0394 - mae: 0.1367 - mse: 0.0394
64/89 [====================>.........] - ETA: 0s - loss: 0.0392 - mae: 0.1369 - mse: 0.0392
89/89 [==============================] - 0s 5ms/step - loss: 0.0392 - mae: 0.1369 - mse: 0.0392 - val_loss: 0.0309 - val_mae: 0.1193 - val_mse: 0.0309
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0488 - mae: 0.1451 - mse: 0.0488
64/89 [====================>.........] - ETA: 0s - loss: 0.0508 - mae: 0.1544 - mse: 0.0508
89/89 [==============================] - 0s 5ms/step - loss: 0.0445 - mae: 0.1488 - mse: 0.0445 - val_loss: 0.0262 - val_mae: 0.1328 - val_mse: 0.0262
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0289 - mae: 0.1278 - mse: 0.0289
64/89 [====================>.........] - ETA: 0s - loss: 0.0399 - mae: 0.1517 - mse: 0.0399
89/89 [==============================] - 0s 5ms/step - loss: 0.0340 - mae: 0.1405 - mse: 0.0340 - val_loss: 0.0253 - val_mae: 0.1302 - val_mse: 0.0253
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0497 - mae: 0.1744 - mse: 0.0497
64/89 [====================>.........] - ETA: 0s - loss: 0.0364 - mae: 0.1461 - mse: 0.0364
89/89 [==============================] - 0s 5ms/step - loss: 0.0340 - mae: 0.1393 - mse: 0.0340 - val_loss: 0.0254 - val_mae: 0.1264 - val_mse: 0.0254
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0373 - mae: 0.1384 - mse: 0.0373
64/89 [====================>.........] - ETA: 0s - loss: 0.0377 - mae: 0.1391 - mse: 0.0377
89/89 [==============================] - 0s 5ms/step - loss: 0.0346 - mae: 0.1383 - mse: 0.0346 - val_loss: 0.0299 - val_mae: 0.1225 - val_mse: 0.0299
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0431 - mae: 0.1645 - mse: 0.0431
64/89 [====================>.........] - ETA: 0s - loss: 0.0375 - mae: 0.1475 - mse: 0.0375
89/89 [==============================] - 0s 5ms/step - loss: 0.0356 - mae: 0.1426 - mse: 0.0356 - val_loss: 0.0259 - val_mae: 0.1136 - val_mse: 0.0259
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0232 - mae: 0.1175 - mse: 0.0232
64/89 [====================>.........] - ETA: 0s - loss: 0.0319 - mae: 0.1341 - mse: 0.0319
89/89 [==============================] - 0s 5ms/step - loss: 0.0288 - mae: 0.1234 - mse: 0.0288 - val_loss: 0.0191 - val_mae: 0.1092 - val_mse: 0.0191
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0318 - mae: 0.1369 - mse: 0.0318
64/89 [====================>.........] - ETA: 0s - loss: 0.0301 - mae: 0.1345 - mse: 0.0301
89/89 [==============================] - 0s 5ms/step - loss: 0.0323 - mae: 0.1403 - mse: 0.0323 - val_loss: 0.0178 - val_mae: 0.1059 - val_mse: 0.0178
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0271 - mae: 0.1199 - mse: 0.0271
64/89 [====================>.........] - ETA: 0s - loss: 0.0288 - mae: 0.1297 - mse: 0.0288
89/89 [==============================] - 0s 5ms/step - loss: 0.0279 - mae: 0.1253 - mse: 0.0279 - val_loss: 0.0223 - val_mae: 0.1064 - val_mse: 0.0223
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0310 - mae: 0.1324 - mse: 0.0310
64/89 [====================>.........] - ETA: 0s - loss: 0.0326 - mae: 0.1260 - mse: 0.0326
89/89 [==============================] - 0s 5ms/step - loss: 0.0315 - mae: 0.1245 - mse: 0.0315 - val_loss: 0.0230 - val_mae: 0.1099 - val_mse: 0.0230
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0215 - mae: 0.1177 - mse: 0.0215
64/89 [====================>.........] - ETA: 0s - loss: 0.0174 - mae: 0.1065 - mse: 0.0174
89/89 [==============================] - 0s 5ms/step - loss: 0.0223 - mae: 0.1162 - mse: 0.0223 - val_loss: 0.0154 - val_mae: 0.0974 - val_mse: 0.0154
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0262 - mae: 0.1174 - mse: 0.0262
64/89 [====================>.........] - ETA: 0s - loss: 0.0267 - mae: 0.1208 - mse: 0.0267
89/89 [==============================] - 0s 5ms/step - loss: 0.0261 - mae: 0.1227 - mse: 0.0261 - val_loss: 0.0146 - val_mae: 0.0937 - val_mse: 0.0146
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0262 - mae: 0.1295 - mse: 0.0262
64/89 [====================>.........] - ETA: 0s - loss: 0.0191 - mae: 0.1024 - mse: 0.0191
89/89 [==============================] - 0s 5ms/step - loss: 0.0239 - mae: 0.1154 - mse: 0.0239 - val_loss: 0.0210 - val_mae: 0.1133 - val_mse: 0.0210
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0292 - mae: 0.1229 - mse: 0.0292
64/89 [====================>.........] - ETA: 0s - loss: 0.0229 - mae: 0.1083 - mse: 0.0229
89/89 [==============================] - 0s 5ms/step - loss: 0.0225 - mae: 0.1121 - mse: 0.0225 - val_loss: 0.0213 - val_mae: 0.1195 - val_mse: 0.0213
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0216 - mae: 0.1069 - mse: 0.0216
64/89 [====================>.........] - ETA: 0s - loss: 0.0187 - mae: 0.1036 - mse: 0.0187
89/89 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 0.1007 - mse: 0.0178 - val_loss: 0.0132 - val_mae: 0.0934 - val_mse: 0.0132
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0145 - mae: 0.0962 - mse: 0.0145
64/89 [====================>.........] - ETA: 0s - loss: 0.0165 - mae: 0.0979 - mse: 0.0165
89/89 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 0.1059 - mse: 0.0184 - val_loss: 0.0106 - val_mae: 0.0863 - val_mse: 0.0106
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0086 - mae: 0.0694 - mse: 0.0086
64/89 [====================>.........] - ETA: 0s - loss: 0.0129 - mae: 0.0851 - mse: 0.0129
89/89 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0986 - mse: 0.0160 - val_loss: 0.0174 - val_mae: 0.1184 - val_mse: 0.0174
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0121 - mae: 0.0801 - mse: 0.0121
64/89 [====================>.........] - ETA: 0s - loss: 0.0124 - mae: 0.0822 - mse: 0.0124
89/89 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0851 - mse: 0.0128 - val_loss: 0.0232 - val_mae: 0.1362 - val_mse: 0.0232
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0103 - mae: 0.0742 - mse: 0.0103
64/89 [====================>.........] - ETA: 0s - loss: 0.0120 - mae: 0.0821 - mse: 0.0120
89/89 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0823 - mse: 0.0115 - val_loss: 0.0174 - val_mae: 0.1190 - val_mse: 0.0174
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         9.59693909 0.         0.        ]
average prediction= [4.555561]
baseline= 9.1
eachuser= [0. 0. 0. 7. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.3709912981305803
85 -:- nan
60 -:- nan
['train-weight-4.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_4_csi_a4_18.dat
65 42
65 43
1_165_65_4_csi_a4_5.dat
65 45
65 46
65 47
65 48
65 49
1_165_65_4_csi_a4_24.dat
65 51
65 52
65 53
65 54
1_165_65_4_csi_a4_7.dat
65 56
65 57
65 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
65 61
65 62
65 63
65 64
65 65
65 66
65 67
65 68
1_165_65_4_csi_a4_29.dat
65 70
50 71
50 72
50 73
2_165_50_4_csi_a4_13.dat
50 75
50 76
50 77
50 78
2_165_50_4_csi_a4_15.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
2_165_50_4_csi_a4_25.dat
50 97
50 98
50 99
50 100
70 101
1_175_70_4_csi_a4_14.dat
70 103
1_175_70_4_csi_a4_16.dat
70 105
1_175_70_4_csi_a4_8.dat
70 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
70 111
70 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
70 115
1_175_70_4_csi_a4_28.dat
70 117
70 118
70 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
70 122
1_175_70_4_csi_a4_5.dat
70 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
70 127
1_175_70_4_csi_a4_22.dat
70 129
70 130
85 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
85 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
85 142
1_180_85_4_csi_a4_30.dat
85 144
85 145
85 146
85 147
1_180_85_4_csi_a4_20.dat
85 149
85 150
85 151
85 152
85 153
1_180_85_4_csi_a4_29.dat
85 155
85 156
85 157
85 158
85 159
85 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
75 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 75]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.3631 - mae: 0.5189 - mse: 0.3631
64/89 [====================>.........] - ETA: 0s - loss: 0.2992 - mae: 0.4481 - mse: 0.2992
89/89 [==============================] - 1s 8ms/step - loss: 0.2647 - mae: 0.4158 - mse: 0.2647 - val_loss: 0.0781 - val_mae: 0.2041 - val_mse: 0.0781
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1026 - mae: 0.2568 - mse: 0.1026
64/89 [====================>.........] - ETA: 0s - loss: 0.0981 - mae: 0.2587 - mse: 0.0981
89/89 [==============================] - 0s 5ms/step - loss: 0.1015 - mae: 0.2647 - mse: 0.1015 - val_loss: 0.0842 - val_mae: 0.2564 - val_mse: 0.0842
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1430 - mae: 0.3244 - mse: 0.1430
64/89 [====================>.........] - ETA: 0s - loss: 0.1575 - mae: 0.3472 - mse: 0.1575
89/89 [==============================] - 0s 5ms/step - loss: 0.1400 - mae: 0.3199 - mse: 0.1400 - val_loss: 0.0576 - val_mae: 0.1650 - val_mse: 0.0576
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1164 - mae: 0.2926 - mse: 0.1164
64/89 [====================>.........] - ETA: 0s - loss: 0.1011 - mae: 0.2778 - mse: 0.1011
89/89 [==============================] - 0s 5ms/step - loss: 0.0865 - mae: 0.2462 - mse: 0.0865 - val_loss: 0.0635 - val_mae: 0.1815 - val_mse: 0.0635
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0871 - mae: 0.2151 - mse: 0.0871
64/89 [====================>.........] - ETA: 0s - loss: 0.0873 - mae: 0.2188 - mse: 0.0873
89/89 [==============================] - 0s 5ms/step - loss: 0.0887 - mae: 0.2197 - mse: 0.0887 - val_loss: 0.0697 - val_mae: 0.1969 - val_mse: 0.0697
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0870 - mae: 0.2086 - mse: 0.0870
64/89 [====================>.........] - ETA: 0s - loss: 0.0962 - mae: 0.2280 - mse: 0.0962
89/89 [==============================] - 0s 5ms/step - loss: 0.0839 - mae: 0.2119 - mse: 0.0839 - val_loss: 0.0536 - val_mae: 0.1594 - val_mse: 0.0536
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0631 - mae: 0.1874 - mse: 0.0631
64/89 [====================>.........] - ETA: 0s - loss: 0.0623 - mae: 0.1843 - mse: 0.0623
89/89 [==============================] - 0s 5ms/step - loss: 0.0666 - mae: 0.1912 - mse: 0.0666 - val_loss: 0.0383 - val_mae: 0.1339 - val_mse: 0.0383
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0530 - mae: 0.1922 - mse: 0.0530
64/89 [====================>.........] - ETA: 0s - loss: 0.0570 - mae: 0.2061 - mse: 0.0570
89/89 [==============================] - 0s 5ms/step - loss: 0.0650 - mae: 0.2223 - mse: 0.0650 - val_loss: 0.0375 - val_mae: 0.1617 - val_mse: 0.0375
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0641 - mae: 0.2099 - mse: 0.0641
64/89 [====================>.........] - ETA: 0s - loss: 0.0557 - mae: 0.1947 - mse: 0.0557
89/89 [==============================] - 0s 5ms/step - loss: 0.0560 - mae: 0.2001 - mse: 0.0560 - val_loss: 0.0339 - val_mae: 0.1343 - val_mse: 0.0339
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0639 - mae: 0.2153 - mse: 0.0639
64/89 [====================>.........] - ETA: 0s - loss: 0.0482 - mae: 0.1812 - mse: 0.0482
89/89 [==============================] - 0s 5ms/step - loss: 0.0524 - mae: 0.1855 - mse: 0.0524 - val_loss: 0.0357 - val_mae: 0.1163 - val_mse: 0.0357
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0648 - mae: 0.2007 - mse: 0.0648
64/89 [====================>.........] - ETA: 0s - loss: 0.0530 - mae: 0.1770 - mse: 0.0530
89/89 [==============================] - 0s 5ms/step - loss: 0.0497 - mae: 0.1699 - mse: 0.0497 - val_loss: 0.0334 - val_mae: 0.1138 - val_mse: 0.0334
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0637 - mae: 0.1993 - mse: 0.0637
64/89 [====================>.........] - ETA: 0s - loss: 0.0429 - mae: 0.1590 - mse: 0.0429
89/89 [==============================] - 0s 5ms/step - loss: 0.0442 - mae: 0.1628 - mse: 0.0442 - val_loss: 0.0274 - val_mae: 0.1277 - val_mse: 0.0274
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0358 - mae: 0.1528 - mse: 0.0358
64/89 [====================>.........] - ETA: 0s - loss: 0.0396 - mae: 0.1555 - mse: 0.0396
89/89 [==============================] - 0s 5ms/step - loss: 0.0391 - mae: 0.1573 - mse: 0.0391 - val_loss: 0.0258 - val_mae: 0.1384 - val_mse: 0.0258
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0479 - mae: 0.1646 - mse: 0.0479
64/89 [====================>.........] - ETA: 0s - loss: 0.0339 - mae: 0.1394 - mse: 0.0339
89/89 [==============================] - 0s 5ms/step - loss: 0.0361 - mae: 0.1497 - mse: 0.0361 - val_loss: 0.0244 - val_mae: 0.1387 - val_mse: 0.0244
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0482 - mae: 0.1777 - mse: 0.0482
64/89 [====================>.........] - ETA: 0s - loss: 0.0337 - mae: 0.1450 - mse: 0.0337
89/89 [==============================] - 0s 5ms/step - loss: 0.0335 - mae: 0.1430 - mse: 0.0335 - val_loss: 0.0210 - val_mae: 0.1152 - val_mse: 0.0210
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0393 - mae: 0.1589 - mse: 0.0393
64/89 [====================>.........] - ETA: 0s - loss: 0.0347 - mae: 0.1426 - mse: 0.0347
89/89 [==============================] - 0s 5ms/step - loss: 0.0303 - mae: 0.1335 - mse: 0.0303 - val_loss: 0.0214 - val_mae: 0.0919 - val_mse: 0.0214
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0183 - mae: 0.1044 - mse: 0.0183
64/89 [====================>.........] - ETA: 0s - loss: 0.0271 - mae: 0.1273 - mse: 0.0271
89/89 [==============================] - 0s 5ms/step - loss: 0.0280 - mae: 0.1282 - mse: 0.0280 - val_loss: 0.0171 - val_mae: 0.0845 - val_mse: 0.0171
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0338 - mae: 0.1374 - mse: 0.0338
64/89 [====================>.........] - ETA: 0s - loss: 0.0237 - mae: 0.1123 - mse: 0.0237
89/89 [==============================] - 0s 5ms/step - loss: 0.0232 - mae: 0.1132 - mse: 0.0232 - val_loss: 0.0117 - val_mae: 0.0886 - val_mse: 0.0117
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0155 - mae: 0.1021 - mse: 0.0155
64/89 [====================>.........] - ETA: 0s - loss: 0.0180 - mae: 0.1078 - mse: 0.0180
89/89 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.1054 - mse: 0.0169 - val_loss: 0.0095 - val_mae: 0.0764 - val_mse: 0.0095
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0196 - mae: 0.1108 - mse: 0.0196
64/89 [====================>.........] - ETA: 0s - loss: 0.0197 - mae: 0.1115 - mse: 0.0197
89/89 [==============================] - 0s 5ms/step - loss: 0.0200 - mae: 0.1133 - mse: 0.0200 - val_loss: 0.0122 - val_mae: 0.0879 - val_mse: 0.0122
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0108 - mae: 0.0849 - mse: 0.0108
64/89 [====================>.........] - ETA: 0s - loss: 0.0143 - mae: 0.0934 - mse: 0.0143
89/89 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 0.0987 - mse: 0.0163 - val_loss: 0.0178 - val_mae: 0.1071 - val_mse: 0.0178
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0094 - mae: 0.0811 - mse: 0.0094
64/89 [====================>.........] - ETA: 0s - loss: 0.0100 - mae: 0.0822 - mse: 0.0100
89/89 [==============================] - 0s 5ms/step - loss: 0.0123 - mae: 0.0900 - mse: 0.0123 - val_loss: 0.0157 - val_mae: 0.1026 - val_mse: 0.0157
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0140 - mae: 0.0946 - mse: 0.0140
64/89 [====================>.........] - ETA: 0s - loss: 0.0124 - mae: 0.0886 - mse: 0.0124
89/89 [==============================] - 0s 5ms/step - loss: 0.0136 - mae: 0.0861 - mse: 0.0136 - val_loss: 0.0207 - val_mae: 0.1116 - val_mse: 0.0207
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0117 - mae: 0.0784 - mse: 0.0117
64/89 [====================>.........] - ETA: 0s - loss: 0.0125 - mae: 0.0837 - mse: 0.0125
89/89 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0897 - mse: 0.0137 - val_loss: 0.0121 - val_mae: 0.0902 - val_mse: 0.0121
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0226 - mae: 0.1228 - mse: 0.0226
64/89 [====================>.........] - ETA: 0s - loss: 0.0172 - mae: 0.1068 - mse: 0.0172
89/89 [==============================] - 0s 5ms/step - loss: 0.0148 - mae: 0.0978 - mse: 0.0148 - val_loss: 0.0179 - val_mae: 0.1051 - val_mse: 0.0179
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0144 - mae: 0.0909 - mse: 0.0144
64/89 [====================>.........] - ETA: 0s - loss: 0.0119 - mae: 0.0840 - mse: 0.0119
89/89 [==============================] - 0s 5ms/step - loss: 0.0124 - mae: 0.0888 - mse: 0.0124 - val_loss: 0.0219 - val_mae: 0.1172 - val_mse: 0.0219
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0126 - mae: 0.0845 - mse: 0.0126
64/89 [====================>.........] - ETA: 0s - loss: 0.0099 - mae: 0.0782 - mse: 0.0099
89/89 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0814 - mse: 0.0104 - val_loss: 0.0183 - val_mae: 0.1074 - val_mse: 0.0183
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0158 - mae: 0.0987 - mse: 0.0158
64/89 [====================>.........] - ETA: 0s - loss: 0.0124 - mae: 0.0882 - mse: 0.0124
89/89 [==============================] - 0s 5ms/step - loss: 0.0114 - mae: 0.0858 - mse: 0.0114 - val_loss: 0.0121 - val_mae: 0.0897 - val_mse: 0.0121
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0159 - mae: 0.0928 - mse: 0.0159
64/89 [====================>.........] - ETA: 0s - loss: 0.0129 - mae: 0.0840 - mse: 0.0129
89/89 [==============================] - 0s 5ms/step - loss: 0.0136 - mae: 0.0884 - mse: 0.0136 - val_loss: 0.0183 - val_mae: 0.1082 - val_mse: 0.0183
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0149 - mae: 0.0967 - mse: 0.0149
64/89 [====================>.........] - ETA: 0s - loss: 0.0130 - mae: 0.0914 - mse: 0.0130
89/89 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0902 - mse: 0.0127 - val_loss: 0.0144 - val_mae: 0.0954 - val_mse: 0.0144
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         8.24326706 0.         0.        ]
average prediction= [3.5473347]
baseline= 7.7
eachuser= [0. 0. 0. 6. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.3738778432210286
85 -:- nan
60 -:- nan
['train-weight-4.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_4_csi_a4_18.dat
65 42
65 43
1_165_65_4_csi_a4_5.dat
65 45
65 46
65 47
65 48
65 49
1_165_65_4_csi_a4_24.dat
65 51
65 52
65 53
65 54
1_165_65_4_csi_a4_7.dat
65 56
65 57
65 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
65 61
65 62
65 63
65 64
65 65
65 66
65 67
65 68
1_165_65_4_csi_a4_29.dat
65 70
50 71
50 72
50 73
2_165_50_4_csi_a4_13.dat
50 75
50 76
50 77
50 78
2_165_50_4_csi_a4_15.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
2_165_50_4_csi_a4_25.dat
50 97
50 98
50 99
50 100
70 101
1_175_70_4_csi_a4_14.dat
70 103
1_175_70_4_csi_a4_16.dat
70 105
1_175_70_4_csi_a4_8.dat
70 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
70 111
70 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
70 115
1_175_70_4_csi_a4_28.dat
70 117
70 118
70 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
70 122
1_175_70_4_csi_a4_5.dat
70 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
70 127
1_175_70_4_csi_a4_22.dat
70 129
70 130
85 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
85 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
85 142
1_180_85_4_csi_a4_30.dat
85 144
85 145
85 146
85 147
1_180_85_4_csi_a4_20.dat
85 149
85 150
85 151
85 152
85 153
1_180_85_4_csi_a4_29.dat
85 155
85 156
85 157
85 158
85 159
85 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
75 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 75]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.2513 - mae: 0.4099 - mse: 0.2513
64/89 [====================>.........] - ETA: 0s - loss: 0.2210 - mae: 0.3827 - mse: 0.2210
89/89 [==============================] - 1s 8ms/step - loss: 0.2145 - mae: 0.3729 - mse: 0.2145 - val_loss: 0.0509 - val_mae: 0.2021 - val_mse: 0.0509
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1183 - mae: 0.2752 - mse: 0.1183
64/89 [====================>.........] - ETA: 0s - loss: 0.0991 - mae: 0.2541 - mse: 0.0991
89/89 [==============================] - 0s 5ms/step - loss: 0.1059 - mae: 0.2742 - mse: 0.1059 - val_loss: 0.0664 - val_mae: 0.2423 - val_mse: 0.0664
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1470 - mae: 0.3485 - mse: 0.1470
64/89 [====================>.........] - ETA: 0s - loss: 0.1210 - mae: 0.3143 - mse: 0.1210
89/89 [==============================] - 0s 5ms/step - loss: 0.1097 - mae: 0.2985 - mse: 0.1097 - val_loss: 0.0376 - val_mae: 0.1749 - val_mse: 0.0376
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0666 - mae: 0.2368 - mse: 0.0666
64/89 [====================>.........] - ETA: 0s - loss: 0.0765 - mae: 0.2465 - mse: 0.0765
89/89 [==============================] - 0s 5ms/step - loss: 0.0731 - mae: 0.2371 - mse: 0.0731 - val_loss: 0.0302 - val_mae: 0.1316 - val_mse: 0.0302
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0711 - mae: 0.2122 - mse: 0.0711
64/89 [====================>.........] - ETA: 0s - loss: 0.0629 - mae: 0.1917 - mse: 0.0629
89/89 [==============================] - 0s 5ms/step - loss: 0.0645 - mae: 0.1956 - mse: 0.0645 - val_loss: 0.0285 - val_mae: 0.1233 - val_mse: 0.0285
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0496 - mae: 0.1594 - mse: 0.0496
64/89 [====================>.........] - ETA: 0s - loss: 0.0579 - mae: 0.1799 - mse: 0.0579
89/89 [==============================] - 0s 5ms/step - loss: 0.0560 - mae: 0.1822 - mse: 0.0560 - val_loss: 0.0248 - val_mae: 0.1271 - val_mse: 0.0248
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0604 - mae: 0.2012 - mse: 0.0604
64/89 [====================>.........] - ETA: 0s - loss: 0.0569 - mae: 0.1960 - mse: 0.0569
89/89 [==============================] - 0s 5ms/step - loss: 0.0609 - mae: 0.2097 - mse: 0.0609 - val_loss: 0.0244 - val_mae: 0.1416 - val_mse: 0.0244
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0539 - mae: 0.1982 - mse: 0.0539
64/89 [====================>.........] - ETA: 0s - loss: 0.0629 - mae: 0.2140 - mse: 0.0629
89/89 [==============================] - 0s 5ms/step - loss: 0.0556 - mae: 0.1986 - mse: 0.0556 - val_loss: 0.0215 - val_mae: 0.1321 - val_mse: 0.0215
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0570 - mae: 0.2110 - mse: 0.0570
64/89 [====================>.........] - ETA: 0s - loss: 0.0637 - mae: 0.2131 - mse: 0.0637
89/89 [==============================] - 0s 5ms/step - loss: 0.0600 - mae: 0.2035 - mse: 0.0600 - val_loss: 0.0190 - val_mae: 0.1099 - val_mse: 0.0190
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0548 - mae: 0.1856 - mse: 0.0548
64/89 [====================>.........] - ETA: 0s - loss: 0.0619 - mae: 0.1937 - mse: 0.0619
89/89 [==============================] - 0s 5ms/step - loss: 0.0536 - mae: 0.1814 - mse: 0.0536 - val_loss: 0.0162 - val_mae: 0.1044 - val_mse: 0.0162
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0449 - mae: 0.1543 - mse: 0.0449
64/89 [====================>.........] - ETA: 0s - loss: 0.0420 - mae: 0.1582 - mse: 0.0420
89/89 [==============================] - 0s 5ms/step - loss: 0.0391 - mae: 0.1467 - mse: 0.0391 - val_loss: 0.0122 - val_mae: 0.0984 - val_mse: 0.0122
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0460 - mae: 0.1638 - mse: 0.0460
64/89 [====================>.........] - ETA: 0s - loss: 0.0394 - mae: 0.1627 - mse: 0.0394
89/89 [==============================] - 0s 5ms/step - loss: 0.0373 - mae: 0.1537 - mse: 0.0373 - val_loss: 0.0101 - val_mae: 0.0904 - val_mse: 0.0101
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0334 - mae: 0.1413 - mse: 0.0334
64/89 [====================>.........] - ETA: 0s - loss: 0.0372 - mae: 0.1527 - mse: 0.0372
89/89 [==============================] - 0s 5ms/step - loss: 0.0357 - mae: 0.1481 - mse: 0.0357 - val_loss: 0.0071 - val_mae: 0.0801 - val_mse: 0.0071
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0252 - mae: 0.1311 - mse: 0.0252
64/89 [====================>.........] - ETA: 0s - loss: 0.0245 - mae: 0.1211 - mse: 0.0245
89/89 [==============================] - 0s 5ms/step - loss: 0.0244 - mae: 0.1191 - mse: 0.0244 - val_loss: 0.0057 - val_mae: 0.0696 - val_mse: 0.0057
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0307 - mae: 0.1288 - mse: 0.0307
64/89 [====================>.........] - ETA: 0s - loss: 0.0334 - mae: 0.1309 - mse: 0.0334
89/89 [==============================] - 0s 5ms/step - loss: 0.0331 - mae: 0.1296 - mse: 0.0331 - val_loss: 0.0054 - val_mae: 0.0580 - val_mse: 0.0054
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0260 - mae: 0.1271 - mse: 0.0260
64/89 [====================>.........] - ETA: 0s - loss: 0.0315 - mae: 0.1333 - mse: 0.0315
89/89 [==============================] - 0s 5ms/step - loss: 0.0268 - mae: 0.1214 - mse: 0.0268 - val_loss: 0.0042 - val_mae: 0.0500 - val_mse: 0.0042
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0198 - mae: 0.1031 - mse: 0.0198
64/89 [====================>.........] - ETA: 0s - loss: 0.0192 - mae: 0.0995 - mse: 0.0192
89/89 [==============================] - 0s 5ms/step - loss: 0.0222 - mae: 0.1043 - mse: 0.0222 - val_loss: 0.0044 - val_mae: 0.0426 - val_mse: 0.0044
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0181 - mae: 0.0883 - mse: 0.0181
64/89 [====================>.........] - ETA: 0s - loss: 0.0178 - mae: 0.0955 - mse: 0.0178
89/89 [==============================] - 0s 5ms/step - loss: 0.0208 - mae: 0.1026 - mse: 0.0208 - val_loss: 0.0094 - val_mae: 0.0729 - val_mse: 0.0094
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0205 - mae: 0.1079 - mse: 0.0205
64/89 [====================>.........] - ETA: 0s - loss: 0.0170 - mae: 0.0994 - mse: 0.0170
89/89 [==============================] - 0s 5ms/step - loss: 0.0195 - mae: 0.1022 - mse: 0.0195 - val_loss: 0.0059 - val_mae: 0.0589 - val_mse: 0.0059
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0149 - mae: 0.0944 - mse: 0.0149
64/89 [====================>.........] - ETA: 0s - loss: 0.0163 - mae: 0.0892 - mse: 0.0163
89/89 [==============================] - 0s 5ms/step - loss: 0.0156 - mae: 0.0866 - mse: 0.0156 - val_loss: 0.0025 - val_mae: 0.0378 - val_mse: 0.0025
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0161 - mae: 0.0931 - mse: 0.0161
64/89 [====================>.........] - ETA: 0s - loss: 0.0216 - mae: 0.1021 - mse: 0.0216
89/89 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 0.0972 - mse: 0.0191 - val_loss: 0.0120 - val_mae: 0.0914 - val_mse: 0.0120
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0211 - mae: 0.0977 - mse: 0.0211
64/89 [====================>.........] - ETA: 0s - loss: 0.0220 - mae: 0.0965 - mse: 0.0220
89/89 [==============================] - 0s 5ms/step - loss: 0.0236 - mae: 0.1033 - mse: 0.0236 - val_loss: 0.0099 - val_mae: 0.0796 - val_mse: 0.0099
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0112 - mae: 0.0800 - mse: 0.0112
64/89 [====================>.........] - ETA: 0s - loss: 0.0154 - mae: 0.0874 - mse: 0.0154
89/89 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0833 - mse: 0.0132 - val_loss: 0.0016 - val_mae: 0.0324 - val_mse: 0.0016
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0195 - mae: 0.0896 - mse: 0.0195
64/89 [====================>.........] - ETA: 0s - loss: 0.0208 - mae: 0.0947 - mse: 0.0208
89/89 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 0.0951 - mse: 0.0201 - val_loss: 0.0063 - val_mae: 0.0607 - val_mse: 0.0063
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0056 - mae: 0.0551 - mse: 0.0056
64/89 [====================>.........] - ETA: 0s - loss: 0.0071 - mae: 0.0623 - mse: 0.0071
89/89 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0682 - mse: 0.0084 - val_loss: 0.0157 - val_mae: 0.0992 - val_mse: 0.0157
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0349 - mae: 0.1392 - mse: 0.0349
64/89 [====================>.........] - ETA: 0s - loss: 0.0253 - mae: 0.1185 - mse: 0.0253
89/89 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 0.1039 - mse: 0.0210 - val_loss: 0.0070 - val_mae: 0.0646 - val_mse: 0.0070
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0080 - mae: 0.0683 - mse: 0.0080
64/89 [====================>.........] - ETA: 0s - loss: 0.0122 - mae: 0.0756 - mse: 0.0122
89/89 [==============================] - 0s 5ms/step - loss: 0.0123 - mae: 0.0772 - mse: 0.0123 - val_loss: 0.0019 - val_mae: 0.0354 - val_mse: 0.0019
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0104 - mae: 0.0789 - mse: 0.0104
64/89 [====================>.........] - ETA: 0s - loss: 0.0143 - mae: 0.0857 - mse: 0.0143
89/89 [==============================] - 0s 4ms/step - loss: 0.0145 - mae: 0.0892 - mse: 0.0145 - val_loss: 0.0031 - val_mae: 0.0416 - val_mse: 0.0031
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0114 - mae: 0.0807 - mse: 0.0114
64/89 [====================>.........] - ETA: 0s - loss: 0.0083 - mae: 0.0637 - mse: 0.0083
89/89 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0735 - mse: 0.0112 - val_loss: 0.0121 - val_mae: 0.0912 - val_mse: 0.0121
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0124 - mae: 0.0881 - mse: 0.0124
64/89 [====================>.........] - ETA: 0s - loss: 0.0137 - mae: 0.0861 - mse: 0.0137
89/89 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0841 - mse: 0.0138 - val_loss: 0.0084 - val_mae: 0.0758 - val_mse: 0.0084
Saving trained model...
96
Testing...
heightdiff= [0.         0.         0.         3.26128006 0.         0.        ]
average prediction= [3.8499897]
baseline= 5.9
eachuser= [0. 0. 0. 3. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 1.0870933532714844
85 -:- nan
60 -:- nan
['train-weight-4.py', '1']
65 1
65 2
65 3
65 4
65 5
65 6
65 7
65 8
65 9
65 10
65 11
65 12
65 13
65 14
65 15
65 16
65 17
65 18
65 19
65 20
65 21
65 22
65 23
65 24
65 25
65 26
65 27
65 28
65 29
65 30
60 31
60 32
60 33
60 34
60 35
60 36
60 37
60 38
60 39
60 40
1_165_65_4_csi_a4_18.dat
65 42
65 43
1_165_65_4_csi_a4_5.dat
65 45
65 46
65 47
65 48
65 49
1_165_65_4_csi_a4_24.dat
65 51
65 52
65 53
65 54
1_165_65_4_csi_a4_7.dat
65 56
65 57
65 58
1_165_65_4_csi_a4_22.dat
1_165_65_4_csi_a4_19.dat
65 61
65 62
65 63
65 64
65 65
65 66
65 67
65 68
1_165_65_4_csi_a4_29.dat
65 70
50 71
50 72
50 73
2_165_50_4_csi_a4_13.dat
50 75
50 76
50 77
50 78
2_165_50_4_csi_a4_15.dat
50 80
50 81
50 82
50 83
50 84
50 85
50 86
50 87
50 88
50 89
50 90
50 91
50 92
50 93
50 94
50 95
2_165_50_4_csi_a4_25.dat
50 97
50 98
50 99
50 100
70 101
1_175_70_4_csi_a4_14.dat
70 103
1_175_70_4_csi_a4_16.dat
70 105
1_175_70_4_csi_a4_8.dat
70 107
1_175_70_4_csi_a4_10.dat
1_175_70_4_csi_a4_17.dat
1_175_70_4_csi_a4_18.dat
70 111
70 112
1_175_70_4_csi_a4_1.dat
1_175_70_4_csi_a4_11.dat
70 115
1_175_70_4_csi_a4_28.dat
70 117
70 118
70 119
1_175_70_4_csi_a4_3.dat
1_175_70_4_csi_a4_29.dat
70 122
1_175_70_4_csi_a4_5.dat
70 124
1_175_70_4_csi_a4_30.dat
1_175_70_4_csi_a4_24.dat
70 127
1_175_70_4_csi_a4_22.dat
70 129
70 130
85 131
1_180_85_4_csi_a4_23.dat
1_180_85_4_csi_a4_7.dat
1_180_85_4_csi_a4_17.dat
1_180_85_4_csi_a4_24.dat
85 136
1_180_85_4_csi_a4_25.dat
1_180_85_4_csi_a4_21.dat
1_180_85_4_csi_a4_6.dat
1_180_85_4_csi_a4_11.dat
1_180_85_4_csi_a4_19.dat
85 142
1_180_85_4_csi_a4_30.dat
85 144
85 145
85 146
85 147
1_180_85_4_csi_a4_20.dat
85 149
85 150
85 151
85 152
85 153
1_180_85_4_csi_a4_29.dat
85 155
85 156
85 157
85 158
85 159
85 160
1_180_75_4_csi_a4_12.dat
1_180_75_4_csi_a4_27.dat
1_180_75_4_csi_a4_1.dat
1_180_75_4_csi_a4_30.dat
1_180_75_4_csi_a4_24.dat
1_180_75_4_csi_a4_26.dat
1_180_75_4_csi_a4_22.dat
1_180_75_4_csi_a4_29.dat
75 169
1_180_75_4_csi_a4_10.dat
1_180_75_4_csi_a4_19.dat
1_180_75_4_csi_a4_7.dat
1_180_75_4_csi_a4_11.dat
1_180_75_4_csi_a4_4.dat
1_180_75_4_csi_a4_3.dat
1_180_75_4_csi_a4_5.dat
1_180_75_4_csi_a4_28.dat
1_180_75_4_csi_a4_23.dat
1_180_75_4_csi_a4_9.dat
1_180_75_4_csi_a4_18.dat
1_180_75_4_csi_a4_16.dat
1_180_75_4_csi_a4_20.dat
1_180_75_4_csi_a4_8.dat
1_180_75_4_csi_a4_6.dat
1_180_75_4_csi_a4_17.dat
1_180_75_4_csi_a4_14.dat
1_180_75_4_csi_a4_15.dat
1_180_75_4_csi_a4_25.dat
1_180_75_4_csi_a4_21.dat
1_180_75_4_csi_a4_13.dat
1_173_85_4_csi_a4_25.dat
1_173_85_4_csi_a4_29.dat
1_173_85_4_csi_a4_3.dat
1_173_85_4_csi_a4_18.dat
1_173_85_4_csi_a4_4.dat
1_173_85_4_csi_a4_22.dat
1_173_85_4_csi_a4_28.dat
1_173_85_4_csi_a4_16.dat
1_173_85_4_csi_a4_2.dat
1_173_85_4_csi_a4_17.dat
1_173_85_4_csi_a4_20.dat
1_173_85_4_csi_a4_5.dat
1_173_85_4_csi_a4_19.dat
1_173_85_4_csi_a4_13.dat
1_173_85_4_csi_a4_23.dat
1_173_85_4_csi_a4_15.dat
1_173_85_4_csi_a4_14.dat
1_173_85_4_csi_a4_26.dat
1_173_85_4_csi_a4_7.dat
1_173_85_4_csi_a4_9.dat
1_173_85_4_csi_a4_10.dat
1_173_85_4_csi_a4_12.dat
1_173_85_4_csi_a4_1.dat
1_173_85_4_csi_a4_30.dat
1_173_85_4_csi_a4_27.dat
1_173_85_4_csi_a4_24.dat
1_173_85_4_csi_a4_6.dat
1_173_85_4_csi_a4_21.dat
1_173_85_4_csi_a4_8.dat
1_173_85_4_csi_a4_11.dat
(124, 30, 3)
(124, 375, 30, 3)
[65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 60 60 60 60 60 60 60 60 60 60 65 65 65 65 65 65 65 65
 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 50 50 50 50 50 50 50 50 50
 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 50 70 70 70 70 70 70
 70 70 70 70 70 70 70 70 70 85 85 85 85 85 85 85 85 85 85 85 85 85 85 85
 85 85 85 75]
(124, 375, 30, 3, 1)

Loaded dataset of 124 samples, each sized (375, 30, 3, 1)


Train on 99 samples
Test on 25 samples

Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
name_model_input (InputLayer (None, 375, 30, 3, 1)     0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 375, 28, 1, 16)    160       
_________________________________________________________________
time_distributed_2 (TimeDist (None, 375, 14, 1, 16)    0         
_________________________________________________________________
time_distributed_3 (TimeDist (None, 375, 224)          0         
_________________________________________________________________
time_distributed_4 (TimeDist (None, 375, 64)           14400     
_________________________________________________________________
time_distributed_5 (TimeDist (None, 375, 64)           0         
_________________________________________________________________
time_distributed_6 (TimeDist (None, 375, 64)           4160      
_________________________________________________________________
gru_1 (GRU)                  (None, 128)               74112     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
name_model_output (Dense)    (None, 1)                 129       
=================================================================
Total params: 92,961
Trainable params: 92,961
Non-trainable params: 0
_________________________________________________________________
Train on 89 samples, validate on 10 samples
Epoch 1/30

32/89 [=========>....................] - ETA: 0s - loss: 0.3191 - mae: 0.4672 - mse: 0.3191
64/89 [====================>.........] - ETA: 0s - loss: 0.2563 - mae: 0.4195 - mse: 0.2563
89/89 [==============================] - 1s 8ms/step - loss: 0.2088 - mae: 0.3745 - mse: 0.2088 - val_loss: 0.1562 - val_mae: 0.3550 - val_mse: 0.1562
Epoch 2/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1353 - mae: 0.2881 - mse: 0.1353
64/89 [====================>.........] - ETA: 0s - loss: 0.1479 - mae: 0.3090 - mse: 0.1479
89/89 [==============================] - 0s 5ms/step - loss: 0.1322 - mae: 0.2875 - mse: 0.1322 - val_loss: 0.1241 - val_mae: 0.3283 - val_mse: 0.1241
Epoch 3/30

32/89 [=========>....................] - ETA: 0s - loss: 0.1108 - mae: 0.2626 - mse: 0.1108
64/89 [====================>.........] - ETA: 0s - loss: 0.0976 - mae: 0.2407 - mse: 0.0976
89/89 [==============================] - 0s 5ms/step - loss: 0.0996 - mae: 0.2465 - mse: 0.0996 - val_loss: 0.0732 - val_mae: 0.2492 - val_mse: 0.0732
Epoch 4/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0873 - mae: 0.2471 - mse: 0.0873
64/89 [====================>.........] - ETA: 0s - loss: 0.0753 - mae: 0.2254 - mse: 0.0753
89/89 [==============================] - 0s 5ms/step - loss: 0.0748 - mae: 0.2183 - mse: 0.0748 - val_loss: 0.0582 - val_mae: 0.2187 - val_mse: 0.0582
Epoch 5/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0688 - mae: 0.2001 - mse: 0.0688
64/89 [====================>.........] - ETA: 0s - loss: 0.0673 - mae: 0.2045 - mse: 0.0673
89/89 [==============================] - 0s 5ms/step - loss: 0.0675 - mae: 0.2119 - mse: 0.0675 - val_loss: 0.0523 - val_mae: 0.2071 - val_mse: 0.0523
Epoch 6/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0532 - mae: 0.1971 - mse: 0.0532
64/89 [====================>.........] - ETA: 0s - loss: 0.0584 - mae: 0.2033 - mse: 0.0584
89/89 [==============================] - 0s 5ms/step - loss: 0.0563 - mae: 0.1954 - mse: 0.0563 - val_loss: 0.0458 - val_mae: 0.1885 - val_mse: 0.0458
Epoch 7/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0643 - mae: 0.2010 - mse: 0.0643
64/89 [====================>.........] - ETA: 0s - loss: 0.0794 - mae: 0.2288 - mse: 0.0794
89/89 [==============================] - 0s 5ms/step - loss: 0.0641 - mae: 0.1973 - mse: 0.0641 - val_loss: 0.0380 - val_mae: 0.1667 - val_mse: 0.0380
Epoch 8/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0631 - mae: 0.2042 - mse: 0.0631
64/89 [====================>.........] - ETA: 0s - loss: 0.0554 - mae: 0.1940 - mse: 0.0554
89/89 [==============================] - 0s 5ms/step - loss: 0.0578 - mae: 0.1948 - mse: 0.0578 - val_loss: 0.0298 - val_mae: 0.1379 - val_mse: 0.0298
Epoch 9/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0408 - mae: 0.1600 - mse: 0.0408
64/89 [====================>.........] - ETA: 0s - loss: 0.0422 - mae: 0.1543 - mse: 0.0422
89/89 [==============================] - 0s 5ms/step - loss: 0.0484 - mae: 0.1627 - mse: 0.0484 - val_loss: 0.0201 - val_mae: 0.1046 - val_mse: 0.0201
Epoch 10/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0577 - mae: 0.1673 - mse: 0.0577
64/89 [====================>.........] - ETA: 0s - loss: 0.0458 - mae: 0.1554 - mse: 0.0458
89/89 [==============================] - 0s 5ms/step - loss: 0.0437 - mae: 0.1514 - mse: 0.0437 - val_loss: 0.0097 - val_mae: 0.0732 - val_mse: 0.0097
Epoch 11/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0543 - mae: 0.1549 - mse: 0.0543
64/89 [====================>.........] - ETA: 0s - loss: 0.0488 - mae: 0.1598 - mse: 0.0488
89/89 [==============================] - 0s 5ms/step - loss: 0.0449 - mae: 0.1569 - mse: 0.0449 - val_loss: 0.0042 - val_mae: 0.0488 - val_mse: 0.0042
Epoch 12/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0224 - mae: 0.1006 - mse: 0.0224
64/89 [====================>.........] - ETA: 0s - loss: 0.0237 - mae: 0.1086 - mse: 0.0237
89/89 [==============================] - 0s 5ms/step - loss: 0.0332 - mae: 0.1296 - mse: 0.0332 - val_loss: 0.0029 - val_mae: 0.0515 - val_mse: 0.0029
Epoch 13/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0430 - mae: 0.1518 - mse: 0.0430
64/89 [====================>.........] - ETA: 0s - loss: 0.0363 - mae: 0.1323 - mse: 0.0363
89/89 [==============================] - 0s 5ms/step - loss: 0.0322 - mae: 0.1229 - mse: 0.0322 - val_loss: 0.0023 - val_mae: 0.0431 - val_mse: 0.0023
Epoch 14/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0407 - mae: 0.1358 - mse: 0.0407
64/89 [====================>.........] - ETA: 0s - loss: 0.0466 - mae: 0.1356 - mse: 0.0466
89/89 [==============================] - 0s 5ms/step - loss: 0.0412 - mae: 0.1347 - mse: 0.0412 - val_loss: 0.0020 - val_mae: 0.0402 - val_mse: 0.0020
Epoch 15/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0250 - mae: 0.1222 - mse: 0.0250
64/89 [====================>.........] - ETA: 0s - loss: 0.0352 - mae: 0.1341 - mse: 0.0352
89/89 [==============================] - 0s 5ms/step - loss: 0.0329 - mae: 0.1327 - mse: 0.0329 - val_loss: 0.0026 - val_mae: 0.0414 - val_mse: 0.0026
Epoch 16/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0392 - mae: 0.1472 - mse: 0.0392
64/89 [====================>.........] - ETA: 0s - loss: 0.0327 - mae: 0.1364 - mse: 0.0327
89/89 [==============================] - 0s 5ms/step - loss: 0.0328 - mae: 0.1351 - mse: 0.0328 - val_loss: 0.0026 - val_mae: 0.0319 - val_mse: 0.0026
Epoch 17/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0171 - mae: 0.0908 - mse: 0.0171
64/89 [====================>.........] - ETA: 0s - loss: 0.0186 - mae: 0.0998 - mse: 0.0186
89/89 [==============================] - 0s 5ms/step - loss: 0.0191 - mae: 0.1002 - mse: 0.0191 - val_loss: 0.0038 - val_mae: 0.0368 - val_mse: 0.0038
Epoch 18/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0271 - mae: 0.1083 - mse: 0.0271
64/89 [====================>.........] - ETA: 0s - loss: 0.0244 - mae: 0.1098 - mse: 0.0244
89/89 [==============================] - 0s 5ms/step - loss: 0.0306 - mae: 0.1219 - mse: 0.0306 - val_loss: 0.0051 - val_mae: 0.0508 - val_mse: 0.0051
Epoch 19/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0308 - mae: 0.1175 - mse: 0.0308
64/89 [====================>.........] - ETA: 0s - loss: 0.0281 - mae: 0.1154 - mse: 0.0281
89/89 [==============================] - 0s 5ms/step - loss: 0.0282 - mae: 0.1160 - mse: 0.0282 - val_loss: 0.0045 - val_mae: 0.0478 - val_mse: 0.0045
Epoch 20/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0206 - mae: 0.1049 - mse: 0.0206
64/89 [====================>.........] - ETA: 0s - loss: 0.0225 - mae: 0.1121 - mse: 0.0225
89/89 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 0.1009 - mse: 0.0189 - val_loss: 0.0038 - val_mae: 0.0400 - val_mse: 0.0038
Epoch 21/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0216 - mae: 0.1164 - mse: 0.0216
64/89 [====================>.........] - ETA: 0s - loss: 0.0210 - mae: 0.1122 - mse: 0.0210
89/89 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.1040 - mse: 0.0190 - val_loss: 0.0046 - val_mae: 0.0481 - val_mse: 0.0046
Epoch 22/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0185 - mae: 0.1031 - mse: 0.0185
64/89 [====================>.........] - ETA: 0s - loss: 0.0236 - mae: 0.1080 - mse: 0.0236
89/89 [==============================] - 0s 4ms/step - loss: 0.0227 - mae: 0.1063 - mse: 0.0227 - val_loss: 0.0045 - val_mae: 0.0471 - val_mse: 0.0045
Epoch 23/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0219 - mae: 0.1045 - mse: 0.0219
64/89 [====================>.........] - ETA: 0s - loss: 0.0226 - mae: 0.1067 - mse: 0.0226
89/89 [==============================] - 0s 4ms/step - loss: 0.0244 - mae: 0.1136 - mse: 0.0244 - val_loss: 0.0034 - val_mae: 0.0465 - val_mse: 0.0034
Epoch 24/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0148 - mae: 0.0931 - mse: 0.0148
64/89 [====================>.........] - ETA: 0s - loss: 0.0154 - mae: 0.0950 - mse: 0.0154
89/89 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0996 - mse: 0.0180 - val_loss: 0.0041 - val_mae: 0.0473 - val_mse: 0.0041
Epoch 25/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0178 - mae: 0.0977 - mse: 0.0178
64/89 [====================>.........] - ETA: 0s - loss: 0.0150 - mae: 0.0832 - mse: 0.0150
89/89 [==============================] - 0s 4ms/step - loss: 0.0130 - mae: 0.0778 - mse: 0.0130 - val_loss: 0.0048 - val_mae: 0.0519 - val_mse: 0.0048
Epoch 26/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0145 - mae: 0.0975 - mse: 0.0145
64/89 [====================>.........] - ETA: 0s - loss: 0.0111 - mae: 0.0821 - mse: 0.0111
89/89 [==============================] - 0s 4ms/step - loss: 0.0113 - mae: 0.0801 - mse: 0.0113 - val_loss: 0.0045 - val_mae: 0.0525 - val_mse: 0.0045
Epoch 27/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0191 - mae: 0.1033 - mse: 0.0191
64/89 [====================>.........] - ETA: 0s - loss: 0.0155 - mae: 0.0894 - mse: 0.0155
89/89 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0987 - mse: 0.0182 - val_loss: 0.0096 - val_mae: 0.0848 - val_mse: 0.0096
Epoch 28/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0098 - mae: 0.0806 - mse: 0.0098
64/89 [====================>.........] - ETA: 0s - loss: 0.0075 - mae: 0.0679 - mse: 0.0075
89/89 [==============================] - 0s 4ms/step - loss: 0.0074 - mae: 0.0686 - mse: 0.0074 - val_loss: 0.0056 - val_mae: 0.0536 - val_mse: 0.0056
Epoch 29/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0098 - mae: 0.0724 - mse: 0.0098
64/89 [====================>.........] - ETA: 0s - loss: 0.0073 - mae: 0.0627 - mse: 0.0073
89/89 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0636 - mse: 0.0077 - val_loss: 0.0089 - val_mae: 0.0641 - val_mse: 0.0089
Epoch 30/30

32/89 [=========>....................] - ETA: 0s - loss: 0.0078 - mae: 0.0672 - mse: 0.0078
64/89 [====================>.........] - ETA: 0s - loss: 0.0089 - mae: 0.0720 - mse: 0.0089
89/89 [==============================] - 0s 4ms/step - loss: 0.0123 - mae: 0.0814 - mse: 0.0123 - val_loss: 0.0078 - val_mae: 0.0649 - val_mse: 0.0078
Saving trained model...
96
Testing...
heightdiff= [0.        0.        0.        3.0274086 0.        0.       ]
average prediction= [2.8628192]
baseline= 8.7
eachuser= [0. 0. 0. 4. 0. 0.]
65 -:- nan
70 -:- nan
75 -:- nan
50 -:- 0.7568521499633789
85 -:- nan
60 -:- nan
